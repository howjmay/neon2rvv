#include <assert.h>
#include <float.h>
#include <inttypes.h>
#include <math.h>
#include <stdalign.h>
#include <stdint.h>
#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <utility>

#include "binding.h"
#include "impl.h"

// Try 10,000 random floating point values for each test we run
#define MAX_TEST_VALUE 10000

// This program a set of unit tests to ensure that each NEON call provide the
// output we expect.  If this fires an assert, then something didn't match up.
//
// Functions with "test_" prefix will be called in run_single_test.
namespace NEON2RVV {

#if defined(__riscv_v_elen)
#define REGISTER_SIZE __riscv_v_elen
#elif defined(__aarch64__)
#define REGISTER_SIZE 128
#endif

class NEON2RVV_TEST_IMPL : public NEON2RVV_TEST {
 public:
  NEON2RVV_TEST_IMPL(void) {
    test_cases_float_pointer1 = (float *)platform_aligned_alloc(REGISTER_SIZE);
    test_cases_float_pointer2 = (float *)platform_aligned_alloc(REGISTER_SIZE);
    test_cases_float_pointer3 = (float *)platform_aligned_alloc(REGISTER_SIZE);
    test_cases_float_pointer4 = (float *)platform_aligned_alloc(REGISTER_SIZE);
    test_cases_int_pointer1 = (int32_t *)platform_aligned_alloc(REGISTER_SIZE);
    test_cases_int_pointer2 = (int32_t *)platform_aligned_alloc(REGISTER_SIZE);
    test_cases_int_pointer3 = (int32_t *)platform_aligned_alloc(REGISTER_SIZE);
    test_cases_int_pointer4 = (int32_t *)platform_aligned_alloc(REGISTER_SIZE);
    srand(0);
    for (uint32_t i = 0; i < MAX_TEST_VALUE; i++) {
      test_cases_floats[i] = ranf(-100000, 100000);
      test_cases_ints[i] = (int32_t)ranf(-100000, 100000);
    }
  }
  float *test_cases_float_pointer1;
  float *test_cases_float_pointer2;
  float *test_cases_float_pointer3;
  float *test_cases_float_pointer4;
  int32_t *test_cases_int_pointer1;
  int32_t *test_cases_int_pointer2;
  int32_t *test_cases_int_pointer3;
  int32_t *test_cases_int_pointer4;
  float test_cases_floats[MAX_TEST_VALUE];
  int32_t test_cases_ints[MAX_TEST_VALUE];

  virtual ~NEON2RVV_TEST_IMPL(void) {
    platform_aligned_free(test_cases_float_pointer1);
    platform_aligned_free(test_cases_float_pointer2);
    platform_aligned_free(test_cases_float_pointer3);
    platform_aligned_free(test_cases_float_pointer4);
    platform_aligned_free(test_cases_int_pointer1);
    platform_aligned_free(test_cases_int_pointer2);
    platform_aligned_free(test_cases_int_pointer3);
    platform_aligned_free(test_cases_int_pointer4);
  }

  void load_test_float_pointers(uint32_t iter) {
    for (int i = 0; i < 4; i++) {
      test_cases_float_pointer1[i] = test_cases_floats[iter + i];
      test_cases_float_pointer2[i] = test_cases_floats[iter + i + 4];
      test_cases_float_pointer3[i] = test_cases_floats[iter + i + 8];
      test_cases_float_pointer4[i] = test_cases_floats[iter + i + 12];
    }
  }
  void load_test_int_pointers(uint32_t iter) {
    for (int i = 0; i < 4; i++) {
      test_cases_int_pointer1[i] = test_cases_ints[iter + i];
      test_cases_int_pointer2[i] = test_cases_ints[iter + i + 4];
      test_cases_int_pointer3[i] = test_cases_ints[iter + i + 8];
      test_cases_int_pointer4[i] = test_cases_ints[iter + i + 12];
    }
  }
  result_t run_single_test(INSTRUCTION_TEST test, uint32_t iter);

  virtual void release(void) { delete this; }
  virtual result_t run_test(INSTRUCTION_TEST test) {
    result_t ret = TEST_SUCCESS;

    // Test a whole bunch of values
    for (uint32_t i = 0; i < (MAX_TEST_VALUE - 16); i++) {
      load_test_float_pointers(i);  // Load some random float values
      load_test_int_pointers(i);    // load some random int values

      // If we are testing the reciprocal, then invert the input data
      // (easier for debugging)
      if (test == it_vrecps_f32 || test == it_vrecpsq_f32 || test == it_vrecpe_f32 || test == it_vrecpe_u32 ||
          test == it_vrecpeq_f32 || test == it_vrecpeq_u32) {
        test_cases_float_pointer1[0] = 1.0f / test_cases_float_pointer1[0];
        test_cases_float_pointer1[1] = 1.0f / test_cases_float_pointer1[1];
        test_cases_float_pointer1[2] = 1.0f / test_cases_float_pointer1[2];
        test_cases_float_pointer1[3] = 1.0f / test_cases_float_pointer1[3];
      }
      if (test == it_vrecps_f32 || test == it_vrecpsq_f32 || test == it_vrecpe_f32 || test == it_vrecpe_u32 ||
          test == it_vrecpeq_f32 || test == it_vrecpeq_u32 || test == it_vrsqrts_f32 || test == it_vrsqrtsq_f32 ||
          test == it_vrsqrte_f32 || test == it_vrsqrte_u32 || test == it_vrsqrteq_f32 || test == it_vrsqrteq_u32) {
        if ((rand() & 3) == 0) {
          uint32_t r1 = rand() & 3;
          uint32_t r2 = rand() & 3;
          uint32_t r3 = rand() & 3;
          uint32_t r4 = rand() & 3;
          uint32_t r5 = rand() & 3;
          uint32_t r6 = rand() & 3;
          uint32_t r7 = rand() & 3;
          uint32_t r8 = rand() & 3;
          test_cases_float_pointer1[r1] = 0.0f;
          test_cases_float_pointer1[r2] = 0.0f;
          test_cases_float_pointer1[r3] = 0.0f;
          test_cases_float_pointer1[r4] = 0.0f;
          test_cases_float_pointer1[r5] = -0.0f;
          test_cases_float_pointer1[r6] = -0.0f;
          test_cases_float_pointer1[r7] = -0.0f;
          test_cases_float_pointer1[r8] = -0.0f;
        }
      }
      if (test == it_vceq_s8 || test == it_vceq_s16 || test == it_vceq_s32 || test == it_vceq_f32 ||
          test == it_vceq_u8 || test == it_vceq_u16 || test == it_vceq_u32 || test == it_vceqq_s8 ||
          test == it_vceqq_s16 || test == it_vceqq_s32 || test == it_vceqq_f32 || test == it_vceqq_u8 ||
          test == it_vceqq_u16 || test == it_vceqq_u32 || test == it_vcge_s8 || test == it_vcge_s16 ||
          test == it_vcge_s32 || test == it_vcge_f32 || test == it_vcge_u8 || test == it_vcge_u16 ||
          test == it_vcge_u32 || test == it_vcgeq_s8 || test == it_vcgeq_s16 || test == it_vcgeq_s32 ||
          test == it_vcgeq_f32 || test == it_vcgeq_u8 || test == it_vcgeq_u16 || test == it_vcgeq_u32 ||
          test == it_vcle_s8 || test == it_vcle_s16 || test == it_vcle_s32 || test == it_vcle_f32 ||
          test == it_vcle_u8 || test == it_vcle_u16 || test == it_vcle_u32 || test == it_vcleq_s8 ||
          test == it_vcleq_s16 || test == it_vcleq_s32 || test == it_vcleq_f32 || test == it_vcleq_u8 ||
          test == it_vcleq_u16 || test == it_vcleq_u32) {
        // Make sure at least one value is the same.
        test_cases_float_pointer1[3] = test_cases_float_pointer2[3];
        test_cases_float_pointer1[3] = test_cases_float_pointer3[3];
      }

      if (test == it_vceq_s8 || test == it_vceq_s16 || test == it_vceq_s32 || test == it_vceq_f32 ||
          test == it_vceq_u8 || test == it_vceq_u16 || test == it_vceq_u32 || test == it_vceqq_s8 ||
          test == it_vceqq_s16 || test == it_vceqq_s32 || test == it_vceqq_f32 || test == it_vceqq_u8 ||
          test == it_vceqq_u16 || test == it_vceqq_u32 || test == it_vcge_s8 || test == it_vcge_s16 ||
          test == it_vcge_s32 || test == it_vcge_f32 || test == it_vcge_u8 || test == it_vcge_u16 ||
          test == it_vcge_u32 || test == it_vcgeq_s8 || test == it_vcgeq_s16 || test == it_vcgeq_s32 ||
          test == it_vcgeq_f32 || test == it_vcgeq_u8 || test == it_vcgeq_u16 || test == it_vcgeq_u32 ||
          test == it_vcle_s8 || test == it_vcle_s16 || test == it_vcle_s32 || test == it_vcle_f32 ||
          test == it_vcle_u8 || test == it_vcle_u16 || test == it_vcle_u32 || test == it_vcleq_s8 ||
          test == it_vcleq_s16 || test == it_vcleq_s32 || test == it_vcleq_f32 || test == it_vcleq_u8 ||
          test == it_vcleq_u16 || test == it_vcleq_u32 || test == it_vcgt_s8 || test == it_vcgt_s16 ||
          test == it_vcgt_s32 || test == it_vcgt_f32 || test == it_vcgt_u8 || test == it_vcgt_u16 ||
          test == it_vcgt_u32 || test == it_vcgtq_s8 || test == it_vcgtq_s16 || test == it_vcgtq_s32 ||
          test == it_vcgtq_f32 || test == it_vcgtq_u8 || test == it_vcgtq_u16 || test == it_vcgtq_u32 ||
          test == it_vclt_s8 || test == it_vclt_s16 || test == it_vclt_s32 || test == it_vclt_f32 ||
          test == it_vclt_u8 || test == it_vclt_u16 || test == it_vclt_u32 || test == it_vcltq_s8 ||
          test == it_vcltq_s16 || test == it_vcltq_s32 || test == it_vcltq_f32 || test == it_vcltq_u8 ||
          test == it_vcltq_u16 || test == it_vcltq_u32) {
        // Make sure the NaN values are included in the testing
        // one out of four times.
        if ((rand() & 3) == 0) {
          uint32_t r1 = rand() & 3;
          uint32_t r2 = rand() & 3;
          uint32_t r3 = rand() & 3;
          test_cases_float_pointer1[r1] = nanf("");
          test_cases_float_pointer2[r2] = nanf("");
          test_cases_float_pointer3[r3] = nanf("");
        }
      }

      if (test == it_vmax_s8 || test == it_vmax_s16 || test == it_vmax_s32 || test == it_vmax_f32 ||
          test == it_vmax_u8 || test == it_vmax_u16 || test == it_vmax_u32 || test == it_vpmax_s8 ||
          test == it_vpmax_s16 || test == it_vpmax_s32 || test == it_vpmax_f32 || test == it_vpmax_u8 ||
          test == it_vpmax_u16 || test == it_vpmax_u32 || test == it_vminnm_f32 || test == it_vminnmq_f32 ||
          test == it_vmin_s8 || test == it_vmin_s16 || test == it_vmin_s32 || test == it_vmin_f32 ||
          test == it_vmin_u8 || test == it_vmin_u16 || test == it_vmin_u32 || test == it_vminq_s8 ||
          test == it_vminq_s16 || test == it_vminq_s32 || test == it_vminq_f32 || test == it_vminq_u8 ||
          test == it_vminq_u16 || test == it_vminq_u32) {
        // Make sure the positive/negative infinity values are included
        // in the testing one out of four times.
        if ((rand() & 3) == 0) {
          uint32_t r1 = ((rand() & 1) << 1) + 1;
          uint32_t r2 = ((rand() & 1) << 1) + 1;
          uint32_t r3 = ((rand() & 1) << 1) + 1;
          uint32_t r4 = ((rand() & 1) << 1) + 1;
          uint32_t r5 = ((rand() & 1) << 1) + 1;
          uint32_t r6 = ((rand() & 1) << 1) + 1;
          test_cases_float_pointer1[r1] = INFINITY;
          test_cases_float_pointer2[r2] = INFINITY;
          test_cases_float_pointer3[r3] = INFINITY;
          test_cases_float_pointer1[r4] = -INFINITY;
          test_cases_float_pointer2[r5] = -INFINITY;
          test_cases_float_pointer3[r6] = -INFINITY;
        }
      }

      // one out of every random 64 times or so, mix up the test floats to
      // contain some integer values
      if ((rand() & 63) == 0) {
        uint32_t option = rand() & 3;
        switch (option) {
          // All integers..
          case 0:
            test_cases_float_pointer1[0] = float(test_cases_int_pointer1[0]);
            test_cases_float_pointer1[1] = float(test_cases_int_pointer1[1]);
            test_cases_float_pointer1[2] = float(test_cases_int_pointer1[2]);
            test_cases_float_pointer1[3] = float(test_cases_int_pointer1[3]);

            test_cases_float_pointer2[0] = float(test_cases_int_pointer2[0]);
            test_cases_float_pointer2[1] = float(test_cases_int_pointer2[1]);
            test_cases_float_pointer2[2] = float(test_cases_int_pointer2[2]);
            test_cases_float_pointer2[3] = float(test_cases_int_pointer2[3]);

            test_cases_float_pointer3[0] = float(test_cases_int_pointer3[0]);
            test_cases_float_pointer3[1] = float(test_cases_int_pointer3[1]);
            test_cases_float_pointer3[2] = float(test_cases_int_pointer3[2]);
            test_cases_float_pointer3[3] = float(test_cases_int_pointer3[3]);

            break;
          case 1: {
            uint32_t index = rand() & 3;
            test_cases_float_pointer1[index] = float(test_cases_int_pointer1[index]);
            index = rand() & 3;
            test_cases_float_pointer2[index] = float(test_cases_int_pointer2[index]);
            index = rand() & 3;
            test_cases_float_pointer3[index] = float(test_cases_int_pointer3[index]);
          } break;
          case 2: {
            uint32_t index1 = rand() & 3;
            uint32_t index2 = rand() & 3;
            test_cases_float_pointer1[index1] = float(test_cases_int_pointer1[index1]);
            test_cases_float_pointer1[index2] = float(test_cases_int_pointer1[index2]);
            index1 = rand() & 3;
            index2 = rand() & 3;
            test_cases_float_pointer2[index1] = float(test_cases_int_pointer2[index1]);
            test_cases_float_pointer2[index2] = float(test_cases_int_pointer2[index2]);
            index1 = rand() & 3;
            index2 = rand() & 3;
            test_cases_float_pointer3[index1] = float(test_cases_int_pointer3[index1]);
            test_cases_float_pointer3[index2] = float(test_cases_int_pointer3[index2]);
          } break;
          case 3:
            test_cases_float_pointer1[0] = float(test_cases_int_pointer1[0]);
            test_cases_float_pointer1[1] = float(test_cases_int_pointer1[1]);
            test_cases_float_pointer1[2] = float(test_cases_int_pointer1[2]);
            test_cases_float_pointer1[3] = float(test_cases_int_pointer1[3]);
            break;
        }
        if ((rand() & 3) == 0) {  // one out of 4 times, make halves
          for (uint32_t j = 0; j < 4; j++) {
            test_cases_float_pointer1[j] *= 0.5f;
            test_cases_float_pointer2[j] *= 0.5f;
          }
        }
      }

      ret = run_single_test(test, i);
      if (ret != TEST_SUCCESS) {
        break;
      }
    }
    return ret;
  }
};

NEON2RVV_TEST *NEON2RVV_TEST::create(void) {
  NEON2RVV_TEST_IMPL *st = new NEON2RVV_TEST_IMPL;
  return static_cast<NEON2RVV_TEST *>(st);
}

result_t test_vadd_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (int8_t *)impl.test_cases_int_pointer2;
  int8_t _d[8];
  for (int i = 0; i < 8; i++) {
    _d[i] = _a[i] + _b[i];
  }

  int8x8_t a = vld1_s8(_a);
  int8x8_t b = vld1_s8(_b);
  int8x8_t c = vadd_s8(a, b);
  return validate_int8(c, _d[0], _d[1], _d[2], _d[3], _d[4], _d[5], _d[6], _d[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vadd_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  int16_t _d[4];
  for (int i = 0; i < 4; i++) {
    _d[i] = _a[i] + _b[i];
  }

  int16x4_t a = vld1_s16(_a);
  int16x4_t b = vld1_s16(_b);
  int16x4_t c = vadd_s16(a, b);
  return validate_int16(c, _d[0], _d[1], _d[2], _d[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vadd_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  int32_t d0 = _a[0] + _b[0];
  int32_t d1 = _a[1] + _b[1];

  int32x2_t a = vld1_s32(_a);
  int32x2_t b = vld1_s32(_b);
  int32x2_t c = vadd_s32(a, b);
  return validate_int32(c, d0, d1);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vadd_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (float *)impl.test_cases_float_pointer1;
  const float *_b = (float *)impl.test_cases_float_pointer2;
  float d0 = _a[0] + _b[0];
  float d1 = _a[1] + _b[1];

  float32x2_t a = vld1_f32(_a);
  float32x2_t b = vld1_f32(_b);
  float32x2_t c = vadd_f32(a, b);
  return validate_float(c, d0, d1);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vadd_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (uint8_t *)impl.test_cases_int_pointer2;
  uint8_t _d[8];
  for (int i = 0; i < 8; i++) {
    _d[i] = _a[i] + _b[i];
  }

  uint8x8_t a = vld1_u8(_a);
  uint8x8_t b = vld1_u8(_b);
  uint8x8_t c = vadd_u8(a, b);
  return validate_uint8(c, _d[0], _d[1], _d[2], _d[3], _d[4], _d[5], _d[6], _d[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vadd_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (uint16_t *)impl.test_cases_int_pointer2;
  uint16_t _d[4];
  for (int i = 0; i < 4; i++) {
    _d[i] = _a[i] + _b[i];
  }

  uint16x4_t a = vld1_u16(_a);
  uint16x4_t b = vld1_u16(_b);
  uint16x4_t c = vadd_u16(a, b);
  return validate_uint16(c, _d[0], _d[1], _d[2], _d[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vadd_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (uint32_t *)impl.test_cases_int_pointer2;
  uint32_t d0 = _a[0] + _b[0];
  uint32_t d1 = _a[1] + _b[1];

  uint32x2_t a = vld1_u32(_a);
  uint32x2_t b = vld1_u32(_b);
  uint32x2_t c = vadd_u32(a, b);
  return validate_uint32(c, d0, d1);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vadd_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (int64_t *)impl.test_cases_int_pointer1;
  const int64_t *_b = (int64_t *)impl.test_cases_int_pointer2;
  int64_t d0 = _a[0] + _b[0];

  int64x1_t a = vld1_s64(_a);
  int64x1_t b = vld1_s64(_b);
  int64x1_t c = vadd_s64(a, b);
  return validate_int64(c, d0);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vadd_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (uint64_t *)impl.test_cases_int_pointer1;
  const uint64_t *_b = (uint64_t *)impl.test_cases_int_pointer2;
  uint64_t d0 = _a[0] + _b[0];

  uint64x1_t a = vld1_u64((const uint64_t *)_a);
  uint64x1_t b = vld1_u64((const uint64_t *)_b);
  uint64x1_t c = vadd_u64(a, b);
  return validate_uint64(c, d0);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vaddq_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (int8_t *)impl.test_cases_int_pointer2;
  int8_t _d[16];
  for (int i = 0; i < 16; i++) {
    _d[i] = _a[i] + _b[i];
  }

  int8x16_t a = vld1q_s8(_a);
  int8x16_t b = vld1q_s8(_b);
  int8x16_t c = vaddq_s8(a, b);
  return validate_int8(c, _d[0], _d[1], _d[2], _d[3], _d[4], _d[5], _d[6], _d[7], _d[8], _d[9], _d[10], _d[11], _d[12],
                       _d[13], _d[14], _d[15]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vaddq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  int16_t _d[8];
  for (int i = 0; i < 8; i++) {
    _d[i] = _a[i] + _b[i];
  }

  int16x8_t a = vld1q_s16(_a);
  int16x8_t b = vld1q_s16(_b);
  int16x8_t c = vaddq_s16(a, b);
  return validate_int16(c, _d[0], _d[1], _d[2], _d[3], _d[4], _d[5], _d[6], _d[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vaddq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  int32_t _d[4];
  for (int i = 0; i < 4; i++) {
    _d[i] = _a[i] + _b[i];
  }

  int32x4_t a = vld1q_s32(_a);
  int32x4_t b = vld1q_s32(_b);
  int32x4_t c = vaddq_s32(a, b);
  return validate_int32(c, _d[0], _d[1], _d[2], _d[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vaddq_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (int64_t *)impl.test_cases_int_pointer1;
  const int64_t *_b = (int64_t *)impl.test_cases_int_pointer2;
  int64_t d0 = _a[0] + _b[0];
  int64_t d1 = _a[1] + _b[1];

  int64x2_t a = vld1q_s64(_a);
  int64x2_t b = vld1q_s64(_b);
  int64x2_t c = vaddq_s64(a, b);
  return validate_int64(c, d0, d1);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vaddq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (float *)impl.test_cases_float_pointer1;
  const float *_b = (float *)impl.test_cases_float_pointer2;
  float _d[4];
  for (int i = 0; i < 4; i++) {
    _d[i] = _a[i] + _b[i];
  }

  float32x4_t a = vld1q_f32(_a);
  float32x4_t b = vld1q_f32(_b);
  float32x4_t c = vaddq_f32(a, b);
  return validate_float(c, _d[0], _d[1], _d[2], _d[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vadd_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const double *_a = (double *)impl.test_cases_float_pointer1;
  const double *_b = (double *)impl.test_cases_float_pointer2;
  double _d[1];
  for (int i = 0; i < 1; i++) {
    _d[i] = _a[i] + _b[i];
  }

  float64x1_t a = vld1_f64(_a);
  float64x1_t b = vld1_f64(_b);
  float64x1_t c = vadd_f64(a, b);
  return validate_double(c, _d[0]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vaddq_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const double *_a = (double *)impl.test_cases_float_pointer1;
  const double *_b = (double *)impl.test_cases_float_pointer2;
  double _d[2];
  for (int i = 0; i < 2; i++) {
    _d[i] = _a[i] + _b[i];
  }

  float64x2_t a = vld1q_f64(_a);
  float64x2_t b = vld1q_f64(_b);
  float64x2_t c = vaddq_f64(a, b);
  return validate_double(c, _d[0], _d[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vaddd_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (int64_t *)impl.test_cases_int_pointer1;
  const int64_t *_b = (int64_t *)impl.test_cases_int_pointer2;
  int64_t d0 = _a[0] + _b[0];

  int64_t c = vaddd_s64(_a[0], _b[0]);
  return c == d0 ? TEST_SUCCESS : TEST_FAIL;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vaddd_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (uint64_t *)impl.test_cases_int_pointer1;
  const uint64_t *_b = (uint64_t *)impl.test_cases_int_pointer2;
  uint64_t d0 = _a[0] + _b[0];

  uint64_t c = vaddd_u64(_a[0], _b[0]);
  return c == d0 ? TEST_SUCCESS : TEST_FAIL;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vaddq_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (uint8_t *)impl.test_cases_int_pointer2;
  uint8_t _d[16];
  for (int i = 0; i < 16; i++) {
    _d[i] = _a[i] + _b[i];
  }

  uint8x16_t a = vld1q_u8(_a);
  uint8x16_t b = vld1q_u8(_b);
  uint8x16_t c = vaddq_u8(a, b);
  return validate_uint8(c, _d[0], _d[1], _d[2], _d[3], _d[4], _d[5], _d[6], _d[7], _d[8], _d[9], _d[10], _d[11], _d[12],
                        _d[13], _d[14], _d[15]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vaddq_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (uint16_t *)impl.test_cases_int_pointer2;
  uint16_t _d[8];
  for (int i = 0; i < 8; i++) {
    _d[i] = _a[i] + _b[i];
  }

  uint16x8_t a = vld1q_u16(_a);
  uint16x8_t b = vld1q_u16(_b);
  uint16x8_t c = vaddq_u16(a, b);
  return validate_uint16(c, _d[0], _d[1], _d[2], _d[3], _d[4], _d[5], _d[6], _d[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vaddq_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (uint32_t *)impl.test_cases_int_pointer2;
  uint32_t _d[4];
  for (int i = 0; i < 4; i++) {
    _d[i] = _a[i] + _b[i];
  }

  uint32x4_t a = vld1q_u32(_a);
  uint32x4_t b = vld1q_u32(_b);
  uint32x4_t c = vaddq_u32(a, b);
  return validate_uint32(c, _d[0], _d[1], _d[2], _d[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vaddq_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (uint64_t *)impl.test_cases_int_pointer1;
  const uint64_t *_b = (uint64_t *)impl.test_cases_int_pointer2;
  uint64_t d0 = _a[0] + _b[0];
  uint64_t d1 = _a[1] + _b[1];

  uint64x2_t a = vld1q_u64(_a);
  uint64x2_t b = vld1q_u64(_b);
  uint64x2_t c = vaddq_u64(a, b);
  return validate_uint64(c, d0, d1);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vaddl_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (int8_t *)impl.test_cases_int_pointer2;
  int16_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = (int16_t)_a[i] + (int16_t)_b[i];
  }

  int8x8_t a = vld1_s8(_a);
  int8x8_t b = vld1_s8(_b);
  int16x8_t c = vaddl_s8(a, b);
  return validate_int16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vaddl_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  int32_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = (int32_t)_a[i] + (int32_t)_b[i];
  }

  int16x4_t a = vld1_s16(_a);
  int16x4_t b = vld1_s16(_b);
  int32x4_t c = vaddl_s16(a, b);
  return validate_int32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vaddl_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  int64_t _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = (int64_t)_a[i] + (int64_t)_b[i];
  }

  int32x2_t a = vld1_s32(_a);
  int32x2_t b = vld1_s32(_b);
  int64x2_t c = vaddl_s32(a, b);
  return validate_int64(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vaddl_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (uint8_t *)impl.test_cases_int_pointer2;
  uint16_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = (uint16_t)_a[i] + (uint16_t)_b[i];
  }

  uint8x8_t a = vld1_u8(_a);
  uint8x8_t b = vld1_u8(_b);
  uint16x8_t c = vaddl_u8(a, b);
  return validate_uint16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vaddl_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (uint16_t *)impl.test_cases_int_pointer2;
  uint32_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = (uint32_t)_a[i] + (uint32_t)_b[i];
  }

  uint16x4_t a = vld1_u16(_a);
  uint16x4_t b = vld1_u16(_b);
  uint32x4_t c = vaddl_u16(a, b);
  return validate_uint32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vaddl_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (uint32_t *)impl.test_cases_int_pointer2;
  uint64_t _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = (uint64_t)_a[i] + (uint64_t)_b[i];
  }

  uint32x2_t a = vld1_u32(_a);
  uint32x2_t b = vld1_u32(_b);
  uint64x2_t c = vaddl_u32(a, b);
  return validate_uint64(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vaddl_high_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (int8_t *)impl.test_cases_int_pointer2;
  int16_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = (int16_t)_a[i + 8] + (int16_t)_b[i + 8];
  }

  int8x16_t a = vld1q_s8(_a);
  int8x16_t b = vld1q_s8(_b);
  int16x8_t c = vaddl_high_s8(a, b);
  return validate_int16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vaddl_high_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  int32_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = (int32_t)_a[i + 4] + (int32_t)_b[i + 4];
  }

  int16x8_t a = vld1q_s16(_a);
  int16x8_t b = vld1q_s16(_b);
  int32x4_t c = vaddl_high_s16(a, b);
  return validate_int32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vaddl_high_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  int64_t _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = (int64_t)_a[i + 2] + (int64_t)_b[i + 2];
  }

  int32x4_t a = vld1q_s32(_a);
  int32x4_t b = vld1q_s32(_b);
  int64x2_t c = vaddl_high_s32(a, b);
  return validate_int64(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vaddl_high_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (uint8_t *)impl.test_cases_int_pointer2;
  uint16_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = (uint16_t)_a[i + 8] + (uint16_t)_b[i + 8];
  }

  uint8x16_t a = vld1q_u8(_a);
  uint8x16_t b = vld1q_u8(_b);
  uint16x8_t c = vaddl_high_u8(a, b);
  return validate_uint16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vaddl_high_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (uint16_t *)impl.test_cases_int_pointer2;
  uint32_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = (uint32_t)_a[i + 4] + (uint32_t)_b[i + 4];
  }

  uint16x8_t a = vld1q_u16(_a);
  uint16x8_t b = vld1q_u16(_b);
  uint32x4_t c = vaddl_high_u16(a, b);
  return validate_uint32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vaddl_high_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (uint32_t *)impl.test_cases_int_pointer2;
  uint64_t _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = (uint64_t)_a[i + 2] + (uint64_t)_b[i + 2];
  }

  uint32x4_t a = vld1q_u32(_a);
  uint32x4_t b = vld1q_u32(_b);
  uint64x2_t c = vaddl_high_u32(a, b);
  return validate_uint64(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vaddw_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (int8_t *)impl.test_cases_int_pointer2;
  int16_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = _a[i] + (int16_t)_b[i];
  }

  int16x8_t a = vld1q_s16(_a);
  int8x8_t b = vld1_s8(_b);
  int16x8_t c = vaddw_s8(a, b);
  return validate_int16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vaddw_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  int32_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = _a[i] + (int32_t)_b[i];
  }

  int32x4_t a = vld1q_s32(_a);
  int16x4_t b = vld1_s16(_b);
  int32x4_t c = vaddw_s16(a, b);
  return validate_int32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vaddw_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (int64_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  int64_t _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = _a[i] + (int64_t)_b[i];
  }

  int64x2_t a = vld1q_s64(_a);
  int32x2_t b = vld1_s32(_b);
  int64x2_t c = vaddw_s32(a, b);
  return validate_int64(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vaddw_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (uint8_t *)impl.test_cases_int_pointer2;
  uint16_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = _a[i] + (uint16_t)_b[i];
  }

  uint16x8_t a = vld1q_u16(_a);
  uint8x8_t b = vld1_u8(_b);
  uint16x8_t c = vaddw_u8(a, b);
  return validate_uint16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vaddw_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (uint16_t *)impl.test_cases_int_pointer2;
  uint32_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = _a[i] + (uint32_t)_b[i];
  }

  uint32x4_t a = vld1q_u32(_a);
  uint16x4_t b = vld1_u16(_b);
  uint32x4_t c = vaddw_u16(a, b);
  return validate_uint32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vaddw_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (uint64_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (uint32_t *)impl.test_cases_int_pointer2;
  uint64_t _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = _a[i] + (uint64_t)_b[i];
  }

  uint64x2_t a = vld1q_u64(_a);
  uint32x2_t b = vld1_u32(_b);
  uint64x2_t c = vaddw_u32(a, b);
  return validate_uint64(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vaddw_high_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (int8_t *)impl.test_cases_int_pointer2;
  int16_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = _a[i] + (int16_t)_b[i + 8];
  }

  int16x8_t a = vld1q_s16(_a);
  int8x16_t b = vld1q_s8(_b);
  int16x8_t c = vaddw_high_s8(a, b);
  return validate_int16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vaddw_high_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  int32_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = _a[i] + (int32_t)_b[i + 4];
  }

  int32x4_t a = vld1q_s32(_a);
  int16x8_t b = vld1q_s16(_b);
  int32x4_t c = vaddw_high_s16(a, b);
  return validate_int32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vaddw_high_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (int64_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  int64_t _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = _a[i] + (int64_t)_b[i + 2];
  }

  int64x2_t a = vld1q_s64(_a);
  int32x4_t b = vld1q_s32(_b);
  int64x2_t c = vaddw_high_s32(a, b);
  return validate_int64(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vaddw_high_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (uint8_t *)impl.test_cases_int_pointer2;
  uint16_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = _a[i] + (uint16_t)_b[i + 8];
  }

  uint16x8_t a = vld1q_u16(_a);
  uint8x16_t b = vld1q_u8(_b);
  uint16x8_t c = vaddw_high_u8(a, b);
  return validate_uint16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vaddw_high_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (uint16_t *)impl.test_cases_int_pointer2;
  uint32_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = _a[i] + (uint32_t)_b[i + 4];
  }

  uint32x4_t a = vld1q_u32(_a);
  uint16x8_t b = vld1q_u16(_b);
  uint32x4_t c = vaddw_high_u16(a, b);
  return validate_uint32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vaddw_high_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (uint64_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (uint32_t *)impl.test_cases_int_pointer2;
  uint64_t _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = _a[i] + (uint64_t)_b[i + 2];
  }

  uint64x2_t a = vld1q_u64(_a);
  uint32x4_t b = vld1q_u32(_b);
  uint64x2_t c = vaddw_high_u32(a, b);
  return validate_uint64(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vhadd_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (const int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (const int8_t *)impl.test_cases_int_pointer2;
  int8_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = (_a[i] + _b[i]) >> 1;
  }

  int8x8_t a = vld1_s8(_a);
  int8x8_t b = vld1_s8(_b);
  int8x8_t c = vhadd_s8(a, b);
  return validate_int8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vhadd_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (const int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (const int16_t *)impl.test_cases_int_pointer2;
  int16_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = (_a[i] + _b[i]) >> 1;
  }

  int16x4_t a = vld1_s16(_a);
  int16x4_t b = vld1_s16(_b);
  int16x4_t c = vhadd_s16(a, b);

  return validate_int16(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vhadd_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (const int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (const int32_t *)impl.test_cases_int_pointer2;
  int32_t _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = (_a[i] + _b[i]) >> 1;
  }

  int32x2_t a = vld1_s32(_a);
  int32x2_t b = vld1_s32(_b);
  int32x2_t c = vhadd_s32(a, b);

  return validate_int32(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vhadd_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (const uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (const uint8_t *)impl.test_cases_int_pointer2;
  uint8_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = (_a[i] + _b[i]) >> 1;
  }

  uint8x8_t a = vld1_u8(_a);
  uint8x8_t b = vld1_u8(_b);
  uint8x8_t c = vhadd_u8(a, b);

  return validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vhadd_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (const uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (const uint16_t *)impl.test_cases_int_pointer2;
  uint16_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = (_a[i] + _b[i]) >> 1;
  }

  uint16x4_t a = vld1_u16(_a);
  uint16x4_t b = vld1_u16(_b);
  uint16x4_t c = vhadd_u16(a, b);

  return validate_uint16(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vhadd_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (const uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (const uint32_t *)impl.test_cases_int_pointer2;
  uint32_t _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = ((uint64_t)_a[i] + (uint64_t)_b[i]) >> 1;
  }

  uint32x2_t a = vld1_u32(_a);
  uint32x2_t b = vld1_u32(_b);
  uint32x2_t c = vhadd_u32(a, b);

  return validate_uint32(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vhaddq_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (const int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (const int8_t *)impl.test_cases_int_pointer2;
  int8_t _c[16];
  for (int i = 0; i < 16; i++) {
    _c[i] = (_a[i] + _b[i]) >> 1;
  }

  int8x16_t a = vld1q_s8(_a);
  int8x16_t b = vld1q_s8(_b);
  int8x16_t c = vhaddq_s8(a, b);
  return validate_int8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7], _c[8], _c[9], _c[10], _c[11], _c[12],
                       _c[13], _c[14], _c[15]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vhaddq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (const int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (const int16_t *)impl.test_cases_int_pointer2;
  int16_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = (_a[i] + _b[i]) >> 1;
  }

  int16x8_t a = vld1q_s16(_a);
  int16x8_t b = vld1q_s16(_b);
  int16x8_t c = vhaddq_s16(a, b);

  return validate_int16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vhaddq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (const int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (const int32_t *)impl.test_cases_int_pointer2;
  int32_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = (_a[i] + _b[i]) >> 1;
  }

  int32x4_t a = vld1q_s32(_a);
  int32x4_t b = vld1q_s32(_b);
  int32x4_t c = vhaddq_s32(a, b);

  return validate_int32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vhaddq_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (const uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (const uint8_t *)impl.test_cases_int_pointer2;
  uint8_t _c[16];
  for (int i = 0; i < 16; i++) {
    _c[i] = (_a[i] + _b[i]) >> 1;
  }

  uint8x16_t a = vld1q_u8(_a);
  uint8x16_t b = vld1q_u8(_b);
  uint8x16_t c = vhaddq_u8(a, b);
  return validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7], _c[8], _c[9], _c[10], _c[11], _c[12],
                        _c[13], _c[14], _c[15]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vhaddq_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (const uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (const uint16_t *)impl.test_cases_int_pointer2;
  uint16_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = (_a[i] + _b[i]) >> 1;
  }

  uint16x8_t a = vld1q_u16(_a);
  uint16x8_t b = vld1q_u16(_b);
  uint16x8_t c = vhaddq_u16(a, b);

  return validate_uint16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vhaddq_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (const uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (const uint32_t *)impl.test_cases_int_pointer2;
  uint32_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = ((uint64_t)_a[i] + (uint64_t)_b[i]) >> 1;
  }

  uint32x4_t a = vld1q_u32(_a);
  uint32x4_t b = vld1q_u32(_b);
  uint32x4_t c = vhaddq_u32(a, b);

  return validate_uint32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrhadd_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (const int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (const int8_t *)impl.test_cases_int_pointer2;
  int8_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = (_a[i] + _b[i] + 1) >> 1;  // equals to add 0.5 which is NEON2RVV_ROUND_TYPE_RNU
  }

  int8x8_t a = vld1_s8(_a);
  int8x8_t b = vld1_s8(_b);
  int8x8_t c = vrhadd_s8(a, b);
  return validate_int8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrhadd_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (const int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (const int16_t *)impl.test_cases_int_pointer2;
  int16_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = (_a[i] + _b[i] + 1) >> 1;  // equals to add 0.5 which is NEON2RVV_ROUND_TYPE_RNU
  }

  int16x4_t a = vld1_s16(_a);
  int16x4_t b = vld1_s16(_b);
  int16x4_t c = vrhadd_s16(a, b);
  return validate_int16(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrhadd_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (const int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (const int32_t *)impl.test_cases_int_pointer2;
  int32_t _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = (_a[i] + _b[i] + 1) >> 1;  // equals to add 0.5 which is NEON2RVV_ROUND_TYPE_RNU
  }

  int32x2_t a = vld1_s32(_a);
  int32x2_t b = vld1_s32(_b);
  int32x2_t c = vrhadd_s32(a, b);
  return validate_int32(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrhadd_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (const uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (const uint8_t *)impl.test_cases_int_pointer2;
  uint8_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = (_a[i] + _b[i] + 1) >> 1;  // equals to add 0.5 which is NEON2RVV_ROUND_TYPE_RNU
  }

  uint8x8_t a = vld1_u8(_a);
  uint8x8_t b = vld1_u8(_b);
  uint8x8_t c = vrhadd_u8(a, b);
  return validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrhadd_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (const uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (const uint16_t *)impl.test_cases_int_pointer2;
  uint16_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = (_a[i] + _b[i] + 1) >> 1;  // equals to add 0.5 which is NEON2RVV_ROUND_TYPE_RNU
  }

  uint16x4_t a = vld1_u16(_a);
  uint16x4_t b = vld1_u16(_b);
  uint16x4_t c = vrhadd_u16(a, b);
  return validate_uint16(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrhadd_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (const uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (const uint32_t *)impl.test_cases_int_pointer2;
  uint32_t _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = ((uint64_t)_a[i] + (uint64_t)_b[i] + 1) >> 1;  // equals to add 0.5 which is NEON2RVV_ROUND_TYPE_RNU
  }

  uint32x2_t a = vld1_u32(_a);
  uint32x2_t b = vld1_u32(_b);
  uint32x2_t c = vrhadd_u32(a, b);
  return validate_uint32(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrhaddq_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (const int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (const int8_t *)impl.test_cases_int_pointer2;
  int8_t _c[16];
  for (int i = 0; i < 16; i++) {
    _c[i] = (_a[i] + _b[i] + 1) >> 1;  // equals to add 0.5 which is NEON2RVV_ROUND_TYPE_RNU
  }

  int8x16_t a = vld1q_s8(_a);
  int8x16_t b = vld1q_s8(_b);
  int8x16_t c = vrhaddq_s8(a, b);
  return validate_int8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7], _c[8], _c[9], _c[10], _c[11], _c[12],
                       _c[13], _c[14], _c[15]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrhaddq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (const int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (const int16_t *)impl.test_cases_int_pointer2;
  int16_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = (_a[i] + _b[i] + 1) >> 1;  // equals to add 0.5 which is NEON2RVV_ROUND_TYPE_RNU
  }

  int16x8_t a = vld1q_s16(_a);
  int16x8_t b = vld1q_s16(_b);
  int16x8_t c = vrhaddq_s16(a, b);
  return validate_int16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrhaddq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (const int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (const int32_t *)impl.test_cases_int_pointer2;
  int32_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = (_a[i] + _b[i] + 1) >> 1;  // equals to add 0.5 which is NEON2RVV_ROUND_TYPE_RNU
  }

  int32x4_t a = vld1q_s32(_a);
  int32x4_t b = vld1q_s32(_b);
  int32x4_t c = vrhaddq_s32(a, b);
  return validate_int32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrhaddq_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (const uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (const uint8_t *)impl.test_cases_int_pointer2;
  uint8_t _c[16];
  for (int i = 0; i < 16; i++) {
    _c[i] = (_a[i] + _b[i] + 1) >> 1;  // equals to add 0.5 which is NEON2RVV_ROUND_TYPE_RNU
  }

  uint8x16_t a = vld1q_u8(_a);
  uint8x16_t b = vld1q_u8(_b);
  uint8x16_t c = vrhaddq_u8(a, b);
  return validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7], _c[8], _c[9], _c[10], _c[11], _c[12],
                        _c[13], _c[14], _c[15]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrhaddq_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (const uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (const uint16_t *)impl.test_cases_int_pointer2;
  uint16_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = (_a[i] + _b[i] + 1) >> 1;  // equals to add 0.5 which is NEON2RVV_ROUND_TYPE_RNU
  }

  uint16x8_t a = vld1q_u16(_a);
  uint16x8_t b = vld1q_u16(_b);
  uint16x8_t c = vrhaddq_u16(a, b);
  return validate_uint16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrhaddq_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (const uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (const uint32_t *)impl.test_cases_int_pointer2;
  uint32_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = ((uint64_t)_a[i] + (uint64_t)_b[i] + 1) >> 1;  // equals to add 0.5 which is NEON2RVV_ROUND_TYPE_RNU
  }

  uint32x4_t a = vld1q_u32(_a);
  uint32x4_t b = vld1q_u32(_b);
  uint32x4_t c = vrhaddq_u32(a, b);
  return validate_uint32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqadd_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (const int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (const int8_t *)impl.test_cases_int_pointer2;
  int8_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = saturate_int8((int16_t)_a[i] + (int16_t)_b[i]);
  }

  int8x8_t a = vld1_s8(_a);
  int8x8_t b = vld1_s8(_b);
  int8x8_t c = vqadd_s8(a, b);
  return validate_int8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqadd_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (const int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (const int16_t *)impl.test_cases_int_pointer2;
  int16_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = saturate_int16((int32_t)_a[i] + (int32_t)_b[i]);
  }

  int16x4_t a = vld1_s16(_a);
  int16x4_t b = vld1_s16(_b);
  int16x4_t c = vqadd_s16(a, b);
  return validate_int16(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqadd_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (const int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (const int32_t *)impl.test_cases_int_pointer2;
  int32_t _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = saturate_int32((int64_t)_a[i] + (int64_t)_b[i]);
  }

  int32x2_t a = vld1_s32(_a);
  int32x2_t b = vld1_s32(_b);
  int32x2_t c = vqadd_s32(a, b);
  return validate_int32(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqadd_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (const int64_t *)impl.test_cases_int_pointer1;
  const int64_t *_b = (const int64_t *)impl.test_cases_int_pointer2;
  int64_t _c[1];
  for (int i = 0; i < 1; i++) {
    if (_a[i] > 0) {
      if (_b[i] > INT64_MAX - _a[i]) {
        _c[i] = INT64_MAX;
      } else {
        _c[i] = _a[i] + _b[i];
      }
    } else if (_b[i] < INT64_MIN - _a[i]) {
      _c[i] = INT64_MIN;
    } else {
      _c[i] = _a[i] + _b[i];
    }
  }

  int64x1_t a = vld1_s64(_a);
  int64x1_t b = vld1_s64(_b);
  int64x1_t c = vqadd_s64(a, b);
  return validate_int64(c, _c[0]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqadd_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (const uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (const uint8_t *)impl.test_cases_int_pointer2;
  uint8_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = saturate_uint8((int16_t)_a[i] + (int16_t)_b[i]);
  }

  uint8x8_t a = vld1_u8(_a);
  uint8x8_t b = vld1_u8(_b);
  uint8x8_t c = vqadd_u8(a, b);
  return validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqadd_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (const uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (const uint16_t *)impl.test_cases_int_pointer2;
  uint16_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = saturate_uint16((int32_t)_a[i] + (int32_t)_b[i]);
  }

  uint16x4_t a = vld1_u16(_a);
  uint16x4_t b = vld1_u16(_b);
  uint16x4_t c = vqadd_u16(a, b);
  return validate_uint16(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqadd_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (const uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (const uint32_t *)impl.test_cases_int_pointer2;
  uint32_t _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = saturate_uint32((int64_t)_a[i] + (int64_t)_b[i]);
  }

  uint32x2_t a = vld1_u32(_a);
  uint32x2_t b = vld1_u32(_b);
  uint32x2_t c = vqadd_u32(a, b);
  return validate_uint32(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqadd_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (const uint64_t *)impl.test_cases_int_pointer1;
  const uint64_t *_b = (const uint64_t *)impl.test_cases_int_pointer2;
  uint64_t _c[1];
  for (int i = 0; i < 1; i++) {
    if (_b[i] > UINT64_MAX - _a[i]) {
      _c[i] = UINT64_MAX;
    } else {
      _c[i] = _a[i] + _b[i];
    }
  }

  uint64x1_t a = vld1_u64(_a);
  uint64x1_t b = vld1_u64(_b);
  uint64x1_t c = vqadd_u64(a, b);
  return validate_uint64(c, _c[0]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqaddq_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (const int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (const int8_t *)impl.test_cases_int_pointer2;
  int8_t _c[16];
  for (int i = 0; i < 16; i++) {
    _c[i] = saturate_int8((int16_t)_a[i] + (int16_t)_b[i]);
  }

  int8x16_t a = vld1q_s8(_a);
  int8x16_t b = vld1q_s8(_b);
  int8x16_t c = vqaddq_s8(a, b);
  return validate_int8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7], _c[8], _c[9], _c[10], _c[11], _c[12],
                       _c[13], _c[14], _c[15]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqaddq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (const int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (const int16_t *)impl.test_cases_int_pointer2;
  int16_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = saturate_int16((int32_t)_a[i] + (int32_t)_b[i]);
  }

  int16x8_t a = vld1q_s16(_a);
  int16x8_t b = vld1q_s16(_b);
  int16x8_t c = vqaddq_s16(a, b);
  return validate_int16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqaddq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (const int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (const int32_t *)impl.test_cases_int_pointer2;
  int32_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = saturate_int32((int64_t)_a[i] + (int64_t)_b[i]);
  }

  int32x4_t a = vld1q_s32(_a);
  int32x4_t b = vld1q_s32(_b);
  int32x4_t c = vqaddq_s32(a, b);
  return validate_int32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqaddq_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (const int64_t *)impl.test_cases_int_pointer1;
  const int64_t *_b = (const int64_t *)impl.test_cases_int_pointer2;
  int64_t _c[2];
  for (int i = 0; i < 2; i++) {
    if (_a[i] > 0) {
      if (_b[i] > INT64_MAX - _a[i]) {
        _c[i] = INT64_MAX;
      } else {
        _c[i] = _a[i] + _b[i];
      }
    } else if (_b[i] < INT64_MIN - _a[i]) {
      _c[i] = INT64_MIN;
    } else {
      _c[i] = _a[i] + _b[i];
    }
  }

  int64x2_t a = vld1q_s64(_a);
  int64x2_t b = vld1q_s64(_b);
  int64x2_t c = vqaddq_s64(a, b);
  return validate_int64(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqaddq_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (const uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (const uint8_t *)impl.test_cases_int_pointer2;
  uint8_t _c[16];
  for (int i = 0; i < 16; i++) {
    _c[i] = saturate_uint8((int16_t)_a[i] + (int16_t)_b[i]);
  }

  uint8x16_t a = vld1q_u8(_a);
  uint8x16_t b = vld1q_u8(_b);
  uint8x16_t c = vqaddq_u8(a, b);
  return validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7], _c[8], _c[9], _c[10], _c[11], _c[12],
                        _c[13], _c[14], _c[15]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqaddq_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (const uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (const uint16_t *)impl.test_cases_int_pointer2;
  uint16_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = saturate_uint16((int32_t)_a[i] + (int32_t)_b[i]);
  }

  uint16x8_t a = vld1q_u16(_a);
  uint16x8_t b = vld1q_u16(_b);
  uint16x8_t c = vqaddq_u16(a, b);
  return validate_uint16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqaddq_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (const uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (const uint32_t *)impl.test_cases_int_pointer2;
  uint32_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = saturate_uint32((int64_t)_a[i] + (int64_t)_b[i]);
  }

  uint32x4_t a = vld1q_u32(_a);
  uint32x4_t b = vld1q_u32(_b);
  uint32x4_t c = vqaddq_u32(a, b);
  return validate_uint32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqaddq_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (const uint64_t *)impl.test_cases_int_pointer1;
  const uint64_t *_b = (const uint64_t *)impl.test_cases_int_pointer2;
  uint64_t _c[2];
  for (int i = 0; i < 2; i++) {
    if (_b[i] > UINT64_MAX - _a[i]) {
      _c[i] = UINT64_MAX;
    } else {
      _c[i] = _a[i] + _b[i];
    }
  }

  uint64x2_t a = vld1q_u64(_a);
  uint64x2_t b = vld1q_u64(_b);
  uint64x2_t c = vqaddq_u64(a, b);
  return validate_uint64(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqaddb_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqaddh_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqadds_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqaddd_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqaddb_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqaddh_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqadds_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqaddd_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vuqadd_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vuqaddq_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vuqadd_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vuqaddq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vuqadd_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vuqaddq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vuqadd_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vuqaddq_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vuqaddb_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vuqaddh_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vuqadds_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vuqaddd_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vsqadd_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vsqaddq_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vsqadd_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vsqaddq_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vsqadd_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vsqaddq_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vsqadd_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vsqaddq_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vsqaddb_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vsqaddh_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vsqadds_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vsqaddd_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vaddhn_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  int8_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = ((_a[i] + _b[i]) >> 8) & UINT8_MAX;
  }

  int16x8_t a = vld1q_s16(_a);
  int16x8_t b = vld1q_s16(_b);
  int8x8_t c = vaddhn_s16(a, b);
  return validate_int8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vaddhn_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  int16_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = ((_a[i] + _b[i]) >> 16) & UINT16_MAX;
  }

  int32x4_t a = vld1q_s32(_a);
  int32x4_t b = vld1q_s32(_b);
  int16x4_t c = vaddhn_s32(a, b);
  return validate_int16(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vaddhn_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (int64_t *)impl.test_cases_int_pointer1;
  const int64_t *_b = (int64_t *)impl.test_cases_int_pointer2;
  int32_t _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = ((_a[i] + _b[i]) >> 32) & UINT32_MAX;
  }

  int64x2_t a = vld1q_s64(_a);
  int64x2_t b = vld1q_s64(_b);
  int32x2_t c = vaddhn_s64(a, b);
  return validate_int32(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vaddhn_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (uint16_t *)impl.test_cases_int_pointer2;
  uint8_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = ((_a[i] + _b[i]) >> 8) & UINT8_MAX;
  }

  uint16x8_t a = vld1q_u16(_a);
  uint16x8_t b = vld1q_u16(_b);
  uint8x8_t c = vaddhn_u16(a, b);
  return validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vaddhn_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (uint32_t *)impl.test_cases_int_pointer2;
  uint16_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = ((_a[i] + _b[i]) >> 16) & UINT16_MAX;
  }

  uint32x4_t a = vld1q_u32(_a);
  uint32x4_t b = vld1q_u32(_b);
  uint16x4_t c = vaddhn_u32(a, b);
  return validate_uint16(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vaddhn_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (uint64_t *)impl.test_cases_int_pointer1;
  const uint64_t *_b = (uint64_t *)impl.test_cases_int_pointer2;
  uint32_t _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = ((_a[i] + _b[i]) >> 32) & UINT32_MAX;
  }

  uint64x2_t a = vld1q_u64(_a);
  uint64x2_t b = vld1q_u64(_b);
  uint32x2_t c = vaddhn_u64(a, b);
  return validate_uint32(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vaddhn_high_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  const int8_t *_r = (int8_t *)impl.test_cases_int_pointer3;
  int8_t _d[16];
  for (int i = 0; i < 8; i++) {
    _d[i] = _r[i];
    _d[i + 8] = ((_a[i] + _b[i]) >> 8) & UINT8_MAX;
  }

  int16x8_t a = vld1q_s16(_a);
  int16x8_t b = vld1q_s16(_b);
  int8x8_t r = vld1_s8(_r);
  int8x16_t d = vaddhn_high_s16(r, a, b);
  return validate_int8(d, _d[0], _d[1], _d[2], _d[3], _d[4], _d[5], _d[6], _d[7], _d[8], _d[9], _d[10], _d[11], _d[12],
                       _d[13], _d[14], _d[15]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vaddhn_high_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  const int16_t *_r = (int16_t *)impl.test_cases_int_pointer3;
  int16_t _d[8];
  for (int i = 0; i < 4; i++) {
    _d[i] = _r[i];
    _d[i + 4] = ((_a[i] + _b[i]) >> 16) & UINT16_MAX;
  }

  int32x4_t a = vld1q_s32(_a);
  int32x4_t b = vld1q_s32(_b);
  int16x4_t r = vld1_s16(_r);
  int16x8_t d = vaddhn_high_s32(r, a, b);
  return validate_int16(d, _d[0], _d[1], _d[2], _d[3], _d[4], _d[5], _d[6], _d[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vaddhn_high_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (int64_t *)impl.test_cases_int_pointer1;
  const int64_t *_b = (int64_t *)impl.test_cases_int_pointer2;
  const int32_t *_r = (int32_t *)impl.test_cases_int_pointer3;
  int32_t _d[4];
  for (int i = 0; i < 2; i++) {
    _d[i] = _r[i];
    _d[i + 2] = ((_a[i] + _b[i]) >> 32) & UINT32_MAX;
  }

  int64x2_t a = vld1q_s64(_a);
  int64x2_t b = vld1q_s64(_b);
  int32x2_t r = vld1_s32(_r);
  int32x4_t d = vaddhn_high_s64(r, a, b);
  return validate_int32(d, _d[0], _d[1], _d[2], _d[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vaddhn_high_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (uint16_t *)impl.test_cases_int_pointer2;
  const uint8_t *_r = (uint8_t *)impl.test_cases_int_pointer3;
  uint8_t _d[16];
  for (int i = 0; i < 8; i++) {
    _d[i] = _r[i];
    _d[i + 8] = ((_a[i] + _b[i]) >> 8) & UINT8_MAX;
  }

  uint16x8_t a = vld1q_u16(_a);
  uint16x8_t b = vld1q_u16(_b);
  uint8x8_t r = vld1_u8(_r);
  uint8x16_t d = vaddhn_high_u16(r, a, b);
  return validate_uint8(d, _d[0], _d[1], _d[2], _d[3], _d[4], _d[5], _d[6], _d[7], _d[8], _d[9], _d[10], _d[11], _d[12],
                        _d[13], _d[14], _d[15]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vaddhn_high_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (uint32_t *)impl.test_cases_int_pointer2;
  const uint16_t *_r = (uint16_t *)impl.test_cases_int_pointer3;
  uint16_t _d[8];
  for (int i = 0; i < 4; i++) {
    _d[i] = _r[i];
    _d[i + 4] = ((_a[i] + _b[i]) >> 16) & UINT16_MAX;
  }

  uint32x4_t a = vld1q_u32(_a);
  uint32x4_t b = vld1q_u32(_b);
  uint16x4_t r = vld1_u16(_r);
  uint16x8_t d = vaddhn_high_u32(r, a, b);
  return validate_uint16(d, _d[0], _d[1], _d[2], _d[3], _d[4], _d[5], _d[6], _d[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vaddhn_high_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (uint64_t *)impl.test_cases_int_pointer1;
  const uint64_t *_b = (uint64_t *)impl.test_cases_int_pointer2;
  const uint32_t *_r = (uint32_t *)impl.test_cases_int_pointer3;
  uint32_t _d[4];
  for (int i = 0; i < 2; i++) {
    _d[i] = _r[i];
    _d[i + 2] = ((_a[i] + _b[i]) >> 32) & UINT32_MAX;
  }

  uint64x2_t a = vld1q_u64(_a);
  uint64x2_t b = vld1q_u64(_b);
  uint32x2_t r = vld1_u32(_r);
  uint32x4_t d = vaddhn_high_u64(r, a, b);
  return validate_uint32(d, _d[0], _d[1], _d[2], _d[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vraddhn_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  int8_t _c[8];
  const int16_t round = 1 << 7;
  for (int i = 0; i < 8; i++) {
    _c[i] = ((_a[i] + _b[i] + round) >> 8) & UINT8_MAX;
  }

  int16x8_t a = vld1q_s16(_a);
  int16x8_t b = vld1q_s16(_b);
  int8x8_t c = vraddhn_s16(a, b);
  return validate_int8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vraddhn_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  int16_t _c[4];
  const int32_t round = 1 << 15;
  for (int i = 0; i < 4; i++) {
    _c[i] = ((_a[i] + _b[i] + round) >> 16) & UINT16_MAX;
  }

  int32x4_t a = vld1q_s32(_a);
  int32x4_t b = vld1q_s32(_b);
  int16x4_t c = vraddhn_s32(a, b);
  return validate_int16(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vraddhn_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (int64_t *)impl.test_cases_int_pointer1;
  const int64_t *_b = (int64_t *)impl.test_cases_int_pointer2;
  int32_t _c[2];
  const int64_t round = (int64_t)1 << 31;
  for (int i = 0; i < 2; i++) {
    _c[i] = ((_a[i] + _b[i] + round) >> 32) & UINT32_MAX;
  }

  int64x2_t a = vld1q_s64(_a);
  int64x2_t b = vld1q_s64(_b);
  int32x2_t c = vraddhn_s64(a, b);
  return validate_int32(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vraddhn_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (uint16_t *)impl.test_cases_int_pointer2;
  uint8_t _c[8];
  const uint16_t round = 1 << 7;
  for (int i = 0; i < 8; i++) {
    _c[i] = ((_a[i] + _b[i] + round) >> 8) & UINT8_MAX;
  }

  uint16x8_t a = vld1q_u16(_a);
  uint16x8_t b = vld1q_u16(_b);
  uint8x8_t c = vraddhn_u16(a, b);
  return validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vraddhn_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (uint32_t *)impl.test_cases_int_pointer2;
  uint16_t _c[4];
  const uint32_t round = 1 << 15;
  for (int i = 0; i < 4; i++) {
    _c[i] = ((_a[i] + _b[i] + round) >> 16) & UINT16_MAX;
  }

  uint32x4_t a = vld1q_u32(_a);
  uint32x4_t b = vld1q_u32(_b);
  uint16x4_t c = vraddhn_u32(a, b);
  return validate_uint16(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vraddhn_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (uint64_t *)impl.test_cases_int_pointer1;
  const uint64_t *_b = (uint64_t *)impl.test_cases_int_pointer2;
  uint32_t _c[2];
  const uint64_t round = (uint64_t)1 << 31;
  for (int i = 0; i < 2; i++) {
    _c[i] = ((_a[i] + _b[i] + round) >> 32) & UINT32_MAX;
  }

  uint64x2_t a = vld1q_u64(_a);
  uint64x2_t b = vld1q_u64(_b);
  uint32x2_t c = vraddhn_u64(a, b);
  return validate_uint32(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vraddhn_high_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vraddhn_high_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vraddhn_high_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vraddhn_high_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vraddhn_high_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vraddhn_high_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmul_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (int8_t *)impl.test_cases_int_pointer2;
  int8_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = _a[i] * _b[i];
  }

  int8x8_t a = vld1_s8(_a);
  int8x8_t b = vld1_s8(_b);
  int8x8_t c = vmul_s8(a, b);
  return validate_int8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmul_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  int16_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = _a[i] * _b[i];
  }

  int16x4_t a = vld1_s16(_a);
  int16x4_t b = vld1_s16(_b);
  int16x4_t c = vmul_s16(a, b);
  return validate_int16(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmul_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  int32_t _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = _a[i] * _b[i];
  }

  int32x2_t a = vld1_s32(_a);
  int32x2_t b = vld1_s32(_b);
  int32x2_t c = vmul_s32(a, b);
  return validate_int32(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmul_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (float *)impl.test_cases_float_pointer1;
  const float *_b = (float *)impl.test_cases_float_pointer2;
  float _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = _a[i] * _b[i];
  }

  float32x2_t a = vld1_f32(_a);
  float32x2_t b = vld1_f32(_b);
  float32x2_t c = vmul_f32(a, b);
  return validate_float(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmul_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (uint8_t *)impl.test_cases_int_pointer2;
  uint8_t _d[8];
  for (int i = 0; i < 8; i++) {
    _d[i] = _a[i] * _b[i];
  }

  uint8x8_t a = vld1_u8(_a);
  uint8x8_t b = vld1_u8(_b);
  uint8x8_t c = vmul_u8(a, b);
  return validate_uint8(c, _d[0], _d[1], _d[2], _d[3], _d[4], _d[5], _d[6], _d[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmul_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (uint16_t *)impl.test_cases_int_pointer2;
  uint16_t _d[4];
  for (int i = 0; i < 4; i++) {
    _d[i] = _a[i] * _b[i];
  }

  uint16x4_t a = vld1_u16(_a);
  uint16x4_t b = vld1_u16(_b);
  uint16x4_t c = vmul_u16(a, b);
  return validate_uint16(c, _d[0], _d[1], _d[2], _d[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmul_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (uint32_t *)impl.test_cases_int_pointer2;
  uint32_t d0 = _a[0] * _b[0];
  uint32_t d1 = _a[1] * _b[1];

  uint32x2_t a = vld1_u32(_a);
  uint32x2_t b = vld1_u32(_b);
  uint32x2_t c = vmul_u32(a, b);
  return validate_uint32(c, d0, d1);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmulq_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (int8_t *)impl.test_cases_int_pointer2;
  int8_t _c[16];
  for (int i = 0; i < 16; i++) {
    _c[i] = _a[i] * _b[i];
  }

  int8x16_t a = vld1q_s8(_a);
  int8x16_t b = vld1q_s8(_b);
  int8x16_t c = vmulq_s8(a, b);
  return validate_int8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7], _c[8], _c[9], _c[10], _c[11], _c[12],
                       _c[13], _c[14], _c[15]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmulq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  int16_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = _a[i] * _b[i];
  }

  int16x8_t a = vld1q_s16(_a);
  int16x8_t b = vld1q_s16(_b);
  int16x8_t c = vmulq_s16(a, b);
  return validate_int16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmulq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  int32_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = _a[i] * _b[i];
  }

  int32x4_t a = vld1q_s32(_a);
  int32x4_t b = vld1q_s32(_b);
  int32x4_t c = vmulq_s32(a, b);
  return validate_int32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmulq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (float *)impl.test_cases_float_pointer1;
  const float *_b = (float *)impl.test_cases_float_pointer2;
  float _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = _a[i] * _b[i];
  }

  float32x4_t a = vld1q_f32(_a);
  float32x4_t b = vld1q_f32(_b);
  float32x4_t c = vmulq_f32(a, b);
  return validate_float(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmul_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmulq_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmul_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmulq_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmulx_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmulxq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmulx_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmulxq_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmulxs_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmulxd_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmulx_lane_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmulxq_lane_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmulx_lane_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmulxq_lane_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmulxs_lane_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmulxd_lane_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmulx_laneq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmulxq_laneq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmulx_laneq_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmulxq_laneq_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmulxs_laneq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmulxd_laneq_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vdiv_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (float *)impl.test_cases_float_pointer1;
  const float *_b = (float *)impl.test_cases_float_pointer2;
  float _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = _a[i] / _b[i];
  }

  float32x2_t a = vld1_f32(_a);
  float32x2_t b = vld1_f32(_b);
  float32x2_t c = vdiv_f32(a, b);
  return validate_float(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vdivq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (float *)impl.test_cases_float_pointer1;
  const float *_b = (float *)impl.test_cases_float_pointer2;
  float _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = _a[i] / _b[i];
  }

  float32x4_t a = vld1q_f32(_a);
  float32x4_t b = vld1q_f32(_b);
  float32x4_t c = vdivq_f32(a, b);
  return validate_float(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vdiv_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const double *_a = (double *)impl.test_cases_float_pointer1;
  const double *_b = (double *)impl.test_cases_float_pointer2;
  double _c[1];
  for (int i = 0; i < 1; i++) {
    _c[i] = _a[i] / _b[i];
  }

  float64x1_t a = vld1_f64(_a);
  float64x1_t b = vld1_f64(_b);
  float64x1_t c = vdiv_f64(a, b);
  return validate_double(c, _c[0]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vdivq_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const double *_a = (double *)impl.test_cases_float_pointer1;
  const double *_b = (double *)impl.test_cases_float_pointer2;
  double _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = _a[i] / _b[i];
  }

  float64x2_t a = vld1q_f64(_a);
  float64x2_t b = vld1q_f64(_b);
  float64x2_t c = vdivq_f64(a, b);
  return validate_double(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmulq_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (uint8_t *)impl.test_cases_int_pointer2;
  uint8_t _c[16];
  for (int i = 0; i < 16; i++) {
    _c[i] = _a[i] * _b[i];
  }

  uint8x16_t a = vld1q_u8(_a);
  uint8x16_t b = vld1q_u8(_b);
  uint8x16_t c = vmulq_u8(a, b);
  return validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7], _c[8], _c[9], _c[10], _c[11], _c[12],
                        _c[13], _c[14], _c[15]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmulq_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (uint16_t *)impl.test_cases_int_pointer2;
  uint16_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = _a[i] * _b[i];
  }

  uint16x8_t a = vld1q_u16(_a);
  uint16x8_t b = vld1q_u16(_b);
  uint16x8_t c = vmulq_u16(a, b);
  return validate_uint16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmulq_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (uint32_t *)impl.test_cases_int_pointer2;
  uint32_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = _a[i] * _b[i];
  }

  uint32x4_t a = vld1q_u32(_a);
  uint32x4_t b = vld1q_u32(_b);
  uint32x4_t c = vmulq_u32(a, b);
  return validate_uint32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqdmulh_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  int16_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = saturate_int16(2 * (int32_t)_a[i] * (int32_t)_b[i] >> 16);
  }

  int16x4_t a = vld1_s16(_a);
  int16x4_t b = vld1_s16(_b);
  int16x4_t c = vqdmulh_s16(a, b);
  return validate_int16(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqdmulh_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  int32_t _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = saturate_int32(2 * (int64_t)_a[i] * (int64_t)_b[i] >> 32);
  }

  int32x2_t a = vld1_s32(_a);
  int32x2_t b = vld1_s32(_b);
  int32x2_t c = vqdmulh_s32(a, b);
  return validate_int32(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqdmulhq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  int16_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = saturate_int16(2 * (int32_t)_a[i] * (int32_t)_b[i] >> 16);
  }

  int16x8_t a = vld1q_s16(_a);
  int16x8_t b = vld1q_s16(_b);
  int16x8_t c = vqdmulhq_s16(a, b);
  return validate_int16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqdmulhq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  int32_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = saturate_int32(2 * (int64_t)_a[i] * (int64_t)_b[i] >> 32);
  }

  int32x4_t a = vld1q_s32(_a);
  int32x4_t b = vld1q_s32(_b);
  int32x4_t c = vqdmulhq_s32(a, b);
  return validate_int32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqdmulhh_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  int16_t _c = saturate_int16(2 * (int32_t)_a[0] * (int32_t)_b[0] >> 16);

  int16_t c = vqdmulhh_s16(_a[0], _b[0]);
  return c == _c ? TEST_SUCCESS : TEST_FAIL;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqdmulhs_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  int32_t _c = saturate_int32(2 * (int64_t)_a[0] * (int64_t)_b[0] >> 32);

  int32_t c = vqdmulhs_s32(_a[0], _b[0]);
  return c == _c ? TEST_SUCCESS : TEST_FAIL;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqrdmulh_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  int16_t _c[4];
  const int32_t round = 1 << 15;
  for (int i = 0; i < 4; i++) {
    int32_t tmp = 2 * (int32_t)_a[i] * (int32_t)_b[i] + round;
    _c[i] = saturate_int16(tmp >> 16);
  }

  int16x4_t a = vld1_s16(_a);
  int16x4_t b = vld1_s16(_b);
  int16x4_t c = vqrdmulh_s16(a, b);
  return validate_int16(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqrdmulh_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  int32_t _c[2];
  int32_t round = 1;
  for (int i = 0; i < 2; i++) {
    int64_t tmp = 2 * (int64_t)_a[i] * (int64_t)_b[i];
    tmp = tmp >> 31;
    tmp += round;
    _c[i] = saturate_int32(tmp >> 1);
  }

  int32x2_t a = vld1_s32(_a);
  int32x2_t b = vld1_s32(_b);
  int32x2_t c = vqrdmulh_s32(a, b);
  return validate_int32(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqrdmulhq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  int16_t _c[8];
  const int32_t round = 1 << 15;
  for (int i = 0; i < 8; i++) {
    int32_t tmp = 2 * (int32_t)_a[i] * (int32_t)_b[i] + round;
    _c[i] = saturate_int16(tmp >> 16);
  }

  int16x8_t a = vld1q_s16(_a);
  int16x8_t b = vld1q_s16(_b);
  int16x8_t c = vqrdmulhq_s16(a, b);
  return validate_int16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqrdmulhq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  int32_t _c[4];
  int32_t round = 1;
  for (int i = 0; i < 4; i++) {
    int64_t tmp = 2 * (int64_t)_a[i] * (int64_t)_b[i];
    tmp = tmp >> 31;
    tmp += round;
    _c[i] = saturate_int32(tmp >> 1);
  }

  int32x4_t a = vld1q_s32(_a);
  int32x4_t b = vld1q_s32(_b);
  int32x4_t c = vqrdmulhq_s32(a, b);
  return validate_int32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqrdmulhh_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  const int32_t round = 1 << 15;
  int32_t tmp = 2 * (int32_t)_a[0] * (int32_t)_b[0] + round;
  int32_t _c = saturate_int16(tmp >> 16);

  int16_t c = vqrdmulhh_s16(_a[0], _b[0]);
  return c == _c ? TEST_SUCCESS : TEST_FAIL;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqrdmulhs_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  int32_t round = 1;
  int64_t tmp = 2 * (int64_t)_a[0] * (int64_t)_b[0];
  tmp = tmp >> 31;
  tmp += round;
  int32_t _c = saturate_int32(tmp >> 1);

  int32_t c = vqrdmulhs_s32(_a[0], _b[0]);
  return c == _c ? TEST_SUCCESS : TEST_FAIL;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqrdmlah_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
#if defined(__GNUC__)
  return TEST_UNIMPL;
#else
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  const int16_t *_c = (int16_t *)impl.test_cases_int_pointer3;
  int16_t _d[4];
  const int32_t round_const = 1 << 15;
  for (int i = 0; i < 4; i++) {
    int32_t tmp = 2 * (int32_t)_b[i] * (int32_t)_c[i] + round_const;
    _d[i] = saturate_int16(_a[i] + (tmp >> 16));
  }

  int16x4_t a = vld1_s16(_a);
  int16x4_t b = vld1_s16(_b);
  int16x4_t c = vld1_s16(_c);
  int16x4_t d = vqrdmlah_s16(a, b, c);
  return validate_int16(d, _d[0], _d[1], _d[2], _d[3]);
#endif
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqrdmlah_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
#if defined(__GNUC__)
  return TEST_UNIMPL;
#else
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  const int32_t *_c = (int32_t *)impl.test_cases_int_pointer3;
  int32_t _d[2];
  const int64_t round_const = (int64_t)1 << 31;
  for (int i = 0; i < 2; i++) {
    int64_t tmp = 2 * (int64_t)_b[i] * (int64_t)_c[i] + round_const;
    _d[i] = saturate_int32((int64_t)_a[i] + (tmp >> 32));
  }

  int32x2_t a = vld1_s32(_a);
  int32x2_t b = vld1_s32(_b);
  int32x2_t c = vld1_s32(_c);
  int32x2_t d = vqrdmlah_s32(a, b, c);
  return validate_int32(d, _d[0], _d[1]);
#endif
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqrdmlahq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
#if defined(__GNUC__)
  return TEST_UNIMPL;
#else
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  const int16_t *_c = (int16_t *)impl.test_cases_int_pointer3;
  int16_t _d[8];
  const int32_t round_const = 1 << 15;
  for (int i = 0; i < 8; i++) {
    int32_t tmp = 2 * (int32_t)_b[i] * (int32_t)_c[i] + round_const;
    _d[i] = saturate_int16(_a[i] + (tmp >> 16));
  }

  int16x8_t a = vld1q_s16(_a);
  int16x8_t b = vld1q_s16(_b);
  int16x8_t c = vld1q_s16(_c);
  int16x8_t d = vqrdmlahq_s16(a, b, c);
  return validate_int16(d, _d[0], _d[1], _d[2], _d[3], _d[4], _d[5], _d[6], _d[7]);
#endif
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqrdmlahq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
#if defined(__GNUC__)
  return TEST_UNIMPL;
#else
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  const int32_t *_c = (int32_t *)impl.test_cases_int_pointer3;
  int32_t _d[4];
  const int64_t round_const = (int64_t)1 << 31;
  for (int i = 0; i < 4; i++) {
    int64_t tmp = 2 * (int64_t)_b[i] * (int64_t)_c[i] + round_const;
    _d[i] = saturate_int32((int64_t)_a[i] + (tmp >> 32));
  }

  int32x4_t a = vld1q_s32(_a);
  int32x4_t b = vld1q_s32(_b);
  int32x4_t c = vld1q_s32(_c);
  int32x4_t d = vqrdmlahq_s32(a, b, c);
  return validate_int32(d, _d[0], _d[1], _d[2], _d[3]);
#endif
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqrdmlsh_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
#if defined(__GNUC__)
  return TEST_UNIMPL;
#else
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  const int16_t *_c = (int16_t *)impl.test_cases_int_pointer3;
  int16_t _d[4];
  const int32_t round_const = 1 << 15;
  for (int i = 0; i < 4; i++) {
    int32_t tmp = -2 * (int32_t)_b[i] * (int32_t)_c[i] + round_const;
    _d[i] = saturate_int16((int32_t)_a[i] + (tmp >> 16));
  }

  int16x4_t a = vld1_s16(_a);
  int16x4_t b = vld1_s16(_b);
  int16x4_t c = vld1_s16(_c);
  int16x4_t d = vqrdmlsh_s16(a, b, c);
  return validate_int16(d, _d[0], _d[1], _d[2], _d[3]);
#endif
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqrdmlsh_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
#if defined(__GNUC__)
  return TEST_UNIMPL;
#else
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  const int32_t *_c = (int32_t *)impl.test_cases_int_pointer3;
  int32_t _d[2];
  const int64_t round_const = (int64_t)1 << 31;
  for (int i = 0; i < 2; i++) {
    int64_t tmp = -2 * (int64_t)_b[i] * (int64_t)_c[i] + round_const;
    _d[i] = saturate_int32((int64_t)_a[i] + (tmp >> 32));
  }

  int32x2_t a = vld1_s32(_a);
  int32x2_t b = vld1_s32(_b);
  int32x2_t c = vld1_s32(_c);
  int32x2_t d = vqrdmlsh_s32(a, b, c);
  return validate_int32(d, _d[0], _d[1]);
#endif
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqrdmlshq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
#if defined(__GNUC__)
  return TEST_UNIMPL;
#else
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  const int16_t *_c = (int16_t *)impl.test_cases_int_pointer3;
  int16_t _d[8];
  const int32_t round_const = 1 << 15;
  for (int i = 0; i < 8; i++) {
    int32_t tmp = -2 * (int32_t)_b[i] * (int32_t)_c[i] + round_const;
    _d[i] = saturate_int16(_a[i] + (tmp >> 16));
  }

  int16x8_t a = vld1q_s16(_a);
  int16x8_t b = vld1q_s16(_b);
  int16x8_t c = vld1q_s16(_c);
  int16x8_t d = vqrdmlshq_s16(a, b, c);
  return validate_int16(d, _d[0], _d[1], _d[2], _d[3], _d[4], _d[5], _d[6], _d[7]);
#endif
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqrdmlshq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
#if defined(__GNUC__)
  return TEST_UNIMPL;
#else
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  const int32_t *_c = (int32_t *)impl.test_cases_int_pointer3;
  int32_t _d[4];
  const int64_t round_const = (int64_t)1 << 31;
  for (int i = 0; i < 4; i++) {
    int64_t tmp = -2 * (int64_t)_b[i] * (int64_t)_c[i] + round_const;
    _d[i] = saturate_int32((int64_t)_a[i] + (tmp >> 32));
  }

  int32x4_t a = vld1q_s32(_a);
  int32x4_t b = vld1q_s32(_b);
  int32x4_t c = vld1q_s32(_c);
  int32x4_t d = vqrdmlshq_s32(a, b, c);
  return validate_int32(d, _d[0], _d[1], _d[2], _d[3]);
#endif
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmull_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (int8_t *)impl.test_cases_int_pointer2;
  int16_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = (int16_t)_a[i] * (int16_t)_b[i];
  }

  int8x8_t a = vld1_s8(_a);
  int8x8_t b = vld1_s8(_b);
  int16x8_t c = vmull_s8(a, b);
  return validate_int16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmull_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  int32_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = (int32_t)_a[i] * (int32_t)_b[i];
  }

  int16x4_t a = vld1_s16(_a);
  int16x4_t b = vld1_s16(_b);
  int32x4_t c = vmull_s16(a, b);
  return validate_int32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmull_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  int64_t _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = (int64_t)_a[i] * (int64_t)_b[i];
  }

  int32x2_t a = vld1_s32(_a);
  int32x2_t b = vld1_s32(_b);
  int64x2_t c = vmull_s32(a, b);
  return validate_int64(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmull_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (uint8_t *)impl.test_cases_int_pointer2;
  uint16_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = (uint16_t)_a[i] * (uint16_t)_b[i];
  }

  uint8x8_t a = vld1_u8(_a);
  uint8x8_t b = vld1_u8(_b);
  uint16x8_t c = vmull_u8(a, b);
  return validate_uint16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmull_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (uint16_t *)impl.test_cases_int_pointer2;
  uint32_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = (uint32_t)_a[i] * (uint32_t)_b[i];
  }

  uint16x4_t a = vld1_u16(_a);
  uint16x4_t b = vld1_u16(_b);
  uint32x4_t c = vmull_u16(a, b);
  return validate_uint32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmull_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (uint32_t *)impl.test_cases_int_pointer2;
  uint64_t _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = (uint64_t)_a[i] * (uint64_t)_b[i];
  }

  uint32x2_t a = vld1_u32(_a);
  uint32x2_t b = vld1_u32(_b);
  uint64x2_t c = vmull_u32(a, b);
  return validate_uint64(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmull_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmull_high_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (int8_t *)impl.test_cases_int_pointer2;
  int16_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = (int16_t)_a[i + 8] * (int16_t)_b[i + 8];
  }

  int8x16_t a = vld1q_s8(_a);
  int8x16_t b = vld1q_s8(_b);
  int16x8_t c = vmull_high_s8(a, b);
  return validate_int16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmull_high_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  int32_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = (int32_t)_a[i + 4] * (int32_t)_b[i + 4];
  }

  int16x8_t a = vld1q_s16(_a);
  int16x8_t b = vld1q_s16(_b);
  int32x4_t c = vmull_high_s16(a, b);
  return validate_int32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmull_high_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  int64_t _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = (int64_t)_a[i + 2] * (int64_t)_b[i + 2];
  }

  int32x4_t a = vld1q_s32(_a);
  int32x4_t b = vld1q_s32(_b);
  int64x2_t c = vmull_high_s32(a, b);
  return validate_int64(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmull_high_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (uint8_t *)impl.test_cases_int_pointer2;
  uint16_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = (uint16_t)_a[i + 8] * (uint16_t)_b[i + 8];
  }

  uint8x16_t a = vld1q_u8(_a);
  uint8x16_t b = vld1q_u8(_b);
  uint16x8_t c = vmull_high_u8(a, b);
  return validate_uint16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmull_high_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (uint16_t *)impl.test_cases_int_pointer2;
  uint32_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = (uint32_t)_a[i + 4] * (uint32_t)_b[i + 4];
  }

  uint16x8_t a = vld1q_u16(_a);
  uint16x8_t b = vld1q_u16(_b);
  uint32x4_t c = vmull_high_u16(a, b);
  return validate_uint32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmull_high_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (uint32_t *)impl.test_cases_int_pointer2;
  uint64_t _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = (uint64_t)_a[i + 2] * (uint64_t)_b[i + 2];
  }

  uint32x4_t a = vld1q_u32(_a);
  uint32x4_t b = vld1q_u32(_b);
  uint64x2_t c = vmull_high_u32(a, b);
  return validate_uint64(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmull_high_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqdmull_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  int32_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = saturate_int32(2 * _a[i] * _b[i]);
  }

  int16x4_t a = vld1_s16(_a);
  int16x4_t b = vld1_s16(_b);
  int32x4_t c = vqdmull_s16(a, b);
  return validate_int32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqdmull_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  int64_t _c[4];
  float max_f = (float)INT64_MAX, min_f = (float)INT64_MIN;
  for (int i = 0; i < 4; i++) {
    float a_f = _a[i];
    float b_f = _b[i];
    if ((a_f * b_f > 0) && (2 * a_f * b_f > max_f)) {
      _c[i] = INT64_MAX;
    } else if (2 * a_f * b_f < min_f) {
      _c[i] = INT64_MIN;
    } else {
      _c[i] = 2 * (int64_t)_a[i] * (int64_t)_b[i];
    }
  }

  int32x2_t a = vld1_s32(_a);
  int32x2_t b = vld1_s32(_b);
  int64x2_t c = vqdmull_s32(a, b);
  return validate_int64(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqdmullh_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqdmulls_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqdmull_high_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqdmull_high_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmla_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (int8_t *)impl.test_cases_int_pointer2;
  const int8_t *_c = (int8_t *)impl.test_cases_int_pointer3;
  int8_t _d[8];
  for (int i = 0; i < 8; i++) {
    _d[i] = _a[i] + _b[i] * _c[i];
  }

  int8x8_t a = vld1_s8(_a);
  int8x8_t b = vld1_s8(_b);
  int8x8_t c = vld1_s8(_c);
  int8x8_t d = vmla_s8(a, b, c);
  return validate_int8(d, _d[0], _d[1], _d[2], _d[3], _d[4], _d[5], _d[6], _d[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmla_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  const int16_t *_c = (int16_t *)impl.test_cases_int_pointer3;
  int16_t _d[4];
  for (int i = 0; i < 4; i++) {
    _d[i] = _a[i] + _b[i] * _c[i];
  }

  int16x4_t a = vld1_s16(_a);
  int16x4_t b = vld1_s16(_b);
  int16x4_t c = vld1_s16(_c);
  int16x4_t d = vmla_s16(a, b, c);
  return validate_int16(d, _d[0], _d[1], _d[2], _d[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmla_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  const int32_t *_c = (int32_t *)impl.test_cases_int_pointer3;
  int32_t _d[2];
  for (int i = 0; i < 2; i++) {
    _d[i] = _a[i] + _b[i] * _c[i];
  }

  int32x2_t a = vld1_s32(_a);
  int32x2_t b = vld1_s32(_b);
  int32x2_t c = vld1_s32(_c);
  int32x2_t d = vmla_s32(a, b, c);
  return validate_int32(d, _d[0], _d[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmla_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (float *)impl.test_cases_float_pointer1;
  const float *_b = (float *)impl.test_cases_float_pointer2;
  const float *_c = (float *)impl.test_cases_float_pointer3;
  float _d[2];
  for (int i = 0; i < 2; i++) {
    _d[i] = _a[i] + _b[i] * _c[i];
  }

  float32x2_t a = vld1_f32(_a);
  float32x2_t b = vld1_f32(_b);
  float32x2_t c = vld1_f32(_c);
  float32x2_t d = vmla_f32(a, b, c);
  return validate_float_error(d, _d[0], _d[1], 0.0001f);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmla_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (uint8_t *)impl.test_cases_int_pointer2;
  const uint8_t *_c = (uint8_t *)impl.test_cases_int_pointer3;
  uint8_t _d[8];
  for (int i = 0; i < 8; i++) {
    _d[i] = _a[i] + _b[i] * _c[i];
  }

  uint8x8_t a = vld1_u8(_a);
  uint8x8_t b = vld1_u8(_b);
  uint8x8_t c = vld1_u8(_c);
  uint8x8_t d = vmla_u8(a, b, c);
  return validate_uint8(d, _d[0], _d[1], _d[2], _d[3], _d[4], _d[5], _d[6], _d[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmla_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (uint16_t *)impl.test_cases_int_pointer2;
  const uint16_t *_c = (uint16_t *)impl.test_cases_int_pointer3;
  uint16_t _d[4];
  for (int i = 0; i < 4; i++) {
    _d[i] = _a[i] + _b[i] * _c[i];
  }

  uint16x4_t a = vld1_u16(_a);
  uint16x4_t b = vld1_u16(_b);
  uint16x4_t c = vld1_u16(_c);
  uint16x4_t d = vmla_u16(a, b, c);
  return validate_uint16(d, _d[0], _d[1], _d[2], _d[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmla_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (uint32_t *)impl.test_cases_int_pointer2;
  const uint32_t *_c = (uint32_t *)impl.test_cases_int_pointer3;
  uint32_t _d[2];
  for (int i = 0; i < 2; i++) {
    _d[i] = _a[i] + _b[i] * _c[i];
  }

  uint32x2_t a = vld1_u32(_a);
  uint32x2_t b = vld1_u32(_b);
  uint32x2_t c = vld1_u32(_c);
  uint32x2_t d = vmla_u32(a, b, c);
  return validate_uint32(d, _d[0], _d[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmlaq_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (int8_t *)impl.test_cases_int_pointer2;
  const int8_t *_c = (int8_t *)impl.test_cases_int_pointer3;
  int8_t _d[16];
  for (int i = 0; i < 16; i++) {
    _d[i] = _a[i] + _b[i] * _c[i];
  }

  int8x16_t b = vld1q_s8(_b);
  int8x16_t a = vld1q_s8(_a);
  int8x16_t c = vld1q_s8(_c);
  int8x16_t d = vmlaq_s8(a, b, c);
  return validate_int8(d, _d[0], _d[1], _d[2], _d[3], _d[4], _d[5], _d[6], _d[7], _d[8], _d[9], _d[10], _d[11], _d[12],
                       _d[13], _d[14], _d[15]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmlaq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  const int16_t *_c = (int16_t *)impl.test_cases_int_pointer3;
  int16_t _d[8];
  for (int i = 0; i < 8; i++) {
    _d[i] = _a[i] + _b[i] * _c[i];
  }

  int16x8_t a = vld1q_s16(_a);
  int16x8_t b = vld1q_s16(_b);
  int16x8_t c = vld1q_s16(_c);
  int16x8_t d = vmlaq_s16(a, b, c);
  return validate_int16(d, _d[0], _d[1], _d[2], _d[3], _d[4], _d[5], _d[6], _d[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmlaq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  const int32_t *_c = (int32_t *)impl.test_cases_int_pointer3;
  int32_t _d[4];
  for (int i = 0; i < 4; i++) {
    _d[i] = _a[i] + _b[i] * _c[i];
  }

  int32x4_t a = vld1q_s32(_a);
  int32x4_t b = vld1q_s32(_b);
  int32x4_t c = vld1q_s32(_c);
  int32x4_t d = vmlaq_s32(a, b, c);
  return validate_int32(d, _d[0], _d[1], _d[2], _d[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmlaq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (float *)impl.test_cases_float_pointer1;
  const float *_b = (float *)impl.test_cases_float_pointer2;
  const float *_c = (float *)impl.test_cases_float_pointer3;
  float _d[4];
  for (int i = 0; i < 4; i++) {
    _d[i] = _a[i] + _b[i] * _c[i];
  }

  float32x4_t a = vld1q_f32(_a);
  float32x4_t b = vld1q_f32(_b);
  float32x4_t c = vld1q_f32(_c);
  float32x4_t d = vmlaq_f32(a, b, c);
  return validate_float_error(d, _d[0], _d[1], _d[2], _d[3], 0.0001f);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmla_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const double *_a = (double *)impl.test_cases_float_pointer1;
  const double *_b = (double *)impl.test_cases_float_pointer2;
  const double *_c = (double *)impl.test_cases_float_pointer3;
  double _d[1];
  for (int i = 0; i < 1; i++) {
    _d[i] = _a[i] + _b[i] * _c[i];
  }

  float64x1_t a = vld1_f64(_a);
  float64x1_t b = vld1_f64(_b);
  float64x1_t c = vld1_f64(_c);
  float64x1_t d = vmla_f64(a, b, c);
  return validate_double_error(d, _d[0], 0.0001f);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmlaq_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const double *_a = (double *)impl.test_cases_float_pointer1;
  const double *_b = (double *)impl.test_cases_float_pointer2;
  const double *_c = (double *)impl.test_cases_float_pointer3;
  double _d[2];
  for (int i = 0; i < 2; i++) {
    _d[i] = _a[i] + _b[i] * _c[i];
  }

  float64x2_t a = vld1q_f64(_a);
  float64x2_t b = vld1q_f64(_b);
  float64x2_t c = vld1q_f64(_c);
  float64x2_t d = vmlaq_f64(a, b, c);
  return validate_double_error(d, _d[0], _d[1], 0.0001f);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmlaq_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (uint8_t *)impl.test_cases_int_pointer2;
  const uint8_t *_c = (uint8_t *)impl.test_cases_int_pointer3;
  uint8_t _d[16];
  for (int i = 0; i < 16; i++) {
    _d[i] = _a[i] + _b[i] * _c[i];
  }

  uint8x16_t a = vld1q_u8(_a);
  uint8x16_t b = vld1q_u8(_b);
  uint8x16_t c = vld1q_u8(_c);
  uint8x16_t d = vmlaq_u8(a, b, c);
  return validate_uint8(d, _d[0], _d[1], _d[2], _d[3], _d[4], _d[5], _d[6], _d[7], _d[8], _d[9], _d[10], _d[11], _d[12],
                        _d[13], _d[14], _d[15]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmlaq_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (uint16_t *)impl.test_cases_int_pointer2;
  const uint16_t *_c = (uint16_t *)impl.test_cases_int_pointer3;
  uint16_t _d[8];
  for (int i = 0; i < 8; i++) {
    _d[i] = _a[i] + _b[i] * _c[i];
  }

  uint16x8_t a = vld1q_u16(_a);
  uint16x8_t b = vld1q_u16(_b);
  uint16x8_t c = vld1q_u16(_c);
  uint16x8_t d = vmlaq_u16(a, b, c);
  return validate_uint16(d, _d[0], _d[1], _d[2], _d[3], _d[4], _d[5], _d[6], _d[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmlaq_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (uint32_t *)impl.test_cases_int_pointer2;
  const uint32_t *_c = (uint32_t *)impl.test_cases_int_pointer3;
  uint32_t _d[4];
  for (int i = 0; i < 4; i++) {
    _d[i] = _a[i] + _b[i] * _c[i];
  }

  uint32x4_t a = vld1q_u32(_a);
  uint32x4_t b = vld1q_u32(_b);
  uint32x4_t c = vld1q_u32(_c);
  uint32x4_t d = vmlaq_u32(a, b, c);
  return validate_uint32(d, _d[0], _d[1], _d[2], _d[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmlal_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (int8_t *)impl.test_cases_int_pointer2;
  const int8_t *_c = (int8_t *)impl.test_cases_int_pointer3;
  int16_t _d[8];
  for (int i = 0; i < 8; i++) {
    _d[i] = _a[i] + (int16_t)_b[i] * (int16_t)_c[i];
  }

  int16x8_t a = vld1q_s16(_a);
  int8x8_t b = vld1_s8(_b);
  int8x8_t c = vld1_s8(_c);
  int16x8_t d = vmlal_s8(a, b, c);
  return validate_int16(d, _d[0], _d[1], _d[2], _d[3], _d[4], _d[5], _d[6], _d[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmlal_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  const int16_t *_c = (int16_t *)impl.test_cases_int_pointer3;
  int32_t _d[4];
  for (int i = 0; i < 4; i++) {
    _d[i] = _a[i] + (int32_t)_b[i] * (int32_t)_c[i];
  }

  int32x4_t a = vld1q_s32(_a);
  int16x4_t b = vld1_s16(_b);
  int16x4_t c = vld1_s16(_c);
  int32x4_t d = vmlal_s16(a, b, c);
  return validate_int32(d, _d[0], _d[1], _d[2], _d[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmlal_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (int64_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  const int32_t *_c = (int32_t *)impl.test_cases_int_pointer3;
  int64_t _d[2];
  for (int i = 0; i < 2; i++) {
    _d[i] = _a[i] + (int64_t)_b[i] * (int64_t)_c[i];
  }

  int64x2_t a = vld1q_s64(_a);
  int32x2_t b = vld1_s32(_b);
  int32x2_t c = vld1_s32(_c);
  int64x2_t d = vmlal_s32(a, b, c);
  return validate_int64(d, _d[0], _d[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmlal_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (uint8_t *)impl.test_cases_int_pointer2;
  const uint8_t *_c = (uint8_t *)impl.test_cases_int_pointer3;
  uint16_t _d[8];
  for (int i = 0; i < 8; i++) {
    _d[i] = _a[i] + (uint16_t)_b[i] * (uint16_t)_c[i];
  }

  uint16x8_t a = vld1q_u16(_a);
  uint8x8_t b = vld1_u8(_b);
  uint8x8_t c = vld1_u8(_c);
  uint16x8_t d = vmlal_u8(a, b, c);
  return validate_uint16(d, _d[0], _d[1], _d[2], _d[3], _d[4], _d[5], _d[6], _d[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmlal_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (uint16_t *)impl.test_cases_int_pointer2;
  const uint16_t *_c = (uint16_t *)impl.test_cases_int_pointer3;
  uint32_t _d[4];
  for (int i = 0; i < 4; i++) {
    _d[i] = _a[i] + (uint32_t)_b[i] * (uint32_t)_c[i];
  }

  uint32x4_t a = vld1q_u32(_a);
  uint16x4_t b = vld1_u16(_b);
  uint16x4_t c = vld1_u16(_c);
  uint32x4_t d = vmlal_u16(a, b, c);
  return validate_uint32(d, _d[0], _d[1], _d[2], _d[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmlal_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (uint64_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (uint32_t *)impl.test_cases_int_pointer2;
  const uint32_t *_c = (uint32_t *)impl.test_cases_int_pointer3;
  uint64_t _d[2];
  for (int i = 0; i < 2; i++) {
    _d[i] = _a[i] + (uint64_t)_b[i] * (uint64_t)_c[i];
  }

  uint64x2_t a = vld1q_u64(_a);
  uint32x2_t b = vld1_u32(_b);
  uint32x2_t c = vld1_u32(_c);
  uint64x2_t d = vmlal_u32(a, b, c);
  return validate_uint64(d, _d[0], _d[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmlal_high_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (int8_t *)impl.test_cases_int_pointer2;
  const int8_t *_c = (int8_t *)impl.test_cases_int_pointer3;
  int16_t _d[8];
  for (int i = 0; i < 8; i++) {
    _d[i] = _a[i] + (int16_t)_b[i + 8] * (int16_t)_c[i + 8];
  }

  int16x8_t a = vld1q_s16(_a);
  int8x16_t b = vld1q_s8(_b);
  int8x16_t c = vld1q_s8(_c);
  int16x8_t d = vmlal_high_s8(a, b, c);
  return validate_int16(d, _d[0], _d[1], _d[2], _d[3], _d[4], _d[5], _d[6], _d[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmlal_high_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  const int16_t *_c = (int16_t *)impl.test_cases_int_pointer3;
  int32_t _d[4];
  for (int i = 0; i < 4; i++) {
    _d[i] = _a[i] + (int32_t)_b[i + 4] * (int32_t)_c[i + 4];
  }

  int32x4_t a = vld1q_s32(_a);
  int16x8_t b = vld1q_s16(_b);
  int16x8_t c = vld1q_s16(_c);
  int32x4_t d = vmlal_high_s16(a, b, c);
  return validate_int32(d, _d[0], _d[1], _d[2], _d[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmlal_high_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (int64_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  const int32_t *_c = (int32_t *)impl.test_cases_int_pointer3;
  int64_t _d[2];
  for (int i = 0; i < 2; i++) {
    _d[i] = _a[i] + (int64_t)_b[i + 2] * (int64_t)_c[i + 2];
  }

  int64x2_t a = vld1q_s64(_a);
  int32x4_t b = vld1q_s32(_b);
  int32x4_t c = vld1q_s32(_c);
  int64x2_t d = vmlal_high_s32(a, b, c);
  return validate_int64(d, _d[0], _d[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmlal_high_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (uint8_t *)impl.test_cases_int_pointer2;
  const uint8_t *_c = (uint8_t *)impl.test_cases_int_pointer3;
  uint16_t _d[8];
  for (int i = 0; i < 8; i++) {
    _d[i] = _a[i] + (uint16_t)_b[i + 8] * (uint16_t)_c[i + 8];
  }

  uint16x8_t a = vld1q_u16(_a);
  uint8x16_t b = vld1q_u8(_b);
  uint8x16_t c = vld1q_u8(_c);
  uint16x8_t d = vmlal_high_u8(a, b, c);
  return validate_uint16(d, _d[0], _d[1], _d[2], _d[3], _d[4], _d[5], _d[6], _d[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmlal_high_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (uint16_t *)impl.test_cases_int_pointer2;
  const uint16_t *_c = (uint16_t *)impl.test_cases_int_pointer3;
  uint32_t _d[4];
  for (int i = 0; i < 4; i++) {
    _d[i] = _a[i] + (uint32_t)_b[i + 4] * (uint32_t)_c[i + 4];
  }

  uint32x4_t a = vld1q_u32(_a);
  uint16x8_t b = vld1q_u16(_b);
  uint16x8_t c = vld1q_u16(_c);
  uint32x4_t d = vmlal_high_u16(a, b, c);
  return validate_uint32(d, _d[0], _d[1], _d[2], _d[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmlal_high_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (uint64_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (uint32_t *)impl.test_cases_int_pointer2;
  const uint32_t *_c = (uint32_t *)impl.test_cases_int_pointer3;
  uint64_t _d[2];
  for (int i = 0; i < 2; i++) {
    _d[i] = _a[i] + (uint64_t)_b[i + 2] * (uint64_t)_c[i + 2];
  }

  uint64x2_t a = vld1q_u64(_a);
  uint32x4_t b = vld1q_u32(_b);
  uint32x4_t c = vld1q_u32(_c);
  uint64x2_t d = vmlal_high_u32(a, b, c);
  return validate_uint64(d, _d[0], _d[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqdmlal_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  const int16_t *_c = (int16_t *)impl.test_cases_int_pointer3;
  int32_t _d[4];
  for (int i = 0; i < 4; i++) {
    int32_t bcx2 = saturate_int32(2 * _b[i] * _c[i]);
    _d[i] = saturate_int32(_a[i] + bcx2);
  }

  int32x4_t a = vld1q_s32(_a);
  int16x4_t b = vld1_s16(_b);
  int16x4_t c = vld1_s16(_c);
  int32x4_t d = vqdmlal_s16(a, b, c);
  return validate_int32(d, _d[0], _d[1], _d[2], _d[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqdmlal_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (int64_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  const int32_t *_c = (int32_t *)impl.test_cases_int_pointer3;
  int64_t _d[2];
  for (int i = 0; i < 2; i++) {
    int64_t tmp = (((int64_t)_b[i] * (int64_t)_c[i]) >> 32) * 2 + (_a[i] >> 32);
    if (tmp > INT64_MAX) {
      _d[i] = INT64_MAX;
    } else if (tmp < INT64_MIN) {
      _d[i] = INT64_MIN;
    } else {
      _d[i] = (int64_t)_b[i] * (int64_t)_c[i] * 2 + _a[i];
    }
  }

  int64x2_t a = vld1q_s64(_a);
  int32x2_t b = vld1_s32(_b);
  int32x2_t c = vld1_s32(_c);
  int64x2_t d = vqdmlal_s32(a, b, c);
  return validate_int64(d, _d[0], _d[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqdmlalh_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqdmlals_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqdmlal_high_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqdmlal_high_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmls_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (int8_t *)impl.test_cases_int_pointer2;
  const int8_t *_c = (int8_t *)impl.test_cases_int_pointer3;
  int8_t _d[8];
  for (int i = 0; i < 8; i++) {
    _d[i] = _a[i] - _b[i] * _c[i];
  }

  int8x8_t b = vld1_s8(_b);
  int8x8_t a = vld1_s8(_a);
  int8x8_t c = vld1_s8(_c);
  int8x8_t d = vmls_s8(a, b, c);
  return validate_int8(d, _d[0], _d[1], _d[2], _d[3], _d[4], _d[5], _d[6], _d[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmls_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  const int16_t *_c = (int16_t *)impl.test_cases_int_pointer3;
  int16_t _d[4];
  for (int i = 0; i < 4; i++) {
    _d[i] = _a[i] - _b[i] * _c[i];
  }

  int16x4_t a = vld1_s16(_a);
  int16x4_t b = vld1_s16(_b);
  int16x4_t c = vld1_s16(_c);
  int16x4_t d = vmls_s16(a, b, c);
  return validate_int16(d, _d[0], _d[1], _d[2], _d[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmls_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  const int32_t *_c = (int32_t *)impl.test_cases_int_pointer3;
  int32_t _d[2];
  for (int i = 0; i < 2; i++) {
    _d[i] = _a[i] - _b[i] * _c[i];
  }

  int32x2_t a = vld1_s32(_a);
  int32x2_t b = vld1_s32(_b);
  int32x2_t c = vld1_s32(_c);
  int32x2_t d = vmls_s32(a, b, c);
  return validate_int32(d, _d[0], _d[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmls_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (float *)impl.test_cases_float_pointer1;
  const float *_b = (float *)impl.test_cases_float_pointer2;
  const float *_c = (float *)impl.test_cases_float_pointer3;
  float _d[2];
  for (int i = 0; i < 2; i++) {
    _d[i] = _a[i] - _b[i] * _c[i];
  }

  float32x2_t a = vld1_f32(_a);
  float32x2_t b = vld1_f32(_b);
  float32x2_t c = vld1_f32(_c);
  float32x2_t d = vmls_f32(a, b, c);
  return validate_float_error(d, _d[0], _d[1], 0.0001f);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmls_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (uint8_t *)impl.test_cases_int_pointer2;
  const uint8_t *_c = (uint8_t *)impl.test_cases_int_pointer3;
  uint8_t _d[8];
  for (int i = 0; i < 8; i++) {
    _d[i] = _a[i] - _b[i] * _c[i];
  }

  uint8x8_t a = vld1_u8(_a);
  uint8x8_t b = vld1_u8(_b);
  uint8x8_t c = vld1_u8(_c);
  uint8x8_t d = vmls_u8(a, b, c);
  return validate_uint8(d, _d[0], _d[1], _d[2], _d[3], _d[4], _d[5], _d[6], _d[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmls_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (uint16_t *)impl.test_cases_int_pointer2;
  const uint16_t *_c = (uint16_t *)impl.test_cases_int_pointer3;
  uint16_t _d[4];
  for (int i = 0; i < 4; i++) {
    _d[i] = _a[i] - _b[i] * _c[i];
  }

  uint16x4_t a = vld1_u16(_a);
  uint16x4_t b = vld1_u16(_b);
  uint16x4_t c = vld1_u16(_c);
  uint16x4_t d = vmls_u16(a, b, c);
  return validate_uint16(d, _d[0], _d[1], _d[2], _d[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmls_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (uint32_t *)impl.test_cases_int_pointer2;
  const uint32_t *_c = (uint32_t *)impl.test_cases_int_pointer3;
  uint32_t _d[2];
  for (int i = 0; i < 2; i++) {
    _d[i] = _a[i] - _b[i] * _c[i];
  }

  uint32x2_t a = vld1_u32(_a);
  uint32x2_t b = vld1_u32(_b);
  uint32x2_t c = vld1_u32(_c);
  uint32x2_t d = vmls_u32(a, b, c);
  return validate_uint32(d, _d[0], _d[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmlsq_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (int8_t *)impl.test_cases_int_pointer2;
  const int8_t *_c = (int8_t *)impl.test_cases_int_pointer3;
  int8_t _d[16];
  for (int i = 0; i < 16; i++) {
    _d[i] = _a[i] - _b[i] * _c[i];
  }

  int8x16_t b = vld1q_s8(_b);
  int8x16_t a = vld1q_s8(_a);
  int8x16_t c = vld1q_s8(_c);
  int8x16_t d = vmlsq_s8(a, b, c);
  return validate_int8(d, _d[0], _d[1], _d[2], _d[3], _d[4], _d[5], _d[6], _d[7], _d[8], _d[9], _d[10], _d[11], _d[12],
                       _d[13], _d[14], _d[15]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmlsq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  const int16_t *_c = (int16_t *)impl.test_cases_int_pointer3;
  int16_t _d[8];
  for (int i = 0; i < 8; i++) {
    _d[i] = _a[i] - _b[i] * _c[i];
  }

  int16x8_t a = vld1q_s16(_a);
  int16x8_t b = vld1q_s16(_b);
  int16x8_t c = vld1q_s16(_c);
  int16x8_t d = vmlsq_s16(a, b, c);
  return validate_int16(d, _d[0], _d[1], _d[2], _d[3], _d[4], _d[5], _d[6], _d[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmlsq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  const int32_t *_c = (int32_t *)impl.test_cases_int_pointer3;
  int32_t _d[4];
  for (int i = 0; i < 4; i++) {
    _d[i] = _a[i] - _b[i] * _c[i];
  }

  int32x4_t a = vld1q_s32(_a);
  int32x4_t b = vld1q_s32(_b);
  int32x4_t c = vld1q_s32(_c);
  int32x4_t d = vmlsq_s32(a, b, c);
  return validate_int32(d, _d[0], _d[1], _d[2], _d[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmlsq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (float *)impl.test_cases_float_pointer1;
  const float *_b = (float *)impl.test_cases_float_pointer2;
  const float *_c = (float *)impl.test_cases_float_pointer3;
  float _d[4];
  for (int i = 0; i < 4; i++) {
    _d[i] = _a[i] - _b[i] * _c[i];
  }

  float32x4_t a = vld1q_f32(_a);
  float32x4_t b = vld1q_f32(_b);
  float32x4_t c = vld1q_f32(_c);
  float32x4_t d = vmlsq_f32(a, b, c);
  return validate_float_error(d, _d[0], _d[1], _d[2], _d[3], 0.0001f);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmls_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const double *_a = (double *)impl.test_cases_float_pointer1;
  const double *_b = (double *)impl.test_cases_float_pointer2;
  const double *_c = (double *)impl.test_cases_float_pointer3;
  double _d[1];
  for (int i = 0; i < 1; i++) {
    _d[i] = _a[i] - _b[i] * _c[i];
  }

  float64x1_t a = vld1_f64(_a);
  float64x1_t b = vld1_f64(_b);
  float64x1_t c = vld1_f64(_c);
  float64x1_t d = vmls_f64(a, b, c);
  return validate_double_error(d, _d[0], 0.0001f);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmlsq_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const double *_a = (double *)impl.test_cases_float_pointer1;
  const double *_b = (double *)impl.test_cases_float_pointer2;
  const double *_c = (double *)impl.test_cases_float_pointer3;
  double _d[2];
  for (int i = 0; i < 2; i++) {
    _d[i] = _a[i] - _b[i] * _c[i];
  }

  float64x2_t a = vld1q_f64(_a);
  float64x2_t b = vld1q_f64(_b);
  float64x2_t c = vld1q_f64(_c);
  float64x2_t d = vmlsq_f64(a, b, c);
  return validate_double_error(d, _d[0], _d[1], 0.0001f);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmlsq_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (uint8_t *)impl.test_cases_int_pointer2;
  const uint8_t *_c = (uint8_t *)impl.test_cases_int_pointer3;
  uint8_t _d[16];
  for (int i = 0; i < 16; i++) {
    _d[i] = _a[i] - _b[i] * _c[i];
  }

  uint8x16_t a = vld1q_u8(_a);
  uint8x16_t b = vld1q_u8(_b);
  uint8x16_t c = vld1q_u8(_c);
  uint8x16_t d = vmlsq_u8(a, b, c);
  return validate_uint8(d, _d[0], _d[1], _d[2], _d[3], _d[4], _d[5], _d[6], _d[7], _d[8], _d[9], _d[10], _d[11], _d[12],
                        _d[13], _d[14], _d[15]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmlsq_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (uint16_t *)impl.test_cases_int_pointer2;
  const uint16_t *_c = (uint16_t *)impl.test_cases_int_pointer3;
  uint16_t _d[8];
  for (int i = 0; i < 8; i++) {
    _d[i] = _a[i] - _b[i] * _c[i];
  }

  uint16x8_t a = vld1q_u16(_a);
  uint16x8_t b = vld1q_u16(_b);
  uint16x8_t c = vld1q_u16(_c);
  uint16x8_t d = vmlsq_u16(a, b, c);
  return validate_uint16(d, _d[0], _d[1], _d[2], _d[3], _d[4], _d[5], _d[6], _d[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmlsq_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (uint32_t *)impl.test_cases_int_pointer2;
  const uint32_t *_c = (uint32_t *)impl.test_cases_int_pointer3;
  uint32_t _d[4];
  for (int i = 0; i < 4; i++) {
    _d[i] = _a[i] - _b[i] * _c[i];
  }

  uint32x4_t a = vld1q_u32(_a);
  uint32x4_t b = vld1q_u32(_b);
  uint32x4_t c = vld1q_u32(_c);
  uint32x4_t d = vmlsq_u32(a, b, c);
  return validate_uint32(d, _d[0], _d[1], _d[2], _d[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmlsl_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (int8_t *)impl.test_cases_int_pointer2;
  const int8_t *_c = (int8_t *)impl.test_cases_int_pointer3;
  int16_t _d[8];
  for (int i = 0; i < 8; i++) {
    _d[i] = _a[i] - (int16_t)_b[i] * (int16_t)_c[i];
  }

  int16x8_t a = vld1q_s16(_a);
  int8x8_t b = vld1_s8(_b);
  int8x8_t c = vld1_s8(_c);
  int16x8_t d = vmlsl_s8(a, b, c);
  return validate_int16(d, _d[0], _d[1], _d[2], _d[3], _d[4], _d[5], _d[6], _d[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmlsl_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  const int16_t *_c = (int16_t *)impl.test_cases_int_pointer3;
  int32_t _d[4];
  for (int i = 0; i < 4; i++) {
    _d[i] = _a[i] - (int32_t)_b[i] * (int32_t)_c[i];
  }

  int32x4_t a = vld1q_s32(_a);
  int16x4_t b = vld1_s16(_b);
  int16x4_t c = vld1_s16(_c);
  int32x4_t d = vmlsl_s16(a, b, c);
  return validate_int32(d, _d[0], _d[1], _d[2], _d[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmlsl_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (int64_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  const int32_t *_c = (int32_t *)impl.test_cases_int_pointer3;
  int64_t _d[2];
  for (int i = 0; i < 2; i++) {
    _d[i] = _a[i] - (int64_t)_b[i] * (int64_t)_c[i];
  }

  int64x2_t a = vld1q_s64(_a);
  int32x2_t b = vld1_s32(_b);
  int32x2_t c = vld1_s32(_c);
  int64x2_t d = vmlsl_s32(a, b, c);
  return validate_int64(d, _d[0], _d[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmlsl_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (uint8_t *)impl.test_cases_int_pointer2;
  const uint8_t *_c = (uint8_t *)impl.test_cases_int_pointer3;
  uint16_t _d[8];
  for (int i = 0; i < 8; i++) {
    _d[i] = _a[i] - (uint16_t)_b[i] * (uint16_t)_c[i];
  }

  uint16x8_t a = vld1q_u16(_a);
  uint8x8_t b = vld1_u8(_b);
  uint8x8_t c = vld1_u8(_c);
  uint16x8_t d = vmlsl_u8(a, b, c);
  return validate_uint16(d, _d[0], _d[1], _d[2], _d[3], _d[4], _d[5], _d[6], _d[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmlsl_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (uint16_t *)impl.test_cases_int_pointer2;
  const uint16_t *_c = (uint16_t *)impl.test_cases_int_pointer3;
  uint32_t _d[4];
  for (int i = 0; i < 4; i++) {
    _d[i] = _a[i] - (uint32_t)_b[i] * (uint32_t)_c[i];
  }

  uint32x4_t a = vld1q_u32(_a);
  uint16x4_t b = vld1_u16(_b);
  uint16x4_t c = vld1_u16(_c);
  uint32x4_t d = vmlsl_u16(a, b, c);
  return validate_uint32(d, _d[0], _d[1], _d[2], _d[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmlsl_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (uint64_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (uint32_t *)impl.test_cases_int_pointer2;
  const uint32_t *_c = (uint32_t *)impl.test_cases_int_pointer3;
  uint64_t _d[2];
  for (int i = 0; i < 2; i++) {
    _d[i] = _a[i] - (uint64_t)_b[i] * (uint64_t)_c[i];
  }

  uint64x2_t a = vld1q_u64(_a);
  uint32x2_t b = vld1_u32(_b);
  uint32x2_t c = vld1_u32(_c);
  uint64x2_t d = vmlsl_u32(a, b, c);
  return validate_uint64(d, _d[0], _d[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmlsl_high_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (int8_t *)impl.test_cases_int_pointer2;
  const int8_t *_c = (int8_t *)impl.test_cases_int_pointer3;
  int16_t _d[8];
  for (int i = 0; i < 8; i++) {
    _d[i] = _a[i] - (int16_t)_b[i + 8] * (int16_t)_c[i + 8];
  }

  int16x8_t a = vld1q_s16(_a);
  int8x16_t b = vld1q_s8(_b);
  int8x16_t c = vld1q_s8(_c);
  int16x8_t d = vmlsl_high_s8(a, b, c);
  return validate_int16(d, _d[0], _d[1], _d[2], _d[3], _d[4], _d[5], _d[6], _d[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmlsl_high_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  const int16_t *_c = (int16_t *)impl.test_cases_int_pointer3;
  int32_t _d[4];
  for (int i = 0; i < 4; i++) {
    _d[i] = _a[i] - (int32_t)_b[i + 4] * (int32_t)_c[i + 4];
  }

  int32x4_t a = vld1q_s32(_a);
  int16x8_t b = vld1q_s16(_b);
  int16x8_t c = vld1q_s16(_c);
  int32x4_t d = vmlsl_high_s16(a, b, c);
  return validate_int32(d, _d[0], _d[1], _d[2], _d[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmlsl_high_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (int64_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  const int32_t *_c = (int32_t *)impl.test_cases_int_pointer3;
  int64_t _d[2];
  for (int i = 0; i < 2; i++) {
    _d[i] = _a[i] - (int64_t)_b[i + 2] * (int64_t)_c[i + 2];
  }

  int64x2_t a = vld1q_s64(_a);
  int32x4_t b = vld1q_s32(_b);
  int32x4_t c = vld1q_s32(_c);
  int64x2_t d = vmlsl_high_s32(a, b, c);
  return validate_int64(d, _d[0], _d[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmlsl_high_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (uint8_t *)impl.test_cases_int_pointer2;
  const uint8_t *_c = (uint8_t *)impl.test_cases_int_pointer3;
  uint16_t _d[8];
  for (int i = 0; i < 8; i++) {
    _d[i] = _a[i] - (uint16_t)_b[i + 8] * (uint16_t)_c[i + 8];
  }

  uint16x8_t a = vld1q_u16(_a);
  uint8x16_t b = vld1q_u8(_b);
  uint8x16_t c = vld1q_u8(_c);
  uint16x8_t d = vmlsl_high_u8(a, b, c);
  return validate_uint16(d, _d[0], _d[1], _d[2], _d[3], _d[4], _d[5], _d[6], _d[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmlsl_high_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (uint16_t *)impl.test_cases_int_pointer2;
  const uint16_t *_c = (uint16_t *)impl.test_cases_int_pointer3;
  uint32_t _d[4];
  for (int i = 0; i < 4; i++) {
    _d[i] = _a[i] - (uint32_t)_b[i + 4] * (uint32_t)_c[i + 4];
  }

  uint32x4_t a = vld1q_u32(_a);
  uint16x8_t b = vld1q_u16(_b);
  uint16x8_t c = vld1q_u16(_c);
  uint32x4_t d = vmlsl_high_u16(a, b, c);
  return validate_uint32(d, _d[0], _d[1], _d[2], _d[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmlsl_high_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (uint64_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (uint32_t *)impl.test_cases_int_pointer2;
  const uint32_t *_c = (uint32_t *)impl.test_cases_int_pointer3;
  uint64_t _d[2];
  for (int i = 0; i < 2; i++) {
    _d[i] = _a[i] - (uint64_t)_b[i + 2] * (uint64_t)_c[i + 2];
  }

  uint64x2_t a = vld1q_u64(_a);
  uint32x4_t b = vld1q_u32(_b);
  uint32x4_t c = vld1q_u32(_c);
  uint64x2_t d = vmlsl_high_u32(a, b, c);
  return validate_uint64(d, _d[0], _d[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqdmlsl_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  const int16_t *_c = (int16_t *)impl.test_cases_int_pointer3;
  int32_t _d[4];
  for (int i = 0; i < 4; i++) {
    int32_t bcx2 = saturate_int32(2 * _b[i] * _c[i]);
    _d[i] = saturate_int32(_a[i] - bcx2);
  }

  int32x4_t a = vld1q_s32(_a);
  int16x4_t b = vld1_s16(_b);
  int16x4_t c = vld1_s16(_c);
  int32x4_t d = vqdmlsl_s16(a, b, c);
  return validate_int32(d, _d[0], _d[1], _d[2], _d[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqdmlsl_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (int64_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  const int32_t *_c = (int32_t *)impl.test_cases_int_pointer3;
  int64_t _d[2];
  float max_f = (float)INT64_MAX, min_f = (float)INT64_MIN;
  for (int i = 0; i < 2; i++) {
    float b_f = _b[i];
    float c_f = _c[i];
    int64_t tmp;
    if ((b_f * c_f > 0) && (2 * b_f * c_f > max_f)) {
      tmp = INT64_MAX;
    } else if (2 * b_f * c_f < min_f) {
      tmp = INT64_MIN;
    } else {
      tmp = 2 * (int64_t)_b[i] * (int64_t)_c[i];
    }
    if ((tmp > 0 && _a[i] < INT64_MIN + tmp) || (tmp < 0 && _a[i] > INT64_MAX + tmp)) {
      _d[i] = (tmp > 0) ? INT64_MAX : INT64_MIN;
    } else {
      _d[i] = (int64_t)_a[i] - tmp;
    }
  }

  int64x2_t a = vld1q_s64(_a);
  int32x2_t b = vld1_s32(_b);
  int32x2_t c = vld1_s32(_c);
  int64x2_t d = vqdmlsl_s32(a, b, c);
  return validate_int64(d, _d[0], _d[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqdmlslh_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqdmlsls_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqdmlsl_high_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqdmlsl_high_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vfma_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (float *)impl.test_cases_float_pointer1;
  const float *_b = (float *)impl.test_cases_float_pointer2;
  const float *_c = (float *)impl.test_cases_float_pointer3;
  float _d[2];
  for (int i = 0; i < 2; i++) {
    _d[i] = _a[i] + _b[i] * _c[i];
  }

  float32x2_t a = vld1_f32(_a);
  float32x2_t b = vld1_f32(_b);
  float32x2_t c = vld1_f32(_c);
  float32x2_t d = vfma_f32(a, b, c);
  return validate_float_error(d, _d[0], _d[1], 0.001f);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vfmaq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (float *)impl.test_cases_float_pointer1;
  const float *_b = (float *)impl.test_cases_float_pointer2;
  const float *_c = (float *)impl.test_cases_float_pointer3;
  float _d[4];
  for (int i = 0; i < 4; i++) {
    _d[i] = _a[i] + _b[i] * _c[i];
  }

  float32x4_t a = vld1q_f32(_a);
  float32x4_t b = vld1q_f32(_b);
  float32x4_t c = vld1q_f32(_c);
  float32x4_t d = vfmaq_f32(a, b, c);
  return validate_float_error(d, _d[0], _d[1], _d[2], _d[3], 0.001f);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vfma_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const double *_a = (double *)impl.test_cases_float_pointer1;
  const double *_b = (double *)impl.test_cases_float_pointer2;
  const double *_c = (double *)impl.test_cases_float_pointer3;
  double _d[1];
  for (int i = 0; i < 1; i++) {
    _d[i] = _a[i] + _b[i] * _c[i];
  }

  float64x1_t a = vld1_f64(_a);
  float64x1_t b = vld1_f64(_b);
  float64x1_t c = vld1_f64(_c);
  float64x1_t d = vfma_f64(a, b, c);
  return validate_double_error(d, _d[0], 0.001f);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vfmaq_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const double *_a = (double *)impl.test_cases_float_pointer1;
  const double *_b = (double *)impl.test_cases_float_pointer2;
  const double *_c = (double *)impl.test_cases_float_pointer3;
  double _d[2];
  for (int i = 0; i < 2; i++) {
    _d[i] = _a[i] + _b[i] * _c[i];
  }

  float64x2_t a = vld1q_f64(_a);
  float64x2_t b = vld1q_f64(_b);
  float64x2_t c = vld1q_f64(_c);
  float64x2_t d = vfmaq_f64(a, b, c);
  return validate_double_error(d, _d[0], _d[1], 0.001f);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vfma_lane_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vfmaq_lane_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vfma_lane_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vfmaq_lane_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vfmas_lane_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vfmad_lane_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vfma_laneq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vfmaq_laneq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vfma_laneq_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vfmaq_laneq_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vfmas_laneq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vfmad_laneq_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vfms_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (float *)impl.test_cases_float_pointer1;
  const float *_b = (float *)impl.test_cases_float_pointer2;
  const float *_c = (float *)impl.test_cases_float_pointer3;
  float _d[2];
  for (int i = 0; i < 2; i++) {
    _d[i] = _a[i] - _b[i] * _c[i];
  }

  float32x2_t a = vld1_f32(_a);
  float32x2_t b = vld1_f32(_b);
  float32x2_t c = vld1_f32(_c);
  float32x2_t d = vfms_f32(a, b, c);
  return validate_float_error(d, _d[0], _d[1], 0.001f);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vfmsq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (float *)impl.test_cases_float_pointer1;
  const float *_b = (float *)impl.test_cases_float_pointer2;
  const float *_c = (float *)impl.test_cases_float_pointer3;
  float _d[4];
  for (int i = 0; i < 4; i++) {
    _d[i] = _a[i] - _b[i] * _c[i];
  }

  float32x4_t a = vld1q_f32(_a);
  float32x4_t b = vld1q_f32(_b);
  float32x4_t c = vld1q_f32(_c);
  float32x4_t d = vfmsq_f32(a, b, c);
  return validate_float_error(d, _d[0], _d[1], _d[2], _d[3], 0.001f);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vfms_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vfmsq_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vfms_lane_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vfmsq_lane_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vfms_lane_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vfmsq_lane_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vfmss_lane_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vfmsd_lane_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vfms_laneq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vfmsq_laneq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vfms_laneq_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vfmsq_laneq_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vfmss_laneq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vfmsd_laneq_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrndn_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (float *)impl.test_cases_float_pointer1;
  float _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = bankers_rounding(_a[i]);
  }

  float32x2_t a = vld1_f32(_a);
  float32x2_t c = vrndn_f32(a);
  return validate_float(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrndnq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (float *)impl.test_cases_float_pointer1;
  float _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = bankers_rounding(_a[i]);
  }

  float32x4_t a = vld1q_f32(_a);
  float32x4_t c = vrndnq_f32(a);
  return validate_float(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrndn_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrndnq_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrndns_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrnda_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (float *)impl.test_cases_float_pointer1;
  float _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = round(_a[i]);
  }

  float32x2_t a = vld1_f32(_a);
  float32x2_t c = vrnda_f32(a);
  return validate_float(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrndaq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (float *)impl.test_cases_float_pointer1;
  float _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = round(_a[i]);
  }

  float32x4_t a = vld1q_f32(_a);
  float32x4_t c = vrndaq_f32(a);
  return validate_float(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrnda_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrndaq_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrndi_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrndiq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrndi_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrndiq_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrndp_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (float *)impl.test_cases_float_pointer1;
  float _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = ceil(_a[i]);
  }

  float32x2_t a = vld1_f32(_a);
  float32x2_t c = vrndp_f32(a);
  return validate_float(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrndpq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (float *)impl.test_cases_float_pointer1;
  float _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = ceil(_a[i]);
  }

  float32x4_t a = vld1q_f32(_a);
  float32x4_t c = vrndpq_f32(a);
  return validate_float(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrndp_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrndpq_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrndm_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (float *)impl.test_cases_float_pointer1;
  float _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = floor(_a[i]);
  }

  float32x2_t a = vld1_f32(_a);
  float32x2_t c = vrndm_f32(a);
  return validate_float(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrndmq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (float *)impl.test_cases_float_pointer1;
  float _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = floor(_a[i]);
  }

  float32x4_t a = vld1q_f32(_a);
  float32x4_t c = vrndmq_f32(a);
  return validate_float(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrndm_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrndmq_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrndx_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrndxq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrndx_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrndxq_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrnd_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (float *)impl.test_cases_float_pointer1;
  float _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = trunc(_a[i]);
  }

  float32x2_t a = vld1_f32(_a);
  float32x2_t c = vrnd_f32(a);
  return validate_float(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrndq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (float *)impl.test_cases_float_pointer1;
  float _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = trunc(_a[i]);
  }

  float32x4_t a = vld1q_f32(_a);
  float32x4_t c = vrndq_f32(a);
  return validate_float(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrnd_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrndq_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vsub_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (int8_t *)impl.test_cases_int_pointer2;
  int8_t _d[8];
  for (int i = 0; i < 8; i++) {
    _d[i] = _a[i] - _b[i];
  }

  int8x8_t a = vld1_s8(_a);
  int8x8_t b = vld1_s8(_b);
  int8x8_t c = vsub_s8(a, b);
  return validate_int8(c, _d[0], _d[1], _d[2], _d[3], _d[4], _d[5], _d[6], _d[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsub_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  int16_t _d[4];
  for (int i = 0; i < 4; i++) {
    _d[i] = _a[i] - _b[i];
  }

  int16x4_t a = vld1_s16(_a);
  int16x4_t b = vld1_s16(_b);
  int16x4_t c = vsub_s16(a, b);
  return validate_int16(c, _d[0], _d[1], _d[2], _d[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsub_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  int32_t _d[2];
  for (int i = 0; i < 2; i++) {
    _d[i] = _a[i] - _b[i];
  }

  int32x2_t a = vld1_s32(_a);
  int32x2_t b = vld1_s32(_b);
  int32x2_t c = vsub_s32(a, b);
  return validate_int32(c, _d[0], _d[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsub_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (float *)impl.test_cases_float_pointer1;
  const float *_b = (float *)impl.test_cases_float_pointer2;
  float _d[2];
  for (int i = 0; i < 2; i++) {
    _d[i] = _a[i] - _b[i];
  }

  float32x2_t a = vld1_f32(_a);
  float32x2_t b = vld1_f32(_b);
  float32x2_t c = vsub_f32(a, b);
  return validate_float(c, _d[0], _d[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsub_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (uint8_t *)impl.test_cases_int_pointer2;
  uint8_t _d[8];
  for (int i = 0; i < 8; i++) {
    _d[i] = _a[i] - _b[i];
  }

  uint8x8_t a = vld1_u8(_a);
  uint8x8_t b = vld1_u8(_b);
  uint8x8_t c = vsub_u8(a, b);
  return validate_uint8(c, _d[0], _d[1], _d[2], _d[3], _d[4], _d[5], _d[6], _d[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsub_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (uint16_t *)impl.test_cases_int_pointer2;
  uint16_t _d[4];
  for (int i = 0; i < 4; i++) {
    _d[i] = _a[i] - _b[i];
  }

  uint16x4_t a = vld1_u16(_a);
  uint16x4_t b = vld1_u16(_b);
  uint16x4_t c = vsub_u16(a, b);
  return validate_uint16(c, _d[0], _d[1], _d[2], _d[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsub_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (uint32_t *)impl.test_cases_int_pointer2;
  uint32_t _d[2];
  for (int i = 0; i < 2; i++) {
    _d[i] = _a[i] - _b[i];
  }

  uint32x2_t a = vld1_u32(_a);
  uint32x2_t b = vld1_u32(_b);
  uint32x2_t c = vsub_u32(a, b);
  return validate_uint32(c, _d[0], _d[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsub_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (int64_t *)impl.test_cases_int_pointer1;
  const int64_t *_b = (int64_t *)impl.test_cases_int_pointer2;
  int64_t _d[1];
  for (int i = 0; i < 1; i++) {
    _d[i] = _a[i] - _b[i];
  }

  int64x1_t a = vld1_s64(_a);
  int64x1_t b = vld1_s64(_b);
  int64x1_t c = vsub_s64(a, b);
  return validate_int64(c, _d[0]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsub_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (uint64_t *)impl.test_cases_int_pointer1;
  const uint64_t *_b = (uint64_t *)impl.test_cases_int_pointer2;
  uint64_t _d[1];
  for (int i = 0; i < 1; i++) {
    _d[i] = _a[i] - _b[i];
  }

  uint64x1_t a = vld1_u64(_a);
  uint64x1_t b = vld1_u64(_b);
  uint64x1_t c = vsub_u64(a, b);
  return validate_uint64(c, _d[0]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsubq_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (int8_t *)impl.test_cases_int_pointer2;
  int8_t _d[16];
  for (int i = 0; i < 16; i++) {
    _d[i] = _a[i] - _b[i];
  }

  int8x16_t a = vld1q_s8(_a);
  int8x16_t b = vld1q_s8(_b);
  int8x16_t c = vsubq_s8(a, b);
  return validate_int8(c, _d[0], _d[1], _d[2], _d[3], _d[4], _d[5], _d[6], _d[7], _d[8], _d[9], _d[10], _d[11], _d[12],
                       _d[13], _d[14], _d[15]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsubq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  int16_t _d[8];
  for (int i = 0; i < 8; i++) {
    _d[i] = _a[i] - _b[i];
  }

  int16x8_t a = vld1q_s16(_a);
  int16x8_t b = vld1q_s16(_b);
  int16x8_t c = vsubq_s16(a, b);
  return validate_int16(c, _d[0], _d[1], _d[2], _d[3], _d[4], _d[5], _d[6], _d[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsubq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  int32_t _d[4];
  for (int i = 0; i < 4; i++) {
    _d[i] = _a[i] - _b[i];
  }

  int32x4_t a = vld1q_s32(_a);
  int32x4_t b = vld1q_s32(_b);
  int32x4_t c = vsubq_s32(a, b);
  return validate_int32(c, _d[0], _d[1], _d[2], _d[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsubq_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (int64_t *)impl.test_cases_int_pointer1;
  const int64_t *_b = (int64_t *)impl.test_cases_int_pointer2;
  int64_t _d[2];
  for (int i = 0; i < 2; i++) {
    _d[i] = _a[i] - _b[i];
  }

  int64x2_t a = vld1q_s64(_a);
  int64x2_t b = vld1q_s64(_b);
  int64x2_t c = vsubq_s64(a, b);
  return validate_int64(c, _d[0], _d[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsubq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (float *)impl.test_cases_int_pointer1;
  const float *_b = (float *)impl.test_cases_int_pointer2;
  float _d[4];
  for (int i = 0; i < 4; i++) {
    _d[i] = _a[i] - _b[i];
  }

  float32x4_t a = vld1q_f32(_a);
  float32x4_t b = vld1q_f32(_b);
  float32x4_t c = vsubq_f32(a, b);
  return validate_float(c, _d[0], _d[1], _d[2], _d[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsub_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const double *_a = (double *)impl.test_cases_int_pointer1;
  const double *_b = (double *)impl.test_cases_int_pointer2;
  double _d[1];
  for (int i = 0; i < 1; i++) {
    _d[i] = _a[i] - _b[i];
  }

  float64x1_t a = vld1_f64(_a);
  float64x1_t b = vld1_f64(_b);
  float64x1_t c = vsub_f64(a, b);
  return validate_double(c, _d[0]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsubq_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const double *_a = (double *)impl.test_cases_int_pointer1;
  const double *_b = (double *)impl.test_cases_int_pointer2;
  double _d[2];
  for (int i = 0; i < 2; i++) {
    _d[i] = _a[i] - _b[i];
  }

  float64x2_t a = vld1q_f64(_a);
  float64x2_t b = vld1q_f64(_b);
  float64x2_t c = vsubq_f64(a, b);
  return validate_double(c, _d[0], _d[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsubd_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (int64_t *)impl.test_cases_int_pointer1;
  const int64_t *_b = (int64_t *)impl.test_cases_int_pointer2;
  int64_t _c = _a[0] - _b[0];

  int64_t c = vsubd_s64(_a[0], _b[0]);
  return c == _c ? TEST_SUCCESS : TEST_FAIL;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsubd_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (uint64_t *)impl.test_cases_int_pointer1;
  const uint64_t *_b = (uint64_t *)impl.test_cases_int_pointer2;
  uint64_t _c = _a[0] - _b[0];

  uint64_t c = vsubd_u64(_a[0], _b[0]);
  return c == _c ? TEST_SUCCESS : TEST_FAIL;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsubq_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (uint8_t *)impl.test_cases_int_pointer2;
  uint8_t _d[16];
  for (int i = 0; i < 16; i++) {
    _d[i] = _a[i] - _b[i];
  }

  uint8x16_t a = vld1q_u8(_a);
  uint8x16_t b = vld1q_u8(_b);
  uint8x16_t c = vsubq_u8(a, b);
  return validate_uint8(c, _d[0], _d[1], _d[2], _d[3], _d[4], _d[5], _d[6], _d[7], _d[8], _d[9], _d[10], _d[11], _d[12],
                        _d[13], _d[14], _d[15]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsubq_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (uint16_t *)impl.test_cases_int_pointer2;
  uint16_t _d[8];
  for (int i = 0; i < 8; i++) {
    _d[i] = _a[i] - _b[i];
  }

  uint16x8_t a = vld1q_u16(_a);
  uint16x8_t b = vld1q_u16(_b);
  uint16x8_t c = vsubq_u16(a, b);
  return validate_uint16(c, _d[0], _d[1], _d[2], _d[3], _d[4], _d[5], _d[6], _d[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsubq_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (uint32_t *)impl.test_cases_int_pointer2;
  uint32_t _d[4];
  for (int i = 0; i < 4; i++) {
    _d[i] = _a[i] - _b[i];
  }

  uint32x4_t a = vld1q_u32(_a);
  uint32x4_t b = vld1q_u32(_b);
  uint32x4_t c = vsubq_u32(a, b);
  return validate_uint32(c, _d[0], _d[1], _d[2], _d[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsubq_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (uint64_t *)impl.test_cases_int_pointer1;
  const uint64_t *_b = (uint64_t *)impl.test_cases_int_pointer2;
  uint64_t _d[2];
  for (int i = 0; i < 2; i++) {
    _d[i] = _a[i] - _b[i];
  }

  uint64x2_t a = vld1q_u64(_a);
  uint64x2_t b = vld1q_u64(_b);
  uint64x2_t c = vsubq_u64(a, b);
  return validate_uint64(c, _d[0], _d[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsubl_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (int8_t *)impl.test_cases_int_pointer2;
  int16_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = (int16_t)_a[i] - (int16_t)_b[i];
  }

  int8x8_t a = vld1_s8(_a);
  int8x8_t b = vld1_s8(_b);
  int16x8_t c = vsubl_s8(a, b);
  return validate_int16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsubl_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  int32_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = (int32_t)_a[i] - (int32_t)_b[i];
  }

  int16x4_t a = vld1_s16(_a);
  int16x4_t b = vld1_s16(_b);
  int32x4_t c = vsubl_s16(a, b);
  return validate_int32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsubl_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  int64_t _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = (int64_t)_a[i] - (int64_t)_b[i];
  }

  int32x2_t a = vld1_s32(_a);
  int32x2_t b = vld1_s32(_b);
  int64x2_t c = vsubl_s32(a, b);
  return validate_int64(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsubl_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (uint8_t *)impl.test_cases_int_pointer2;
  uint16_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = (uint16_t)_a[i] - (uint16_t)_b[i];
  }

  uint8x8_t a = vld1_u8(_a);
  uint8x8_t b = vld1_u8(_b);
  uint16x8_t c = vsubl_u8(a, b);
  return validate_uint16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsubl_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (uint16_t *)impl.test_cases_int_pointer2;
  uint32_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = (uint32_t)_a[i] - (uint32_t)_b[i];
  }

  uint16x4_t a = vld1_u16(_a);
  uint16x4_t b = vld1_u16(_b);
  uint32x4_t c = vsubl_u16(a, b);
  return validate_uint32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsubl_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (uint32_t *)impl.test_cases_int_pointer2;
  uint64_t _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = (uint64_t)_a[i] - (uint64_t)_b[i];
  }

  uint32x2_t a = vld1_u32(_a);
  uint32x2_t b = vld1_u32(_b);
  uint64x2_t c = vsubl_u32(a, b);
  return validate_uint64(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsubl_high_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (int8_t *)impl.test_cases_int_pointer2;
  int16_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = (int16_t)_a[i + 8] - (int16_t)_b[i + 8];
  }

  int8x16_t a = vld1q_s8(_a);
  int8x16_t b = vld1q_s8(_b);
  int16x8_t c = vsubl_high_s8(a, b);
  return validate_int16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsubl_high_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  int32_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = (int32_t)_a[i + 4] - (int32_t)_b[i + 4];
  }

  int16x8_t a = vld1q_s16(_a);
  int16x8_t b = vld1q_s16(_b);
  int32x4_t c = vsubl_high_s16(a, b);
  return validate_int32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsubl_high_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  int64_t _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = (int64_t)_a[i + 2] - (int64_t)_b[i + 2];
  }

  int32x4_t a = vld1q_s32(_a);
  int32x4_t b = vld1q_s32(_b);
  int64x2_t c = vsubl_high_s32(a, b);
  return validate_int64(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsubl_high_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (uint8_t *)impl.test_cases_int_pointer2;
  uint16_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = (uint16_t)_a[i + 8] - (uint16_t)_b[i + 8];
  }

  uint8x16_t a = vld1q_u8(_a);
  uint8x16_t b = vld1q_u8(_b);
  uint16x8_t c = vsubl_high_u8(a, b);
  return validate_uint16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsubl_high_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (uint16_t *)impl.test_cases_int_pointer2;
  uint32_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = (uint32_t)_a[i + 4] - (uint32_t)_b[i + 4];
  }

  uint16x8_t a = vld1q_u16(_a);
  uint16x8_t b = vld1q_u16(_b);
  uint32x4_t c = vsubl_high_u16(a, b);
  return validate_uint32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsubl_high_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (uint32_t *)impl.test_cases_int_pointer2;
  uint64_t _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = (uint64_t)_a[i + 2] - (uint64_t)_b[i + 2];
  }

  uint32x4_t a = vld1q_u32(_a);
  uint32x4_t b = vld1q_u32(_b);
  uint64x2_t c = vsubl_high_u32(a, b);
  return validate_uint64(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsubw_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (int8_t *)impl.test_cases_int_pointer2;
  int16_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = _a[i] - (int16_t)_b[i];
  }

  int16x8_t a = vld1q_s16(_a);
  int8x8_t b = vld1_s8(_b);
  int16x8_t c = vsubw_s8(a, b);
  return validate_int16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsubw_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  int32_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = _a[i] - (int32_t)_b[i];
  }

  int32x4_t a = vld1q_s32(_a);
  int16x4_t b = vld1_s16(_b);
  int32x4_t c = vsubw_s16(a, b);
  return validate_int32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsubw_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (int64_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  int64_t _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = _a[i] - (int64_t)_b[i];
  }

  int64x2_t a = vld1q_s64(_a);
  int32x2_t b = vld1_s32(_b);
  int64x2_t c = vsubw_s32(a, b);
  return validate_int64(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsubw_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (uint8_t *)impl.test_cases_int_pointer2;
  uint16_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = _a[i] - (uint16_t)_b[i];
  }

  uint16x8_t a = vld1q_u16(_a);
  uint8x8_t b = vld1_u8(_b);
  uint16x8_t c = vsubw_u8(a, b);
  return validate_uint16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsubw_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (uint16_t *)impl.test_cases_int_pointer2;
  uint32_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = _a[i] - (uint32_t)_b[i];
  }

  uint32x4_t a = vld1q_u32(_a);
  uint16x4_t b = vld1_u16(_b);
  uint32x4_t c = vsubw_u16(a, b);
  return validate_uint32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsubw_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (uint64_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (uint32_t *)impl.test_cases_int_pointer2;
  uint64_t _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = _a[i] - (uint64_t)_b[i];
  }

  uint64x2_t a = vld1q_u64(_a);
  uint32x2_t b = vld1_u32(_b);
  uint64x2_t c = vsubw_u32(a, b);
  return validate_uint64(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsubw_high_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (int8_t *)impl.test_cases_int_pointer2;
  int16_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = _a[i] - (int16_t)_b[i + 8];
  }

  int16x8_t a = vld1q_s16(_a);
  int8x16_t b = vld1q_s8(_b);
  int16x8_t c = vsubw_high_s8(a, b);
  return validate_int16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsubw_high_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  int32_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = _a[i] - (int32_t)_b[i + 4];
  }

  int32x4_t a = vld1q_s32(_a);
  int16x8_t b = vld1q_s16(_b);
  int32x4_t c = vsubw_high_s16(a, b);
  return validate_int32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsubw_high_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (int64_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  int64_t _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = _a[i] - (int64_t)_b[i + 2];
  }

  int64x2_t a = vld1q_s64(_a);
  int32x4_t b = vld1q_s32(_b);
  int64x2_t c = vsubw_high_s32(a, b);
  return validate_int64(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsubw_high_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (uint8_t *)impl.test_cases_int_pointer2;
  uint16_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = _a[i] - (uint16_t)_b[i + 8];
  }

  uint16x8_t a = vld1q_u16(_a);
  uint8x16_t b = vld1q_u8(_b);
  uint16x8_t c = vsubw_high_u8(a, b);
  return validate_uint16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsubw_high_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (uint16_t *)impl.test_cases_int_pointer2;
  uint32_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = _a[i] - (uint32_t)_b[i + 4];
  }

  uint32x4_t a = vld1q_u32(_a);
  uint16x8_t b = vld1q_u16(_b);
  uint32x4_t c = vsubw_high_u16(a, b);
  return validate_uint32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsubw_high_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (uint64_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (uint32_t *)impl.test_cases_int_pointer2;
  uint64_t _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = _a[i] - (uint64_t)_b[i + 2];
  }

  uint64x2_t a = vld1q_u64(_a);
  uint32x4_t b = vld1q_u32(_b);
  uint64x2_t c = vsubw_high_u32(a, b);
  return validate_uint64(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vhsub_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (const int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (const int8_t *)impl.test_cases_int_pointer2;
  int8_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = (_a[i] - _b[i]) >> 1;
  }

  int8x8_t a = vld1_s8(_a);
  int8x8_t b = vld1_s8(_b);
  int8x8_t c = vhsub_s8(a, b);
  return validate_int8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vhsub_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (const int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (const int16_t *)impl.test_cases_int_pointer2;
  int16_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = (_a[i] - _b[i]) >> 1;
  }

  int16x4_t a = vld1_s16(_a);
  int16x4_t b = vld1_s16(_b);
  int16x4_t c = vhsub_s16(a, b);
  return validate_int16(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vhsub_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (const int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (const int32_t *)impl.test_cases_int_pointer2;
  int32_t _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = (_a[i] - _b[i]) >> 1;
  }

  int32x2_t a = vld1_s32(_a);
  int32x2_t b = vld1_s32(_b);
  int32x2_t c = vhsub_s32(a, b);
  return validate_int32(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vhsub_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (const uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (const uint8_t *)impl.test_cases_int_pointer2;
  uint8_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = (_a[i] - _b[i]) >> 1;
  }

  uint8x8_t a = vld1_u8(_a);
  uint8x8_t b = vld1_u8(_b);
  uint8x8_t c = vhsub_u8(a, b);
  return validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vhsub_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (const uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (const uint16_t *)impl.test_cases_int_pointer2;
  uint16_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = (_a[i] - _b[i]) >> 1;
  }

  uint16x4_t a = vld1_u16(_a);
  uint16x4_t b = vld1_u16(_b);
  uint16x4_t c = vhsub_u16(a, b);
  return validate_uint16(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vhsub_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (const uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (const uint32_t *)impl.test_cases_int_pointer2;
  uint32_t _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = ((uint64_t)_a[i] - (uint64_t)_b[i]) >> 1;
  }

  uint32x2_t a = vld1_u32(_a);
  uint32x2_t b = vld1_u32(_b);
  uint32x2_t c = vhsub_u32(a, b);
  return validate_uint32(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vhsubq_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (const int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (const int8_t *)impl.test_cases_int_pointer2;
  int8_t _c[16];
  for (int i = 0; i < 16; i++) {
    _c[i] = (_a[i] - _b[i]) >> 1;
  }

  int8x16_t a = vld1q_s8(_a);
  int8x16_t b = vld1q_s8(_b);
  int8x16_t c = vhsubq_s8(a, b);
  return validate_int8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7], _c[8], _c[9], _c[10], _c[11], _c[12],
                       _c[13], _c[14], _c[15]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vhsubq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (const int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (const int16_t *)impl.test_cases_int_pointer2;
  int16_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = (_a[i] - _b[i]) >> 1;
  }

  int16x8_t a = vld1q_s16(_a);
  int16x8_t b = vld1q_s16(_b);
  int16x8_t c = vhsubq_s16(a, b);
  return validate_int16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vhsubq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (const int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (const int32_t *)impl.test_cases_int_pointer2;
  int32_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = (_a[i] - _b[i]) >> 1;
  }

  int32x4_t a = vld1q_s32(_a);
  int32x4_t b = vld1q_s32(_b);
  int32x4_t c = vhsubq_s32(a, b);
  return validate_int32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vhsubq_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (const uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (const uint8_t *)impl.test_cases_int_pointer2;
  uint8_t _c[16];
  for (int i = 0; i < 16; i++) {
    _c[i] = (_a[i] - _b[i]) >> 1;
  }

  uint8x16_t a = vld1q_u8(_a);
  uint8x16_t b = vld1q_u8(_b);
  uint8x16_t c = vhsubq_u8(a, b);
  return validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7], _c[8], _c[9], _c[10], _c[11], _c[12],
                        _c[13], _c[14], _c[15]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vhsubq_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (const uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (const uint16_t *)impl.test_cases_int_pointer2;
  uint16_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = (_a[i] - _b[i]) >> 1;
  }

  uint16x8_t a = vld1q_u16(_a);
  uint16x8_t b = vld1q_u16(_b);
  uint16x8_t c = vhsubq_u16(a, b);
  return validate_uint16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vhsubq_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (const uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (const uint32_t *)impl.test_cases_int_pointer2;
  uint32_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = ((uint64_t)_a[i] - (uint64_t)_b[i]) >> 1;
  }

  uint32x4_t a = vld1q_u32(_a);
  uint32x4_t b = vld1q_u32(_b);
  uint32x4_t c = vhsubq_u32(a, b);
  return validate_uint32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqsub_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (const int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (const int8_t *)impl.test_cases_int_pointer2;
  int16_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = saturate_int8((int16_t)_a[i] - (int16_t)_b[i]);
  }

  int8x8_t a = vld1_s8(_a);
  int8x8_t b = vld1_s8(_b);
  int8x8_t c = vqsub_s8(a, b);
  return validate_int8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqsub_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (const int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (const int16_t *)impl.test_cases_int_pointer2;
  int32_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = saturate_int16((int32_t)_a[i] - (int32_t)_b[i]);
  }

  int16x4_t a = vld1_s16(_a);
  int16x4_t b = vld1_s16(_b);
  int16x4_t c = vqsub_s16(a, b);
  return validate_int16(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqsub_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (const int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (const int32_t *)impl.test_cases_int_pointer2;
  int64_t _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = saturate_int32((int64_t)_a[i] - (int64_t)_b[i]);
  }

  int32x2_t a = vld1_s32(_a);
  int32x2_t b = vld1_s32(_b);
  int32x2_t c = vqsub_s32(a, b);
  return validate_int32(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqsub_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (const int64_t *)impl.test_cases_int_pointer1;
  const int64_t *_b = (const int64_t *)impl.test_cases_int_pointer2;
  int64_t _c[1];
  for (int i = 0; i < 1; i++) {
    if ((_b[i] > 0 && _a[i] < INT64_MIN + _b[i]) || (_b[i] < 0 && _a[i] > INT64_MAX + _b[i])) {
      _c[i] = (_b[i] > 0) ? INT64_MAX : INT64_MIN;
    } else {
      _c[i] = _a[i] - _b[i];
    }
  }

  int64x1_t a = vld1_s64(_a);
  int64x1_t b = vld1_s64(_b);
  int64x1_t c = vqsub_s64(a, b);
  return validate_int64(c, _c[0]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqsub_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (const uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (const uint8_t *)impl.test_cases_int_pointer2;
  uint8_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = saturate_uint8((int16_t)_a[i] - (int16_t)_b[i]);
  }

  uint8x8_t a = vld1_u8(_a);
  uint8x8_t b = vld1_u8(_b);
  uint8x8_t c = vqsub_u8(a, b);
  return validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqsub_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (const uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (const uint16_t *)impl.test_cases_int_pointer2;
  uint32_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = saturate_uint16((uint32_t)_a[i] - (uint32_t)_b[i]);
  }

  uint16x4_t a = vld1_u16(_a);
  uint16x4_t b = vld1_u16(_b);
  uint16x4_t c = vqsub_u16(a, b);
  return validate_uint16(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqsub_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (const uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (const uint32_t *)impl.test_cases_int_pointer2;
  uint64_t _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = saturate_uint32((uint64_t)_a[i] - (uint64_t)_b[i]);
  }

  uint32x2_t a = vld1_u32(_a);
  uint32x2_t b = vld1_u32(_b);
  uint32x2_t c = vqsub_u32(a, b);
  return validate_uint32(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqsub_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (const uint64_t *)impl.test_cases_int_pointer1;
  const uint64_t *_b = (const uint64_t *)impl.test_cases_int_pointer2;
  uint64_t _c[1];
  for (int i = 0; i < 1; i++) {
    if (_a[i] > _b[i]) {
      _c[i] = _a[i] - _b[i];
    } else {
      _c[i] = 0;
    }
  }

  uint64x1_t a = vld1_u64(_a);
  uint64x1_t b = vld1_u64(_b);
  uint64x1_t c = vqsub_u64(a, b);
  return validate_uint64(c, _c[0]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqsubq_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (const int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (const int8_t *)impl.test_cases_int_pointer2;
  int16_t _c[16];
  for (int i = 0; i < 16; i++) {
    _c[i] = saturate_int8((int16_t)_a[i] - (int16_t)_b[i]);
  }

  int8x16_t a = vld1q_s8(_a);
  int8x16_t b = vld1q_s8(_b);
  int8x16_t c = vqsubq_s8(a, b);
  return validate_int8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7], _c[8], _c[9], _c[10], _c[11], _c[12],
                       _c[13], _c[14], _c[15]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqsubq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (const int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (const int16_t *)impl.test_cases_int_pointer2;
  int32_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = saturate_int16((int32_t)_a[i] - (int32_t)_b[i]);
  }

  int16x8_t a = vld1q_s16(_a);
  int16x8_t b = vld1q_s16(_b);
  int16x8_t c = vqsubq_s16(a, b);
  return validate_int16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqsubq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (const int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (const int32_t *)impl.test_cases_int_pointer2;
  int64_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = saturate_int32((int64_t)_a[i] - (int64_t)_b[i]);
  }

  int32x4_t a = vld1q_s32(_a);
  int32x4_t b = vld1q_s32(_b);
  int32x4_t c = vqsubq_s32(a, b);
  return validate_int32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqsubq_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (const int64_t *)impl.test_cases_int_pointer1;
  const int64_t *_b = (const int64_t *)impl.test_cases_int_pointer2;
  int64_t _c[2];
  for (int i = 0; i < 2; i++) {
    if ((_b[i] > 0 && _a[i] < INT64_MIN + _b[i]) || (_b[i] < 0 && _a[i] > INT64_MAX + _b[i])) {
      _c[i] = (_b[i] > 0) ? INT64_MAX : INT64_MIN;
    } else {
      _c[i] = _a[i] - _b[i];
    }
  }

  int64x2_t a = vld1q_s64(_a);
  int64x2_t b = vld1q_s64(_b);
  int64x2_t c = vqsubq_s64(a, b);
  return validate_int64(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqsubq_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (const uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (const uint8_t *)impl.test_cases_int_pointer2;
  uint8_t _c[16];
  for (int i = 0; i < 16; i++) {
    _c[i] = saturate_uint8((int16_t)_a[i] - (int16_t)_b[i]);
  }

  uint8x16_t a = vld1q_u8(_a);
  uint8x16_t b = vld1q_u8(_b);
  uint8x16_t c = vqsubq_u8(a, b);
  return validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7], _c[8], _c[9], _c[10], _c[11], _c[12],
                        _c[13], _c[14], _c[15]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqsubq_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (const uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (const uint16_t *)impl.test_cases_int_pointer2;
  uint32_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = saturate_uint16((uint32_t)_a[i] - (uint32_t)_b[i]);
  }

  uint16x8_t a = vld1q_u16(_a);
  uint16x8_t b = vld1q_u16(_b);
  uint16x8_t c = vqsubq_u16(a, b);
  return validate_uint16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqsubq_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (const uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (const uint32_t *)impl.test_cases_int_pointer2;
  uint64_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = saturate_uint32((uint64_t)_a[i] - (uint64_t)_b[i]);
  }

  uint32x4_t a = vld1q_u32(_a);
  uint32x4_t b = vld1q_u32(_b);
  uint32x4_t c = vqsubq_u32(a, b);
  return validate_uint32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqsubq_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (const uint64_t *)impl.test_cases_int_pointer1;
  const uint64_t *_b = (const uint64_t *)impl.test_cases_int_pointer2;
  uint64_t _c[2];
  for (int i = 0; i < 2; i++) {
    if (_a[i] > _b[i]) {
      _c[i] = _a[i] - _b[i];
    } else {
      _c[i] = 0;
    }
  }

  uint64x2_t a = vld1q_u64(_a);
  uint64x2_t b = vld1q_u64(_b);
  uint64x2_t c = vqsubq_u64(a, b);
  return validate_uint64(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqsubb_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqsubh_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqsubs_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqsubd_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqsubb_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqsubh_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqsubs_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqsubd_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vsubhn_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  int8_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = ((_a[i] - _b[i]) >> 8) & UINT8_MAX;
  }

  int16x8_t a = vld1q_s16(_a);
  int16x8_t b = vld1q_s16(_b);
  int8x8_t c = vsubhn_s16(a, b);
  return validate_int8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsubhn_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  int16_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = ((_a[i] - _b[i]) >> 16) & UINT16_MAX;
  }

  int32x4_t a = vld1q_s32(_a);
  int32x4_t b = vld1q_s32(_b);
  int16x4_t c = vsubhn_s32(a, b);
  return validate_int16(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsubhn_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (int64_t *)impl.test_cases_int_pointer1;
  const int64_t *_b = (int64_t *)impl.test_cases_int_pointer2;
  int32_t _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = ((_a[i] - _b[i]) >> 32) & UINT32_MAX;
  }

  int64x2_t a = vld1q_s64(_a);
  int64x2_t b = vld1q_s64(_b);
  int32x2_t c = vsubhn_s64(a, b);
  return validate_int32(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsubhn_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (uint16_t *)impl.test_cases_int_pointer2;
  uint8_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = ((_a[i] - _b[i]) >> 8) & UINT8_MAX;
  }

  uint16x8_t a = vld1q_u16(_a);
  uint16x8_t b = vld1q_u16(_b);
  uint8x8_t c = vsubhn_u16(a, b);
  return validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsubhn_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (uint32_t *)impl.test_cases_int_pointer2;
  uint16_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = ((_a[i] - _b[i]) >> 16) & UINT16_MAX;
  }

  uint32x4_t a = vld1q_u32(_a);
  uint32x4_t b = vld1q_u32(_b);
  uint16x4_t c = vsubhn_u32(a, b);
  return validate_uint16(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsubhn_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (uint64_t *)impl.test_cases_int_pointer1;
  const uint64_t *_b = (uint64_t *)impl.test_cases_int_pointer2;
  uint32_t _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = ((_a[i] - _b[i]) >> 32) & UINT32_MAX;
  }

  uint64x2_t a = vld1q_u64(_a);
  uint64x2_t b = vld1q_u64(_b);
  uint32x2_t c = vsubhn_u64(a, b);
  return validate_uint32(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsubhn_high_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vsubhn_high_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vsubhn_high_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vsubhn_high_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vsubhn_high_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vsubhn_high_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrsubhn_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  int8_t _c[8];
  const int16_t round = 1 << 7;
  for (int i = 0; i < 8; i++) {
    _c[i] = ((_a[i] - _b[i] + round) >> 8) & UINT8_MAX;
  }

  int16x8_t a = vld1q_s16(_a);
  int16x8_t b = vld1q_s16(_b);
  int8x8_t c = vrsubhn_s16(a, b);
  return validate_int8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrsubhn_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  int16_t _c[4];
  const int32_t round = 1 << 15;
  for (int i = 0; i < 4; i++) {
    _c[i] = ((_a[i] - _b[i] + round) >> 16) & UINT16_MAX;
  }

  int32x4_t a = vld1q_s32(_a);
  int32x4_t b = vld1q_s32(_b);
  int16x4_t c = vrsubhn_s32(a, b);
  return validate_int16(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrsubhn_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (int64_t *)impl.test_cases_int_pointer1;
  const int64_t *_b = (int64_t *)impl.test_cases_int_pointer2;
  int32_t _c[2];
  const int64_t round = 1;
  for (int i = 0; i < 2; i++) {
    int64_t tmp = ((int64_t)_a[i] - (int64_t)_b[i]) >> 31;
    _c[i] = ((tmp + round) >> 1) & UINT32_MAX;
  }

  int64x2_t a = vld1q_s64(_a);
  int64x2_t b = vld1q_s64(_b);
  int32x2_t c = vrsubhn_s64(a, b);
  return validate_int32(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrsubhn_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (uint16_t *)impl.test_cases_int_pointer2;
  uint8_t _c[8];
  const uint16_t round = 1 << 7;
  for (int i = 0; i < 8; i++) {
    _c[i] = ((_a[i] - _b[i] + round) >> 8) & UINT8_MAX;
  }

  uint16x8_t a = vld1q_u16(_a);
  uint16x8_t b = vld1q_u16(_b);
  uint8x8_t c = vrsubhn_u16(a, b);
  return validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrsubhn_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (uint32_t *)impl.test_cases_int_pointer2;
  uint16_t _c[4];
  const uint32_t round = 1 << 15;
  for (int i = 0; i < 4; i++) {
    _c[i] = ((_a[i] - _b[i] + round) >> 16) & UINT16_MAX;
  }

  uint32x4_t a = vld1q_u32(_a);
  uint32x4_t b = vld1q_u32(_b);
  uint16x4_t c = vrsubhn_u32(a, b);
  return validate_uint16(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrsubhn_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (uint64_t *)impl.test_cases_int_pointer1;
  const uint64_t *_b = (uint64_t *)impl.test_cases_int_pointer2;
  uint32_t _c[2];
  const uint64_t round = (uint64_t)1 << 31;
  for (int i = 0; i < 2; i++) {
    _c[i] = ((_a[i] - _b[i] + round) >> 32) & UINT32_MAX;
  }

  uint64x2_t a = vld1q_u64(_a);
  uint64x2_t b = vld1q_u64(_b);
  uint32x2_t c = vrsubhn_u64(a, b);
  return validate_uint32(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrsubhn_high_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrsubhn_high_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrsubhn_high_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrsubhn_high_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrsubhn_high_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrsubhn_high_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vceq_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (const int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (const int8_t *)impl.test_cases_int_pointer2;
  uint8_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = (_a[i] == _b[i]) ? UINT8_MAX : 0x00;
  }

  int8x8_t a = vld1_s8(_a);
  int8x8_t b = vld1_s8(_b);
  uint8x8_t c = vceq_s8(a, b);
  return validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vceq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (const int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (const int16_t *)impl.test_cases_int_pointer2;
  uint16_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = (_a[i] == _b[i]) ? UINT16_MAX : 0x00;
  }

  int16x4_t a = vld1_s16(_a);
  int16x4_t b = vld1_s16(_b);
  uint16x4_t c = vceq_s16(a, b);
  return validate_uint16(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vceq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (const int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (const int32_t *)impl.test_cases_int_pointer2;
  uint32_t _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = (_a[i] == _b[i]) ? UINT32_MAX : 0x00;
  }

  int32x2_t a = vld1_s32(_a);
  int32x2_t b = vld1_s32(_b);
  uint32x2_t c = vceq_s32(a, b);
  return validate_uint32(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vceq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (const float *)impl.test_cases_float_pointer1;
  const float *_b = (const float *)impl.test_cases_float_pointer2;
  uint32_t _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = (_a[i] == _b[i]) ? UINT32_MAX : 0x00;
  }

  float32x2_t a = vld1_f32(_a);
  float32x2_t b = vld1_f32(_b);
  uint32x2_t c = vceq_f32(a, b);
  return validate_uint32(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vceq_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (const uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (const uint8_t *)impl.test_cases_int_pointer2;
  uint8_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = (_a[i] == _b[i]) ? UINT8_MAX : 0x00;
  }

  uint8x8_t a = vld1_u8(_a);
  uint8x8_t b = vld1_u8(_b);
  uint8x8_t c = vceq_u8(a, b);
  return validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vceq_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (const uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (const uint16_t *)impl.test_cases_int_pointer2;
  uint16_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = (_a[i] == _b[i]) ? UINT16_MAX : 0x00;
  }

  uint16x4_t a = vld1_u16(_a);
  uint16x4_t b = vld1_u16(_b);
  uint16x4_t c = vceq_u16(a, b);
  return validate_uint16(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vceq_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (const uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (const uint32_t *)impl.test_cases_int_pointer2;
  uint32_t _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = (_a[i] == _b[i]) ? UINT32_MAX : 0x00;
  }

  uint32x2_t a = vld1_u32(_a);
  uint32x2_t b = vld1_u32(_b);
  uint32x2_t c = vceq_u32(a, b);
  return validate_uint32(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vceqq_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (const int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (const int8_t *)impl.test_cases_int_pointer2;
  uint8_t _c[16];
  for (int i = 0; i < 16; i++) {
    _c[i] = (_a[i] == _b[i]) ? UINT8_MAX : 0x00;
  }

  int8x16_t a = vld1q_s8(_a);
  int8x16_t b = vld1q_s8(_b);
  uint8x16_t c = vceqq_s8(a, b);
  return validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7], _c[8], _c[9], _c[10], _c[11], _c[12],
                        _c[13], _c[14], _c[15]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vceqq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (const int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (const int16_t *)impl.test_cases_int_pointer2;
  uint16_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = (_a[i] == _b[i]) ? UINT16_MAX : 0x00;
  }

  int16x8_t a = vld1q_s16(_a);
  int16x8_t b = vld1q_s16(_b);
  uint16x8_t c = vceqq_s16(a, b);
  return validate_uint16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vceqq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (const int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (const int32_t *)impl.test_cases_int_pointer2;
  uint32_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = (_a[i] == _b[i]) ? UINT32_MAX : 0x00;
  }

  int32x4_t a = vld1q_s32(_a);
  int32x4_t b = vld1q_s32(_b);
  uint32x4_t c = vceqq_s32(a, b);
  return validate_uint32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vceqq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (const float *)impl.test_cases_float_pointer1;
  const float *_b = (const float *)impl.test_cases_float_pointer2;
  uint32_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = (_a[i] == _b[i]) ? UINT32_MAX : 0x00;
  }

  float32x4_t a = vld1q_f32(_a);
  float32x4_t b = vld1q_f32(_b);
  uint32x4_t c = vceqq_f32(a, b);
  return validate_uint32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vceq_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vceqq_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vceq_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (const int64_t *)impl.test_cases_int_pointer1;
  const int64_t *_b = (const int64_t *)impl.test_cases_int_pointer2;
  uint64_t _c[1];
  for (int i = 0; i < 1; i++) {
    _c[i] = (_a[i] == _b[i]) ? UINT64_MAX : 0x00;
  }

  int64x1_t a = vld1_s64(_a);
  int64x1_t b = vld1_s64(_b);
  uint64x1_t c = vceq_s64(a, b);
  return validate_uint64(c, _c[0]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vceqq_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (const int64_t *)impl.test_cases_int_pointer1;
  const int64_t *_b = (const int64_t *)impl.test_cases_int_pointer2;
  uint64_t _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = (_a[i] == _b[i]) ? UINT64_MAX : 0x00;
  }

  int64x2_t a = vld1q_s64(_a);
  int64x2_t b = vld1q_s64(_b);
  uint64x2_t c = vceqq_s64(a, b);
  return validate_uint64(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vceq_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (const uint64_t *)impl.test_cases_int_pointer1;
  const uint64_t *_b = (const uint64_t *)impl.test_cases_int_pointer2;
  uint64_t _c[1];
  for (int i = 0; i < 1; i++) {
    _c[i] = (_a[i] == _b[i]) ? UINT64_MAX : 0x00;
  }

  uint64x1_t a = vld1_u64(_a);
  uint64x1_t b = vld1_u64(_b);
  uint64x1_t c = vceq_u64(a, b);
  return validate_uint64(c, _c[0]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vceqq_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (const uint64_t *)impl.test_cases_int_pointer1;
  const uint64_t *_b = (const uint64_t *)impl.test_cases_int_pointer2;
  uint64_t _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = (_a[i] == _b[i]) ? UINT64_MAX : 0x00;
  }

  uint64x2_t a = vld1q_u64(_a);
  uint64x2_t b = vld1q_u64(_b);
  uint64x2_t c = vceqq_u64(a, b);
  return validate_uint64(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vceq_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vceqq_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vceq_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const double *_a = (const double *)impl.test_cases_float_pointer1;
  const double *_b = (const double *)impl.test_cases_float_pointer2;
  uint64_t _c[1];
  for (int i = 0; i < 1; i++) {
    _c[i] = (_a[i] == _b[i]) ? UINT64_MAX : 0x00;
  }

  float64x1_t a = vld1_f64(_a);
  float64x1_t b = vld1_f64(_b);
  uint64x1_t c = vceq_f64(a, b);
  return validate_uint64(c, _c[0]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vceqq_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const double *_a = (const double *)impl.test_cases_float_pointer1;
  const double *_b = (const double *)impl.test_cases_float_pointer2;
  uint64_t _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = (_a[i] == _b[i]) ? UINT64_MAX : 0x00;
  }

  float64x2_t a = vld1q_f64(_a);
  float64x2_t b = vld1q_f64(_b);
  uint64x2_t c = vceqq_f64(a, b);
  return validate_uint64(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vceqd_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (const int64_t *)impl.test_cases_int_pointer1;
  const int64_t *_b = (const int64_t *)impl.test_cases_int_pointer2;
  uint64_t _c = (_a[0] == _b[0]) ? UINT64_MAX : 0x00;

  uint64_t c = vceqd_s64(_a[0], _b[0]);
  return c == _c ? TEST_SUCCESS : TEST_FAIL;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vceqd_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (const uint64_t *)impl.test_cases_int_pointer1;
  const uint64_t *_b = (const uint64_t *)impl.test_cases_int_pointer2;
  uint64_t _c = (_a[0] == _b[0]) ? UINT64_MAX : 0x00;

  uint64_t c = vceqd_u64(_a[0], _b[0]);
  return c == _c ? TEST_SUCCESS : TEST_FAIL;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vceqs_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (const float *)impl.test_cases_float_pointer1;
  const float *_b = (const float *)impl.test_cases_float_pointer2;
  uint32_t _c = (_a[0] == _b[0]) ? UINT32_MAX : 0x00;

  uint32_t c = vceqs_f32(_a[0], _b[0]);
  return c == _c ? TEST_SUCCESS : TEST_FAIL;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vceqd_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const double *_a = (const double *)impl.test_cases_float_pointer1;
  const double *_b = (const double *)impl.test_cases_float_pointer2;
  uint64_t _c = (_a[0] == _b[0]) ? UINT64_MAX : 0x00;

  uint64_t c = vceqd_f64(_a[0], _b[0]);
  return c == _c ? TEST_SUCCESS : TEST_FAIL;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vceqz_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (const int8_t *)impl.test_cases_int_pointer1;
  uint8_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = (_a[i] == 0) ? UINT8_MAX : 0x00;
  }

  int8x8_t a = vld1_s8(_a);
  uint8x8_t c = vceqz_s8(a);
  return validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vceqzq_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (const int8_t *)impl.test_cases_int_pointer1;
  uint8_t _c[16];
  for (int i = 0; i < 16; i++) {
    _c[i] = (_a[i] == 0) ? UINT8_MAX : 0x00;
  }

  int8x16_t a = vld1q_s8(_a);
  uint8x16_t c = vceqzq_s8(a);
  return validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7], _c[8], _c[9], _c[10], _c[11], _c[12],
                        _c[13], _c[14], _c[15]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vceqz_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (const int16_t *)impl.test_cases_int_pointer1;
  uint16_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = (_a[i] == 0) ? UINT16_MAX : 0x00;
  }

  int16x4_t a = vld1_s16(_a);
  uint16x4_t c = vceqz_s16(a);
  return validate_uint16(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vceqzq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (const int16_t *)impl.test_cases_int_pointer1;
  uint16_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = (_a[i] == 0) ? UINT16_MAX : 0x00;
  }

  int16x8_t a = vld1q_s16(_a);
  uint16x8_t c = vceqzq_s16(a);
  return validate_uint16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vceqz_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (const int32_t *)impl.test_cases_int_pointer1;
  uint32_t _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = (_a[i] == 0) ? UINT32_MAX : 0x00;
  }

  int32x2_t a = vld1_s32(_a);
  uint32x2_t c = vceqz_s32(a);
  return validate_uint32(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vceqzq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (const int32_t *)impl.test_cases_int_pointer1;
  uint32_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = (_a[i] == 0) ? UINT32_MAX : 0x00;
  }

  int32x4_t a = vld1q_s32(_a);
  uint32x4_t c = vceqzq_s32(a);
  return validate_uint32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vceqz_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (const uint8_t *)impl.test_cases_int_pointer1;
  uint8_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = (_a[i] == 0) ? UINT8_MAX : 0x00;
  }

  uint8x8_t a = vld1_u8(_a);
  uint8x8_t c = vceqz_u8(a);
  return validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vceqzq_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (const uint8_t *)impl.test_cases_int_pointer1;
  uint8_t _c[16];
  for (int i = 0; i < 16; i++) {
    _c[i] = (_a[i] == 0) ? UINT8_MAX : 0x00;
  }

  uint8x16_t a = vld1q_u8(_a);
  uint8x16_t c = vceqzq_u8(a);
  return validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7], _c[8], _c[9], _c[10], _c[11], _c[12],
                        _c[13], _c[14], _c[15]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vceqz_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (const uint16_t *)impl.test_cases_int_pointer1;
  uint16_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = (_a[i] == 0) ? UINT16_MAX : 0x00;
  }

  uint16x4_t a = vld1_u16(_a);
  uint16x4_t c = vceqz_u16(a);
  return validate_uint16(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vceqzq_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (const uint16_t *)impl.test_cases_int_pointer1;
  uint16_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = (_a[i] == 0) ? UINT16_MAX : 0x00;
  }

  uint16x8_t a = vld1q_u16(_a);
  uint16x8_t c = vceqzq_u16(a);
  return validate_uint16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vceqz_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (const uint32_t *)impl.test_cases_int_pointer1;
  uint32_t _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = (_a[i] == 0) ? UINT32_MAX : 0x00;
  }

  uint32x2_t a = vld1_u32(_a);
  uint32x2_t c = vceqz_u32(a);
  return validate_uint32(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vceqzq_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (const uint32_t *)impl.test_cases_int_pointer1;
  uint32_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = (_a[i] == 0) ? UINT32_MAX : 0x00;
  }

  uint32x4_t a = vld1q_u32(_a);
  uint32x4_t c = vceqzq_u32(a);
  return validate_uint32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vceqz_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (const float *)impl.test_cases_float_pointer1;
  uint32_t _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = (_a[i] == 0) ? UINT32_MAX : 0x00;
  }

  float32x2_t a = vld1_f32(_a);
  uint32x2_t c = vceqz_f32(a);
  return validate_uint32(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vceqzq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (const float *)impl.test_cases_float_pointer1;
  uint32_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = (_a[i] == 0) ? UINT32_MAX : 0x00;
  }

  float32x4_t a = vld1q_f32(_a);
  uint32x4_t c = vceqzq_f32(a);
  return validate_uint32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vceqz_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vceqzq_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vceqz_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (const int64_t *)impl.test_cases_int_pointer1;
  uint64_t _c[1];
  for (int i = 0; i < 1; i++) {
    _c[i] = (_a[i] == 0) ? UINT64_MAX : 0x00;
  }

  int64x1_t a = vld1_s64(_a);
  uint64x1_t c = vceqz_s64(a);
  return validate_uint64(c, _c[0]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vceqzq_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (const int64_t *)impl.test_cases_int_pointer1;
  uint64_t _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = (_a[i] == 0) ? UINT64_MAX : 0x00;
  }

  int64x2_t a = vld1q_s64(_a);
  uint64x2_t c = vceqzq_s64(a);
  return validate_uint64(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vceqz_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (const uint64_t *)impl.test_cases_int_pointer1;
  uint64_t _c[1];
  for (int i = 0; i < 1; i++) {
    _c[i] = (_a[i] == 0) ? UINT64_MAX : 0x00;
  }

  uint64x1_t a = vld1_u64(_a);
  uint64x1_t c = vceqz_u64(a);
  return validate_uint64(c, _c[0]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vceqzq_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (const uint64_t *)impl.test_cases_int_pointer1;
  uint64_t _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = (_a[i] == 0) ? UINT64_MAX : 0x00;
  }

  uint64x2_t a = vld1q_u64(_a);
  uint64x2_t c = vceqzq_u64(a);
  return validate_uint64(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vceqz_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vceqzq_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vceqz_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const double *_a = (const double *)impl.test_cases_float_pointer1;
  uint64_t _c[1];
  for (int i = 0; i < 1; i++) {
    _c[i] = (_a[i] == 0) ? UINT64_MAX : 0x00;
  }

  float64x1_t a = vld1_f64(_a);
  uint64x1_t c = vceqz_f64(a);
  return validate_uint64(c, _c[0]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vceqzq_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const double *_a = (const double *)impl.test_cases_float_pointer1;
  uint64_t _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = (_a[i] == 0) ? UINT64_MAX : 0x00;
  }

  float64x2_t a = vld1q_f64(_a);
  uint64x2_t c = vceqzq_f64(a);
  return validate_uint64(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vceqzd_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (const int64_t *)impl.test_cases_int_pointer1;
  uint64_t _c = (_a[0] == 0) ? UINT64_MAX : 0x00;

  uint64_t c = vceqzd_s64(_a[0]);
  return c == _c ? TEST_SUCCESS : TEST_FAIL;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vceqzd_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (const uint64_t *)impl.test_cases_int_pointer1;
  uint64_t _c = (_a[0] == 0) ? UINT64_MAX : 0x00;

  uint64_t c = vceqzd_u64(_a[0]);
  return c == _c ? TEST_SUCCESS : TEST_FAIL;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vceqzs_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (const float *)impl.test_cases_float_pointer1;
  uint32_t _c = (_a[0] == 0) ? UINT32_MAX : 0x00;

  uint32_t c = vceqzs_f32(_a[0]);
  return c == _c ? TEST_SUCCESS : TEST_FAIL;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vceqzd_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const double *_a = (const double *)impl.test_cases_float_pointer1;
  uint64_t _c = (_a[0] == 0) ? UINT64_MAX : 0x00;

  uint64_t c = vceqzd_f64(_a[0]);
  return c == _c ? TEST_SUCCESS : TEST_FAIL;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vceqq_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (const uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (const uint8_t *)impl.test_cases_int_pointer2;
  uint8_t _c[16];
  for (int i = 0; i < 16; i++) {
    _c[i] = (_a[i] == _b[i]) ? UINT8_MAX : 0x00;
  }

  uint8x16_t a = vld1q_u8(_a);
  uint8x16_t b = vld1q_u8(_b);
  uint8x16_t c = vceqq_u8(a, b);
  return validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7], _c[8], _c[9], _c[10], _c[11], _c[12],
                        _c[13], _c[14], _c[15]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vceqq_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (const uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (const uint16_t *)impl.test_cases_int_pointer2;
  uint16_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = (_a[i] == _b[i]) ? UINT16_MAX : 0x00;
  }

  uint16x8_t a = vld1q_u16(_a);
  uint16x8_t b = vld1q_u16(_b);
  uint16x8_t c = vceqq_u16(a, b);
  return validate_uint16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vceqq_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (const uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (const uint32_t *)impl.test_cases_int_pointer2;
  uint32_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = (_a[i] == _b[i]) ? UINT32_MAX : 0x00;
  }

  uint32x4_t a = vld1q_u32(_a);
  uint32x4_t b = vld1q_u32(_b);
  uint32x4_t c = vceqq_u32(a, b);
  return validate_uint32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vcge_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (const int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (const int8_t *)impl.test_cases_int_pointer2;
  uint8_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = (_a[i] >= _b[i]) ? UINT8_MAX : 0x00;
  }

  int8x8_t a = vld1_s8(_a);
  int8x8_t b = vld1_s8(_b);
  uint8x8_t c = vcge_s8(a, b);
  return validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vcge_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (const int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (const int16_t *)impl.test_cases_int_pointer2;
  uint16_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = (_a[i] >= _b[i]) ? UINT16_MAX : 0x00;
  }

  int16x4_t a = vld1_s16(_a);
  int16x4_t b = vld1_s16(_b);
  uint16x4_t c = vcge_s16(a, b);
  return validate_uint16(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vcge_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (const int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (const int32_t *)impl.test_cases_int_pointer2;
  uint32_t _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = (_a[i] >= _b[i]) ? UINT32_MAX : 0x00;
  }

  int32x2_t a = vld1_s32(_a);
  int32x2_t b = vld1_s32(_b);
  uint32x2_t c = vcge_s32(a, b);
  return validate_uint32(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vcge_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (const float *)impl.test_cases_float_pointer1;
  const float *_b = (const float *)impl.test_cases_float_pointer2;
  uint32_t _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = (_a[i] >= _b[i]) ? UINT32_MAX : 0x00;
  }

  float32x2_t a = vld1_f32(_a);
  float32x2_t b = vld1_f32(_b);
  uint32x2_t c = vcge_f32(a, b);
  return validate_uint32(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vcge_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (const uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (const uint8_t *)impl.test_cases_int_pointer2;
  uint8_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = (_a[i] >= _b[i]) ? UINT8_MAX : 0x00;
  }

  uint8x8_t a = vld1_u8(_a);
  uint8x8_t b = vld1_u8(_b);
  uint8x8_t c = vcge_u8(a, b);
  return validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vcge_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (const uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (const uint16_t *)impl.test_cases_int_pointer2;
  uint16_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = (_a[i] >= _b[i]) ? UINT16_MAX : 0x00;
  }

  uint16x4_t a = vld1_u16(_a);
  uint16x4_t b = vld1_u16(_b);
  uint16x4_t c = vcge_u16(a, b);
  return validate_uint16(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vcge_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (const uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (const uint32_t *)impl.test_cases_int_pointer2;
  uint32_t _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = (_a[i] >= _b[i]) ? UINT32_MAX : 0x00;
  }

  uint32x2_t a = vld1_u32(_a);
  uint32x2_t b = vld1_u32(_b);
  uint32x2_t c = vcge_u32(a, b);
  return validate_uint32(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vcgeq_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (const int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (const int8_t *)impl.test_cases_int_pointer2;
  uint8_t _c[16];
  for (int i = 0; i < 16; i++) {
    _c[i] = (_a[i] >= _b[i]) ? UINT8_MAX : 0x00;
  }

  int8x16_t a = vld1q_s8(_a);
  int8x16_t b = vld1q_s8(_b);
  uint8x16_t c = vcgeq_s8(a, b);
  return validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7], _c[8], _c[9], _c[10], _c[11], _c[12],
                        _c[13], _c[14], _c[15]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vcgeq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (const int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (const int16_t *)impl.test_cases_int_pointer2;
  uint16_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = (_a[i] >= _b[i]) ? UINT16_MAX : 0x00;
  }

  int16x8_t a = vld1q_s16(_a);
  int16x8_t b = vld1q_s16(_b);
  uint16x8_t c = vcgeq_s16(a, b);
  return validate_uint16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vcgeq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (const int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (const int32_t *)impl.test_cases_int_pointer2;
  uint32_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = (_a[i] >= _b[i]) ? UINT32_MAX : 0x00;
  }

  int32x4_t a = vld1q_s32(_a);
  int32x4_t b = vld1q_s32(_b);
  uint32x4_t c = vcgeq_s32(a, b);
  return validate_uint32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vcgeq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (const float *)impl.test_cases_float_pointer1;
  const float *_b = (const float *)impl.test_cases_float_pointer2;
  uint32_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = (_a[i] >= _b[i]) ? UINT32_MAX : 0x00;
  }

  float32x4_t a = vld1q_f32(_a);
  float32x4_t b = vld1q_f32(_b);
  uint32x4_t c = vcgeq_f32(a, b);
  return validate_uint32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vcge_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcgeq_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcge_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcgeq_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcge_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcgeq_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcged_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcged_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcges_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcged_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcgez_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcgezq_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcgez_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcgezq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcgez_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcgezq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcgez_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcgezq_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcgez_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcgezq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcgez_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcgezq_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcgezd_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcgezs_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcgezd_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcgeq_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (const uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (const uint8_t *)impl.test_cases_int_pointer2;
  uint8_t _c[16];
  for (int i = 0; i < 16; i++) {
    _c[i] = (_a[i] >= _b[i]) ? UINT8_MAX : 0x00;
  }

  uint8x16_t a = vld1q_u8(_a);
  uint8x16_t b = vld1q_u8(_b);
  uint8x16_t c = vcgeq_u8(a, b);
  return validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7], _c[8], _c[9], _c[10], _c[11], _c[12],
                        _c[13], _c[14], _c[15]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vcgeq_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (const uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (const uint16_t *)impl.test_cases_int_pointer2;
  uint16_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = (_a[i] >= _b[i]) ? UINT16_MAX : 0x00;
  }

  uint16x8_t a = vld1q_u16(_a);
  uint16x8_t b = vld1q_u16(_b);
  uint16x8_t c = vcgeq_u16(a, b);
  return validate_uint16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vcgeq_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (const uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (const uint32_t *)impl.test_cases_int_pointer2;
  uint32_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = (_a[i] >= _b[i]) ? UINT32_MAX : 0x00;
  }

  uint32x4_t a = vld1q_u32(_a);
  uint32x4_t b = vld1q_u32(_b);
  uint32x4_t c = vcgeq_u32(a, b);
  return validate_uint32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vcle_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (const int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (const int8_t *)impl.test_cases_int_pointer2;
  uint8_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = (_a[i] <= _b[i]) ? UINT8_MAX : 0x00;
  }

  int8x8_t a = vld1_s8(_a);
  int8x8_t b = vld1_s8(_b);
  uint8x8_t c = vcle_s8(a, b);
  return validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vcle_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (const int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (const int16_t *)impl.test_cases_int_pointer2;
  uint16_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = (_a[i] <= _b[i]) ? UINT16_MAX : 0x00;
  }

  int16x4_t a = vld1_s16(_a);
  int16x4_t b = vld1_s16(_b);
  uint16x4_t c = vcle_s16(a, b);
  return validate_uint16(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vcle_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (const int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (const int32_t *)impl.test_cases_int_pointer2;
  uint32_t _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = (_a[i] <= _b[i]) ? UINT32_MAX : 0x00;
  }

  int32x2_t a = vld1_s32(_a);
  int32x2_t b = vld1_s32(_b);
  uint32x2_t c = vcle_s32(a, b);
  return validate_uint32(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vcle_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (const float *)impl.test_cases_float_pointer1;
  const float *_b = (const float *)impl.test_cases_float_pointer2;
  uint32_t _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = (_a[i] <= _b[i]) ? UINT32_MAX : 0x00;
  }

  float32x2_t a = vld1_f32(_a);
  float32x2_t b = vld1_f32(_b);
  uint32x2_t c = vcle_f32(a, b);
  return validate_uint32(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vcle_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (const uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (const uint8_t *)impl.test_cases_int_pointer2;
  uint8_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = (_a[i] <= _b[i]) ? UINT8_MAX : 0x00;
  }

  uint8x8_t a = vld1_u8(_a);
  uint8x8_t b = vld1_u8(_b);
  uint8x8_t c = vcle_u8(a, b);
  return validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vcle_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (const uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (const uint16_t *)impl.test_cases_int_pointer2;
  uint16_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = (_a[i] <= _b[i]) ? UINT16_MAX : 0x00;
  }

  uint16x4_t a = vld1_u16(_a);
  uint16x4_t b = vld1_u16(_b);
  uint16x4_t c = vcle_u16(a, b);
  return validate_uint16(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vcle_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (const uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (const uint32_t *)impl.test_cases_int_pointer2;
  uint32_t _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = (_a[i] <= _b[i]) ? UINT32_MAX : 0x00;
  }

  uint32x2_t a = vld1_u32(_a);
  uint32x2_t b = vld1_u32(_b);
  uint32x2_t c = vcle_u32(a, b);
  return validate_uint32(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vcleq_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (const int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (const int8_t *)impl.test_cases_int_pointer2;
  uint8_t _c[16];
  for (int i = 0; i < 16; i++) {
    _c[i] = (_a[i] <= _b[i]) ? UINT8_MAX : 0x00;
  }

  int8x16_t a = vld1q_s8(_a);
  int8x16_t b = vld1q_s8(_b);
  uint8x16_t c = vcleq_s8(a, b);
  return validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7], _c[8], _c[9], _c[10], _c[11], _c[12],
                        _c[13], _c[14], _c[15]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vcleq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (const int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (const int16_t *)impl.test_cases_int_pointer2;
  uint16_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = (_a[i] <= _b[i]) ? UINT16_MAX : 0x00;
  }

  int16x8_t a = vld1q_s16(_a);
  int16x8_t b = vld1q_s16(_b);
  uint16x8_t c = vcleq_s16(a, b);
  return validate_uint16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vcleq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (const int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (const int32_t *)impl.test_cases_int_pointer2;
  uint32_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = (_a[i] <= _b[i]) ? UINT32_MAX : 0x00;
  }

  int32x4_t a = vld1q_s32(_a);
  int32x4_t b = vld1q_s32(_b);
  uint32x4_t c = vcleq_s32(a, b);
  return validate_uint32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vcleq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (const float *)impl.test_cases_float_pointer1;
  const float *_b = (const float *)impl.test_cases_float_pointer2;
  uint32_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = (_a[i] <= _b[i]) ? UINT32_MAX : 0x00;
  }

  float32x4_t a = vld1q_f32(_a);
  float32x4_t b = vld1q_f32(_b);
  uint32x4_t c = vcleq_f32(a, b);
  return validate_uint32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vcle_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcleq_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcle_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcleq_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcle_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcleq_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcled_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcled_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcles_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcled_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vclez_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vclezq_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vclez_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vclezq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vclez_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vclezq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vclez_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vclezq_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vclez_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vclezq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vclez_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vclezq_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vclezd_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vclezs_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vclezd_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcleq_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (const uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (const uint8_t *)impl.test_cases_int_pointer2;
  uint8_t _c[16];
  for (int i = 0; i < 16; i++) {
    _c[i] = (_a[i] <= _b[i]) ? UINT8_MAX : 0x00;
  }

  uint8x16_t a = vld1q_u8(_a);
  uint8x16_t b = vld1q_u8(_b);
  uint8x16_t c = vcleq_u8(a, b);
  return validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7], _c[8], _c[9], _c[10], _c[11], _c[12],
                        _c[13], _c[14], _c[15]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vcleq_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (const uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (const uint16_t *)impl.test_cases_int_pointer2;
  uint16_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = (_a[i] <= _b[i]) ? UINT16_MAX : 0x00;
  }

  uint16x8_t a = vld1q_u16(_a);
  uint16x8_t b = vld1q_u16(_b);
  uint16x8_t c = vcleq_u16(a, b);
  return validate_uint16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vcleq_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (const uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (const uint32_t *)impl.test_cases_int_pointer2;
  uint32_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = (_a[i] <= _b[i]) ? UINT32_MAX : 0x00;
  }

  uint32x4_t a = vld1q_u32(_a);
  uint32x4_t b = vld1q_u32(_b);
  uint32x4_t c = vcleq_u32(a, b);
  return validate_uint32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vcgt_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (const int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (const int8_t *)impl.test_cases_int_pointer2;
  uint8_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = (_a[i] > _b[i]) ? UINT8_MAX : 0x00;
  }

  int8x8_t a = vld1_s8(_a);
  int8x8_t b = vld1_s8(_b);
  uint8x8_t c = vcgt_s8(a, b);
  return validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vcgt_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (const int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (const int16_t *)impl.test_cases_int_pointer2;
  uint16_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = (_a[i] > _b[i]) ? UINT16_MAX : 0x00;
  }

  int16x4_t a = vld1_s16(_a);
  int16x4_t b = vld1_s16(_b);
  uint16x4_t c = vcgt_s16(a, b);
  return validate_uint16(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vcgt_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (const int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (const int32_t *)impl.test_cases_int_pointer2;
  uint32_t _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = (_a[i] > _b[i]) ? UINT32_MAX : 0x00;
  }

  int32x2_t a = vld1_s32(_a);
  int32x2_t b = vld1_s32(_b);
  uint32x2_t c = vcgt_s32(a, b);
  return validate_uint32(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vcgt_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (const float *)impl.test_cases_float_pointer1;
  const float *_b = (const float *)impl.test_cases_float_pointer2;
  uint32_t _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = (_a[i] > _b[i]) ? UINT32_MAX : 0x00;
  }

  float32x2_t a = vld1_f32(_a);
  float32x2_t b = vld1_f32(_b);
  uint32x2_t c = vcgt_f32(a, b);
  return validate_uint32(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vcgt_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (const uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (const uint8_t *)impl.test_cases_int_pointer2;
  uint8_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = (_a[i] > _b[i]) ? UINT8_MAX : 0x00;
  }

  uint8x8_t a = vld1_u8(_a);
  uint8x8_t b = vld1_u8(_b);
  uint8x8_t c = vcgt_u8(a, b);
  return validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vcgt_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (const uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (const uint16_t *)impl.test_cases_int_pointer2;
  uint16_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = (_a[i] > _b[i]) ? UINT16_MAX : 0x00;
  }

  uint16x4_t a = vld1_u16(_a);
  uint16x4_t b = vld1_u16(_b);
  uint16x4_t c = vcgt_u16(a, b);
  return validate_uint16(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vcgt_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (const uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (const uint32_t *)impl.test_cases_int_pointer2;
  uint32_t _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = (_a[i] > _b[i]) ? UINT32_MAX : 0x00;
  }

  uint32x2_t a = vld1_u32(_a);
  uint32x2_t b = vld1_u32(_b);
  uint32x2_t c = vcgt_u32(a, b);
  return validate_uint32(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vcgtq_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (const int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (const int8_t *)impl.test_cases_int_pointer2;
  uint8_t _c[16];
  for (int i = 0; i < 16; i++) {
    _c[i] = (_a[i] > _b[i]) ? UINT8_MAX : 0x00;
  }

  int8x16_t a = vld1q_s8(_a);
  int8x16_t b = vld1q_s8(_b);
  uint8x16_t c = vcgtq_s8(a, b);
  return validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7], _c[8], _c[9], _c[10], _c[11], _c[12],
                        _c[13], _c[14], _c[15]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vcgtq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (const int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (const int16_t *)impl.test_cases_int_pointer2;
  uint16_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = (_a[i] > _b[i]) ? UINT16_MAX : 0x00;
  }

  int16x8_t a = vld1q_s16(_a);
  int16x8_t b = vld1q_s16(_b);
  uint16x8_t c = vcgtq_s16(a, b);
  return validate_uint16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vcgtq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (const int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (const int32_t *)impl.test_cases_int_pointer2;
  uint32_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = (_a[i] > _b[i]) ? UINT32_MAX : 0x00;
  }

  int32x4_t a = vld1q_s32(_a);
  int32x4_t b = vld1q_s32(_b);
  uint32x4_t c = vcgtq_s32(a, b);
  return validate_uint32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vcgtq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (const float *)impl.test_cases_float_pointer1;
  const float *_b = (const float *)impl.test_cases_float_pointer2;
  uint32_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = (_a[i] > _b[i]) ? UINT32_MAX : 0x00;
  }

  float32x4_t a = vld1q_f32(_a);
  float32x4_t b = vld1q_f32(_b);
  uint32x4_t c = vcgtq_f32(a, b);
  return validate_uint32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vcgt_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcgtq_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcgt_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcgtq_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcgt_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcgtq_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcgtd_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcgtd_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcgts_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcgtd_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcgtz_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcgtzq_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcgtz_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcgtzq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcgtz_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcgtzq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcgtz_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcgtzq_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcgtz_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcgtzq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcgtz_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcgtzq_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcgtzd_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcgtzs_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcgtzd_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcgtq_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (const uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (const uint8_t *)impl.test_cases_int_pointer2;
  uint8_t _c[16];
  for (int i = 0; i < 16; i++) {
    _c[i] = (_a[i] > _b[i]) ? UINT8_MAX : 0x00;
  }

  uint8x16_t a = vld1q_u8(_a);
  uint8x16_t b = vld1q_u8(_b);
  uint8x16_t c = vcgtq_u8(a, b);
  return validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7], _c[8], _c[9], _c[10], _c[11], _c[12],
                        _c[13], _c[14], _c[15]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vcgtq_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (const uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (const uint16_t *)impl.test_cases_int_pointer2;
  uint16_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = (_a[i] > _b[i]) ? UINT16_MAX : 0x00;
  }

  uint16x8_t a = vld1q_u16(_a);
  uint16x8_t b = vld1q_u16(_b);
  uint16x8_t c = vcgtq_u16(a, b);
  return validate_uint16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vcgtq_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (const uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (const uint32_t *)impl.test_cases_int_pointer2;
  uint32_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = (_a[i] > _b[i]) ? UINT32_MAX : 0x00;
  }

  uint32x4_t a = vld1q_u32(_a);
  uint32x4_t b = vld1q_u32(_b);
  uint32x4_t c = vcgtq_u32(a, b);
  return validate_uint32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vclt_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (const int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (const int8_t *)impl.test_cases_int_pointer2;
  uint8_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = (_a[i] < _b[i]) ? UINT8_MAX : 0x00;
  }

  int8x8_t a = vld1_s8(_a);
  int8x8_t b = vld1_s8(_b);
  uint8x8_t c = vclt_s8(a, b);
  return validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vclt_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (const int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (const int16_t *)impl.test_cases_int_pointer2;
  uint16_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = (_a[i] < _b[i]) ? UINT16_MAX : 0x00;
  }

  int16x4_t a = vld1_s16(_a);
  int16x4_t b = vld1_s16(_b);
  uint16x4_t c = vclt_s16(a, b);
  return validate_uint16(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vclt_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (const int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (const int32_t *)impl.test_cases_int_pointer2;
  uint32_t _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = (_a[i] < _b[i]) ? UINT32_MAX : 0x00;
  }

  int32x2_t a = vld1_s32(_a);
  int32x2_t b = vld1_s32(_b);
  uint32x2_t c = vclt_s32(a, b);
  return validate_uint32(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vclt_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (const float *)impl.test_cases_float_pointer1;
  const float *_b = (const float *)impl.test_cases_float_pointer2;
  uint32_t _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = (_a[i] < _b[i]) ? UINT32_MAX : 0x00;
  }

  float32x2_t a = vld1_f32(_a);
  float32x2_t b = vld1_f32(_b);
  uint32x2_t c = vclt_f32(a, b);
  return validate_uint32(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vclt_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (const uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (const uint8_t *)impl.test_cases_int_pointer2;
  uint8_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = (_a[i] < _b[i]) ? UINT8_MAX : 0x00;
  }

  uint8x8_t a = vld1_u8(_a);
  uint8x8_t b = vld1_u8(_b);
  uint8x8_t c = vclt_u8(a, b);
  return validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vclt_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (const uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (const uint16_t *)impl.test_cases_int_pointer2;
  uint16_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = (_a[i] < _b[i]) ? UINT16_MAX : 0x00;
  }

  uint16x4_t a = vld1_u16(_a);
  uint16x4_t b = vld1_u16(_b);
  uint16x4_t c = vclt_u16(a, b);
  return validate_uint16(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vclt_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (const uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (const uint32_t *)impl.test_cases_int_pointer2;
  uint32_t _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = (_a[i] < _b[i]) ? UINT32_MAX : 0x00;
  }

  uint32x2_t a = vld1_u32(_a);
  uint32x2_t b = vld1_u32(_b);
  uint32x2_t c = vclt_u32(a, b);
  return validate_uint32(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vcltq_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (const int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (const int8_t *)impl.test_cases_int_pointer2;
  uint8_t _c[16];
  for (int i = 0; i < 16; i++) {
    _c[i] = (_a[i] < _b[i]) ? UINT8_MAX : 0x00;
  }

  int8x16_t a = vld1q_s8(_a);
  int8x16_t b = vld1q_s8(_b);
  uint8x16_t c = vcltq_s8(a, b);
  return validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7], _c[8], _c[9], _c[10], _c[11], _c[12],
                        _c[13], _c[14], _c[15]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vcltq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (const int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (const int16_t *)impl.test_cases_int_pointer2;
  uint16_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = (_a[i] < _b[i]) ? UINT16_MAX : 0x00;
  }

  int16x8_t a = vld1q_s16(_a);
  int16x8_t b = vld1q_s16(_b);
  uint16x8_t c = vcltq_s16(a, b);
  return validate_uint16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vcltq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (const int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (const int32_t *)impl.test_cases_int_pointer2;
  uint32_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = (_a[i] < _b[i]) ? UINT32_MAX : 0x00;
  }

  int32x4_t a = vld1q_s32(_a);
  int32x4_t b = vld1q_s32(_b);
  uint32x4_t c = vcltq_s32(a, b);
  return validate_uint32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vcltq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (const float *)impl.test_cases_float_pointer1;
  const float *_b = (const float *)impl.test_cases_float_pointer2;
  uint32_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = (_a[i] < _b[i]) ? UINT32_MAX : 0x00;
  }

  float32x4_t a = vld1q_f32(_a);
  float32x4_t b = vld1q_f32(_b);
  uint32x4_t c = vcltq_f32(a, b);
  return validate_uint32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vclt_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcltq_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vclt_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcltq_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vclt_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcltq_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcltd_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcltd_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vclts_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcltd_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcltz_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcltzq_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcltz_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcltzq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcltz_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcltzq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcltz_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcltzq_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcltz_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcltzq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcltz_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcltzq_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcltzd_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcltzs_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcltzd_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcltq_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (const uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (const uint8_t *)impl.test_cases_int_pointer2;
  uint8_t _c[16];
  for (int i = 0; i < 16; i++) {
    _c[i] = (_a[i] < _b[i]) ? UINT8_MAX : 0x00;
  }

  uint8x16_t a = vld1q_u8(_a);
  uint8x16_t b = vld1q_u8(_b);
  uint8x16_t c = vcltq_u8(a, b);
  return validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7], _c[8], _c[9], _c[10], _c[11], _c[12],
                        _c[13], _c[14], _c[15]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vcltq_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (const uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (const uint16_t *)impl.test_cases_int_pointer2;
  uint16_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = (_a[i] < _b[i]) ? UINT16_MAX : 0x00;
  }

  uint16x8_t a = vld1q_u16(_a);
  uint16x8_t b = vld1q_u16(_b);
  uint16x8_t c = vcltq_u16(a, b);
  return validate_uint16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vcltq_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (const uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (const uint32_t *)impl.test_cases_int_pointer2;
  uint32_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = (_a[i] < _b[i]) ? UINT32_MAX : 0x00;
  }

  uint32x4_t a = vld1q_u32(_a);
  uint32x4_t b = vld1q_u32(_b);
  uint32x4_t c = vcltq_u32(a, b);
  return validate_uint32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vabs_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (const int8_t *)impl.test_cases_int_pointer1;
  int8_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = abs(_a[i]);
  }

  int8x8_t a = vld1_s8(_a);
  int8x8_t c = vabs_s8(a);
  return validate_int8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vabs_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (const int16_t *)impl.test_cases_int_pointer1;
  int16_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = abs(_a[i]);
  }

  int16x4_t a = vld1_s16(_a);
  int16x4_t c = vabs_s16(a);
  return validate_int16(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vabs_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (const int32_t *)impl.test_cases_int_pointer1;
  int32_t _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = abs(_a[i]);
  }

  int32x2_t a = vld1_s32(_a);
  int32x2_t c = vabs_s32(a);
  return validate_int32(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vabs_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (const float *)impl.test_cases_float_pointer1;
  float _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = fabs(_a[i]);
  }

  float32x2_t a = vld1_f32(_a);
  float32x2_t c = vabs_f32(a);
  return validate_float(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vabsq_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (const int8_t *)impl.test_cases_int_pointer1;
  int8_t _c[16];
  for (int i = 0; i < 16; i++) {
    _c[i] = abs(_a[i]);
  }

  int8x16_t a = vld1q_s8(_a);
  int8x16_t c = vabsq_s8(a);
  return validate_int8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7], _c[8], _c[9], _c[10], _c[11], _c[12],
                       _c[13], _c[14], _c[15]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vabsq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (const int16_t *)impl.test_cases_int_pointer1;
  int16_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = abs(_a[i]);
  }

  int16x8_t a = vld1q_s16(_a);
  int16x8_t c = vabsq_s16(a);
  return validate_int16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vabsq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (const int32_t *)impl.test_cases_int_pointer1;
  int32_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = abs(_a[i]);
  }

  int32x4_t a = vld1q_s32(_a);
  int32x4_t c = vabsq_s32(a);
  return validate_int32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vabsq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (const float *)impl.test_cases_float_pointer1;
  float _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = fabs(_a[i]);
  }

  float32x4_t a = vld1q_f32(_a);
  float32x4_t c = vabsq_f32(a);
  return validate_float(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vabs_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vabsd_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vabsq_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vabs_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vabsq_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqabs_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  int8_t _c[8];
  // insert edge case _a[i] = INT8_MIN
  _a[0] = INT8_MIN;
  for (int i = 0; i < 8; i++) {
    if (abs(_a[i]) > INT8_MAX) {
      _c[i] = INT8_MAX;
    } else {
      _c[i] = abs(_a[i]);
    }
  }

  int8x8_t a = vld1_s8(_a);
  int8x8_t c = vqabs_s8(a);
  return validate_int8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqabs_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  int16_t _c[4];
  // insert edge case _a[i] = INT16_MIN
  _a[0] = INT16_MIN;
  for (int i = 0; i < 4; i++) {
    if (abs(_a[i]) > INT16_MAX) {
      _c[i] = INT16_MAX;
    } else {
      _c[i] = abs(_a[i]);
    }
  }

  int16x4_t a = vld1_s16(_a);
  int16x4_t c = vqabs_s16(a);
  return validate_int16(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqabs_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  int32_t _c[2];
  // insert edge case _a[i] = INT32_MIN
  _a[0] = INT32_MIN;
  for (int i = 0; i < 2; i++) {
    int64_t tmp = _a[i];
    if (_a[i] < 0) {
      tmp = -tmp;
    }
    if (tmp > INT32_MAX) {
      _c[i] = INT32_MAX;
    } else {
      _c[i] = tmp;
    }
  }

  int32x2_t a = vld1_s32(_a);
  int32x2_t c = vqabs_s32(a);
  return validate_int32(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqabsq_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  int8_t _c[16];
  // insert edge case _a[i] = INT8_MIN
  _a[0] = INT8_MIN;
  for (int i = 0; i < 16; i++) {
    if (abs(_a[i]) > INT8_MAX) {
      _c[i] = INT8_MAX;
    } else {
      _c[i] = abs(_a[i]);
    }
  }

  int8x16_t a = vld1q_s8(_a);
  int8x16_t c = vqabsq_s8(a);
  return validate_int8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7], _c[8], _c[9], _c[10], _c[11], _c[12],
                       _c[13], _c[14], _c[15]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqabsq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  int16_t _c[8];
  // insert edge case _a[i] = INT16_MIN
  _a[0] = INT16_MIN;
  for (int i = 0; i < 8; i++) {
    if (abs(_a[i]) > INT16_MAX) {
      _c[i] = INT16_MAX;
    } else {
      _c[i] = abs(_a[i]);
    }
  }

  int16x8_t a = vld1q_s16(_a);
  int16x8_t c = vqabsq_s16(a);
  return validate_int16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqabsq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  int32_t _c[4];
  // insert edge case _a[i] = INT32_MIN
  _a[0] = INT32_MIN;
  for (int i = 0; i < 4; i++) {
    for (int i = 0; i < 4; i++) {
      int64_t tmp = _a[i];
      if (_a[i] < 0) {
        tmp = -tmp;
      }
      if (tmp > INT32_MAX) {
        _c[i] = INT32_MAX;
      } else {
        _c[i] = tmp;
      }
    }
  }

  int32x4_t a = vld1q_s32(_a);
  int32x4_t c = vqabsq_s32(a);
  return validate_int32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqabs_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqabsq_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqabsb_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqabsh_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqabss_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqabsd_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcage_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (const float *)impl.test_cases_float_pointer1;
  const float *_b = (const float *)impl.test_cases_float_pointer2;
  float _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = fabs(_a[i]) >= fabs(_b[i]) ? UINT32_MAX : 0x0;
  }

  float32x2_t a = vld1_f32(_a);
  float32x2_t b = vld1_f32(_b);
  uint32x2_t c = vcage_f32(a, b);
  return validate_uint32(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vcageq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (const float *)impl.test_cases_float_pointer1;
  const float *_b = (const float *)impl.test_cases_float_pointer2;
  float _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = fabs(_a[i]) >= fabs(_b[i]) ? UINT32_MAX : 0x0;
  }

  float32x4_t a = vld1q_f32(_a);
  float32x4_t b = vld1q_f32(_b);
  uint32x4_t c = vcageq_f32(a, b);
  return validate_uint32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vcage_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcageq_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcages_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcaged_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcale_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (const float *)impl.test_cases_float_pointer1;
  const float *_b = (const float *)impl.test_cases_float_pointer2;
  float _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = fabs(_a[i]) <= fabs(_b[i]) ? UINT32_MAX : 0x0;
  }

  float32x2_t a = vld1_f32(_a);
  float32x2_t b = vld1_f32(_b);
  uint32x2_t c = vcale_f32(a, b);
  return validate_uint32(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vcaleq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (const float *)impl.test_cases_float_pointer1;
  const float *_b = (const float *)impl.test_cases_float_pointer2;
  float _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = fabs(_a[i]) <= fabs(_b[i]) ? UINT32_MAX : 0x0;
  }

  float32x4_t a = vld1q_f32(_a);
  float32x4_t b = vld1q_f32(_b);
  uint32x4_t c = vcaleq_f32(a, b);
  return validate_uint32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vcale_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcaleq_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcales_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcaled_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcagt_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (const float *)impl.test_cases_float_pointer1;
  const float *_b = (const float *)impl.test_cases_float_pointer2;
  float _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = fabs(_a[i]) > fabs(_b[i]) ? UINT32_MAX : 0x0;
  }

  float32x2_t a = vld1_f32(_a);
  float32x2_t b = vld1_f32(_b);
  uint32x2_t c = vcagt_f32(a, b);
  return validate_uint32(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vcagtq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (const float *)impl.test_cases_float_pointer1;
  const float *_b = (const float *)impl.test_cases_float_pointer2;
  float _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = fabs(_a[i]) > fabs(_b[i]) ? UINT32_MAX : 0x0;
  }

  float32x4_t a = vld1q_f32(_a);
  float32x4_t b = vld1q_f32(_b);
  uint32x4_t c = vcagtq_f32(a, b);
  return validate_uint32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vcagt_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcagtq_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcagts_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcagtd_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcalt_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (const float *)impl.test_cases_float_pointer1;
  const float *_b = (const float *)impl.test_cases_float_pointer2;
  float _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = fabs(_a[i]) < fabs(_b[i]) ? UINT32_MAX : 0x0;
  }

  float32x2_t a = vld1_f32(_a);
  float32x2_t b = vld1_f32(_b);
  uint32x2_t c = vcalt_f32(a, b);
  return validate_uint32(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vcaltq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (const float *)impl.test_cases_float_pointer1;
  const float *_b = (const float *)impl.test_cases_float_pointer2;
  float _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = fabs(_a[i]) < fabs(_b[i]) ? UINT32_MAX : 0x0;
  }

  float32x4_t a = vld1q_f32(_a);
  float32x4_t b = vld1q_f32(_b);
  uint32x4_t c = vcaltq_f32(a, b);
  return validate_uint32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vcalt_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcaltq_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcalts_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcaltd_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vtst_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (const int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (const int8_t *)impl.test_cases_int_pointer1;
  uint8_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = (_a[i] & _b[i]) ? UINT8_MAX : 0x0;
  }

  int8x8_t a = vld1_s8(_a);
  int8x8_t b = vld1_s8(_b);
  uint8x8_t c = vtst_s8(a, b);
  return validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vtst_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (const int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (const int16_t *)impl.test_cases_int_pointer1;
  uint16_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = (_a[i] & _b[i]) ? UINT16_MAX : 0x0;
  }

  int16x4_t a = vld1_s16(_a);
  int16x4_t b = vld1_s16(_b);
  uint16x4_t c = vtst_s16(a, b);
  return validate_uint16(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vtst_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (const int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (const int32_t *)impl.test_cases_int_pointer1;
  uint32_t _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = (_a[i] & _b[i]) ? UINT32_MAX : 0x0;
  }

  int32x2_t a = vld1_s32(_a);
  int32x2_t b = vld1_s32(_b);
  uint32x2_t c = vtst_s32(a, b);
  return validate_uint32(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vtst_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (const uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (const uint8_t *)impl.test_cases_int_pointer1;
  uint8_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = (_a[i] & _b[i]) ? UINT8_MAX : 0x0;
  }

  uint8x8_t a = vld1_u8(_a);
  uint8x8_t b = vld1_u8(_b);
  uint8x8_t c = vtst_u8(a, b);
  return validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vtst_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (const uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (const uint16_t *)impl.test_cases_int_pointer1;
  uint16_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = (_a[i] & _b[i]) ? UINT16_MAX : 0x0;
  }

  uint16x4_t a = vld1_u16(_a);
  uint16x4_t b = vld1_u16(_b);
  uint16x4_t c = vtst_u16(a, b);
  return validate_uint16(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vtst_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (const uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (const uint32_t *)impl.test_cases_int_pointer1;
  uint32_t _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = (_a[i] & _b[i]) ? UINT32_MAX : 0x0;
  }

  uint32x2_t a = vld1_u32(_a);
  uint32x2_t b = vld1_u32(_b);
  uint32x2_t c = vtst_u32(a, b);
  return validate_uint32(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vtstq_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (const int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (const int8_t *)impl.test_cases_int_pointer1;
  uint8_t _c[16];
  for (int i = 0; i < 16; i++) {
    _c[i] = (_a[i] & _b[i]) ? UINT8_MAX : 0x0;
  }

  int8x16_t a = vld1q_s8(_a);
  int8x16_t b = vld1q_s8(_b);
  uint8x16_t c = vtstq_s8(a, b);
  return validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7], _c[8], _c[9], _c[10], _c[11], _c[12],
                        _c[13], _c[14], _c[15]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vtstq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (const int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (const int16_t *)impl.test_cases_int_pointer1;
  uint16_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = (_a[i] & _b[i]) ? UINT16_MAX : 0x0;
  }

  int16x8_t a = vld1q_s16(_a);
  int16x8_t b = vld1q_s16(_b);
  uint16x8_t c = vtstq_s16(a, b);
  return validate_uint16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vtstq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (const int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (const int32_t *)impl.test_cases_int_pointer1;
  uint32_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = (_a[i] & _b[i]) ? UINT32_MAX : 0x0;
  }

  int32x4_t a = vld1q_s32(_a);
  int32x4_t b = vld1q_s32(_b);
  uint32x4_t c = vtstq_s32(a, b);
  return validate_uint32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vtstq_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (const uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (const uint8_t *)impl.test_cases_int_pointer1;
  uint8_t _c[16];
  for (int i = 0; i < 16; i++) {
    _c[i] = (_a[i] & _b[i]) ? UINT8_MAX : 0x0;
  }

  uint8x16_t a = vld1q_u8(_a);
  uint8x16_t b = vld1q_u8(_b);
  uint8x16_t c = vtstq_u8(a, b);
  return validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7], _c[8], _c[9], _c[10], _c[11], _c[12],
                        _c[13], _c[14], _c[15]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vtstq_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (const uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (const uint16_t *)impl.test_cases_int_pointer1;
  uint16_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = (_a[i] & _b[i]) ? UINT16_MAX : 0x0;
  }

  uint16x8_t a = vld1q_u16(_a);
  uint16x8_t b = vld1q_u16(_b);
  uint16x8_t c = vtstq_u16(a, b);
  return validate_uint16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vtstq_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (const uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (const uint32_t *)impl.test_cases_int_pointer1;
  uint32_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = (_a[i] & _b[i]) ? UINT32_MAX : 0x0;
  }

  uint32x4_t a = vld1q_u32(_a);
  uint32x4_t b = vld1q_u32(_b);
  uint32x4_t c = vtstq_u32(a, b);
  return validate_uint32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vtst_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vtstq_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vtst_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vtstq_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vtst_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vtstq_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vtst_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vtstq_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vtstd_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vtstd_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vabd_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (const int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (const int8_t *)impl.test_cases_int_pointer2;
  int8_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = abs(_a[i] - _b[i]);
  }
  int8x8_t a = vld1_s8(_a);
  int8x8_t b = vld1_s8(_b);
  int8x8_t c = vabd_s8(a, b);

  return validate_int8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vabd_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (const int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (const int16_t *)impl.test_cases_int_pointer2;
  int16_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = abs(_a[i] - _b[i]);
  }
  int16x4_t a = vld1_s16(_a);
  int16x4_t b = vld1_s16(_b);
  int16x4_t c = vabd_s16(a, b);

  return validate_int16(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vabd_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (const int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (const int32_t *)impl.test_cases_int_pointer2;
  int32_t _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = abs(_a[i] - _b[i]);
  }
  int32x2_t a = vld1_s32(_a);
  int32x2_t b = vld1_s32(_b);
  int32x2_t c = vabd_s32(a, b);

  return validate_int32(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vabd_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (const float *)impl.test_cases_float_pointer1;
  const float *_b = (const float *)impl.test_cases_float_pointer2;
  float _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = abs(_a[i] - _b[i]);
  }
  float32x2_t a = vld1_f32(_a);
  float32x2_t b = vld1_f32(_b);
  float32x2_t c = vabd_f32(a, b);

  return validate_float(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vabd_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (const uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (const uint8_t *)impl.test_cases_int_pointer2;
  uint8_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = abs(_a[i] - _b[i]);
  }
  uint8x8_t a = vld1_u8(_a);
  uint8x8_t b = vld1_u8(_b);
  uint8x8_t c = vabd_u8(a, b);

  return validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vabd_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (const uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (const uint16_t *)impl.test_cases_int_pointer2;
  uint16_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = abs(_a[i] - _b[i]);
  }
  uint16x4_t a = vld1_u16(_a);
  uint16x4_t b = vld1_u16(_b);
  uint16x4_t c = vabd_u16(a, b);

  return validate_uint16(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vabd_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (const uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (const uint32_t *)impl.test_cases_int_pointer2;
  uint32_t _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = (_a[i] > _b[i]) ? (_a[i] - _b[i]) : (_b[i] - _a[i]);
  }
  uint32x2_t a = vld1_u32(_a);
  uint32x2_t b = vld1_u32(_b);
  uint32x2_t c = vabd_u32(a, b);

  return validate_uint32(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vabdq_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (const int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (const int8_t *)impl.test_cases_int_pointer2;
  int8_t _c[16];
  for (int i = 0; i < 16; i++) {
    _c[i] = abs(_a[i] - _b[i]);
  }
  int8x16_t a = vld1q_s8(_a);
  int8x16_t b = vld1q_s8(_b);
  int8x16_t c = vabdq_s8(a, b);

  return validate_int8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7], _c[8], _c[9], _c[10], _c[11], _c[12],
                       _c[13], _c[14], _c[15]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vabdq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (const int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (const int16_t *)impl.test_cases_int_pointer2;
  int16_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = abs(_a[i] - _b[i]);
  }
  int16x8_t a = vld1q_s16(_a);
  int16x8_t b = vld1q_s16(_b);
  int16x8_t c = vabdq_s16(a, b);

  return validate_int16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vabdq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (const int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (const int32_t *)impl.test_cases_int_pointer2;
  int32_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = abs(_a[i] - _b[i]);
  }
  int32x4_t a = vld1q_s32(_a);
  int32x4_t b = vld1q_s32(_b);
  int32x4_t c = vabdq_s32(a, b);

  return validate_int32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vabdq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (const float *)impl.test_cases_float_pointer1;
  const float *_b = (const float *)impl.test_cases_float_pointer2;
  float _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = abs(_a[i] - _b[i]);
  }
  float32x4_t a = vld1q_f32(_a);
  float32x4_t b = vld1q_f32(_b);
  float32x4_t c = vabdq_f32(a, b);

  return validate_float(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vabd_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vabdq_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vabds_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vabdd_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vabdq_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (const uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (const uint8_t *)impl.test_cases_int_pointer2;
  uint8_t _c[16];
  for (int i = 0; i < 16; i++) {
    _c[i] = abs(_a[i] - _b[i]);
  }
  uint8x16_t a = vld1q_u8(_a);
  uint8x16_t b = vld1q_u8(_b);
  uint8x16_t c = vabdq_u8(a, b);

  return validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7], _c[8], _c[9], _c[10], _c[11], _c[12],
                        _c[13], _c[14], _c[15]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vabdq_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (const uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (const uint16_t *)impl.test_cases_int_pointer2;
  uint16_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = abs(_a[i] - _b[i]);
  }
  uint16x8_t a = vld1q_u16(_a);
  uint16x8_t b = vld1q_u16(_b);
  uint16x8_t c = vabdq_u16(a, b);

  return validate_uint16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vabdq_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (const uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (const uint32_t *)impl.test_cases_int_pointer2;
  uint32_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = (_a[i] > _b[i]) ? (_a[i] - _b[i]) : (_b[i] - _a[i]);
  }
  uint32x4_t a = vld1q_u32(_a);
  uint32x4_t b = vld1q_u32(_b);
  uint32x4_t c = vabdq_u32(a, b);

  return validate_uint32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vabdl_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (const int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (const int8_t *)impl.test_cases_int_pointer2;
  int16_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = abs(_a[i] - _b[i]);
  }
  int8x8_t a = vld1_s8(_a);
  int8x8_t b = vld1_s8(_b);
  int16x8_t c = vabdl_s8(a, b);

  return validate_int16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vabdl_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (const int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (const int16_t *)impl.test_cases_int_pointer2;
  int32_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = abs(_a[i] - _b[i]);
  }
  int16x4_t a = vld1_s16(_a);
  int16x4_t b = vld1_s16(_b);
  int32x4_t c = vabdl_s16(a, b);

  return validate_int32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vabdl_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (const int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (const int32_t *)impl.test_cases_int_pointer2;
  int64_t _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = abs(_a[i] - _b[i]);
  }
  int32x2_t a = vld1_s32(_a);
  int32x2_t b = vld1_s32(_b);
  int64x2_t c = vabdl_s32(a, b);

  return validate_int64(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vabdl_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (const uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (const uint8_t *)impl.test_cases_int_pointer2;
  uint16_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = abs(_a[i] - _b[i]);
  }
  uint8x8_t a = vld1_u8(_a);
  uint8x8_t b = vld1_u8(_b);
  uint16x8_t c = vabdl_u8(a, b);

  return validate_uint16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vabdl_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (const uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (const uint16_t *)impl.test_cases_int_pointer2;
  uint32_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = abs(_a[i] - _b[i]);
  }
  uint16x4_t a = vld1_u16(_a);
  uint16x4_t b = vld1_u16(_b);
  uint32x4_t c = vabdl_u16(a, b);

  return validate_uint32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vabdl_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (const uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (const uint32_t *)impl.test_cases_int_pointer2;
  uint64_t _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = (_a[i] > _b[i]) ? (_a[i] - _b[i]) : (_b[i] - _a[i]);
  }
  uint32x2_t a = vld1_u32(_a);
  uint32x2_t b = vld1_u32(_b);
  uint64x2_t c = vabdl_u32(a, b);

  return validate_uint64(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vabdl_high_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vabdl_high_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vabdl_high_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vabdl_high_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vabdl_high_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vabdl_high_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vaba_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (const int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (const int8_t *)impl.test_cases_int_pointer2;
  const int8_t *_c = (const int8_t *)impl.test_cases_int_pointer3;
  int8_t _d[8];
  for (int i = 0; i < 8; i++) {
    _d[i] = _a[i] + abs(_b[i] - _c[i]);
  }
  int8x8_t a = vld1_s8(_a);
  int8x8_t b = vld1_s8(_b);
  int8x8_t c = vld1_s8(_c);
  int8x8_t d = vaba_s8(a, b, c);

  return validate_int8(d, _d[0], _d[1], _d[2], _d[3], _d[4], _d[5], _d[6], _d[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vaba_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (const int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (const int16_t *)impl.test_cases_int_pointer2;
  const int16_t *_c = (const int16_t *)impl.test_cases_int_pointer3;
  int16_t _d[4];
  for (int i = 0; i < 4; i++) {
    _d[i] = _a[i] + abs(_b[i] - _c[i]);
  }
  int16x4_t a = vld1_s16(_a);
  int16x4_t b = vld1_s16(_b);
  int16x4_t c = vld1_s16(_c);
  int16x4_t d = vaba_s16(a, b, c);

  return validate_int16(d, _d[0], _d[1], _d[2], _d[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vaba_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (const int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (const int32_t *)impl.test_cases_int_pointer2;
  const int32_t *_c = (const int32_t *)impl.test_cases_int_pointer3;
  int32_t _d[2];
  for (int i = 0; i < 2; i++) {
    _d[i] = _a[i] + abs(_b[i] - _c[i]);
  }
  int32x2_t a = vld1_s32(_a);
  int32x2_t b = vld1_s32(_b);
  int32x2_t c = vld1_s32(_c);
  int32x2_t d = vaba_s32(a, b, c);

  return validate_int32(d, _d[0], _d[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vaba_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (const uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (const uint8_t *)impl.test_cases_int_pointer2;
  const uint8_t *_c = (const uint8_t *)impl.test_cases_int_pointer3;
  uint8_t _d[8];
  for (int i = 0; i < 8; i++) {
    _d[i] = _a[i] + abs(_b[i] - _c[i]);
  }
  uint8x8_t a = vld1_u8(_a);
  uint8x8_t b = vld1_u8(_b);
  uint8x8_t c = vld1_u8(_c);
  uint8x8_t d = vaba_u8(a, b, c);

  return validate_uint8(d, _d[0], _d[1], _d[2], _d[3], _d[4], _d[5], _d[6], _d[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vaba_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (const uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (const uint16_t *)impl.test_cases_int_pointer2;
  const uint16_t *_c = (const uint16_t *)impl.test_cases_int_pointer3;
  uint16_t _d[4];
  for (int i = 0; i < 4; i++) {
    _d[i] = _a[i] + abs(_b[i] - _c[i]);
  }
  uint16x4_t a = vld1_u16(_a);
  uint16x4_t b = vld1_u16(_b);
  uint16x4_t c = vld1_u16(_c);
  uint16x4_t d = vaba_u16(a, b, c);

  return validate_uint16(d, _d[0], _d[1], _d[2], _d[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vaba_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (const uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (const uint32_t *)impl.test_cases_int_pointer2;
  const uint32_t *_c = (const uint32_t *)impl.test_cases_int_pointer3;
  uint32_t _d[2];
  for (int i = 0; i < 2; i++) {
    uint32_t tmp = _b[i] > _c[i] ? (_b[i] - _c[i]) : (_c[i] - _b[i]);
    _d[i] = _a[i] + tmp;
  }
  uint32x2_t a = vld1_u32(_a);
  uint32x2_t b = vld1_u32(_b);
  uint32x2_t c = vld1_u32(_c);
  uint32x2_t d = vaba_u32(a, b, c);

  return validate_uint32(d, _d[0], _d[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vabaq_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (const int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (const int8_t *)impl.test_cases_int_pointer2;
  const int8_t *_c = (const int8_t *)impl.test_cases_int_pointer3;
  int8_t _d[16];
  for (int i = 0; i < 16; i++) {
    _d[i] = _a[i] + abs(_b[i] - _c[i]);
  }
  int8x16_t a = vld1q_s8(_a);
  int8x16_t b = vld1q_s8(_b);
  int8x16_t c = vld1q_s8(_c);
  int8x16_t d = vabaq_s8(a, b, c);

  return validate_int8(d, _d[0], _d[1], _d[2], _d[3], _d[4], _d[5], _d[6], _d[7], _d[8], _d[9], _d[10], _d[11], _d[12],
                       _d[13], _d[14], _d[15]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vabaq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (const int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (const int16_t *)impl.test_cases_int_pointer2;
  const int16_t *_c = (const int16_t *)impl.test_cases_int_pointer3;
  int16_t _d[8];
  for (int i = 0; i < 8; i++) {
    _d[i] = _a[i] + abs(_b[i] - _c[i]);
  }
  int16x8_t a = vld1q_s16(_a);
  int16x8_t b = vld1q_s16(_b);
  int16x8_t c = vld1q_s16(_c);
  int16x8_t d = vabaq_s16(a, b, c);

  return validate_int16(d, _d[0], _d[1], _d[2], _d[3], _d[4], _d[5], _d[6], _d[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vabaq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (const int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (const int32_t *)impl.test_cases_int_pointer2;
  const int32_t *_c = (const int32_t *)impl.test_cases_int_pointer3;
  int32_t _d[4];
  for (int i = 0; i < 4; i++) {
    _d[i] = _a[i] + abs(_b[i] - _c[i]);
  }
  int32x4_t a = vld1q_s32(_a);
  int32x4_t b = vld1q_s32(_b);
  int32x4_t c = vld1q_s32(_c);
  int32x4_t d = vabaq_s32(a, b, c);

  return validate_int32(d, _d[0], _d[1], _d[2], _d[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vabaq_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (const uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (const uint8_t *)impl.test_cases_int_pointer2;
  const uint8_t *_c = (const uint8_t *)impl.test_cases_int_pointer3;
  uint8_t _d[16];
  for (int i = 0; i < 16; i++) {
    _d[i] = _a[i] + abs(_b[i] - _c[i]);
  }
  uint8x16_t a = vld1q_u8(_a);
  uint8x16_t b = vld1q_u8(_b);
  uint8x16_t c = vld1q_u8(_c);
  uint8x16_t d = vabaq_u8(a, b, c);

  return validate_uint8(d, _d[0], _d[1], _d[2], _d[3], _d[4], _d[5], _d[6], _d[7], _d[8], _d[9], _d[10], _d[11], _d[12],
                        _d[13], _d[14], _d[15]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vabaq_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (const uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (const uint16_t *)impl.test_cases_int_pointer2;
  const uint16_t *_c = (const uint16_t *)impl.test_cases_int_pointer3;
  uint16_t _d[8];
  for (int i = 0; i < 8; i++) {
    _d[i] = _a[i] + abs(_b[i] - _c[i]);
  }
  uint16x8_t a = vld1q_u16(_a);
  uint16x8_t b = vld1q_u16(_b);
  uint16x8_t c = vld1q_u16(_c);
  uint16x8_t d = vabaq_u16(a, b, c);

  return validate_uint16(d, _d[0], _d[1], _d[2], _d[3], _d[4], _d[5], _d[6], _d[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vabaq_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (const uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (const uint32_t *)impl.test_cases_int_pointer2;
  const uint32_t *_c = (const uint32_t *)impl.test_cases_int_pointer3;
  uint32_t _d[4];
  for (int i = 0; i < 4; i++) {
    uint32_t tmp = _b[i] > _c[i] ? (_b[i] - _c[i]) : (_c[i] - _b[i]);
    _d[i] = _a[i] + tmp;
  }
  uint32x4_t a = vld1q_u32(_a);
  uint32x4_t b = vld1q_u32(_b);
  uint32x4_t c = vld1q_u32(_c);
  uint32x4_t d = vabaq_u32(a, b, c);

  return validate_uint32(d, _d[0], _d[1], _d[2], _d[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vabal_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (const int16_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (const int8_t *)impl.test_cases_int_pointer2;
  const int8_t *_c = (const int8_t *)impl.test_cases_int_pointer3;
  int16_t _d[8];
  for (int i = 0; i < 8; i++) {
    _d[i] = _a[i] + abs(_b[i] - _c[i]);
  }
  int16x8_t a = vld1q_s16(_a);
  int8x8_t b = vld1_s8(_b);
  int8x8_t c = vld1_s8(_c);
  int16x8_t d = vabal_s8(a, b, c);

  return validate_int16(d, _d[0], _d[1], _d[2], _d[3], _d[4], _d[5], _d[6], _d[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vabal_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (const int32_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (const int16_t *)impl.test_cases_int_pointer2;
  const int16_t *_c = (const int16_t *)impl.test_cases_int_pointer3;
  int32_t _d[4];
  for (int i = 0; i < 4; i++) {
    _d[i] = _a[i] + abs(_b[i] - _c[i]);
  }
  int32x4_t a = vld1q_s32(_a);
  int16x4_t b = vld1_s16(_b);
  int16x4_t c = vld1_s16(_c);
  int32x4_t d = vabal_s16(a, b, c);

  return validate_int32(d, _d[0], _d[1], _d[2], _d[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vabal_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (const int64_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (const int32_t *)impl.test_cases_int_pointer2;
  const int32_t *_c = (const int32_t *)impl.test_cases_int_pointer3;
  int64_t _d[2];
  for (int i = 0; i < 2; i++) {
    _d[i] = _a[i] + abs(_b[i] - _c[i]);
  }
  int64x2_t a = vld1q_s64(_a);
  int32x2_t b = vld1_s32(_b);
  int32x2_t c = vld1_s32(_c);
  int64x2_t d = vabal_s32(a, b, c);

  return validate_int64(d, _d[0], _d[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vabal_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (const uint16_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (const uint8_t *)impl.test_cases_int_pointer2;
  const uint8_t *_c = (const uint8_t *)impl.test_cases_int_pointer3;
  uint16_t _d[8];
  for (int i = 0; i < 8; i++) {
    _d[i] = _a[i] + abs(_b[i] - _c[i]);
  }
  uint16x8_t a = vld1q_u16(_a);
  uint8x8_t b = vld1_u8(_b);
  uint8x8_t c = vld1_u8(_c);
  uint16x8_t d = vabal_u8(a, b, c);

  return validate_uint16(d, _d[0], _d[1], _d[2], _d[3], _d[4], _d[5], _d[6], _d[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vabal_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (const uint32_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (const uint16_t *)impl.test_cases_int_pointer2;
  const uint16_t *_c = (const uint16_t *)impl.test_cases_int_pointer3;
  uint32_t _d[4];
  for (int i = 0; i < 4; i++) {
    _d[i] = _a[i] + abs(_b[i] - _c[i]);
  }
  uint32x4_t a = vld1q_u32(_a);
  uint16x4_t b = vld1_u16(_b);
  uint16x4_t c = vld1_u16(_c);
  uint32x4_t d = vabal_u16(a, b, c);

  return validate_uint32(d, _d[0], _d[1], _d[2], _d[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vabal_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (const uint64_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (const uint32_t *)impl.test_cases_int_pointer2;
  const uint32_t *_c = (const uint32_t *)impl.test_cases_int_pointer3;
  uint64_t _d[2];
  for (int i = 0; i < 2; i++) {
    uint64_t tmp = _b[i] > _c[i] ? (_b[i] - _c[i]) : (_c[i] - _b[i]);
    _d[i] = _a[i] + tmp;
  }
  uint64x2_t a = vld1q_u64(_a);
  uint32x2_t b = vld1_u32(_b);
  uint32x2_t c = vld1_u32(_c);
  uint64x2_t d = vabal_u32(a, b, c);

  return validate_uint64(d, _d[0], _d[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vabal_high_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vabal_high_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vabal_high_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vabal_high_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vabal_high_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vabal_high_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmax_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (int8_t *)impl.test_cases_int_pointer2;
  int8_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = _a[i] > _b[i] ? _a[i] : _b[i];
  }

  int8x8_t a = vld1_s8(_a);
  int8x8_t b = vld1_s8(_b);
  int8x8_t c = vmax_s8(a, b);
  return validate_int8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmax_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  int16_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = _a[i] > _b[i] ? _a[i] : _b[i];
  }

  int16x4_t a = vld1_s16(_a);
  int16x4_t b = vld1_s16(_b);
  int16x4_t c = vmax_s16(a, b);
  return validate_int16(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmax_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  int32_t _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = _a[i] > _b[i] ? _a[i] : _b[i];
  }

  int32x2_t a = vld1_s32(_a);
  int32x2_t b = vld1_s32(_b);
  int32x2_t c = vmax_s32(a, b);
  return validate_int32(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmax_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (float *)impl.test_cases_float_pointer1;
  const float *_b = (float *)impl.test_cases_float_pointer2;
  float _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = _a[i] > _b[i] ? _a[i] : _b[i];
  }

  float32x2_t a = vld1_f32(_a);
  float32x2_t b = vld1_f32(_b);
  float32x2_t c = vmax_f32(a, b);
  return validate_float(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmax_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (uint8_t *)impl.test_cases_int_pointer2;
  uint8_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = _a[i] > _b[i] ? _a[i] : _b[i];
  }

  uint8x8_t a = vld1_u8(_a);
  uint8x8_t b = vld1_u8(_b);
  uint8x8_t c = vmax_u8(a, b);
  return validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmax_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (uint16_t *)impl.test_cases_int_pointer2;
  uint16_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = _a[i] > _b[i] ? _a[i] : _b[i];
  }

  uint16x4_t a = vld1_u16(_a);
  uint16x4_t b = vld1_u16(_b);
  uint16x4_t c = vmax_u16(a, b);
  return validate_uint16(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmax_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (uint32_t *)impl.test_cases_int_pointer2;
  uint32_t _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = _a[i] > _b[i] ? _a[i] : _b[i];
  }

  uint32x2_t a = vld1_u32(_a);
  uint32x2_t b = vld1_u32(_b);
  uint32x2_t c = vmax_u32(a, b);
  return validate_uint32(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmaxq_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (int8_t *)impl.test_cases_int_pointer2;
  int8_t _c[16];
  for (int i = 0; i < 16; i++) {
    _c[i] = _a[i] > _b[i] ? _a[i] : _b[i];
  }

  int8x16_t a = vld1q_s8(_a);
  int8x16_t b = vld1q_s8(_b);
  int8x16_t c = vmaxq_s8(a, b);
  return validate_int8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7], _c[8], _c[9], _c[10], _c[11], _c[12],
                       _c[13], _c[14], _c[15]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmaxq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  int16_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = _a[i] > _b[i] ? _a[i] : _b[i];
  }

  int16x8_t a = vld1q_s16(_a);
  int16x8_t b = vld1q_s16(_b);
  int16x8_t c = vmaxq_s16(a, b);
  return validate_int16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmaxq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  int32_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = _a[i] > _b[i] ? _a[i] : _b[i];
  }

  int32x4_t a = vld1q_s32(_a);
  int32x4_t b = vld1q_s32(_b);
  int32x4_t c = vmaxq_s32(a, b);
  return validate_int32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmaxq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (float *)impl.test_cases_float_pointer1;
  const float *_b = (float *)impl.test_cases_float_pointer2;
  float _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = _a[i] > _b[i] ? _a[i] : _b[i];
  }

  float32x2_t a = vld1_f32(_a);
  float32x2_t b = vld1_f32(_b);
  float32x2_t c = vmax_f32(a, b);
  return validate_float(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmax_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmaxq_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmaxnm_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (float *)impl.test_cases_float_pointer1;
  const float *_b = (float *)impl.test_cases_float_pointer2;
  float _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = _a[i] > _b[i] ? _a[i] : _b[i];
  }

  float32x2_t a = vld1_f32(_a);
  float32x2_t b = vld1_f32(_b);
  float32x2_t c = vmaxnm_f32(a, b);
  return validate_float(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmaxnmq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (float *)impl.test_cases_float_pointer1;
  const float *_b = (float *)impl.test_cases_float_pointer2;
  float _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = _a[i] > _b[i] ? _a[i] : _b[i];
  }

  float32x4_t a = vld1q_f32(_a);
  float32x4_t b = vld1q_f32(_b);
  float32x4_t c = vmaxnmq_f32(a, b);
  return validate_float(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmaxnm_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmaxnmq_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vminnm_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (float *)impl.test_cases_float_pointer1;
  const float *_b = (float *)impl.test_cases_float_pointer2;
  float _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = _a[i] < _b[i] ? _a[i] : _b[i];
  }

  float32x2_t a = vld1_f32(_a);
  float32x2_t b = vld1_f32(_b);
  float32x2_t c = vminnm_f32(a, b);
  return validate_float(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vminnmq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (float *)impl.test_cases_float_pointer1;
  const float *_b = (float *)impl.test_cases_float_pointer2;
  float _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = _a[i] < _b[i] ? _a[i] : _b[i];
  }

  float32x4_t a = vld1q_f32(_a);
  float32x4_t b = vld1q_f32(_b);
  float32x4_t c = vminnmq_f32(a, b);
  return validate_float(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vminnm_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vminnmq_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmaxq_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (uint8_t *)impl.test_cases_int_pointer2;
  uint8_t _c[16];
  for (int i = 0; i < 16; i++) {
    _c[i] = _a[i] > _b[i] ? _a[i] : _b[i];
  }

  uint8x16_t a = vld1q_u8(_a);
  uint8x16_t b = vld1q_u8(_b);
  uint8x16_t c = vmaxq_u8(a, b);
  return validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7], _c[8], _c[9], _c[10], _c[11], _c[12],
                        _c[13], _c[14], _c[15]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmaxq_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (uint16_t *)impl.test_cases_int_pointer2;
  uint16_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = _a[i] > _b[i] ? _a[i] : _b[i];
  }

  uint16x8_t a = vld1q_u16(_a);
  uint16x8_t b = vld1q_u16(_b);
  uint16x8_t c = vmaxq_u16(a, b);
  return validate_uint16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmaxq_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (uint32_t *)impl.test_cases_int_pointer2;
  uint32_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = _a[i] > _b[i] ? _a[i] : _b[i];
  }

  uint32x4_t a = vld1q_u32(_a);
  uint32x4_t b = vld1q_u32(_b);
  uint32x4_t c = vmaxq_u32(a, b);
  return validate_uint32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmin_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (int8_t *)impl.test_cases_int_pointer2;
  int8_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = _a[i] < _b[i] ? _a[i] : _b[i];
  }

  int8x8_t a = vld1_s8(_a);
  int8x8_t b = vld1_s8(_b);
  int8x8_t c = vmin_s8(a, b);
  return validate_int8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmin_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  int16_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = _a[i] < _b[i] ? _a[i] : _b[i];
  }

  int16x4_t a = vld1_s16(_a);
  int16x4_t b = vld1_s16(_b);
  int16x4_t c = vmin_s16(a, b);
  return validate_int16(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmin_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  int32_t _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = _a[i] < _b[i] ? _a[i] : _b[i];
  }

  int32x2_t a = vld1_s32(_a);
  int32x2_t b = vld1_s32(_b);
  int32x2_t c = vmin_s32(a, b);
  return validate_int32(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmin_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (float *)impl.test_cases_float_pointer1;
  const float *_b = (float *)impl.test_cases_float_pointer2;
  float _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = _a[i] < _b[i] ? _a[i] : _b[i];
  }

  float32x2_t a = vld1_f32(_a);
  float32x2_t b = vld1_f32(_b);
  float32x2_t c = vmin_f32(a, b);
  return validate_float(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmin_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (uint8_t *)impl.test_cases_int_pointer2;
  uint8_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = _a[i] < _b[i] ? _a[i] : _b[i];
  }

  uint8x8_t a = vld1_u8(_a);
  uint8x8_t b = vld1_u8(_b);
  uint8x8_t c = vmin_u8(a, b);
  return validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmin_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (uint16_t *)impl.test_cases_int_pointer2;
  uint16_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = _a[i] < _b[i] ? _a[i] : _b[i];
  }

  uint16x4_t a = vld1_u16(_a);
  uint16x4_t b = vld1_u16(_b);
  uint16x4_t c = vmin_u16(a, b);
  return validate_uint16(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmin_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (uint32_t *)impl.test_cases_int_pointer2;
  uint32_t _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = _a[i] < _b[i] ? _a[i] : _b[i];
  }

  uint32x2_t a = vld1_u32(_a);
  uint32x2_t b = vld1_u32(_b);
  uint32x2_t c = vmin_u32(a, b);
  return validate_uint32(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vminq_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (int8_t *)impl.test_cases_int_pointer2;
  int8_t _c[16];
  for (int i = 0; i < 16; i++) {
    _c[i] = _a[i] < _b[i] ? _a[i] : _b[i];
  }

  int8x16_t a = vld1q_s8(_a);
  int8x16_t b = vld1q_s8(_b);
  int8x16_t c = vminq_s8(a, b);
  return validate_int8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7], _c[8], _c[9], _c[10], _c[11], _c[12],
                       _c[13], _c[14], _c[15]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vminq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  int16_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = _a[i] < _b[i] ? _a[i] : _b[i];
  }

  int16x8_t a = vld1q_s16(_a);
  int16x8_t b = vld1q_s16(_b);
  int16x8_t c = vminq_s16(a, b);
  return validate_int16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vminq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  int32_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = _a[i] < _b[i] ? _a[i] : _b[i];
  }

  int32x4_t a = vld1q_s32(_a);
  int32x4_t b = vld1q_s32(_b);
  int32x4_t c = vminq_s32(a, b);
  return validate_int32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vminq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (float *)impl.test_cases_float_pointer1;
  const float *_b = (float *)impl.test_cases_float_pointer2;
  float _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = _a[i] < _b[i] ? _a[i] : _b[i];
  }

  float32x2_t a = vld1_f32(_a);
  float32x2_t b = vld1_f32(_b);
  float32x2_t c = vmin_f32(a, b);
  return validate_float(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmin_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vminq_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vminq_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (uint8_t *)impl.test_cases_int_pointer2;
  uint8_t _c[16];
  for (int i = 0; i < 16; i++) {
    _c[i] = _a[i] < _b[i] ? _a[i] : _b[i];
  }

  uint8x16_t a = vld1q_u8(_a);
  uint8x16_t b = vld1q_u8(_b);
  uint8x16_t c = vminq_u8(a, b);
  return validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7], _c[8], _c[9], _c[10], _c[11], _c[12],
                        _c[13], _c[14], _c[15]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vminq_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (uint16_t *)impl.test_cases_int_pointer2;
  uint16_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = _a[i] < _b[i] ? _a[i] : _b[i];
  }

  uint16x8_t a = vld1q_u16(_a);
  uint16x8_t b = vld1q_u16(_b);
  uint16x8_t c = vminq_u16(a, b);
  return validate_uint16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vminq_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (uint32_t *)impl.test_cases_int_pointer2;
  uint32_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = _a[i] < _b[i] ? _a[i] : _b[i];
  }

  uint32x4_t a = vld1q_u32(_a);
  uint32x4_t b = vld1q_u32(_b);
  uint32x4_t c = vminq_u32(a, b);
  return validate_uint32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vpadd_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (int8_t *)impl.test_cases_int_pointer2;
  int8_t _c[8];
  for (int i = 0; i < 4; i++) {
    _c[i] = _a[2 * i] + _a[2 * i + 1];
    _c[i + 4] = _b[2 * i] + _b[2 * i + 1];
  }

  int8x8_t a = vld1_s8(_a);
  int8x8_t b = vld1_s8(_b);
  int8x8_t c = vpadd_s8(a, b);
  return validate_int8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vpadd_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  int16_t _c[4];
  for (int i = 0; i < 2; i++) {
    _c[i] = _a[2 * i] + _a[2 * i + 1];
    _c[i + 2] = _b[2 * i] + _b[2 * i + 1];
  }

  int16x4_t a = vld1_s16(_a);
  int16x4_t b = vld1_s16(_b);
  int16x4_t c = vpadd_s16(a, b);
  return validate_int16(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vpadd_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  int32_t _c[2];
  for (int i = 0; i < 1; i++) {
    _c[i] = _a[2 * i] + _a[2 * i + 1];
    _c[i + 1] = _b[2 * i] + _b[2 * i + 1];
  }

  int32x2_t a = vld1_s32(_a);
  int32x2_t b = vld1_s32(_b);
  int32x2_t c = vpadd_s32(a, b);
  return validate_int32(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vpadd_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (float *)impl.test_cases_float_pointer1;
  const float *_b = (float *)impl.test_cases_float_pointer2;
  float _c[2];
  for (int i = 0; i < 1; i++) {
    _c[i] = _a[2 * i] + _a[2 * i + 1];
    _c[i + 1] = _b[2 * i] + _b[2 * i + 1];
  }

  float32x2_t a = vld1_f32(_a);
  float32x2_t b = vld1_f32(_b);
  float32x2_t c = vpadd_f32(a, b);
  return validate_float(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vpaddq_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vpaddq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vpaddq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vpaddq_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vpaddq_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vpaddq_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vpaddq_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vpaddq_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vpaddq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vpaddq_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vpadd_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (uint8_t *)impl.test_cases_int_pointer2;
  uint8_t _c[8];
  for (int i = 0; i < 4; i++) {
    _c[i] = _a[2 * i] + _a[2 * i + 1];
    _c[i + 4] = _b[2 * i] + _b[2 * i + 1];
  }

  uint8x8_t a = vld1_u8(_a);
  uint8x8_t b = vld1_u8(_b);
  uint8x8_t c = vpadd_u8(a, b);
  return validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vpadd_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (uint16_t *)impl.test_cases_int_pointer2;
  uint16_t _c[4];
  for (int i = 0; i < 2; i++) {
    _c[i] = _a[2 * i] + _a[2 * i + 1];
    _c[i + 2] = _b[2 * i] + _b[2 * i + 1];
  }

  uint16x4_t a = vld1_u16(_a);
  uint16x4_t b = vld1_u16(_b);
  uint16x4_t c = vpadd_u16(a, b);
  return validate_uint16(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vpadd_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (uint32_t *)impl.test_cases_int_pointer2;
  uint32_t _c[2];
  for (int i = 0; i < 1; i++) {
    _c[i] = _a[2 * i] + _a[2 * i + 1];
    _c[i + 1] = _b[2 * i] + _b[2 * i + 1];
  }

  uint32x2_t a = vld1_u32(_a);
  uint32x2_t b = vld1_u32(_b);
  uint32x2_t c = vpadd_u32(a, b);
  return validate_uint32(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vpaddl_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  int16_t _c[4];
  _c[0] = (int16_t)_a[0] + (int16_t)_a[1];
  _c[1] = (int16_t)_a[2] + (int16_t)_a[3];
  _c[2] = (int16_t)_a[4] + (int16_t)_a[5];
  _c[3] = (int16_t)_a[6] + (int16_t)_a[7];

  int8x8_t a = vld1_s8(_a);
  int16x4_t c = vpaddl_s8(a);
  return validate_int16(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vpaddl_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  int32_t _c[4];
  _c[0] = (int32_t)_a[0] + (int32_t)_a[1];
  _c[1] = (int32_t)_a[2] + (int32_t)_a[3];

  int16x4_t a = vld1_s16(_a);
  int32x2_t c = vpaddl_s16(a);
  return validate_int32(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vpaddl_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  int64_t _c[1];
  _c[0] = (int64_t)_a[0] + (int64_t)_a[1];

  int32x2_t a = vld1_s32(_a);
  int64x1_t c = vpaddl_s32(a);
  return validate_int64(c, _c[0]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vpaddl_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (uint8_t *)impl.test_cases_int_pointer1;
  uint16_t _c[4];
  _c[0] = (uint16_t)_a[0] + (uint16_t)_a[1];
  _c[1] = (uint16_t)_a[2] + (uint16_t)_a[3];
  _c[2] = (uint16_t)_a[4] + (uint16_t)_a[5];
  _c[3] = (uint16_t)_a[6] + (uint16_t)_a[7];

  uint8x8_t a = vld1_u8(_a);
  uint16x4_t c = vpaddl_u8(a);
  return validate_uint16(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vpaddl_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  uint32_t _c[4];
  _c[0] = (uint32_t)_a[0] + (uint32_t)_a[1];
  _c[1] = (uint32_t)_a[2] + (uint32_t)_a[3];

  uint16x4_t a = vld1_u16(_a);
  uint32x2_t c = vpaddl_u16(a);
  return validate_uint32(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vpaddl_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  uint64_t _c[1];
  _c[0] = (uint64_t)_a[0] + (uint64_t)_a[1];

  uint32x2_t a = vld1_u32(_a);
  uint64x1_t c = vpaddl_u32(a);
  return validate_uint64(c, _c[0]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vpaddlq_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  int16_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = (int16_t)_a[2 * i] + (int16_t)_a[2 * i + 1];
  }

  int8x16_t a = vld1q_s8(_a);
  int16x8_t c = vpaddlq_s8(a);
  return validate_int16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vpaddlq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  int32_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = (int32_t)_a[2 * i] + (int32_t)_a[2 * i + 1];
  }

  int16x8_t a = vld1q_s16(_a);
  int32x4_t c = vpaddlq_s16(a);
  return validate_int32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vpaddlq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  int64_t _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = (int64_t)_a[2 * i] + (int64_t)_a[2 * i + 1];
  }

  int32x4_t a = vld1q_s32(_a);
  int64x2_t c = vpaddlq_s32(a);
  return validate_int64(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vpaddlq_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (uint8_t *)impl.test_cases_int_pointer1;
  uint16_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = (uint16_t)_a[2 * i] + (uint16_t)_a[2 * i + 1];
  }

  uint8x16_t a = vld1q_u8(_a);
  uint16x8_t c = vpaddlq_u8(a);
  return validate_uint16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vpaddlq_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  uint32_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = (uint32_t)_a[2 * i] + (uint32_t)_a[2 * i + 1];
  }

  uint16x8_t a = vld1q_u16(_a);
  uint32x4_t c = vpaddlq_u16(a);
  return validate_uint32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vpaddlq_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  uint64_t _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = (uint64_t)_a[2 * i] + (uint64_t)_a[2 * i + 1];
  }

  uint32x4_t a = vld1q_u32(_a);
  uint64x2_t c = vpaddlq_u32(a);
  return validate_uint64(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vpadal_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (int8_t *)impl.test_cases_int_pointer2;
  int16_t _c[4];
  _c[0] = _a[0] + (int16_t)_b[0] + (int16_t)_b[1];
  _c[1] = _a[1] + (int16_t)_b[2] + (int16_t)_b[3];
  _c[2] = _a[2] + (int16_t)_b[4] + (int16_t)_b[5];
  _c[3] = _a[3] + (int16_t)_b[6] + (int16_t)_b[7];

  int16x4_t a = vld1_s16(_a);
  int8x8_t b = vld1_s8(_b);
  int16x4_t c = vpadal_s8(a, b);
  return validate_int16(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vpadal_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  int32_t _c[2];
  _c[0] = _a[0] + (int32_t)_b[0] + (int32_t)_b[1];
  _c[1] = _a[1] + (int32_t)_b[2] + (int32_t)_b[3];

  int32x2_t a = vld1_s32(_a);
  int16x4_t b = vld1_s16(_b);
  int32x2_t c = vpadal_s16(a, b);
  return validate_int32(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vpadal_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (int64_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  int64_t _c[1];
  _c[0] = _a[0] + (int64_t)_b[0] + (int64_t)_b[1];

  int64x1_t a = vld1_s64(_a);
  int32x2_t b = vld1_s32(_b);
  int64x1_t c = vpadal_s32(a, b);
  return validate_int64(c, _c[0]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vpadal_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (uint8_t *)impl.test_cases_int_pointer2;
  uint16_t _c[4];
  _c[0] = _a[0] + (uint16_t)_b[0] + (uint16_t)_b[1];
  _c[1] = _a[1] + (uint16_t)_b[2] + (uint16_t)_b[3];
  _c[2] = _a[2] + (uint16_t)_b[4] + (uint16_t)_b[5];
  _c[3] = _a[3] + (uint16_t)_b[6] + (uint16_t)_b[7];

  uint16x4_t a = vld1_u16(_a);
  uint8x8_t b = vld1_u8(_b);
  uint16x4_t c = vpadal_u8(a, b);
  return validate_uint16(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vpadal_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (uint16_t *)impl.test_cases_int_pointer2;
  uint32_t _c[2];
  _c[0] = _a[0] + (uint32_t)_b[0] + (uint32_t)_b[1];
  _c[1] = _a[1] + (uint32_t)_b[2] + (uint32_t)_b[3];

  uint32x2_t a = vld1_u32(_a);
  uint16x4_t b = vld1_u16(_b);
  uint32x2_t c = vpadal_u16(a, b);
  return validate_uint32(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vpadal_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (uint64_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (uint32_t *)impl.test_cases_int_pointer2;
  uint64_t _c[1];
  _c[0] = _a[0] + (uint64_t)_b[0] + (uint64_t)_b[1];

  uint64x1_t a = vld1_u64(_a);
  uint32x2_t b = vld1_u32(_b);
  uint64x1_t c = vpadal_u32(a, b);
  return validate_uint64(c, _c[0]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vpadalq_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (int8_t *)impl.test_cases_int_pointer2;
  int16_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = _a[i] + (int16_t)_b[2 * i] + (int16_t)_b[2 * i + 1];
  }

  int16x8_t a = vld1q_s16(_a);
  int8x16_t b = vld1q_s8(_b);
  int16x8_t c = vpadalq_s8(a, b);
  return validate_int16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vpadalq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer1;
  int32_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = _a[i] + (int32_t)_b[2 * i] + (int32_t)_b[2 * i + 1];
  }

  int32x4_t a = vld1q_s32(_a);
  int16x8_t b = vld1q_s16(_b);
  int32x4_t c = vpadalq_s16(a, b);
  return validate_int32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vpadalq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (int64_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer1;
  int64_t _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = _a[i] + (int64_t)_b[2 * i] + (int64_t)_b[2 * i + 1];
  }

  int64x2_t a = vld1q_s64(_a);
  int32x4_t b = vld1q_s32(_b);
  int64x2_t c = vpadalq_s32(a, b);
  return validate_int64(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vpadalq_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (uint8_t *)impl.test_cases_int_pointer2;
  uint16_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = _a[i] + (uint16_t)_b[2 * i] + (uint16_t)_b[2 * i + 1];
  }

  uint16x8_t a = vld1q_u16(_a);
  uint8x16_t b = vld1q_u8(_b);
  uint16x8_t c = vpadalq_u8(a, b);
  return validate_uint16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vpadalq_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (uint16_t *)impl.test_cases_int_pointer1;
  uint32_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = _a[i] + (uint32_t)_b[2 * i] + (uint32_t)_b[2 * i + 1];
  }

  uint32x4_t a = vld1q_u32(_a);
  uint16x8_t b = vld1q_u16(_b);
  uint32x4_t c = vpadalq_u16(a, b);
  return validate_uint32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vpadalq_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (uint64_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (uint32_t *)impl.test_cases_int_pointer1;
  uint64_t _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = _a[i] + (uint64_t)_b[2 * i] + (uint64_t)_b[2 * i + 1];
  }

  uint64x2_t a = vld1q_u64(_a);
  uint32x4_t b = vld1q_u32(_b);
  uint64x2_t c = vpadalq_u32(a, b);
  return validate_uint64(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vpmax_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (int8_t *)impl.test_cases_int_pointer2;
  int8_t _c[8];
  for (int i = 0; i < 4; i++) {
    _c[i] = (_a[2 * i] > _a[2 * i + 1]) ? _a[2 * i] : _a[2 * i + 1];
    _c[i + 4] = (_b[2 * i] > _b[2 * i + 1]) ? _b[2 * i] : _b[2 * i + 1];
  }

  int8x8_t a = vld1_s8(_a);
  int8x8_t b = vld1_s8(_b);
  int8x8_t c = vpmax_s8(a, b);
  return validate_int8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vpmax_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (const int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (const int16_t *)impl.test_cases_int_pointer2;
  int16_t _c[4];
  for (int i = 0; i < 2; i++) {
    _c[i] = (_a[2 * i] > _a[2 * i + 1]) ? _a[2 * i] : _a[2 * i + 1];
    _c[i + 2] = (_b[2 * i] > _b[2 * i + 1]) ? _b[2 * i] : _b[2 * i + 1];
  }

  int16x4_t a = vld1_s16(_a);
  int16x4_t b = vld1_s16(_b);
  int16x4_t c = vpmax_s16(a, b);
  return validate_int16(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vpmax_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (const int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (const int32_t *)impl.test_cases_int_pointer2;
  int32_t _c[2];
  for (int i = 0; i < 1; i++) {
    _c[i] = (_a[2 * i] > _a[2 * i + 1]) ? _a[2 * i] : _a[2 * i + 1];
    _c[i + 1] = (_b[2 * i] > _b[2 * i + 1]) ? _b[2 * i] : _b[2 * i + 1];
  }

  int32x2_t a = vld1_s32(_a);
  int32x2_t b = vld1_s32(_b);
  int32x2_t c = vpmax_s32(a, b);
  return validate_int32(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vpmax_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (const float *)impl.test_cases_float_pointer1;
  const float *_b = (const float *)impl.test_cases_float_pointer2;
  float _c[2];
  for (int i = 0; i < 1; i++) {
    _c[i] = (_a[2 * i] > _a[2 * i + 1]) ? _a[2 * i] : _a[2 * i + 1];
    _c[i + 1] = (_b[2 * i] > _b[2 * i + 1]) ? _b[2 * i] : _b[2 * i + 1];
  }

  float32x2_t a = vld1_f32(_a);
  float32x2_t b = vld1_f32(_b);
  float32x2_t c = vpmax_f32(a, b);
  return validate_float(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vpmaxq_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vpmaxq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vpmaxq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vpmaxq_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vpmaxq_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vpmaxq_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vpmaxq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vpmaxq_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vpmax_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (uint8_t *)impl.test_cases_int_pointer2;
  uint8_t _c[8];
  for (int i = 0; i < 4; i++) {
    _c[i] = (_a[2 * i] > _a[2 * i + 1]) ? _a[2 * i] : _a[2 * i + 1];
    _c[i + 4] = (_b[2 * i] > _b[2 * i + 1]) ? _b[2 * i] : _b[2 * i + 1];
  }

  uint8x8_t a = vld1_u8(_a);
  uint8x8_t b = vld1_u8(_b);
  uint8x8_t c = vpmax_u8(a, b);
  return validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vpmax_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (const uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (const uint16_t *)impl.test_cases_int_pointer2;
  uint16_t _c[4];
  for (int i = 0; i < 2; i++) {
    _c[i] = (_a[2 * i] > _a[2 * i + 1]) ? _a[2 * i] : _a[2 * i + 1];
    _c[i + 2] = (_b[2 * i] > _b[2 * i + 1]) ? _b[2 * i] : _b[2 * i + 1];
  }

  uint16x4_t a = vld1_u16(_a);
  uint16x4_t b = vld1_u16(_b);
  uint16x4_t c = vpmax_u16(a, b);
  return validate_uint16(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vpmax_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (const uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (const uint32_t *)impl.test_cases_int_pointer2;
  uint32_t _c[2];
  for (int i = 0; i < 1; i++) {
    _c[i] = (_a[2 * i] > _a[2 * i + 1]) ? _a[2 * i] : _a[2 * i + 1];
    _c[i + 1] = (_b[2 * i] > _b[2 * i + 1]) ? _b[2 * i] : _b[2 * i + 1];
  }

  uint32x2_t a = vld1_u32(_a);
  uint32x2_t b = vld1_u32(_b);
  uint32x2_t c = vpmax_u32(a, b);
  return validate_uint32(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vpmin_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (int8_t *)impl.test_cases_int_pointer2;
  int8_t _c[8];
  for (int i = 0; i < 4; i++) {
    _c[i] = (_a[2 * i] < _a[2 * i + 1]) ? _a[2 * i] : _a[2 * i + 1];
    _c[i + 4] = (_b[2 * i] < _b[2 * i + 1]) ? _b[2 * i] : _b[2 * i + 1];
  }

  int8x8_t a = vld1_s8(_a);
  int8x8_t b = vld1_s8(_b);
  int8x8_t c = vpmin_s8(a, b);
  return validate_int8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vpmin_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (const int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (const int16_t *)impl.test_cases_int_pointer2;
  int16_t _c[4];
  for (int i = 0; i < 2; i++) {
    _c[i] = (_a[2 * i] < _a[2 * i + 1]) ? _a[2 * i] : _a[2 * i + 1];
    _c[i + 2] = (_b[2 * i] < _b[2 * i + 1]) ? _b[2 * i] : _b[2 * i + 1];
  }

  int16x4_t a = vld1_s16(_a);
  int16x4_t b = vld1_s16(_b);
  int16x4_t c = vpmin_s16(a, b);
  return validate_int16(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vpmin_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (const int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (const int32_t *)impl.test_cases_int_pointer2;
  int32_t _c[2];
  for (int i = 0; i < 1; i++) {
    _c[i] = (_a[2 * i] < _a[2 * i + 1]) ? _a[2 * i] : _a[2 * i + 1];
    _c[i + 1] = (_b[2 * i] < _b[2 * i + 1]) ? _b[2 * i] : _b[2 * i + 1];
  }

  int32x2_t a = vld1_s32(_a);
  int32x2_t b = vld1_s32(_b);
  int32x2_t c = vpmin_s32(a, b);
  return validate_int32(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vpmin_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (const float *)impl.test_cases_float_pointer1;
  const float *_b = (const float *)impl.test_cases_float_pointer2;
  float _c[2];
  for (int i = 0; i < 1; i++) {
    _c[i] = (_a[2 * i] < _a[2 * i + 1]) ? _a[2 * i] : _a[2 * i + 1];
    _c[i + 1] = (_b[2 * i] < _b[2 * i + 1]) ? _b[2 * i] : _b[2 * i + 1];
  }

  float32x2_t a = vld1_f32(_a);
  float32x2_t b = vld1_f32(_b);
  float32x2_t c = vpmin_f32(a, b);
  return validate_float(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vpminq_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vpminq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vpminq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vpminq_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vpminq_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vpminq_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vpminq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vpminq_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vpmaxnm_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vpmaxnmq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vpmaxnmq_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vpminnm_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vpminnmq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vpminnmq_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vpaddd_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vpaddd_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vpadds_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vpaddd_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vpmaxs_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vpmaxqd_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vpmins_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vpminqd_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vpmaxnms_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vpmaxnmqd_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vpminnms_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vpminnmqd_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vaddv_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  int8_t _c = 0;
  for (int i = 0; i < 8; i++) {
    _c += _a[i];
  }

  int8x8_t a = vld1_s8(_a);
  int8_t c = vaddv_s8(a);
  return c == _c ? TEST_SUCCESS : TEST_FAIL;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vaddvq_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  int8_t _c = 0;
  for (int i = 0; i < 16; i++) {
    _c += _a[i];
  }

  int8x16_t a = vld1q_s8(_a);
  int8_t c = vaddvq_s8(a);
  return c == _c ? TEST_SUCCESS : TEST_FAIL;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vaddv_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  int16_t _c = 0;
  for (int i = 0; i < 4; i++) {
    _c += _a[i];
  }

  int16x4_t a = vld1_s16(_a);
  int16_t c = vaddv_s16(a);
  return c == _c ? TEST_SUCCESS : TEST_FAIL;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vaddvq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  int16_t _c = 0;
  for (int i = 0; i < 8; i++) {
    _c += _a[i];
  }

  int16x8_t a = vld1q_s16(_a);
  int16_t c = vaddvq_s16(a);
  return c == _c ? TEST_SUCCESS : TEST_FAIL;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vaddv_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  int32_t _c = 0;
  for (int i = 0; i < 2; i++) {
    _c += _a[i];
  }

  int32x2_t a = vld1_s32(_a);
  int32_t c = vaddv_s32(a);
  return c == _c ? TEST_SUCCESS : TEST_FAIL;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vaddvq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  int32_t _c = 0;
  for (int i = 0; i < 4; i++) {
    _c += _a[i];
  }

  int32x4_t a = vld1q_s32(_a);
  int32_t c = vaddvq_s32(a);
  return c == _c ? TEST_SUCCESS : TEST_FAIL;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vaddvq_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (int64_t *)impl.test_cases_int_pointer1;
  int64_t _c = 0;
  for (int i = 0; i < 2; i++) {
    _c += _a[i];
  }

  int64x2_t a = vld1q_s64(_a);
  int64_t c = vaddvq_s64(a);
  return c == _c ? TEST_SUCCESS : TEST_FAIL;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vaddv_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (uint8_t *)impl.test_cases_int_pointer1;
  uint8_t _c = 0;
  for (int i = 0; i < 8; i++) {
    _c += _a[i];
  }

  uint8x8_t a = vld1_u8(_a);
  uint8_t c = vaddv_u8(a);
  return c == _c ? TEST_SUCCESS : TEST_FAIL;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vaddvq_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (uint8_t *)impl.test_cases_int_pointer1;
  uint8_t _c = 0;
  for (int i = 0; i < 16; i++) {
    _c += _a[i];
  }

  uint8x16_t a = vld1q_u8(_a);
  uint8_t c = vaddvq_u8(a);
  return c == _c ? TEST_SUCCESS : TEST_FAIL;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vaddv_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  uint16_t _c = 0;
  for (int i = 0; i < 4; i++) {
    _c += _a[i];
  }

  uint16x4_t a = vld1_u16(_a);
  uint16_t c = vaddv_u16(a);
  return c == _c ? TEST_SUCCESS : TEST_FAIL;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vaddvq_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  uint16_t _c = 0;
  for (int i = 0; i < 8; i++) {
    _c += _a[i];
  }

  uint16x8_t a = vld1q_u16(_a);
  uint16_t c = vaddvq_u16(a);
  return c == _c ? TEST_SUCCESS : TEST_FAIL;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vaddv_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  uint32_t _c = 0;
  for (int i = 0; i < 2; i++) {
    _c += _a[i];
  }

  uint32x2_t a = vld1_u32(_a);
  uint32_t c = vaddv_u32(a);
  return c == _c ? TEST_SUCCESS : TEST_FAIL;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vaddvq_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  uint32_t _c = 0;
  for (int i = 0; i < 4; i++) {
    _c += _a[i];
  }

  uint32x4_t a = vld1q_u32(_a);
  uint32_t c = vaddvq_u32(a);
  return c == _c ? TEST_SUCCESS : TEST_FAIL;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vaddvq_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (uint64_t *)impl.test_cases_int_pointer1;
  uint64_t _c = 0;
  for (int i = 0; i < 2; i++) {
    _c += _a[i];
  }

  uint64x2_t a = vld1q_u64(_a);
  uint64_t c = vaddvq_u64(a);
  return c == _c ? TEST_SUCCESS : TEST_FAIL;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vaddv_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vaddvq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vaddvq_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vaddlv_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vaddlvq_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vaddlv_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vaddlvq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vaddlv_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vaddlvq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vaddlv_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vaddlvq_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vaddlv_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vaddlvq_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vaddlv_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vaddlvq_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmaxv_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmaxvq_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmaxv_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmaxvq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmaxv_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmaxvq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmaxv_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmaxvq_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmaxv_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmaxvq_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmaxv_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmaxvq_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmaxv_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmaxvq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmaxvq_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vminv_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vminvq_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vminv_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vminvq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vminv_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vminvq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vminv_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vminvq_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vminv_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vminvq_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vminv_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vminvq_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vminv_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vminvq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vminvq_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmaxnmv_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmaxnmvq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmaxnmvq_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vminnmv_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vminnmvq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vminnmvq_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vpmin_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (uint8_t *)impl.test_cases_int_pointer2;
  uint8_t _c[8];
  for (int i = 0; i < 4; i++) {
    _c[i] = (_a[2 * i] < _a[2 * i + 1]) ? _a[2 * i] : _a[2 * i + 1];
    _c[i + 4] = (_b[2 * i] < _b[2 * i + 1]) ? _b[2 * i] : _b[2 * i + 1];
  }

  uint8x8_t a = vld1_u8(_a);
  uint8x8_t b = vld1_u8(_b);
  uint8x8_t c = vpmin_u8(a, b);
  return validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vpmin_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (const uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (const uint16_t *)impl.test_cases_int_pointer2;
  uint16_t _c[4];
  for (int i = 0; i < 2; i++) {
    _c[i] = (_a[2 * i] < _a[2 * i + 1]) ? _a[2 * i] : _a[2 * i + 1];
    _c[i + 2] = (_b[2 * i] < _b[2 * i + 1]) ? _b[2 * i] : _b[2 * i + 1];
  }

  uint16x4_t a = vld1_u16(_a);
  uint16x4_t b = vld1_u16(_b);
  uint16x4_t c = vpmin_u16(a, b);
  return validate_uint16(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vpmin_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (const uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (const uint32_t *)impl.test_cases_int_pointer2;
  uint32_t _c[2];
  for (int i = 0; i < 1; i++) {
    _c[i] = (_a[2 * i] < _a[2 * i + 1]) ? _a[2 * i] : _a[2 * i + 1];
    _c[i + 1] = (_b[2 * i] < _b[2 * i + 1]) ? _b[2 * i] : _b[2 * i + 1];
  }

  uint32x2_t a = vld1_u32(_a);
  uint32x2_t b = vld1_u32(_b);
  uint32x2_t c = vpmin_u32(a, b);
  return validate_uint32(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrecps_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = impl.test_cases_float_pointer1;
  const float *_b = impl.test_cases_float_pointer2;
  float _c[2];
  _c[0] = 2.0 - _a[0] * _b[0];
  _c[1] = 2.0 - _a[1] * _b[1];

  float32x2_t a = vld1_f32(_a);
  float32x2_t b = vld1_f32(_b);
  float32x2_t c = vrecps_f32(a, b);

  return validate_float_error(c, _c[0], _c[1], 0.0001f);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrecpsq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = impl.test_cases_float_pointer1;
  const float *_b = impl.test_cases_float_pointer2;
  float _c[4];
  _c[0] = 2.0 - _a[0] * _b[0];
  _c[1] = 2.0 - _a[1] * _b[1];
  _c[2] = 2.0 - _a[2] * _b[2];
  _c[3] = 2.0 - _a[3] * _b[3];

  float32x4_t a = vld1q_f32(_a);
  float32x4_t b = vld1q_f32(_b);
  float32x4_t c = vrecpsq_f32(a, b);

  return validate_float_error(c, _c[0], _c[1], _c[2], _c[3], 0.0001f);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrecps_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrecpsq_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrecpss_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrecpsd_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vsqrt_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vsqrtq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vsqrt_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vsqrtq_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrsqrts_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = impl.test_cases_float_pointer1;
  const float *_b = impl.test_cases_float_pointer2;
  float _c[2];
  _c[0] = (3.0 - _a[0] * _b[0]) / 2.0;
  _c[1] = (3.0 - _a[1] * _b[1]) / 2.0;

  float32x2_t a = vld1_f32(_a);
  float32x2_t b = vld1_f32(_b);
  float32x2_t c = vrsqrts_f32(a, b);

  return validate_float_error(c, _c[0], _c[1], 0.0001f);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrsqrtsq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = impl.test_cases_float_pointer1;
  const float *_b = impl.test_cases_float_pointer2;
  float _c[4];
  _c[0] = (3.0 - _a[0] * _b[0]) / 2.0;
  _c[1] = (3.0 - _a[1] * _b[1]) / 2.0;
  _c[2] = (3.0 - _a[2] * _b[2]) / 2.0;
  _c[3] = (3.0 - _a[3] * _b[3]) / 2.0;

  float32x4_t a = vld1q_f32(_a);
  float32x4_t b = vld1q_f32(_b);
  float32x4_t c = vrsqrtsq_f32(a, b);

  return validate_float_error(c, _c[0], _c[1], _c[2], _c[3], 0.0001f);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrsqrts_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrsqrtsq_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrsqrtss_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrsqrtsd_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vshl_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  int8_t *_b = (int8_t *)impl.test_cases_int_pointer2;
  // force _b[] in a more reasonable shift range
  for (int i = 0; i < 8; i++) {
    _b[i] = _b[i] % 8;
  }
  int8_t _c[8];
  for (int i = 0; i < 8; i++) {
    if (_b[i] < 0) {
      _c[i] = _a[i] >> -_b[i];
    } else {
      _c[i] = _a[i] << _b[i];
    }
  }
  int8x8_t a = vld1_s8(_a);
  int8x8_t b = vld1_s8(_b);
  int8x8_t c = vshl_s8(a, b);
  return validate_int8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vshl_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  // force _b[] in a more reasonable shift range
  for (int i = 0; i < 4; i++) {
    _b[i] = _b[i] % 16;
  }
  int16_t _c[4];
  for (int i = 0; i < 4; i++) {
    if (_b[i] < 0) {
      _c[i] = _a[i] >> -_b[i];
    } else {
      _c[i] = _a[i] << _b[i];
    }
  }
  int16x4_t a = vld1_s16(_a);
  int16x4_t b = vld1_s16(_b);
  int16x4_t c = vshl_s16(a, b);
  return validate_int16(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vshl_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  // force _b[] in a more reasonable shift range
  for (int i = 0; i < 2; i++) {
    _b[i] = _b[i] % 32;
  }
  int32_t _c[2];
  for (int i = 0; i < 2; i++) {
    if (_b[i] < 0) {
      _c[i] = _a[i] >> -_b[i];
    } else {
      _c[i] = _a[i] << _b[i];
    }
  }
  int32x2_t a = vld1_s32(_a);
  int32x2_t b = vld1_s32(_b);
  int32x2_t c = vshl_s32(a, b);
  return validate_int32(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vshl_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (int64_t *)impl.test_cases_int_pointer1;
  int64_t *_b = (int64_t *)impl.test_cases_int_pointer2;
  // force _b[] in a more reasonable shift range
  for (int i = 0; i < 1; i++) {
    _b[i] = _b[i] % 64;
  }
  int64_t _c[1];
  for (int i = 0; i < 1; i++) {
    if (_b[i] < 0) {
      _c[i] = _a[i] >> -_b[i];
    } else {
      _c[i] = _a[i] << _b[i];
    }
  }
  int64x1_t a = vld1_s64(_a);
  int64x1_t b = vld1_s64(_b);
  int64x1_t c = vshl_s64(a, b);
  return validate_int64(c, _c[0]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vshl_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (uint8_t *)impl.test_cases_int_pointer1;
  int8_t *_b = (int8_t *)impl.test_cases_int_pointer2;
  // force _b[] in a more reasonable shift range
  for (int i = 0; i < 8; i++) {
    _b[i] = _b[i] % 8;
  }
  uint8_t _c[8];
  for (int i = 0; i < 8; i++) {
    if (_b[i] < 0) {
      _c[i] = _a[i] >> -_b[i];
    } else {
      _c[i] = _a[i] << _b[i];
    }
  }
  uint8x8_t a = vld1_u8(_a);
  int8x8_t b = vld1_s8(_b);
  uint8x8_t c = vshl_u8(a, b);
  return validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vshl_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  // force _b[] in a more reasonable shift range
  for (int i = 0; i < 4; i++) {
    _b[i] = _b[i] % 16;
  }
  uint16_t _c[4];
  for (int i = 0; i < 4; i++) {
    if (_b[i] < 0) {
      _c[i] = _a[i] >> -_b[i];
    } else {
      _c[i] = _a[i] << _b[i];
    }
  }
  uint16x4_t a = vld1_u16(_a);
  int16x4_t b = vld1_s16(_b);
  uint16x4_t c = vshl_u16(a, b);
  return validate_uint16(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vshl_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  // force _b[] in a more reasonable shift range
  for (int i = 0; i < 2; i++) {
    _b[i] = _b[i] % 32;
  }
  uint32_t _c[2];
  for (int i = 0; i < 2; i++) {
    if (_b[i] < 0) {
      _c[i] = _a[i] >> -_b[i];
    } else {
      _c[i] = _a[i] << _b[i];
    }
  }
  uint32x2_t a = vld1_u32(_a);
  int32x2_t b = vld1_s32(_b);
  uint32x2_t c = vshl_u32(a, b);
  return validate_uint32(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vshl_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (uint64_t *)impl.test_cases_int_pointer1;
  int64_t *_b = (int64_t *)impl.test_cases_int_pointer2;
  // force _b[] in a more reasonable shift range
  for (int i = 0; i < 1; i++) {
    _b[i] = _b[i] % 64;
  }
  uint64_t _c[1];
  for (int i = 0; i < 1; i++) {
    if (_b[i] < 0) {
      _c[i] = _a[i] >> -_b[i];
    } else {
      _c[i] = _a[i] << _b[i];
    }
  }
  uint64x1_t a = vld1_u64(_a);
  int64x1_t b = vld1_s64(_b);
  uint64x1_t c = vshl_u64(a, b);
  return validate_uint64(c, _c[0]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vshlq_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  int8_t *_b = (int8_t *)impl.test_cases_int_pointer2;
  // force _b[] in a more reasonable shift range
  for (int i = 0; i < 16; i++) {
    _b[i] = _b[i] % 8;
  }
  int8_t _c[16];
  for (int i = 0; i < 16; i++) {
    if (_b[i] < 0) {
      _c[i] = _a[i] >> -_b[i];
    } else {
      _c[i] = _a[i] << _b[i];
    }
  }
  int8x16_t a = vld1q_s8(_a);
  int8x16_t b = vld1q_s8(_b);
  int8x16_t c = vshlq_s8(a, b);
  return validate_int8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7], _c[8], _c[9], _c[10], _c[11], _c[12],
                       _c[13], _c[14], _c[15]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vshlq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  // force _b[] in a more reasonable shift range
  for (int i = 0; i < 8; i++) {
    _b[i] = _b[i] % 16;
  }
  int16_t _c[8];
  for (int i = 0; i < 8; i++) {
    if (_b[i] < 0) {
      _c[i] = _a[i] >> -_b[i];
    } else {
      _c[i] = _a[i] << _b[i];
    }
  }
  int16x8_t a = vld1q_s16(_a);
  int16x8_t b = vld1q_s16(_b);
  int16x8_t c = vshlq_s16(a, b);
  return validate_int16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vshlq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  // force _b[] in a more reasonable shift range
  for (int i = 0; i < 4; i++) {
    _b[i] = _b[i] % 32;
  }
  int32_t _c[4];
  for (int i = 0; i < 4; i++) {
    if (_b[i] < 0) {
      _c[i] = _a[i] >> -_b[i];
    } else {
      _c[i] = _a[i] << _b[i];
    }
  }
  int32x4_t a = vld1q_s32(_a);
  int32x4_t b = vld1q_s32(_b);
  int32x4_t c = vshlq_s32(a, b);
  return validate_int32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vshlq_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (int64_t *)impl.test_cases_int_pointer1;
  int64_t *_b = (int64_t *)impl.test_cases_int_pointer2;
  // force _b[] in a more reasonable shift range
  for (int i = 0; i < 2; i++) {
    _b[i] = _b[i] % 64;
  }
  int64_t _c[2];
  for (int i = 0; i < 2; i++) {
    if (_b[i] < 0) {
      _c[i] = _a[i] >> -_b[i];
    } else {
      _c[i] = _a[i] << _b[i];
    }
  }
  int64x2_t a = vld1q_s64(_a);
  int64x2_t b = vld1q_s64(_b);
  int64x2_t c = vshlq_s64(a, b);
  return validate_int64(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vshlq_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (uint8_t *)impl.test_cases_int_pointer1;
  int8_t *_b = (int8_t *)impl.test_cases_int_pointer2;
  // force _b[] in a more reasonable shift range
  for (int i = 0; i < 16; i++) {
    _b[i] = _b[i] % 8;
  }
  uint8_t _c[16];
  for (int i = 0; i < 16; i++) {
    if (_b[i] < 0) {
      _c[i] = _a[i] >> -_b[i];
    } else {
      _c[i] = _a[i] << _b[i];
    }
  }
  uint8x16_t a = vld1q_u8(_a);
  int8x16_t b = vld1q_s8(_b);
  uint8x16_t c = vshlq_u8(a, b);
  return validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7], _c[8], _c[9], _c[10], _c[11], _c[12],
                        _c[13], _c[14], _c[15]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vshlq_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  // force _b[] in a more reasonable shift range
  for (int i = 0; i < 8; i++) {
    _b[i] = _b[i] % 16;
  }
  uint16_t _c[8];
  for (int i = 0; i < 8; i++) {
    if (_b[i] < 0) {
      _c[i] = _a[i] >> -_b[i];
    } else {
      _c[i] = _a[i] << _b[i];
    }
  }
  uint16x8_t a = vld1q_u16(_a);
  int16x8_t b = vld1q_s16(_b);
  uint16x8_t c = vshlq_u16(a, b);
  return validate_uint16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vshlq_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  // force _b[] in a more reasonable shift range
  for (int i = 0; i < 4; i++) {
    _b[i] = _b[i] % 32;
  }
  uint32_t _c[4];
  for (int i = 0; i < 4; i++) {
    if (_b[i] < 0) {
      _c[i] = _a[i] >> -_b[i];
    } else {
      _c[i] = _a[i] << _b[i];
    }
  }
  uint32x4_t a = vld1q_u32(_a);
  int32x4_t b = vld1q_s32(_b);
  uint32x4_t c = vshlq_u32(a, b);
  return validate_uint32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vshlq_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (uint64_t *)impl.test_cases_int_pointer1;
  int64_t *_b = (int64_t *)impl.test_cases_int_pointer2;
  // force _b[] in a more reasonable shift range
  for (int i = 0; i < 2; i++) {
    _b[i] = _b[i] % 64;
  }
  uint64_t _c[2];
  for (int i = 0; i < 2; i++) {
    if (_b[i] < 0) {
      _c[i] = _a[i] >> -_b[i];
    } else {
      _c[i] = _a[i] << _b[i];
    }
  }
  uint64x2_t a = vld1q_u64(_a);
  int64x2_t b = vld1q_s64(_b);
  uint64x2_t c = vshlq_u64(a, b);
  return validate_uint64(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vshld_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vshld_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrshl_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  int8_t *_b = (int8_t *)impl.test_cases_int_pointer2;
  for (int i = 0; i < 8; i++) {
    _b[i] = _b[i] % 8;
  }
  int8_t _c[8];
  for (int i = 0; i < 8; i++) {
    if (_b[i] < 0) {
      int8_t b_neg = -_b[i];
      _c[i] = (_a[i] + (1 << (b_neg - 1))) >> b_neg;
    } else {
      _c[i] = (_a[i]) << _b[i];
    }
  }
  int8x8_t a = vld1_s8(_a);
  int8x8_t b = vld1_s8(_b);
  int8x8_t c = vrshl_s8(a, b);
  return validate_int8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrshl_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  for (int i = 0; i < 4; i++) {
    _b[i] = _b[i] % 8;
  }
  int16_t _c[4];
  for (int i = 0; i < 4; i++) {
    if (_b[i] < 0) {
      int32_t b_neg = -_b[i];
      _c[i] = (_a[i] + (1 << (b_neg - 1))) >> b_neg;
    } else {
      _c[i] = (_a[i]) << _b[i];
    }
  }
  int16x4_t a = vld1_s16(_a);
  int16x4_t b = vld1_s16(_b);
  int16x4_t c = vrshl_s16(a, b);
  return validate_int16(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrshl_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  for (int i = 0; i < 2; i++) {
    _b[i] = _b[i] % 8;
  }
  int32_t _c[2];
  for (int i = 0; i < 2; i++) {
    if (_b[i] < 0) {
      int64_t b_neg = -_b[i];
      _c[i] = (_a[i] + (1 << (b_neg - 1))) >> b_neg;
    } else {
      _c[i] = (_a[i]) << _b[i];
    }
  }
  int32x2_t a = vld1_s32(_a);
  int32x2_t b = vld1_s32(_b);
  int32x2_t c = vrshl_s32(a, b);
  return validate_int32(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrshl_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (int64_t *)impl.test_cases_int_pointer1;
  int64_t *_b = (int64_t *)impl.test_cases_int_pointer2;
  for (int i = 0; i < 1; i++) {
    _b[i] = _b[i] % 8;
  }
  int64_t _c[1];
  for (int i = 0; i < 1; i++) {
    if (_b[i] < 0) {
      int64_t b_neg = -_b[i];
      _c[i] = (_a[i] + (1 << (b_neg - 1))) >> b_neg;
    } else {
      _c[i] = (_a[i]) << _b[i];
    }
  }
  int64x1_t a = vld1_s64(_a);
  int64x1_t b = vld1_s64(_b);
  int64x1_t c = vrshl_s64(a, b);

  return validate_int64(c, _c[0]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrshl_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (uint8_t *)impl.test_cases_int_pointer1;
  int8_t *_b = (int8_t *)impl.test_cases_int_pointer2;
  for (int i = 0; i < 8; i++) {
    _b[i] = _b[i] % 8;
  }
  uint8_t _c[8];
  for (int i = 0; i < 8; i++) {
    if (_b[i] < 0) {
      int8_t b_neg = -_b[i];
      _c[i] = (_a[i] + (1 << (b_neg - 1))) >> b_neg;
    } else {
      _c[i] = (_a[i]) << _b[i];
    }
  }
  uint8x8_t a = vld1_u8(_a);
  int8x8_t b = vld1_s8(_b);
  uint8x8_t c = vrshl_u8(a, b);
  return validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrshl_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  for (int i = 0; i < 4; i++) {
    _b[i] = _b[i] % 16;
  }
  uint16_t _c[4];
  for (int i = 0; i < 4; i++) {
    if (_b[i] < 0) {
      int16_t b_neg = -_b[i];
      _c[i] = (_a[i] + (1 << (b_neg - 1))) >> b_neg;
    } else {
      _c[i] = (_a[i]) << _b[i];
    }
  }
  uint16x4_t a = vld1_u16(_a);
  int16x4_t b = vld1_s16(_b);
  uint16x4_t c = vrshl_u16(a, b);
  return validate_uint16(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrshl_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  for (int i = 0; i < 2; i++) {
    _b[i] = _b[i] % 32;
  }
  uint32_t _c[2];
  for (int i = 0; i < 2; i++) {
    if (_b[i] < 0) {
      int32_t b_neg = -_b[i];
      _c[i] = ((uint64_t)_a[i] + (uint64_t)(1 << (b_neg - 1))) >> b_neg;
    } else {
      _c[i] = (_a[i]) << _b[i];
    }
  }
  uint32x2_t a = vld1_u32(_a);
  int32x2_t b = vld1_s32(_b);
  uint32x2_t c = vrshl_u32(a, b);
  return validate_uint32(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrshl_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (uint64_t *)impl.test_cases_int_pointer1;
  int64_t *_b = (int64_t *)impl.test_cases_int_pointer2;
  for (int i = 0; i < 1; i++) {
    _b[i] = _b[i] % 8;
  }
  uint64_t _c[1];
  for (int i = 0; i < 1; i++) {
    if (_b[i] < 0) {
      int64_t b_neg = -_b[i];
      _c[i] = (_a[i] + (1 << (b_neg - 1))) >> b_neg;
    } else {
      _c[i] = (_a[i]) << _b[i];
    }
  }
  uint64x1_t a = vld1_u64(_a);
  int64x1_t b = vld1_s64(_b);
  uint64x1_t c = vrshl_u64(a, b);

  return validate_uint64(c, _c[0]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrshlq_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  int8_t *_b = (int8_t *)impl.test_cases_int_pointer2;
  for (int i = 0; i < 16; i++) {
    _b[i] = _b[i] % 8;
  }
  int8_t _c[16];
  for (int i = 0; i < 16; i++) {
    if (_b[i] < 0) {
      int8_t b_neg = -_b[i];
      _c[i] = (_a[i] + (1 << (b_neg - 1))) >> b_neg;
    } else {
      _c[i] = (_a[i]) << _b[i];
    }
  }
  int8x16_t a = vld1q_s8(_a);
  int8x16_t b = vld1q_s8(_b);
  int8x16_t c = vrshlq_s8(a, b);
  return validate_int8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7], _c[8], _c[9], _c[10], _c[11], _c[12],
                       _c[13], _c[14], _c[15]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrshlq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  for (int i = 0; i < 8; i++) {
    _b[i] = _b[i] % 8;
  }
  int16_t _c[8];
  for (int i = 0; i < 8; i++) {
    if (_b[i] < 0) {
      int32_t b_neg = -_b[i];
      _c[i] = (_a[i] + (1 << (b_neg - 1))) >> b_neg;
    } else {
      _c[i] = (_a[i]) << _b[i];
    }
  }
  int16x8_t a = vld1q_s16(_a);
  int16x8_t b = vld1q_s16(_b);
  int16x8_t c = vrshlq_s16(a, b);
  return validate_int16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrshlq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  for (int i = 0; i < 4; i++) {
    _b[i] = _b[i] % 8;
  }
  int32_t _c[4];
  for (int i = 0; i < 4; i++) {
    if (_b[i] < 0) {
      int64_t b_neg = -_b[i];
      _c[i] = (_a[i] + (1 << (b_neg - 1))) >> b_neg;
    } else {
      _c[i] = (_a[i]) << _b[i];
    }
  }
  int32x4_t a = vld1q_s32(_a);
  int32x4_t b = vld1q_s32(_b);
  int32x4_t c = vrshlq_s32(a, b);
  return validate_int32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrshlq_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (int64_t *)impl.test_cases_int_pointer1;
  int64_t *_b = (int64_t *)impl.test_cases_int_pointer2;
  for (int i = 0; i < 2; i++) {
    _b[i] = _b[i] % 8;
  }
  int64_t _c[2];
  for (int i = 0; i < 2; i++) {
    if (_b[i] < 0) {
      int64_t b_neg = -_b[i];
      _c[i] = (_a[i] + (1 << (b_neg - 1))) >> b_neg;
    } else {
      _c[i] = (_a[i]) << _b[i];
    }
  }
  int64x2_t a = vld1q_s64(_a);
  int64x2_t b = vld1q_s64(_b);
  int64x2_t c = vrshlq_s64(a, b);

  return validate_int64(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrshlq_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (uint8_t *)impl.test_cases_int_pointer1;
  int8_t *_b = (int8_t *)impl.test_cases_int_pointer2;
  for (int i = 0; i < 16; i++) {
    _b[i] = _b[i] % 8;
  }
  uint8_t _c[16];
  for (int i = 0; i < 16; i++) {
    if (_b[i] < 0) {
      int8_t b_neg = -_b[i];
      _c[i] = (_a[i] + (1 << (b_neg - 1))) >> b_neg;
    } else {
      _c[i] = (_a[i]) << _b[i];
    }
  }
  uint8x16_t a = vld1q_u8(_a);
  int8x16_t b = vld1q_s8(_b);
  uint8x16_t c = vrshlq_u8(a, b);
  return validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7], _c[8], _c[9], _c[10], _c[11], _c[12],
                        _c[13], _c[14], _c[15]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrshlq_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  for (int i = 0; i < 8; i++) {
    _b[i] = _b[i] % 16;
  }
  uint16_t _c[8];
  for (int i = 0; i < 8; i++) {
    if (_b[i] < 0) {
      int16_t b_neg = -_b[i];
      _c[i] = (_a[i] + (1 << (b_neg - 1))) >> b_neg;
    } else {
      _c[i] = (_a[i]) << _b[i];
    }
  }
  uint16x8_t a = vld1q_u16(_a);
  int16x8_t b = vld1q_s16(_b);
  uint16x8_t c = vrshlq_u16(a, b);
  return validate_uint16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrshlq_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  for (int i = 0; i < 4; i++) {
    _b[i] = _b[i] % 32;
  }
  uint32_t _c[4];
  for (int i = 0; i < 4; i++) {
    if (_b[i] < 0) {
      int32_t b_neg = -_b[i];
      _c[i] = ((uint64_t)_a[i] + (uint64_t)(1 << (b_neg - 1))) >> b_neg;
    } else {
      _c[i] = (_a[i]) << _b[i];
    }
  }
  uint32x4_t a = vld1q_u32(_a);
  int32x4_t b = vld1q_s32(_b);
  uint32x4_t c = vrshlq_u32(a, b);
  return validate_uint32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrshlq_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (uint64_t *)impl.test_cases_int_pointer1;
  int64_t *_b = (int64_t *)impl.test_cases_int_pointer2;
  for (int i = 0; i < 2; i++) {
    _b[i] = _b[i] % 8;
  }
  uint64_t _c[2];
  for (int i = 0; i < 2; i++) {
    if (_b[i] < 0) {
      int64_t b_neg = -_b[i];
      _c[i] = (_a[i] + (1 << (b_neg - 1))) >> b_neg;
    } else {
      _c[i] = (_a[i]) << _b[i];
    }
  }
  uint64x2_t a = vld1q_u64(_a);
  int64x2_t b = vld1q_s64(_b);
  uint64x2_t c = vrshlq_u64(a, b);

  return validate_uint64(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrshld_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrshld_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqshl_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  int8_t *_b = (int8_t *)impl.test_cases_int_pointer2;
  for (int i = 0; i < 8; i++) {
    _b[i] = _b[i] % 8;
  }
  int8_t _c[8];
  for (int i = 0; i < 8; i++) {
    if (_b[i] < 0) {
      int8_t b_neg = -_b[i];
      _c[i] = _a[i] >> b_neg;
    } else {
      _c[i] = saturate_int8((int16_t)_a[i] << _b[i]);
    }
  }
  int8x8_t a = vld1_s8(_a);
  int8x8_t b = vld1_s8(_b);
  int8x8_t c = vqshl_s8(a, b);
  return validate_int8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqshl_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  for (int i = 0; i < 4; i++) {
    _b[i] = _b[i] % 8;
  }
  int16_t _c[4];
  for (int i = 0; i < 4; i++) {
    if (_b[i] < 0) {
      int16_t b_neg = -_b[i];
      _c[i] = _a[i] >> b_neg;
    } else {
      _c[i] = saturate_int16((int32_t)_a[i] << _b[i]);
    }
  }
  int16x4_t a = vld1_s16(_a);
  int16x4_t b = vld1_s16(_b);
  int16x4_t c = vqshl_s16(a, b);
  return validate_int16(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqshl_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  for (int i = 0; i < 2; i++) {
    _b[i] = _b[i] % 8;
  }
  int32_t _c[2];
  for (int i = 0; i < 2; i++) {
    if (_b[i] < 0) {
      int32_t b_neg = -_b[i];
      _c[i] = _a[i] >> b_neg;
    } else {
      _c[i] = saturate_int32((int64_t)_a[i] << _b[i]);
    }
  }
  int32x2_t a = vld1_s32(_a);
  int32x2_t b = vld1_s32(_b);
  int32x2_t c = vqshl_s32(a, b);
  return validate_int32(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqshl_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (int64_t *)impl.test_cases_int_pointer1;
  int64_t *_b = (int64_t *)impl.test_cases_int_pointer2;
  for (int i = 0; i < 1; i++) {
    _b[i] = _b[i] % 8;
  }
  int64_t _c[1];
  for (int i = 0; i < 1; i++) {
    if (_b[i] < 0) {
      int64_t b_neg = -_b[i];
      _c[i] = _a[i] >> b_neg;
    } else {
      _c[i] = (int64_t)_a[i] << _b[i];
    }
  }
  int64x1_t a = vld1_s64(_a);
  int64x1_t b = vld1_s64(_b);
  int64x1_t c = vqshl_s64(a, b);
  return validate_int64(c, _c[0]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqshl_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (uint8_t *)impl.test_cases_int_pointer1;
  int8_t *_b = (int8_t *)impl.test_cases_int_pointer2;
  for (int i = 0; i < 8; i++) {
    _b[i] = _b[i] % 8;
  }
  uint8_t _c[8];
  for (int i = 0; i < 8; i++) {
    if (_b[i] < 0) {
      uint8_t b_neg = -_b[i];
      _c[i] = _a[i] >> b_neg;
    } else {
      _c[i] = saturate_uint8((int16_t)_a[i] << _b[i]);
    }
  }
  uint8x8_t a = vld1_u8(_a);
  int8x8_t b = vld1_s8(_b);
  uint8x8_t c = vqshl_u8(a, b);
  return validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqshl_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  for (int i = 0; i < 4; i++) {
    _b[i] = _b[i] % 4;
  }
  uint16_t _c[4];
  for (int i = 0; i < 4; i++) {
    if (_b[i] < 0) {
      uint16_t b_neg = -_b[i];
      _c[i] = _a[i] >> b_neg;
    } else {
      _c[i] = saturate_uint16((uint32_t)_a[i] << _b[i]);
    }
  }
  uint16x4_t a = vld1_u16(_a);
  int16x4_t b = vld1_s16(_b);
  uint16x4_t c = vqshl_u16(a, b);
  return validate_uint16(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqshl_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  for (int i = 0; i < 2; i++) {
    _b[i] = _b[i] % 2;
  }
  uint32_t _c[2];
  for (int i = 0; i < 2; i++) {
    if (_b[i] < 0) {
      uint32_t b_neg = -_b[i];
      _c[i] = _a[i] >> b_neg;
    } else {
      _c[i] = saturate_uint32((uint64_t)_a[i] << _b[i]);
    }
  }
  uint32x2_t a = vld1_u32(_a);
  int32x2_t b = vld1_s32(_b);
  uint32x2_t c = vqshl_u32(a, b);
  return validate_uint32(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqshl_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (uint64_t *)impl.test_cases_int_pointer1;
  int64_t *_b = (int64_t *)impl.test_cases_int_pointer2;
  for (int i = 0; i < 1; i++) {
    _b[i] = _b[i] % 8;
  }
  uint64_t _c[1];
  for (int i = 0; i < 1; i++) {
    if (_b[i] < 0) {
      uint64_t b_neg = -_b[i];
      _c[i] = _a[i] >> b_neg;
    } else {
      if ((UINT64_MAX >> _b[i]) < _a[i]) {
        _c[i] = UINT64_MAX;
      } else {
        _c[i] = (uint64_t)_a[i] << _b[i];
      }
    }
  }
  uint64x1_t a = vld1_u64(_a);
  int64x1_t b = vld1_s64(_b);
  uint64x1_t c = vqshl_u64(a, b);
  return validate_uint64(c, _c[0]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqshlq_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  int8_t *_b = (int8_t *)impl.test_cases_int_pointer2;
  for (int i = 0; i < 16; i++) {
    _b[i] = _b[i] % 8;
  }
  int8_t _c[16];
  for (int i = 0; i < 16; i++) {
    if (_b[i] < 0) {
      int8_t b_neg = -_b[i];
      _c[i] = _a[i] >> b_neg;
    } else {
      _c[i] = saturate_int8((int16_t)_a[i] << _b[i]);
    }
  }
  int8x16_t a = vld1q_s8(_a);
  int8x16_t b = vld1q_s8(_b);
  int8x16_t c = vqshlq_s8(a, b);
  return validate_int8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7], _c[8], _c[9], _c[10], _c[11], _c[12],
                       _c[13], _c[14], _c[15]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqshlq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  for (int i = 0; i < 8; i++) {
    _b[i] = _b[i] % 4;
  }
  int16_t _c[8];
  for (int i = 0; i < 8; i++) {
    if (_b[i] < 0) {
      int16_t b_neg = -_b[i];
      _c[i] = _a[i] >> b_neg;
    } else {
      _c[i] = saturate_int16((int32_t)_a[i] << _b[i]);
    }
  }
  int16x8_t a = vld1q_s16(_a);
  int16x8_t b = vld1q_s16(_b);
  int16x8_t c = vqshlq_s16(a, b);
  return validate_int16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqshlq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  for (int i = 0; i < 4; i++) {
    _b[i] = _b[i] % 2;
  }
  int32_t _c[4];
  for (int i = 0; i < 4; i++) {
    if (_b[i] < 0) {
      int32_t b_neg = -_b[i];
      _c[i] = _a[i] >> b_neg;
    } else {
      _c[i] = saturate_int32((int64_t)_a[i] << _b[i]);
    }
  }
  int32x4_t a = vld1q_s32(_a);
  int32x4_t b = vld1q_s32(_b);
  int32x4_t c = vqshlq_s32(a, b);
  return validate_int32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqshlq_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (int64_t *)impl.test_cases_int_pointer1;
  int64_t *_b = (int64_t *)impl.test_cases_int_pointer2;
  for (int i = 0; i < 2; i++) {
    _b[i] = _b[i] % 8;
  }
  int64_t _c[2];
  for (int i = 0; i < 2; i++) {
    if (_b[i] < 0) {
      int64_t b_neg = -_b[i];
      _c[i] = _a[i] >> b_neg;
    } else {
      _c[i] = (int64_t)_a[i] << _b[i];
    }
  }
  int64x2_t a = vld1q_s64(_a);
  int64x2_t b = vld1q_s64(_b);
  int64x2_t c = vqshlq_s64(a, b);
  return validate_int64(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqshlq_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (uint8_t *)impl.test_cases_int_pointer1;
  int8_t *_b = (int8_t *)impl.test_cases_int_pointer2;
  for (int i = 0; i < 16; i++) {
    _b[i] = _b[i] % 8;
  }
  uint8_t _c[16];
  for (int i = 0; i < 16; i++) {
    if (_b[i] < 0) {
      uint8_t b_neg = -_b[i];
      _c[i] = _a[i] >> b_neg;
    } else {
      _c[i] = saturate_uint8((int16_t)_a[i] << _b[i]);
    }
  }
  uint8x16_t a = vld1q_u8(_a);
  int8x16_t b = vld1q_s8(_b);
  uint8x16_t c = vqshlq_u8(a, b);
  return validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7], _c[8], _c[9], _c[10], _c[11], _c[12],
                        _c[13], _c[14], _c[15]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqshlq_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  for (int i = 0; i < 8; i++) {
    _b[i] = _b[i] % 4;
  }
  uint16_t _c[8];
  for (int i = 0; i < 8; i++) {
    if (_b[i] < 0) {
      uint16_t b_neg = -_b[i];
      _c[i] = _a[i] >> b_neg;
    } else {
      _c[i] = saturate_uint16((uint32_t)_a[i] << _b[i]);
    }
  }
  uint16x8_t a = vld1q_u16(_a);
  int16x8_t b = vld1q_s16(_b);
  uint16x8_t c = vqshlq_u16(a, b);
  return validate_uint16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqshlq_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  for (int i = 0; i < 4; i++) {
    _b[i] = _b[i] % 2;
  }
  uint32_t _c[4];
  for (int i = 0; i < 4; i++) {
    if (_b[i] < 0) {
      uint32_t b_neg = -_b[i];
      _c[i] = _a[i] >> b_neg;
    } else {
      _c[i] = saturate_uint32((uint64_t)_a[i] << _b[i]);
    }
  }
  uint32x4_t a = vld1q_u32(_a);
  int32x4_t b = vld1q_s32(_b);
  uint32x4_t c = vqshlq_u32(a, b);
  return validate_uint32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqshlq_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (uint64_t *)impl.test_cases_int_pointer1;
  int64_t *_b = (int64_t *)impl.test_cases_int_pointer2;
  for (int i = 0; i < 2; i++) {
    _b[i] = _b[i] % 8;
  }
  uint64_t _c[2];
  for (int i = 0; i < 2; i++) {
    if (_b[i] < 0) {
      uint64_t b_neg = -_b[i];
      _c[i] = _a[i] >> b_neg;
    } else {
      if ((UINT64_MAX >> _b[i]) < _a[i]) {
        _c[i] = UINT64_MAX;
      } else {
        _c[i] = (uint64_t)_a[i] << _b[i];
      }
    }
  }
  uint64x2_t a = vld1q_u64(_a);
  int64x2_t b = vld1q_s64(_b);
  uint64x2_t c = vqshlq_u64(a, b);
  return validate_uint64(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqshlb_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqshlh_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqshls_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqshld_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqshlb_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqshlh_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqshls_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqshld_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqrshl_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  int8_t *_b = (int8_t *)impl.test_cases_int_pointer2;
  for (int i = 0; i < 8; i++) {
    _b[i] = _b[i] % 8;
  }
  int8_t _c[8];
  for (int i = 0; i < 8; i++) {
    if (_b[i] < 0) {
      int8_t b_neg = -_b[i];
      uint8_t round_const = 1 << (-_b[i] - 1);
      _c[i] = (_a[i] + round_const) >> b_neg;
    } else {
      _c[i] = saturate_int8((int16_t)_a[i] << _b[i]);
    }
  }
  int8x8_t a = vld1_s8(_a);
  int8x8_t b = vld1_s8(_b);
  int8x8_t c = vqrshl_s8(a, b);
  return validate_int8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqrshl_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  for (int i = 0; i < 4; i++) {
    _b[i] = _b[i] % 16;
  }
  int16_t _c[4];
  for (int i = 0; i < 4; i++) {
    if (_b[i] < 0) {
      int16_t b_neg = -_b[i];
      uint16_t round_const = 1 << (-_b[i] - 1);
      _c[i] = (_a[i] + round_const) >> b_neg;
    } else {
      _c[i] = saturate_int16((int32_t)_a[i] << _b[i]);
    }
  }
  int16x4_t a = vld1_s16(_a);
  int16x4_t b = vld1_s16(_b);
  int16x4_t c = vqrshl_s16(a, b);
  return validate_int16(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqrshl_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  for (int i = 0; i < 2; i++) {
    _b[i] = _b[i] % 32;
  }
  int32_t _c[2];
  for (int i = 0; i < 2; i++) {
    if (_b[i] < 0) {
      int32_t b_neg = -_b[i];
      uint32_t round_const = 1 << (-_b[i] - 1);
      _c[i] = ((int64_t)_a[i] + round_const) >> b_neg;
    } else {
      _c[i] = saturate_int32((int64_t)_a[i] << _b[i]);
    }
  }
  int32x2_t a = vld1_s32(_a);
  int32x2_t b = vld1_s32(_b);
  int32x2_t c = vqrshl_s32(a, b);
  return validate_int32(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqrshl_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqrshl_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (uint8_t *)impl.test_cases_int_pointer1;
  int8_t *_b = (int8_t *)impl.test_cases_int_pointer2;
  for (int i = 0; i < 8; i++) {
    _b[i] = _b[i] % 8;
  }
  uint8_t _c[8];
  for (int i = 0; i < 8; i++) {
    if (_b[i] < 0) {
      uint8_t b_neg = -_b[i];
      uint8_t round_const = 1 << (-_b[i] - 1);
      _c[i] = (_a[i] + round_const) >> b_neg;
    } else {
      _c[i] = saturate_uint8((uint16_t)_a[i] << _b[i]);
    }
  }
  uint8x8_t a = vld1_u8(_a);
  int8x8_t b = vld1_s8(_b);
  uint8x8_t c = vqrshl_u8(a, b);
  return validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqrshl_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  for (int i = 0; i < 4; i++) {
    _b[i] = _b[i] % 16;
  }
  uint16_t _c[4];
  for (int i = 0; i < 4; i++) {
    if (_b[i] < 0) {
      uint16_t b_neg = -_b[i];
      uint16_t round_const = 1 << (-_b[i] - 1);
      _c[i] = (_a[i] + round_const) >> b_neg;
    } else {
      _c[i] = saturate_uint16((uint32_t)_a[i] << _b[i]);
    }
  }
  uint16x4_t a = vld1_u16(_a);
  int16x4_t b = vld1_s16(_b);
  uint16x4_t c = vqrshl_u16(a, b);
  return validate_uint16(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqrshl_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  for (int i = 0; i < 2; i++) {
    _b[i] = _b[i] % 32;
  }
  uint32_t _c[2];
  for (int i = 0; i < 2; i++) {
    if (_b[i] < 0) {
      uint32_t b_neg = -_b[i];
      uint32_t round_const = 1 << (-_b[i] - 1);
      _c[i] = ((uint64_t)_a[i] + round_const) >> b_neg;
    } else {
      _c[i] = saturate_uint32((uint64_t)_a[i] << _b[i]);
    }
  }
  uint32x2_t a = vld1_u32(_a);
  int32x2_t b = vld1_s32(_b);
  uint32x2_t c = vqrshl_u32(a, b);
  return validate_uint32(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqrshl_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqrshlq_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  int8_t *_b = (int8_t *)impl.test_cases_int_pointer2;
  for (int i = 0; i < 16; i++) {
    _b[i] = _b[i] % 8;
  }
  int8_t _c[16];
  for (int i = 0; i < 16; i++) {
    if (_b[i] < 0) {
      int8_t b_neg = -_b[i];
      uint8_t round_const = 1 << (-_b[i] - 1);
      _c[i] = (_a[i] + round_const) >> b_neg;
    } else {
      _c[i] = saturate_int8((int16_t)_a[i] << _b[i]);
    }
  }
  int8x16_t a = vld1q_s8(_a);
  int8x16_t b = vld1q_s8(_b);
  int8x16_t c = vqrshlq_s8(a, b);
  return validate_int8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7], _c[8], _c[9], _c[10], _c[11], _c[12],
                       _c[13], _c[14], _c[15]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqrshlq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  for (int i = 0; i < 8; i++) {
    _b[i] = _b[i] % 16;
  }
  int16_t _c[8];
  for (int i = 0; i < 8; i++) {
    if (_b[i] < 0) {
      int16_t b_neg = -_b[i];
      uint16_t round_const = 1 << (-_b[i] - 1);
      _c[i] = (_a[i] + round_const) >> b_neg;
    } else {
      _c[i] = saturate_int16((int32_t)_a[i] << _b[i]);
    }
  }
  int16x8_t a = vld1q_s16(_a);
  int16x8_t b = vld1q_s16(_b);
  int16x8_t c = vqrshlq_s16(a, b);
  return validate_int16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqrshlq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  for (int i = 0; i < 4; i++) {
    _b[i] = _b[i] % 32;
  }
  int32_t _c[4];
  for (int i = 0; i < 4; i++) {
    if (_b[i] < 0) {
      int32_t b_neg = -_b[i];
      uint32_t round_const = 1 << (-_b[i] - 1);
      _c[i] = ((int64_t)_a[i] + round_const) >> b_neg;
    } else {
      _c[i] = saturate_int32((int64_t)_a[i] << _b[i]);
    }
  }
  int32x4_t a = vld1q_s32(_a);
  int32x4_t b = vld1q_s32(_b);
  int32x4_t c = vqrshlq_s32(a, b);
  return validate_int32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqrshlq_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqrshlq_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (uint8_t *)impl.test_cases_int_pointer1;
  int8_t *_b = (int8_t *)impl.test_cases_int_pointer2;
  for (int i = 0; i < 16; i++) {
    _b[i] = _b[i] % 8;
  }
  uint8_t _c[16];
  for (int i = 0; i < 16; i++) {
    if (_b[i] < 0) {
      uint8_t b_neg = -_b[i];
      uint8_t round_const = 1 << (-_b[i] - 1);
      _c[i] = (_a[i] + round_const) >> b_neg;
    } else {
      _c[i] = saturate_uint8((uint16_t)_a[i] << _b[i]);
    }
  }
  uint8x16_t a = vld1q_u8(_a);
  int8x16_t b = vld1q_s8(_b);
  uint8x16_t c = vqrshlq_u8(a, b);
  return validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7], _c[8], _c[9], _c[10], _c[11], _c[12],
                        _c[13], _c[14], _c[15]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqrshlq_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  for (int i = 0; i < 8; i++) {
    _b[i] = _b[i] % 16;
  }
  uint16_t _c[8];
  for (int i = 0; i < 8; i++) {
    if (_b[i] < 0) {
      uint16_t b_neg = -_b[i];
      uint16_t round_const = 1 << (-_b[i] - 1);
      _c[i] = (_a[i] + round_const) >> b_neg;
    } else {
      _c[i] = saturate_uint16((uint32_t)_a[i] << _b[i]);
    }
  }
  uint16x8_t a = vld1q_u16(_a);
  int16x8_t b = vld1q_s16(_b);
  uint16x8_t c = vqrshlq_u16(a, b);
  return validate_uint16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqrshlq_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  for (int i = 0; i < 4; i++) {
    _b[i] = _b[i] % 32;
  }
  uint32_t _c[4];
  for (int i = 0; i < 4; i++) {
    if (_b[i] < 0) {
      uint32_t b_neg = -_b[i];
      uint32_t round_const = 1 << (-_b[i] - 1);
      _c[i] = ((uint64_t)_a[i] + round_const) >> b_neg;
    } else {
      _c[i] = saturate_uint32((uint64_t)_a[i] << _b[i]);
    }
  }
  uint32x4_t a = vld1q_u32(_a);
  int32x4_t b = vld1q_s32(_b);
  uint32x4_t c = vqrshlq_u32(a, b);
  return validate_uint32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqrshlq_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqrshlb_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqrshlh_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqrshls_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqrshld_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqrshlb_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqrshlh_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqrshls_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqrshld_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vshr_n_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (const int8_t *)impl.test_cases_int_pointer1;
  const int element_num = 8;
  int8_t _c[element_num];
  int8x8_t a = vld1_s8(_a);
  int8x8_t c;

#define TEST_IMPL(IDX)                    \
  for (int i = 0; i < element_num; i++) { \
    _c[i] = _a[i] >> (IDX + 1);           \
  }                                       \
  c = vshr_n_s8(a, (IDX + 1));            \
  CHECK_RESULT(validate_int8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]))

  IMM_8_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vshr_n_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (const int16_t *)impl.test_cases_int_pointer1;
  const int element_num = 4;
  int16_t _c[element_num];
  int16x4_t a = vld1_s16(_a);
  int16x4_t c;

#define TEST_IMPL(IDX)                    \
  for (int i = 0; i < element_num; i++) { \
    _c[i] = _a[i] >> (IDX + 1);           \
  }                                       \
  c = vshr_n_s16(a, (IDX + 1));           \
  CHECK_RESULT(validate_int16(c, _c[0], _c[1], _c[2], _c[3]))

  IMM_16_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vshr_n_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (const int32_t *)impl.test_cases_int_pointer1;
  const int element_num = 2;
  int32_t _c[element_num];
  int32x2_t a = vld1_s32(_a);
  int32x2_t c;

#define TEST_IMPL(IDX)                    \
  for (int i = 0; i < element_num; i++) { \
    _c[i] = (int64_t)_a[i] >> (IDX + 1);  \
  }                                       \
  c = vshr_n_s32(a, (IDX + 1));           \
  CHECK_RESULT(validate_int32(c, _c[0], _c[1]))

  IMM_32_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vshr_n_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (const int64_t *)impl.test_cases_int_pointer1;
  const int element_num = 1;
  int64_t _c[element_num];
  int64x1_t a = vld1_s64(_a);
  int64x1_t c;

#define TEST_IMPL(IDX)                    \
  for (int i = 0; i < element_num; i++) { \
    _c[i] = _a[i] >> (IDX + 1);           \
  }                                       \
  c = vshr_n_s64(a, (IDX + 1));           \
  CHECK_RESULT(validate_int64(c, _c[0]))

  IMM_63_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vshr_n_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (const uint8_t *)impl.test_cases_int_pointer1;
  const int element_num = 8;
  uint8_t _c[element_num];
  uint8x8_t a = vld1_u8(_a);
  uint8x8_t c;

#define TEST_IMPL(IDX)                    \
  for (int i = 0; i < element_num; i++) { \
    _c[i] = _a[i] >> (IDX + 1);           \
  }                                       \
  c = vshr_n_u8(a, (IDX + 1));            \
  CHECK_RESULT(validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]))

  IMM_8_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vshr_n_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (const uint16_t *)impl.test_cases_int_pointer1;
  const int element_num = 4;
  uint16_t _c[element_num];
  uint16x4_t a = vld1_u16(_a);
  uint16x4_t c;

#define TEST_IMPL(IDX)                    \
  for (int i = 0; i < element_num; i++) { \
    _c[i] = _a[i] >> (IDX + 1);           \
  }                                       \
  c = vshr_n_u16(a, (IDX + 1));           \
  CHECK_RESULT(validate_uint16(c, _c[0], _c[1], _c[2], _c[3]))

  IMM_16_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vshr_n_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (const int32_t *)impl.test_cases_int_pointer1;
  const int element_num = 2;
  int32_t _c[element_num];
  int32x2_t a = vld1_s32(_a);
  int32x2_t c;

#define TEST_IMPL(IDX)                    \
  for (int i = 0; i < element_num; i++) { \
    _c[i] = (int64_t)_a[i] >> (IDX + 1);  \
  }                                       \
  c = vshr_n_s32(a, (IDX + 1));           \
  CHECK_RESULT(validate_int32(c, _c[0], _c[1]))

  IMM_32_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vshr_n_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (const uint64_t *)impl.test_cases_int_pointer1;
  const int element_num = 1;
  uint64_t _c[element_num];
  uint64x1_t a = vld1_u64(_a);
  uint64x1_t c;

#define TEST_IMPL(IDX)                    \
  for (int i = 0; i < element_num; i++) { \
    _c[i] = _a[i] >> (IDX + 1);           \
  }                                       \
  c = vshr_n_u64(a, (IDX + 1));           \
  CHECK_RESULT(validate_uint64(c, _c[0]))

  IMM_63_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vshrq_n_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (const int8_t *)impl.test_cases_int_pointer1;
  const int element_num = 16;
  int8_t _c[element_num];
  int8x16_t a = vld1q_s8(_a);
  int8x16_t c;

#define TEST_IMPL(IDX)                                                                                                \
  for (int i = 0; i < element_num; i++) {                                                                             \
    _c[i] = _a[i] >> (IDX + 1);                                                                                       \
  }                                                                                                                   \
  c = vshrq_n_s8(a, (IDX + 1));                                                                                       \
  CHECK_RESULT(validate_int8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7], _c[8], _c[9], _c[10], _c[11], \
                             _c[12], _c[13], _c[14], _c[15]))

  IMM_8_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vshrq_n_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (const int16_t *)impl.test_cases_int_pointer1;
  const int element_num = 8;
  int16_t _c[element_num];
  int16x8_t a = vld1q_s16(_a);
  int16x8_t c;

#define TEST_IMPL(IDX)                    \
  for (int i = 0; i < element_num; i++) { \
    _c[i] = _a[i] >> (IDX + 1);           \
  }                                       \
  c = vshrq_n_s16(a, (IDX + 1));          \
  CHECK_RESULT(validate_int16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]))

  IMM_16_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vshrq_n_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (const int32_t *)impl.test_cases_int_pointer1;
  const int element_num = 4;
  int32_t _c[element_num];
  int32x4_t a = vld1q_s32(_a);
  int32x4_t c;

#define TEST_IMPL(IDX)                    \
  for (int i = 0; i < element_num; i++) { \
    _c[i] = (int64_t)_a[i] >> (IDX + 1);  \
  }                                       \
  c = vshrq_n_s32(a, (IDX + 1));          \
  CHECK_RESULT(validate_int32(c, _c[0], _c[1], _c[2], _c[3]))

  IMM_32_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vshrq_n_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (const int64_t *)impl.test_cases_int_pointer1;
  const int element_num = 2;
  int64_t _c[element_num];
  int64x2_t a = vld1q_s64(_a);
  int64x2_t c;

#define TEST_IMPL(IDX)                    \
  for (int i = 0; i < element_num; i++) { \
    _c[i] = _a[i] >> (IDX + 1);           \
  }                                       \
  c = vshrq_n_s64(a, (IDX + 1));          \
  CHECK_RESULT(validate_int64(c, _c[0], _c[1]))

  IMM_63_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vshrq_n_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (const uint8_t *)impl.test_cases_int_pointer1;
  const int element_num = 16;
  uint8_t _c[element_num];
  uint8x16_t a = vld1q_u8(_a);
  uint8x16_t c;

#define TEST_IMPL(IDX)                                                                                                 \
  for (int i = 0; i < element_num; i++) {                                                                              \
    _c[i] = _a[i] >> (IDX + 1);                                                                                        \
  }                                                                                                                    \
  c = vshrq_n_u8(a, (IDX + 1));                                                                                        \
  CHECK_RESULT(validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7], _c[8], _c[9], _c[10], _c[11], \
                              _c[12], _c[13], _c[14], _c[15]))

  IMM_8_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vshrq_n_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (const uint16_t *)impl.test_cases_int_pointer1;
  const int element_num = 8;
  uint16_t _c[element_num];
  uint16x8_t a = vld1q_u16(_a);
  uint16x8_t c;

#define TEST_IMPL(IDX)                    \
  for (int i = 0; i < element_num; i++) { \
    _c[i] = _a[i] >> (IDX + 1);           \
  }                                       \
  c = vshrq_n_u16(a, (IDX + 1));          \
  CHECK_RESULT(validate_uint16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]))

  IMM_16_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vshrq_n_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (const uint32_t *)impl.test_cases_int_pointer1;
  const int element_num = 4;
  uint32_t _c[element_num];
  uint32x4_t a = vld1q_u32(_a);
  uint32x4_t c;

#define TEST_IMPL(IDX)                    \
  for (int i = 0; i < element_num; i++) { \
    _c[i] = (int64_t)_a[i] >> (IDX + 1);  \
  }                                       \
  c = vshrq_n_u32(a, (IDX + 1));          \
  CHECK_RESULT(validate_uint32(c, _c[0], _c[1], _c[2], _c[3]))

  IMM_32_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vshrq_n_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (const uint64_t *)impl.test_cases_int_pointer1;
  const int element_num = 2;
  uint64_t _c[element_num];
  uint64x2_t a = vld1q_u64(_a);
  uint64x2_t c;

#define TEST_IMPL(IDX)                    \
  for (int i = 0; i < element_num; i++) { \
    _c[i] = _a[i] >> (IDX + 1);           \
  }                                       \
  c = vshrq_n_u64(a, (IDX + 1));          \
  CHECK_RESULT(validate_uint64(c, _c[0], _c[1]))

  IMM_63_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vshrd_n_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vshrd_n_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrshr_n_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (const int8_t *)impl.test_cases_int_pointer1;
  int8_t _c[8];
  int8x8_t a = vld1_s8(_a);
  int8x8_t c;
  uint8_t round_const;

#define TEST_IMPL(IDX)                          \
  for (int i = 0; i < 8; i++) {                 \
    round_const = 1 << ((IDX + 1) - 1);         \
    _c[i] = (_a[i] + round_const) >> (IDX + 1); \
  }                                             \
  c = vrshr_n_s8(a, (IDX + 1));                 \
  CHECK_RESULT(validate_int8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]))

  IMM_8_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrshr_n_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (const int16_t *)impl.test_cases_int_pointer1;
  int16_t _c[4];
  int16x4_t a = vld1_s16(_a);
  int16x4_t c;
  uint16_t round_const;

#define TEST_IMPL(IDX)                          \
  for (int i = 0; i < 4; i++) {                 \
    round_const = 1 << ((IDX + 1) - 1);         \
    _c[i] = (_a[i] + round_const) >> (IDX + 1); \
  }                                             \
  c = vrshr_n_s16(a, (IDX + 1));                \
  CHECK_RESULT(validate_int16(c, _c[0], _c[1], _c[2], _c[3]))

  IMM_16_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrshr_n_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (const int32_t *)impl.test_cases_int_pointer1;
  int32_t _c[2];
  int32x2_t a = vld1_s32(_a);
  int32x2_t c;
  uint32_t round_const;

#define TEST_IMPL(IDX)                                              \
  for (int i = 0; i < 2; i++) {                                     \
    round_const = 1 << ((IDX + 1) - 1);                             \
    _c[i] = ((uint64_t)_a[i] + (uint64_t)round_const) >> (IDX + 1); \
  }                                                                 \
  c = vrshr_n_s32(a, (IDX + 1));                                    \
  CHECK_RESULT(validate_int32(c, _c[0], _c[1]))

  IMM_32_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrshr_n_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (const int64_t *)impl.test_cases_int_pointer1;
  int64_t _c[1];
  int64x1_t a = vld1_s64(_a);
  int64x1_t c;
  uint64_t round_const = 0;

#define TEST_IMPL(IDX)                                             \
  for (int i = 0; i < 1; i++) {                                    \
    if (_a[i] & ((int64_t)1 << ((IDX + 1) - 1))) {                 \
      round_const = 1;                                             \
    }                                                              \
    _c[i] = (int64_t)(((int64_t)_a[i] >> IDX) + round_const) >> 1; \
  }                                                                \
  c = vrshr_n_s64(a, (IDX + 1));                                   \
  CHECK_RESULT(validate_int64(c, _c[0]))

  IMM_64_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrshr_n_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (const uint8_t *)impl.test_cases_int_pointer1;
  uint8_t _c[8];
  uint8x8_t a = vld1_u8(_a);
  uint8x8_t c;
  uint8_t round_const;

#define TEST_IMPL(IDX)                          \
  for (int i = 0; i < 8; i++) {                 \
    round_const = 1 << ((IDX + 1) - 1);         \
    _c[i] = (_a[i] + round_const) >> (IDX + 1); \
  }                                             \
  c = vrshr_n_u8(a, (IDX + 1));                 \
  CHECK_RESULT(validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]))

  IMM_8_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrshr_n_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (const uint16_t *)impl.test_cases_int_pointer1;
  uint16_t _c[4];
  uint16x4_t a = vld1_u16(_a);
  uint16x4_t c;
  uint16_t round_const;

#define TEST_IMPL(IDX)                          \
  for (int i = 0; i < 4; i++) {                 \
    round_const = 1 << ((IDX + 1) - 1);         \
    _c[i] = (_a[i] + round_const) >> (IDX + 1); \
  }                                             \
  c = vrshr_n_u16(a, (IDX + 1));                \
  CHECK_RESULT(validate_uint16(c, _c[0], _c[1], _c[2], _c[3]))

  IMM_16_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrshr_n_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (const uint32_t *)impl.test_cases_int_pointer1;
  uint32_t _c[2];
  uint32x2_t a = vld1_u32(_a);
  uint32x2_t c;
  uint32_t round_const;

#define TEST_IMPL(IDX)                                    \
  for (int i = 0; i < 2; i++) {                           \
    round_const = 1 << ((IDX + 1) - 1);                   \
    _c[i] = ((uint64_t)_a[i] + round_const) >> (IDX + 1); \
  }                                                       \
  c = vrshr_n_u32(a, (IDX + 1));                          \
  CHECK_RESULT(validate_uint32(c, _c[0], _c[1]))

  IMM_32_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrshr_n_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (const uint64_t *)impl.test_cases_int_pointer1;
  uint64_t _c[1];
  uint64x1_t a = vld1_u64(_a);
  uint64x1_t c;
  uint64_t round_const = 0;

#define TEST_IMPL(IDX)                                               \
  for (int i = 0; i < 1; i++) {                                      \
    if (_a[i] & ((uint64_t)1 << ((IDX + 1) - 1))) {                  \
      round_const = 1;                                               \
    }                                                                \
    _c[i] = (uint64_t)(((uint64_t)_a[i] >> IDX) + round_const) >> 1; \
  }                                                                  \
  c = vrshr_n_u64(a, (IDX + 1));                                     \
  CHECK_RESULT(validate_uint64(c, _c[0]))

  IMM_64_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrshrq_n_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (const int8_t *)impl.test_cases_int_pointer1;
  int8_t _c[16];
  int8x16_t a = vld1q_s8(_a);
  int8x16_t c;
  uint8_t round_const;

#define TEST_IMPL(IDX)                                                                                                \
  for (int i = 0; i < 16; i++) {                                                                                      \
    round_const = 1 << ((IDX + 1) - 1);                                                                               \
    _c[i] = (_a[i] + round_const) >> (IDX + 1);                                                                       \
  }                                                                                                                   \
  c = vrshrq_n_s8(a, (IDX + 1));                                                                                      \
  CHECK_RESULT(validate_int8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7], _c[8], _c[9], _c[10], _c[11], \
                             _c[12], _c[13], _c[14], _c[15]))

  IMM_8_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrshrq_n_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (const int16_t *)impl.test_cases_int_pointer1;
  int16_t _c[8];
  int16x8_t a = vld1q_s16(_a);
  int16x8_t c;
  uint16_t round_const;

#define TEST_IMPL(IDX)                          \
  for (int i = 0; i < 8; i++) {                 \
    round_const = 1 << ((IDX + 1) - 1);         \
    _c[i] = (_a[i] + round_const) >> (IDX + 1); \
  }                                             \
  c = vrshrq_n_s16(a, (IDX + 1));               \
  CHECK_RESULT(validate_int16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]))

  IMM_16_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrshrq_n_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (const int32_t *)impl.test_cases_int_pointer1;
  int32_t _c[4];
  int32x4_t a = vld1q_s32(_a);
  int32x4_t c;
  uint32_t round_const;

#define TEST_IMPL(IDX)                                              \
  for (int i = 0; i < 4; i++) {                                     \
    round_const = 1 << ((IDX + 1) - 1);                             \
    _c[i] = ((uint64_t)_a[i] + (uint64_t)round_const) >> (IDX + 1); \
  }                                                                 \
  c = vrshrq_n_s32(a, (IDX + 1));                                   \
  CHECK_RESULT(validate_int32(c, _c[0], _c[1], _c[2], _c[3]))

  IMM_32_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrshrq_n_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (const int64_t *)impl.test_cases_int_pointer1;
  int64_t _c[2];
  int64x2_t a = vld1q_s64(_a);
  int64x2_t c;
  uint64_t round_const = 0;

#define TEST_IMPL(IDX)                                             \
  for (int i = 0; i < 2; i++) {                                    \
    if (_a[i] & ((int64_t)1 << ((IDX + 1) - 1))) {                 \
      round_const = 1;                                             \
    }                                                              \
    _c[i] = (int64_t)(((int64_t)_a[i] >> IDX) + round_const) >> 1; \
  }                                                                \
  c = vrshrq_n_s64(a, (IDX + 1));                                  \
  CHECK_RESULT(validate_int64(c, _c[0], _c[1]))

  IMM_64_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrshrq_n_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (const uint8_t *)impl.test_cases_int_pointer1;
  uint8_t _c[16];
  uint8x16_t a = vld1q_u8(_a);
  uint8x16_t c;
  uint8_t round_const;

#define TEST_IMPL(IDX)                                                                                                 \
  for (int i = 0; i < 16; i++) {                                                                                       \
    round_const = 1 << ((IDX + 1) - 1);                                                                                \
    _c[i] = (_a[i] + round_const) >> (IDX + 1);                                                                        \
  }                                                                                                                    \
  c = vrshrq_n_u8(a, (IDX + 1));                                                                                       \
  CHECK_RESULT(validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7], _c[8], _c[9], _c[10], _c[11], \
                              _c[12], _c[13], _c[14], _c[15]))

  IMM_8_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrshrq_n_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (const uint16_t *)impl.test_cases_int_pointer1;
  uint16_t _c[8];
  uint16x8_t a = vld1q_u16(_a);
  uint16x8_t c;
  uint16_t round_const;

#define TEST_IMPL(IDX)                          \
  for (int i = 0; i < 8; i++) {                 \
    round_const = 1 << ((IDX + 1) - 1);         \
    _c[i] = (_a[i] + round_const) >> (IDX + 1); \
  }                                             \
  c = vrshrq_n_u16(a, (IDX + 1));               \
  CHECK_RESULT(validate_uint16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]))

  IMM_16_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrshrq_n_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (const uint32_t *)impl.test_cases_int_pointer1;
  uint32_t _c[4];
  uint32x4_t a = vld1q_u32(_a);
  uint32x4_t c;
  uint32_t round_const;

#define TEST_IMPL(IDX)                                    \
  for (int i = 0; i < 4; i++) {                           \
    round_const = 1 << ((IDX + 1) - 1);                   \
    _c[i] = ((uint64_t)_a[i] + round_const) >> (IDX + 1); \
  }                                                       \
  c = vrshrq_n_u32(a, (IDX + 1));                         \
  CHECK_RESULT(validate_uint32(c, _c[0], _c[1], _c[2], _c[3]))

  IMM_32_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrshrq_n_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (const uint64_t *)impl.test_cases_int_pointer1;
  uint64_t _c[2];
  uint64x2_t a = vld1q_u64(_a);
  uint64x2_t c;
  uint64_t round_const = 0;

#define TEST_IMPL(IDX)                                               \
  for (int i = 0; i < 2; i++) {                                      \
    if (_a[i] & ((uint64_t)1 << ((IDX + 1) - 1))) {                  \
      round_const = 1;                                               \
    }                                                                \
    _c[i] = (uint64_t)(((uint64_t)_a[i] >> IDX) + round_const) >> 1; \
  }                                                                  \
  c = vrshrq_n_u64(a, (IDX + 1));                                    \
  CHECK_RESULT(validate_uint64(c, _c[0], _c[1]))

  IMM_64_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrshrd_n_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrshrd_n_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vshrn_n_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (const int16_t *)impl.test_cases_int_pointer1;
  int8_t _c[8];
  int16x8_t a = vld1q_s16(_a);
  int8x8_t c;

#define TEST_IMPL(IDX)                        \
  for (int i = 0; i < 8; i++) {               \
    _c[i] = (_a[i] >> (IDX + 1)) & UINT8_MAX; \
  }                                           \
  c = vshrn_n_s16(a, (IDX + 1));              \
  CHECK_RESULT(validate_int8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]))

  IMM_8_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vshrn_n_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (const int32_t *)impl.test_cases_int_pointer1;
  int16_t _c[4];
  int32x4_t a = vld1q_s32(_a);
  int16x4_t c;

#define TEST_IMPL(IDX)                         \
  for (int i = 0; i < 4; i++) {                \
    _c[i] = (_a[i] >> (IDX + 1)) & UINT16_MAX; \
  }                                            \
  c = vshrn_n_s32(a, (IDX + 1));               \
  CHECK_RESULT(validate_int16(c, _c[0], _c[1], _c[2], _c[3]))

  IMM_4_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vshrn_n_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (const int64_t *)impl.test_cases_int_pointer1;
  int32_t _c[2];
  int64x2_t a = vld1q_s64(_a);
  int32x2_t c;

#define TEST_IMPL(IDX)                         \
  for (int i = 0; i < 2; i++) {                \
    _c[i] = (_a[i] >> (IDX + 1)) & UINT32_MAX; \
  }                                            \
  c = vshrn_n_s64(a, (IDX + 1));               \
  CHECK_RESULT(validate_int32(c, _c[0], _c[1]))

  IMM_2_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vshrn_n_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (const uint16_t *)impl.test_cases_int_pointer1;
  uint8_t _c[8];
  uint16x8_t a = vld1q_u16(_a);
  uint8x8_t c;

#define TEST_IMPL(IDX)                        \
  for (int i = 0; i < 8; i++) {               \
    _c[i] = (_a[i] >> (IDX + 1)) & UINT8_MAX; \
  }                                           \
  c = vshrn_n_u16(a, (IDX + 1));              \
  CHECK_RESULT(validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]))

  IMM_8_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vshrn_n_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (const uint32_t *)impl.test_cases_int_pointer1;
  uint16_t _c[4];
  uint32x4_t a = vld1q_u32(_a);
  uint16x4_t c;

#define TEST_IMPL(IDX)                         \
  for (int i = 0; i < 4; i++) {                \
    _c[i] = (_a[i] >> (IDX + 1)) & UINT16_MAX; \
  }                                            \
  c = vshrn_n_u32(a, (IDX + 1));               \
  CHECK_RESULT(validate_uint16(c, _c[0], _c[1], _c[2], _c[3]))

  IMM_4_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vshrn_n_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (const uint64_t *)impl.test_cases_int_pointer1;
  uint32_t _c[2];
  uint64x2_t a = vld1q_u64(_a);
  uint32x2_t c;

#define TEST_IMPL(IDX)                         \
  for (int i = 0; i < 2; i++) {                \
    _c[i] = (_a[i] >> (IDX + 1)) & UINT32_MAX; \
  }                                            \
  c = vshrn_n_u64(a, (IDX + 1));               \
  CHECK_RESULT(validate_uint32(c, _c[0], _c[1]))

  IMM_2_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vshrn_high_n_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vshrn_high_n_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vshrn_high_n_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vshrn_high_n_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vshrn_high_n_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vshrn_high_n_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrshrn_n_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (const int16_t *)impl.test_cases_int_pointer1;
  int8_t _c[8];
  int16x8_t a = vld1q_s16(_a);
  int8x8_t c;

#define TEST_IMPL(IDX)                                                            \
  for (int i = 0; i < 8; i++) {                                                   \
    uint16_t round_const = 1 << ((IDX + 1) - 1);                                  \
    _c[i] = ((((const uint16_t *)_a)[i] + round_const) >> (IDX + 1)) & UINT8_MAX; \
  }                                                                               \
  c = vrshrn_n_s16(a, (IDX + 1));                                                 \
  CHECK_RESULT(validate_int8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]))

  IMM_8_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrshrn_n_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (const int32_t *)impl.test_cases_int_pointer1;
  int16_t _c[4];
  int32x4_t a = vld1q_s32(_a);
  int16x4_t c;

#define TEST_IMPL(IDX)                                                             \
  for (int i = 0; i < 4; i++) {                                                    \
    uint32_t round_const = 1 << ((IDX + 1) - 1);                                   \
    _c[i] = ((((const uint32_t *)_a)[i] + round_const) >> (IDX + 1)) & UINT16_MAX; \
  }                                                                                \
  c = vrshrn_n_s32(a, (IDX + 1));                                                  \
  CHECK_RESULT(validate_int16(c, _c[0], _c[1], _c[2], _c[3]))

  IMM_16_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrshrn_n_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (const int64_t *)impl.test_cases_int_pointer1;
  int32_t _c[2];
  int64x2_t a = vld1q_s64(_a);
  int32x2_t c;

#define TEST_IMPL(IDX)                                         \
  for (int i = 0; i < 2; i++) {                                \
    int64_t round_const = 0;                                   \
    if (_a[i] & (int64_t(1) << ((IDX + 1) - 1))) {             \
      if (_a[i] > 0) {                                         \
        round_const = 1;                                       \
      } else {                                                 \
        round_const = 1;                                       \
      }                                                        \
    }                                                          \
    _c[i] = ((_a[i] >> (IDX + 1)) + round_const) & UINT32_MAX; \
  }                                                            \
  c = vrshrn_n_s64(a, (IDX + 1));                              \
  CHECK_RESULT(validate_int32(c, _c[0], _c[1]))

  IMM_32_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrshrn_n_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (const uint16_t *)impl.test_cases_int_pointer1;
  uint8_t _c[8];
  uint16x8_t a = vld1q_u16(_a);
  uint8x8_t c;

#define TEST_IMPL(IDX)                                                            \
  for (int i = 0; i < 8; i++) {                                                   \
    uint16_t round_const = 1 << ((IDX + 1) - 1);                                  \
    _c[i] = ((((const uint16_t *)_a)[i] + round_const) >> (IDX + 1)) & UINT8_MAX; \
  }                                                                               \
  c = vrshrn_n_u16(a, (IDX + 1));                                                 \
  CHECK_RESULT(validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]))

  IMM_8_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrshrn_n_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (const uint32_t *)impl.test_cases_int_pointer1;
  uint16_t _c[4];
  uint32x4_t a = vld1q_u32(_a);
  uint16x4_t c;

#define TEST_IMPL(IDX)                                                             \
  for (int i = 0; i < 4; i++) {                                                    \
    uint32_t round_const = 1 << ((IDX + 1) - 1);                                   \
    _c[i] = ((((const uint32_t *)_a)[i] + round_const) >> (IDX + 1)) & UINT16_MAX; \
  }                                                                                \
  c = vrshrn_n_u32(a, (IDX + 1));                                                  \
  CHECK_RESULT(validate_uint16(c, _c[0], _c[1], _c[2], _c[3]))

  IMM_16_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrshrn_n_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (const uint64_t *)impl.test_cases_int_pointer1;
  uint32_t _c[2];
  uint64x2_t a = vld1q_u64(_a);
  uint32x2_t c;

#define TEST_IMPL(IDX)                                         \
  for (int i = 0; i < 2; i++) {                                \
    uint64_t round_const = 0;                                  \
    if (_a[i] & (int64_t(1) << ((IDX + 1) - 1))) {             \
      round_const = 1;                                         \
    }                                                          \
    _c[i] = ((_a[i] >> (IDX + 1)) + round_const) & UINT32_MAX; \
  }                                                            \
  c = vrshrn_n_u64(a, (IDX + 1));                              \
  CHECK_RESULT(validate_uint32(c, _c[0], _c[1]))

  IMM_32_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrshrn_high_n_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrshrn_high_n_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrshrn_high_n_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrshrn_high_n_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrshrn_high_n_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrshrn_high_n_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqshrn_n_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (const int16_t *)impl.test_cases_int_pointer1;
  int8_t _c[8];
  int16x8_t a = vld1q_s16(_a);
  int8x8_t c;

#define TEST_IMPL(IDX)                         \
  for (int i = 0; i < 8; i++) {                \
    _c[i] = saturate_int8(_a[i] >> (IDX + 1)); \
  }                                            \
  c = vqshrn_n_s16(a, (IDX + 1));              \
  CHECK_RESULT(validate_int8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]))

  IMM_8_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqshrn_n_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (const int32_t *)impl.test_cases_int_pointer1;
  int16_t _c[4];
  int32x4_t a = vld1q_s32(_a);
  int16x4_t c;

#define TEST_IMPL(IDX)                          \
  for (int i = 0; i < 4; i++) {                 \
    _c[i] = saturate_int16(_a[i] >> (IDX + 1)); \
  }                                             \
  c = vqshrn_n_s32(a, (IDX + 1));               \
  CHECK_RESULT(validate_int16(c, _c[0], _c[1], _c[2], _c[3]))

  IMM_16_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqshrn_n_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (const int64_t *)impl.test_cases_int_pointer1;
  int32_t _c[2];
  int64x2_t a = vld1q_s64(_a);
  int32x2_t c;

#define TEST_IMPL(IDX)                          \
  for (int i = 0; i < 2; i++) {                 \
    _c[i] = saturate_int32(_a[i] >> (IDX + 1)); \
  }                                             \
  c = vqshrn_n_s64(a, (IDX + 1));               \
  CHECK_RESULT(validate_int32(c, _c[0], _c[1]))

  IMM_32_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqshrn_n_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (const uint16_t *)impl.test_cases_int_pointer1;
  uint8_t _c[8];
  uint16x8_t a = vld1q_u16(_a);
  uint8x8_t c;

#define TEST_IMPL(IDX)                          \
  for (int i = 0; i < 8; i++) {                 \
    _c[i] = saturate_uint8(_a[i] >> (IDX + 1)); \
  }                                             \
  c = vqshrn_n_u16(a, (IDX + 1));               \
  CHECK_RESULT(validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]))

  IMM_8_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqshrn_n_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (const uint32_t *)impl.test_cases_int_pointer1;
  uint16_t _c[4];
  uint32x4_t a = vld1q_u32(_a);
  uint16x4_t c;

#define TEST_IMPL(IDX)                           \
  for (int i = 0; i < 4; i++) {                  \
    _c[i] = saturate_uint16(_a[i] >> (IDX + 1)); \
  }                                              \
  c = vqshrn_n_u32(a, (IDX + 1));                \
  CHECK_RESULT(validate_uint16(c, _c[0], _c[1], _c[2], _c[3]))

  IMM_16_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqshrn_n_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (const uint64_t *)impl.test_cases_int_pointer1;
  uint32_t _c[2];
  uint64x2_t a = vld1q_u64(_a);
  uint32x2_t c;

#define TEST_IMPL(IDX)                           \
  for (int i = 0; i < 2; i++) {                  \
    _c[i] = saturate_uint32(_a[i] >> (IDX + 1)); \
  }                                              \
  c = vqshrn_n_u64(a, (IDX + 1));                \
  CHECK_RESULT(validate_uint32(c, _c[0], _c[1]))

  IMM_32_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqshrnh_n_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqshrns_n_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqshrnd_n_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqshrnh_n_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqshrns_n_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqshrnd_n_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqshrn_high_n_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqshrn_high_n_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqshrn_high_n_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqshrn_high_n_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqshrn_high_n_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqshrn_high_n_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqrshrn_n_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (const int16_t *)impl.test_cases_int_pointer1;
  int8_t _c[8];
  int16x8_t a = vld1q_s16(_a);
  int8x8_t c;

#define TEST_IMPL(IDX)                                         \
  for (int i = 0; i < 8; i++) {                                \
    int16_t round_const = 1 << ((IDX + 1) - 1);                \
    _c[i] = saturate_int8((_a[i] + round_const) >> (IDX + 1)); \
  }                                                            \
  c = vqrshrn_n_s16(a, (IDX + 1));                             \
  CHECK_RESULT(validate_int8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]))

  IMM_8_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqrshrn_n_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (const int32_t *)impl.test_cases_int_pointer1;
  int16_t _c[4];
  int32x4_t a = vld1q_s32(_a);
  int16x4_t c;

#define TEST_IMPL(IDX)                                          \
  for (int i = 0; i < 4; i++) {                                 \
    int32_t round_const = 1 << ((IDX + 1) - 1);                 \
    _c[i] = saturate_int16((_a[i] + round_const) >> (IDX + 1)); \
  }                                                             \
  c = vqrshrn_n_s32(a, (IDX + 1));                              \
  CHECK_RESULT(validate_int16(c, _c[0], _c[1], _c[2], _c[3]))

  IMM_16_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqrshrn_n_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (const int64_t *)impl.test_cases_int_pointer1;
  int32_t _c[2];
  int64x2_t a = vld1q_s64(_a);
  int32x2_t c;

#define TEST_IMPL(IDX)                                                             \
  for (int i = 0; i < 2; i++) {                                                    \
    uint64_t round_const = 0;                                                      \
    if (_a[i] & ((int64_t)1 << ((IDX + 1) - 1))) {                                 \
      round_const = 1;                                                             \
    }                                                                              \
    _c[i] = saturate_int32((int64_t)(((int64_t)_a[i] >> IDX) + round_const) >> 1); \
  }                                                                                \
  c = vqrshrn_n_s64(a, (IDX + 1));                                                 \
  CHECK_RESULT(validate_int32(c, _c[0], _c[1]))

  IMM_32_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqrshrn_n_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (const uint16_t *)impl.test_cases_int_pointer1;
  uint8_t _c[8];
  uint16x8_t a = vld1q_u16(_a);
  uint8x8_t c;

#define TEST_IMPL(IDX)                                          \
  for (int i = 0; i < 8; i++) {                                 \
    uint16_t round_const = 1 << ((IDX + 1) - 1);                \
    _c[i] = saturate_uint8((_a[i] + round_const) >> (IDX + 1)); \
  }                                                             \
  c = vqrshrn_n_u16(a, (IDX + 1));                              \
  CHECK_RESULT(validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]))

  IMM_8_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqrshrn_n_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (const uint32_t *)impl.test_cases_int_pointer1;
  uint16_t _c[4];
  uint32x4_t a = vld1q_u32(_a);
  uint16x4_t c;

#define TEST_IMPL(IDX)                                                     \
  for (int i = 0; i < 4; i++) {                                            \
    uint32_t round_const = 1 << ((IDX + 1) - 1);                           \
    _c[i] = saturate_uint16(((uint64_t)_a[i] + round_const) >> (IDX + 1)); \
  }                                                                        \
  c = vqrshrn_n_u32(a, (IDX + 1));                                         \
  CHECK_RESULT(validate_uint16(c, _c[0], _c[1], _c[2], _c[3]))

  IMM_16_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqrshrn_n_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (const uint64_t *)impl.test_cases_int_pointer1;
  uint32_t _c[2];
  uint64x2_t a = vld1q_u64(_a);
  uint32x2_t c;

#define TEST_IMPL(IDX)                                                                \
  for (int i = 0; i < 2; i++) {                                                       \
    uint64_t round_const = 0;                                                         \
    if (_a[i] & ((uint64_t)1 << ((IDX + 1) - 1))) {                                   \
      round_const = 1;                                                                \
    }                                                                                 \
    _c[i] = saturate_uint32((uint64_t)(((uint64_t)_a[i] >> IDX) + round_const) >> 1); \
  }                                                                                   \
  c = vqrshrn_n_u64(a, (IDX + 1));                                                    \
  CHECK_RESULT(validate_uint32(c, _c[0], _c[1]))

  IMM_32_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqrshrnh_n_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqrshrns_n_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqrshrnd_n_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqrshrnh_n_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqrshrns_n_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqrshrnd_n_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqrshrn_high_n_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqrshrn_high_n_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqrshrn_high_n_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqrshrn_high_n_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqrshrn_high_n_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqrshrn_high_n_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqshrun_n_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (const int16_t *)impl.test_cases_int_pointer1;
  uint8_t _c[8];
  int16x8_t a = vld1q_s16(_a);
  uint8x8_t c;

#define TEST_IMPL(IDX)                                   \
  for (int i = 0; i < 8; i++) {                          \
    _c[i] = saturate_uint8((int16_t)_a[i] >> (IDX + 1)); \
  }                                                      \
  c = vqshrun_n_s16(a, (IDX + 1));                       \
  CHECK_RESULT(validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]))

  IMM_8_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqshrun_n_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (const int32_t *)impl.test_cases_int_pointer1;
  uint16_t _c[4];
  int32x4_t a = vld1q_s32(_a);
  uint16x4_t c;

#define TEST_IMPL(IDX)                                    \
  for (int i = 0; i < 4; i++) {                           \
    _c[i] = saturate_uint16((int32_t)_a[i] >> (IDX + 1)); \
  }                                                       \
  c = vqshrun_n_s32(a, (IDX + 1));                        \
  CHECK_RESULT(validate_uint16(c, _c[0], _c[1], _c[2], _c[3]))

  IMM_4_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqshrun_n_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (const int64_t *)impl.test_cases_int_pointer1;
  uint32_t _c[2];
  int64x2_t a = vld1q_s64(_a);
  uint32x2_t c;

#define TEST_IMPL(IDX)                                    \
  for (int i = 0; i < 2; i++) {                           \
    _c[i] = saturate_uint32((int64_t)_a[i] >> (IDX + 1)); \
  }                                                       \
  c = vqshrun_n_s64(a, (IDX + 1));                        \
  CHECK_RESULT(validate_uint32(c, _c[0], _c[1]))

  IMM_2_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqshrunh_n_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqshruns_n_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqshrund_n_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqshrun_high_n_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqshrun_high_n_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqshrun_high_n_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqrshrun_n_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (const int16_t *)impl.test_cases_int_pointer1;
  uint8_t _c[8];
  int16x8_t a = vld1q_s16(_a);
  uint8x8_t c;
  uint16_t round_const;

#define TEST_IMPL(IDX)                                          \
  for (int i = 0; i < 8; i++) {                                 \
    round_const = 1 << ((IDX + 1) - 1);                         \
    _c[i] = saturate_uint8((_a[i] + round_const) >> (IDX + 1)); \
  }                                                             \
  c = vqrshrun_n_s16(a, (IDX + 1));                             \
  CHECK_RESULT(validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]))

  IMM_8_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqrshrun_n_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (const int32_t *)impl.test_cases_int_pointer1;
  uint16_t _c[4];
  int32x4_t a = vld1q_s32(_a);
  uint16x4_t c;
  uint32_t round_const;

#define TEST_IMPL(IDX)                                                    \
  for (int i = 0; i < 4; i++) {                                           \
    round_const = 1 << ((IDX + 1) - 1);                                   \
    _c[i] = saturate_uint16((_a[i] + (int32_t)round_const) >> (IDX + 1)); \
  }                                                                       \
  c = vqrshrun_n_s32(a, (IDX + 1));                                       \
  CHECK_RESULT(validate_uint16(c, _c[0], _c[1], _c[2], _c[3]))

  IMM_16_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqrshrun_n_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (const int64_t *)impl.test_cases_int_pointer1;
  uint32_t _c[2];
  int64x2_t a = vld1q_s64(_a);
  uint32x2_t c;

#define TEST_IMPL(IDX)                       \
  for (int i = 0; i < 2; i++) {              \
    int64_t tmp = _a[i] >> ((IDX + 1) - 1);  \
    _c[i] = saturate_uint32((tmp + 1) >> 1); \
  }                                          \
  c = vqrshrun_n_s64(a, (IDX + 1));          \
  CHECK_RESULT(validate_uint32(c, _c[0], _c[1]))

  IMM_32_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqrshrunh_n_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqrshruns_n_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqrshrund_n_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqrshrun_high_n_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqrshrun_high_n_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqrshrun_high_n_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vshl_n_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (const int8_t *)impl.test_cases_int_pointer1;
  int8_t _c[8];
  int8x8_t a = vld1_s8(_a);
  int8x8_t c;

#define TEST_IMPL(IDX)          \
  for (int i = 0; i < 8; i++) { \
    _c[i] = _a[i] << IDX;       \
  }                             \
  c = vshl_n_s8(a, IDX);        \
  CHECK_RESULT(validate_int8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]))

  IMM_8_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vshl_n_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (const int16_t *)impl.test_cases_int_pointer1;
  int16_t _c[4];
  int16x4_t a = vld1_s16(_a);
  int16x4_t c;

#define TEST_IMPL(IDX)          \
  for (int i = 0; i < 4; i++) { \
    _c[i] = _a[i] << IDX;       \
  }                             \
  c = vshl_n_s16(a, IDX);       \
  CHECK_RESULT(validate_int16(c, _c[0], _c[1], _c[2], _c[3]))

  IMM_16_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vshl_n_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (const int32_t *)impl.test_cases_int_pointer1;
  int32_t _c[2];
  int32x2_t a = vld1_s32(_a);
  int32x2_t c;

#define TEST_IMPL(IDX)          \
  for (int i = 0; i < 2; i++) { \
    _c[i] = _a[i] << IDX;       \
  }                             \
  c = vshl_n_s32(a, IDX);       \
  CHECK_RESULT(validate_int32(c, _c[0], _c[1]))

  IMM_32_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vshl_n_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (const int64_t *)impl.test_cases_int_pointer1;
  int64_t _c[1];
  int64x1_t a = vld1_s64(_a);
  int64x1_t c;

#define TEST_IMPL(IDX)          \
  for (int i = 0; i < 1; i++) { \
    _c[i] = _a[i] << IDX;       \
  }                             \
  c = vshl_n_s64(a, IDX);       \
  CHECK_RESULT(validate_int64(c, _c[0]))

  IMM_64_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vshl_n_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (const uint8_t *)impl.test_cases_int_pointer1;
  uint8_t _c[8];
  uint8x8_t a = vld1_u8(_a);
  uint8x8_t c;

#define TEST_IMPL(IDX)          \
  for (int i = 0; i < 8; i++) { \
    _c[i] = _a[i] << IDX;       \
  }                             \
  c = vshl_n_u8(a, IDX);        \
  CHECK_RESULT(validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]))

  IMM_8_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vshl_n_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (const uint16_t *)impl.test_cases_int_pointer1;
  uint16_t _c[4];
  uint16x4_t a = vld1_u16(_a);
  uint16x4_t c;

#define TEST_IMPL(IDX)          \
  for (int i = 0; i < 4; i++) { \
    _c[i] = _a[i] << IDX;       \
  }                             \
  c = vshl_n_u16(a, IDX);       \
  CHECK_RESULT(validate_uint16(c, _c[0], _c[1], _c[2], _c[3]))

  IMM_16_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vshl_n_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (const uint32_t *)impl.test_cases_int_pointer1;
  uint32_t _c[2];
  uint32x2_t a = vld1_u32(_a);
  uint32x2_t c;

#define TEST_IMPL(IDX)          \
  for (int i = 0; i < 2; i++) { \
    _c[i] = _a[i] << IDX;       \
  }                             \
  c = vshl_n_u32(a, IDX);       \
  CHECK_RESULT(validate_uint32(c, _c[0], _c[1]))

  IMM_32_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vshl_n_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (const uint64_t *)impl.test_cases_int_pointer1;
  uint64_t _c[1];
  uint64x1_t a = vld1_u64(_a);
  uint64x1_t c;

#define TEST_IMPL(IDX)          \
  for (int i = 0; i < 1; i++) { \
    _c[i] = _a[i] << IDX;       \
  }                             \
  c = vshl_n_u64(a, IDX);       \
  CHECK_RESULT(validate_uint64(c, _c[0]))

  IMM_64_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vshlq_n_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (const int8_t *)impl.test_cases_int_pointer1;
  int8_t _c[16];
  int8x16_t a = vld1q_s8(_a);
  int8x16_t c;

#define TEST_IMPL(IDX)                                                                                                \
  for (int i = 0; i < 16; i++) {                                                                                      \
    _c[i] = _a[i] << IDX;                                                                                             \
  }                                                                                                                   \
  c = vshlq_n_s8(a, IDX);                                                                                             \
  CHECK_RESULT(validate_int8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7], _c[8], _c[9], _c[10], _c[11], \
                             _c[12], _c[13], _c[14], _c[15]))

  IMM_8_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vshlq_n_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (const int16_t *)impl.test_cases_int_pointer1;
  int16_t _c[8];
  int16x8_t a = vld1q_s16(_a);
  int16x8_t c;

#define TEST_IMPL(IDX)          \
  for (int i = 0; i < 8; i++) { \
    _c[i] = _a[i] << IDX;       \
  }                             \
  c = vshlq_n_s16(a, IDX);      \
  CHECK_RESULT(validate_int16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]))

  IMM_16_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vshlq_n_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (const int32_t *)impl.test_cases_int_pointer1;
  int32_t _c[4];
  int32x4_t a = vld1q_s32(_a);
  int32x4_t c;

#define TEST_IMPL(IDX)          \
  for (int i = 0; i < 4; i++) { \
    _c[i] = _a[i] << IDX;       \
  }                             \
  c = vshlq_n_s32(a, IDX);      \
  CHECK_RESULT(validate_int32(c, _c[0], _c[1], _c[2], _c[3]))

  IMM_32_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vshlq_n_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (const int64_t *)impl.test_cases_int_pointer1;
  int64_t _c[2];
  int64x2_t a = vld1q_s64(_a);
  int64x2_t c;

#define TEST_IMPL(IDX)          \
  for (int i = 0; i < 2; i++) { \
    _c[i] = _a[i] << IDX;       \
  }                             \
  c = vshlq_n_s64(a, IDX);      \
  CHECK_RESULT(validate_int64(c, _c[0], _c[1]))

  IMM_64_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vshlq_n_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (const uint8_t *)impl.test_cases_int_pointer1;
  uint8_t _c[16];
  uint8x16_t a = vld1q_u8(_a);
  uint8x16_t c;

#define TEST_IMPL(IDX)                                                                                                 \
  for (int i = 0; i < 16; i++) {                                                                                       \
    _c[i] = _a[i] << IDX;                                                                                              \
  }                                                                                                                    \
  c = vshlq_n_u8(a, IDX);                                                                                              \
  CHECK_RESULT(validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7], _c[8], _c[9], _c[10], _c[11], \
                              _c[12], _c[13], _c[14], _c[15]))

  IMM_8_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vshlq_n_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (const uint16_t *)impl.test_cases_int_pointer1;
  uint16_t _c[8];
  uint16x8_t a = vld1q_u16(_a);
  uint16x8_t c;

#define TEST_IMPL(IDX)          \
  for (int i = 0; i < 8; i++) { \
    _c[i] = _a[i] << IDX;       \
  }                             \
  c = vshlq_n_u16(a, IDX);      \
  CHECK_RESULT(validate_uint16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]))

  IMM_16_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vshlq_n_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (const uint32_t *)impl.test_cases_int_pointer1;
  uint32_t _c[4];
  uint32x4_t a = vld1q_u32(_a);
  uint32x4_t c;

#define TEST_IMPL(IDX)          \
  for (int i = 0; i < 4; i++) { \
    _c[i] = _a[i] << IDX;       \
  }                             \
  c = vshlq_n_u32(a, IDX);      \
  CHECK_RESULT(validate_uint32(c, _c[0], _c[1], _c[2], _c[3]))

  IMM_32_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vshlq_n_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (const uint64_t *)impl.test_cases_int_pointer1;
  uint64_t _c[2];
  uint64x2_t a = vld1q_u64(_a);
  uint64x2_t c;

#define TEST_IMPL(IDX)          \
  for (int i = 0; i < 2; i++) { \
    _c[i] = _a[i] << IDX;       \
  }                             \
  c = vshlq_n_u64(a, IDX);      \
  CHECK_RESULT(validate_uint64(c, _c[0], _c[1]))

  IMM_64_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vshld_n_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vshld_n_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqshl_n_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (const int8_t *)impl.test_cases_int_pointer1;
  int8_t _c[8];
  int8x8_t a = vld1_s8(_a);
  int8x8_t c;

#define TEST_IMPL(IDX)                   \
  for (int i = 0; i < 8; i++) {          \
    _c[i] = saturate_int8(_a[i] << IDX); \
  }                                      \
  c = vqshl_n_s8(a, IDX);                \
  CHECK_RESULT(validate_int8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]))

  IMM_8_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqshl_n_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (const int16_t *)impl.test_cases_int_pointer1;
  int16_t _c[4];
  int16x4_t a = vld1_s16(_a);
  int16x4_t c;

#define TEST_IMPL(IDX)                    \
  for (int i = 0; i < 4; i++) {           \
    _c[i] = saturate_int16(_a[i] << IDX); \
  }                                       \
  c = vqshl_n_s16(a, IDX);                \
  CHECK_RESULT(validate_int16(c, _c[0], _c[1], _c[2], _c[3]))

  IMM_16_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqshl_n_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (const int32_t *)impl.test_cases_int_pointer1;
  int32_t _c[2];
  int32x2_t a = vld1_s32(_a);
  int32x2_t c;

#define TEST_IMPL(IDX)                             \
  for (int i = 0; i < 2; i++) {                    \
    _c[i] = saturate_int32((int64_t)_a[i] << IDX); \
  }                                                \
  c = vqshl_n_s32(a, IDX);                         \
  CHECK_RESULT(validate_int32(c, _c[0], _c[1]))

  IMM_32_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqshl_n_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (const int64_t *)impl.test_cases_int_pointer1;
  int64_t _c[1];
  int64x1_t a = vld1_s64(_a);
  int64x1_t c;

#define TEST_IMPL(IDX)                  \
  for (int i = 0; i < 1; i++) {         \
    if (_a[i] > 0) {                    \
      if (_a[i] > (INT64_MAX >> IDX)) { \
        _c[i] = INT64_MAX;              \
      } else {                          \
        _c[i] = _a[i] << IDX;           \
      }                                 \
    } else {                            \
      if (_a[i] < (INT64_MIN >> IDX)) { \
        _c[i] = INT64_MIN;              \
      } else {                          \
        _c[i] = _a[i] << IDX;           \
      }                                 \
    }                                   \
  }                                     \
  c = vqshl_n_s64(a, IDX);              \
  CHECK_RESULT(validate_int64(c, _c[0]))

  IMM_64_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqshl_n_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (const uint8_t *)impl.test_cases_int_pointer1;
  uint8_t _c[8];
  uint8x8_t a = vld1_u8(_a);
  uint8x8_t c;

#define TEST_IMPL(IDX)                    \
  for (int i = 0; i < 8; i++) {           \
    _c[i] = saturate_uint8(_a[i] << IDX); \
  }                                       \
  c = vqshl_n_u8(a, IDX);                 \
  CHECK_RESULT(validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]))

  IMM_8_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqshl_n_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (const uint16_t *)impl.test_cases_int_pointer1;
  uint16_t _c[4];
  uint16x4_t a = vld1_u16(_a);
  uint16x4_t c;

#define TEST_IMPL(IDX)                     \
  for (int i = 0; i < 4; i++) {            \
    _c[i] = saturate_uint16(_a[i] << IDX); \
  }                                        \
  c = vqshl_n_u16(a, IDX);                 \
  CHECK_RESULT(validate_uint16(c, _c[0], _c[1], _c[2], _c[3]))

  IMM_16_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqshl_n_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (const uint32_t *)impl.test_cases_int_pointer1;
  uint32_t _c[2];
  uint32x2_t a = vld1_u32(_a);
  uint32x2_t c;

#define TEST_IMPL(IDX)                              \
  for (int i = 0; i < 2; i++) {                     \
    _c[i] = saturate_uint32((int64_t)_a[i] << IDX); \
  }                                                 \
  c = vqshl_n_u32(a, IDX);                          \
  CHECK_RESULT(validate_uint32(c, _c[0], _c[1]))

  IMM_32_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqshl_n_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (const uint64_t *)impl.test_cases_int_pointer1;
  uint64_t _c[1];
  uint64x1_t a = vld1_u64(_a);
  uint64x1_t c;

#define TEST_IMPL(IDX)                 \
  for (int i = 0; i < 1; i++) {        \
    if (_a[i] > (UINT64_MAX >> IDX)) { \
      _c[i] = UINT64_MAX;              \
    } else {                           \
      _c[i] = _a[i] << IDX;            \
    }                                  \
  }                                    \
  c = vqshl_n_u64(a, IDX);             \
  CHECK_RESULT(validate_uint64(c, _c[0]))

  IMM_64_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqshlq_n_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (const int8_t *)impl.test_cases_int_pointer1;
  int8_t _c[16];
  int8x16_t a = vld1q_s8(_a);
  int8x16_t c;

#define TEST_IMPL(IDX)                                                                                                \
  for (int i = 0; i < 16; i++) {                                                                                      \
    _c[i] = saturate_int8(_a[i] << IDX);                                                                              \
  }                                                                                                                   \
  c = vqshlq_n_s8(a, IDX);                                                                                            \
  CHECK_RESULT(validate_int8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7], _c[8], _c[9], _c[10], _c[11], \
                             _c[12], _c[13], _c[14], _c[15]))

  IMM_8_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqshlq_n_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (const int16_t *)impl.test_cases_int_pointer1;
  int16_t _c[8];
  int16x8_t a = vld1q_s16(_a);
  int16x8_t c;

#define TEST_IMPL(IDX)                    \
  for (int i = 0; i < 8; i++) {           \
    _c[i] = saturate_int16(_a[i] << IDX); \
  }                                       \
  c = vqshlq_n_s16(a, IDX);               \
  CHECK_RESULT(validate_int16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]))

  IMM_16_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqshlq_n_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (const int32_t *)impl.test_cases_int_pointer1;
  int32_t _c[4];
  int32x4_t a = vld1q_s32(_a);
  int32x4_t c;

#define TEST_IMPL(IDX)                             \
  for (int i = 0; i < 4; i++) {                    \
    _c[i] = saturate_int32((int64_t)_a[i] << IDX); \
  }                                                \
  c = vqshlq_n_s32(a, IDX);                        \
  CHECK_RESULT(validate_int32(c, _c[0], _c[1], _c[2], _c[3]))

  IMM_32_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqshlq_n_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (const int64_t *)impl.test_cases_int_pointer1;
  int64_t _c[2];
  int64x2_t a = vld1q_s64(_a);
  int64x2_t c;

#define TEST_IMPL(IDX)                  \
  for (int i = 0; i < 2; i++) {         \
    if (_a[i] > 0) {                    \
      if (_a[i] > (INT64_MAX >> IDX)) { \
        _c[i] = INT64_MAX;              \
      } else {                          \
        _c[i] = _a[i] << IDX;           \
      }                                 \
    } else {                            \
      if (_a[i] < (INT64_MIN >> IDX)) { \
        _c[i] = INT64_MIN;              \
      } else {                          \
        _c[i] = _a[i] << IDX;           \
      }                                 \
    }                                   \
  }                                     \
  c = vqshlq_n_s64(a, IDX);             \
  CHECK_RESULT(validate_int64(c, _c[0], _c[1]))

  IMM_64_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqshlq_n_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (const uint8_t *)impl.test_cases_int_pointer1;
  uint8_t _c[16];
  uint8x16_t a = vld1q_u8(_a);
  uint8x16_t c;

#define TEST_IMPL(IDX)                                                                                                 \
  for (int i = 0; i < 16; i++) {                                                                                       \
    _c[i] = saturate_uint8(_a[i] << IDX);                                                                              \
  }                                                                                                                    \
  c = vqshlq_n_u8(a, IDX);                                                                                             \
  CHECK_RESULT(validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7], _c[8], _c[9], _c[10], _c[11], \
                              _c[12], _c[13], _c[14], _c[15]))

  IMM_8_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqshlq_n_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (const uint16_t *)impl.test_cases_int_pointer1;
  uint16_t _c[8];
  uint16x8_t a = vld1q_u16(_a);
  uint16x8_t c;

#define TEST_IMPL(IDX)                     \
  for (int i = 0; i < 8; i++) {            \
    _c[i] = saturate_uint16(_a[i] << IDX); \
  }                                        \
  c = vqshlq_n_u16(a, IDX);                \
  CHECK_RESULT(validate_uint16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]))

  IMM_16_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqshlq_n_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (const uint32_t *)impl.test_cases_int_pointer1;
  uint32_t _c[4];
  uint32x4_t a = vld1q_u32(_a);
  uint32x4_t c;

#define TEST_IMPL(IDX)                              \
  for (int i = 0; i < 4; i++) {                     \
    _c[i] = saturate_uint32((int64_t)_a[i] << IDX); \
  }                                                 \
  c = vqshlq_n_u32(a, IDX);                         \
  CHECK_RESULT(validate_uint32(c, _c[0], _c[1], _c[2], _c[3]))

  IMM_32_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqshlq_n_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (const uint64_t *)impl.test_cases_int_pointer1;
  uint64_t _c[2];
  uint64x2_t a = vld1q_u64(_a);
  uint64x2_t c;

#define TEST_IMPL(IDX)                 \
  for (int i = 0; i < 2; i++) {        \
    if (_a[i] > (UINT64_MAX >> IDX)) { \
      _c[i] = UINT64_MAX;              \
    } else {                           \
      _c[i] = _a[i] << IDX;            \
    }                                  \
  }                                    \
  c = vqshlq_n_u64(a, IDX);            \
  CHECK_RESULT(validate_uint64(c, _c[0], _c[1]))

  IMM_64_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqshlb_n_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqshlh_n_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqshls_n_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqshld_n_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqshlb_n_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqshlh_n_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqshls_n_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqshld_n_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqshlu_n_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (const int8_t *)impl.test_cases_int_pointer1;
  int8_t _c[8];
  int8x8_t a = vld1_s8(_a);
  uint8x8_t c;

#define TEST_IMPL(IDX)                    \
  for (int i = 0; i < 8; i++) {           \
    _c[i] = saturate_uint8(_a[i] << IDX); \
  }                                       \
  c = vqshlu_n_s8(a, IDX);                \
  CHECK_RESULT(validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]))

  IMM_8_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqshlu_n_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (const int16_t *)impl.test_cases_int_pointer1;
  int16_t _c[4];
  int16x4_t a = vld1_s16(_a);
  uint16x4_t c;

#define TEST_IMPL(IDX)                     \
  for (int i = 0; i < 4; i++) {            \
    _c[i] = saturate_uint16(_a[i] << IDX); \
  }                                        \
  c = vqshlu_n_s16(a, IDX);                \
  CHECK_RESULT(validate_uint16(c, _c[0], _c[1], _c[2], _c[3]))

  IMM_16_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqshlu_n_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (const int32_t *)impl.test_cases_int_pointer1;
  int32_t _c[2];
  int32x2_t a = vld1_s32(_a);
  uint32x2_t c;

#define TEST_IMPL(IDX)                              \
  for (int i = 0; i < 2; i++) {                     \
    _c[i] = saturate_uint32((int64_t)_a[i] << IDX); \
  }                                                 \
  c = vqshlu_n_s32(a, IDX);                         \
  CHECK_RESULT(validate_uint32(c, _c[0], _c[1]))

  IMM_32_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqshlu_n_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (const int64_t *)impl.test_cases_int_pointer1;
  int64_t _c[1];
  int64x1_t a = vld1_s64(_a);
  uint64x1_t c;

#define TEST_IMPL(IDX)                             \
  for (int i = 0; i < 1; i++) {                    \
    if (_a[i] < 0) {                               \
      _c[i] = 0;                                   \
    } else {                                       \
      if ((uint64_t)_a[i] > (UINT64_MAX >> IDX)) { \
        _c[i] = UINT64_MAX;                        \
      } else {                                     \
        _c[i] = _a[i] << IDX;                      \
      }                                            \
    }                                              \
  }                                                \
  c = vqshlu_n_s64(a, IDX);                        \
  CHECK_RESULT(validate_uint64(c, _c[0]))

  IMM_64_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqshluq_n_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (const int8_t *)impl.test_cases_int_pointer1;
  int8_t _c[16];
  int8x16_t a = vld1q_s8(_a);
  uint8x16_t c;

#define TEST_IMPL(IDX)                                                                                                 \
  for (int i = 0; i < 16; i++) {                                                                                       \
    _c[i] = saturate_uint8(_a[i] << IDX);                                                                              \
  }                                                                                                                    \
  c = vqshluq_n_s8(a, IDX);                                                                                            \
  CHECK_RESULT(validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7], _c[8], _c[9], _c[10], _c[11], \
                              _c[12], _c[13], _c[14], _c[15]))

  IMM_8_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqshluq_n_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (const int16_t *)impl.test_cases_int_pointer1;
  int16_t _c[8];
  int16x8_t a = vld1q_s16(_a);
  uint16x8_t c;

#define TEST_IMPL(IDX)                     \
  for (int i = 0; i < 8; i++) {            \
    _c[i] = saturate_uint16(_a[i] << IDX); \
  }                                        \
  c = vqshluq_n_s16(a, IDX);               \
  CHECK_RESULT(validate_uint16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]))

  IMM_16_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqshluq_n_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (const int32_t *)impl.test_cases_int_pointer1;
  int32_t _c[4];
  int32x4_t a = vld1q_s32(_a);
  uint32x4_t c;

#define TEST_IMPL(IDX)                              \
  for (int i = 0; i < 4; i++) {                     \
    _c[i] = saturate_uint32((int64_t)_a[i] << IDX); \
  }                                                 \
  c = vqshluq_n_s32(a, IDX);                        \
  CHECK_RESULT(validate_uint32(c, _c[0], _c[1], _c[2], _c[3]))

  IMM_32_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqshluq_n_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (const int64_t *)impl.test_cases_int_pointer1;
  int64_t _c[2];
  int64x2_t a = vld1q_s64(_a);
  uint64x2_t c;

#define TEST_IMPL(IDX)                             \
  for (int i = 0; i < 2; i++) {                    \
    if (_a[i] < 0) {                               \
      _c[i] = 0;                                   \
    } else {                                       \
      if ((uint64_t)_a[i] > (UINT64_MAX >> IDX)) { \
        _c[i] = UINT64_MAX;                        \
      } else {                                     \
        _c[i] = _a[i] << IDX;                      \
      }                                            \
    }                                              \
  }                                                \
  c = vqshluq_n_s64(a, IDX);                       \
  CHECK_RESULT(validate_uint64(c, _c[0], _c[1]))

  IMM_64_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqshlub_n_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqshluh_n_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqshlus_n_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqshlud_n_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vshll_n_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (const int8_t *)impl.test_cases_int_pointer1;
  int16_t _c[8];
  int8x8_t a = vld1_s8(_a);
  int16x8_t c;

#define TEST_IMPL(IDX)             \
  for (int i = 0; i < 8; i++) {    \
    _c[i] = (int16_t)_a[i] << IDX; \
  }                                \
  c = vshll_n_s8(a, IDX);          \
  CHECK_RESULT(validate_int16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]))

  IMM_8_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vshll_n_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (const int16_t *)impl.test_cases_int_pointer1;
  int32_t _c[4];
  int16x4_t a = vld1_s16(_a);
  int32x4_t c;

#define TEST_IMPL(IDX)             \
  for (int i = 0; i < 4; i++) {    \
    _c[i] = (int32_t)_a[i] << IDX; \
  }                                \
  c = vshll_n_s16(a, IDX);         \
  CHECK_RESULT(validate_int32(c, _c[0], _c[1], _c[2], _c[3]))

  IMM_16_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vshll_n_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (const int32_t *)impl.test_cases_int_pointer1;
  int64_t _c[2];
  int32x2_t a = vld1_s32(_a);
  int64x2_t c;

#define TEST_IMPL(IDX)             \
  for (int i = 0; i < 2; i++) {    \
    _c[i] = (int64_t)_a[i] << IDX; \
  }                                \
  c = vshll_n_s32(a, IDX);         \
  CHECK_RESULT(validate_int64(c, _c[0], _c[1]))

  IMM_32_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vshll_n_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (const uint8_t *)impl.test_cases_int_pointer1;
  uint16_t _c[8];
  uint8x8_t a = vld1_u8(_a);
  uint16x8_t c;

#define TEST_IMPL(IDX)              \
  for (int i = 0; i < 8; i++) {     \
    _c[i] = (uint16_t)_a[i] << IDX; \
  }                                 \
  c = vshll_n_u8(a, IDX);           \
  CHECK_RESULT(validate_uint16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]))

  IMM_8_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vshll_n_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (const uint16_t *)impl.test_cases_int_pointer1;
  uint32_t _c[4];
  uint16x4_t a = vld1_u16(_a);
  uint32x4_t c;

#define TEST_IMPL(IDX)              \
  for (int i = 0; i < 4; i++) {     \
    _c[i] = (uint32_t)_a[i] << IDX; \
  }                                 \
  c = vshll_n_u16(a, IDX);          \
  CHECK_RESULT(validate_uint32(c, _c[0], _c[1], _c[2], _c[3]))

  IMM_16_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vshll_n_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (const uint32_t *)impl.test_cases_int_pointer1;
  uint64_t _c[2];
  uint32x2_t a = vld1_u32(_a);
  uint64x2_t c;

#define TEST_IMPL(IDX)              \
  for (int i = 0; i < 2; i++) {     \
    _c[i] = (uint64_t)_a[i] << IDX; \
  }                                 \
  c = vshll_n_u32(a, IDX);          \
  CHECK_RESULT(validate_uint64(c, _c[0], _c[1]))

  IMM_32_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vshll_high_n_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vshll_high_n_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vshll_high_n_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vshll_high_n_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vshll_high_n_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vshll_high_n_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vsra_n_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (const int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (const int8_t *)impl.test_cases_int_pointer2;
  int8_t _c[8];
  int8x8_t a = vld1_s8(_a);
  int8x8_t b = vld1_s8(_b);
  int8x8_t c;

#define TEST_IMPL(IDX)                    \
  for (int i = 0; i < 8; i++) {           \
    _c[i] = _a[i] + (_b[i] >> (IDX + 1)); \
  }                                       \
  c = vsra_n_s8(a, b, (IDX + 1));         \
  CHECK_RESULT(validate_int8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]))

  IMM_8_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsra_n_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (const int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (const int16_t *)impl.test_cases_int_pointer2;
  int16_t _c[4];
  int16x4_t a = vld1_s16(_a);
  int16x4_t b = vld1_s16(_b);
  int16x4_t c;

#define TEST_IMPL(IDX)                    \
  for (int i = 0; i < 4; i++) {           \
    _c[i] = _a[i] + (_b[i] >> (IDX + 1)); \
  }                                       \
  c = vsra_n_s16(a, b, (IDX + 1));        \
  CHECK_RESULT(validate_int16(c, _c[0], _c[1], _c[2], _c[3]))

  IMM_16_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsra_n_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (const int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (const int32_t *)impl.test_cases_int_pointer2;
  int32_t _c[2];
  int32x2_t a = vld1_s32(_a);
  int32x2_t b = vld1_s32(_b);
  int32x2_t c;

#define TEST_IMPL(IDX)                                      \
  for (int i = 0; i < 2; i++) {                             \
    _c[i] = _a[i] + (int32_t)((int64_t)_b[i] >> (IDX + 1)); \
  }                                                         \
  c = vsra_n_s32(a, b, (IDX + 1));                          \
  CHECK_RESULT(validate_int32(c, _c[0], _c[1]))

  IMM_32_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsra_n_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (const int64_t *)impl.test_cases_int_pointer1;
  const int64_t *_b = (const int64_t *)impl.test_cases_int_pointer2;
  int64_t _c[1];
  int64x1_t a = vld1_s64(_a);
  int64x1_t b = vld1_s64(_b);
  int64x1_t c;

#define TEST_IMPL(IDX)                \
  for (int i = 0; i < 1; i++) {       \
    int idx = (IDX + 1);              \
    if (idx == 64) {                  \
      if (_b[i] > 0) {                \
        _c[i] = _a[i];                \
      } else {                        \
        _c[i] = _a[i] - 1;            \
      }                               \
    } else {                          \
      _c[i] = _a[i] + (_b[i] >> idx); \
    }                                 \
  }                                   \
  c = vsra_n_s64(a, b, (IDX + 1));    \
  CHECK_RESULT(validate_int64(c, _c[0]))

  IMM_64_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsra_n_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (const uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (const uint8_t *)impl.test_cases_int_pointer2;
  uint8_t _c[8];
  uint8x8_t a = vld1_u8(_a);
  uint8x8_t b = vld1_u8(_b);
  uint8x8_t c;

#define TEST_IMPL(IDX)                    \
  for (int i = 0; i < 8; i++) {           \
    _c[i] = _a[i] + (_b[i] >> (IDX + 1)); \
  }                                       \
  c = vsra_n_u8(a, b, (IDX + 1));         \
  CHECK_RESULT(validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]))

  IMM_8_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsra_n_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (const uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (const uint16_t *)impl.test_cases_int_pointer2;
  uint16_t _c[4];
  uint16x4_t a = vld1_u16(_a);
  uint16x4_t b = vld1_u16(_b);
  uint16x4_t c;

#define TEST_IMPL(IDX)                    \
  for (int i = 0; i < 4; i++) {           \
    _c[i] = _a[i] + (_b[i] >> (IDX + 1)); \
  }                                       \
  c = vsra_n_u16(a, b, (IDX + 1));        \
  CHECK_RESULT(validate_uint16(c, _c[0], _c[1], _c[2], _c[3]))

  IMM_16_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsra_n_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (const uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (const uint32_t *)impl.test_cases_int_pointer2;
  uint32_t _c[2];
  uint32x2_t a = vld1_u32(_a);
  uint32x2_t b = vld1_u32(_b);
  uint32x2_t c;

#define TEST_IMPL(IDX)                              \
  for (int i = 0; i < 2; i++) {                     \
    _c[i] = _a[i] + ((uint64_t)_b[i] >> (IDX + 1)); \
  }                                                 \
  c = vsra_n_u32(a, b, (IDX + 1));                  \
  CHECK_RESULT(validate_uint32(c, _c[0], _c[1]))

  IMM_32_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsra_n_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (const uint64_t *)impl.test_cases_int_pointer1;
  const uint64_t *_b = (const uint64_t *)impl.test_cases_int_pointer2;
  uint64_t _c[1];
  uint64x1_t a = vld1_u64(_a);
  uint64x1_t b = vld1_u64(_b);
  uint64x1_t c;

#define TEST_IMPL(IDX)                \
  for (int i = 0; i < 1; i++) {       \
    int idx = (IDX + 1);              \
    if (idx == 64) {                  \
      _c[i] = _a[i];                  \
    } else {                          \
      _c[i] = _a[i] + (_b[i] >> idx); \
    }                                 \
  }                                   \
  c = vsra_n_u64(a, b, (IDX + 1));    \
  CHECK_RESULT(validate_uint64(c, _c[0]))

  IMM_64_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsraq_n_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (const int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (const int8_t *)impl.test_cases_int_pointer2;
  int8_t _c[16];
  int8x16_t a = vld1q_s8(_a);
  int8x16_t b = vld1q_s8(_b);
  int8x16_t c;

#define TEST_IMPL(IDX)                                                                                                \
  for (int i = 0; i < 16; i++) {                                                                                      \
    _c[i] = _a[i] + (_b[i] >> (IDX + 1));                                                                             \
  }                                                                                                                   \
  c = vsraq_n_s8(a, b, (IDX + 1));                                                                                    \
  CHECK_RESULT(validate_int8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7], _c[8], _c[9], _c[10], _c[11], \
                             _c[12], _c[13], _c[14], _c[15]))

  IMM_8_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsraq_n_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (const int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (const int16_t *)impl.test_cases_int_pointer2;
  int16_t _c[8];
  int16x8_t a = vld1q_s16(_a);
  int16x8_t b = vld1q_s16(_b);
  int16x8_t c;

#define TEST_IMPL(IDX)                    \
  for (int i = 0; i < 8; i++) {           \
    _c[i] = _a[i] + (_b[i] >> (IDX + 1)); \
  }                                       \
  c = vsraq_n_s16(a, b, (IDX + 1));       \
  CHECK_RESULT(validate_int16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]))

  IMM_16_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsraq_n_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (const int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (const int32_t *)impl.test_cases_int_pointer2;
  int32_t _c[4];
  int32x4_t a = vld1q_s32(_a);
  int32x4_t b = vld1q_s32(_b);
  int32x4_t c;

#define TEST_IMPL(IDX)                                      \
  for (int i = 0; i < 4; i++) {                             \
    _c[i] = _a[i] + (int32_t)((int64_t)_b[i] >> (IDX + 1)); \
  }                                                         \
  c = vsraq_n_s32(a, b, (IDX + 1));                         \
  CHECK_RESULT(validate_int32(c, _c[0], _c[1], _c[2], _c[3]))

  IMM_32_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsraq_n_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (const int64_t *)impl.test_cases_int_pointer1;
  const int64_t *_b = (const int64_t *)impl.test_cases_int_pointer2;
  int64_t _c[2];
  int64x2_t a = vld1q_s64(_a);
  int64x2_t b = vld1q_s64(_b);
  int64x2_t c;

#define TEST_IMPL(IDX)                \
  for (int i = 0; i < 2; i++) {       \
    int idx = (IDX + 1);              \
    if (idx == 64) {                  \
      if (_b[i] > 0) {                \
        _c[i] = _a[i];                \
      } else {                        \
        _c[i] = _a[i] - 1;            \
      }                               \
    } else {                          \
      _c[i] = _a[i] + (_b[i] >> idx); \
    }                                 \
  }                                   \
  c = vsraq_n_s64(a, b, (IDX + 1));   \
  CHECK_RESULT(validate_int64(c, _c[0], _c[1]))

  IMM_64_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsraq_n_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (const uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (const uint8_t *)impl.test_cases_int_pointer2;
  uint8_t _c[16];
  uint8x16_t a = vld1q_u8(_a);
  uint8x16_t b = vld1q_u8(_b);
  uint8x16_t c;

#define TEST_IMPL(IDX)                                                                                                 \
  for (int i = 0; i < 16; i++) {                                                                                       \
    _c[i] = _a[i] + (_b[i] >> (IDX + 1));                                                                              \
  }                                                                                                                    \
  c = vsraq_n_u8(a, b, (IDX + 1));                                                                                     \
  CHECK_RESULT(validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7], _c[8], _c[9], _c[10], _c[11], \
                              _c[12], _c[13], _c[14], _c[15]))

  IMM_8_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsraq_n_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (const uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (const uint16_t *)impl.test_cases_int_pointer2;
  uint16_t _c[8];
  uint16x8_t a = vld1q_u16(_a);
  uint16x8_t b = vld1q_u16(_b);
  uint16x8_t c;

#define TEST_IMPL(IDX)                    \
  for (int i = 0; i < 8; i++) {           \
    _c[i] = _a[i] + (_b[i] >> (IDX + 1)); \
  }                                       \
  c = vsraq_n_u16(a, b, (IDX + 1));       \
  CHECK_RESULT(validate_uint16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]))

  IMM_16_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsraq_n_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (const uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (const uint32_t *)impl.test_cases_int_pointer2;
  uint32_t _c[4];
  uint32x4_t a = vld1q_u32(_a);
  uint32x4_t b = vld1q_u32(_b);
  uint32x4_t c;

#define TEST_IMPL(IDX)                                        \
  for (int i = 0; i < 4; i++) {                               \
    _c[i] = _a[i] + (uint32_t)((uint64_t)_b[i] >> (IDX + 1)); \
  }                                                           \
  c = vsraq_n_u32(a, b, (IDX + 1));                           \
  CHECK_RESULT(validate_uint32(c, _c[0], _c[1], _c[2], _c[3]))

  IMM_32_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsraq_n_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (const uint64_t *)impl.test_cases_int_pointer1;
  const uint64_t *_b = (const uint64_t *)impl.test_cases_int_pointer2;
  uint64_t _c[2];
  uint64x2_t a = vld1q_u64(_a);
  uint64x2_t b = vld1q_u64(_b);
  uint64x2_t c;

#define TEST_IMPL(IDX)                \
  for (int i = 0; i < 2; i++) {       \
    int idx = (IDX + 1);              \
    if (idx == 64) {                  \
      _c[i] = _a[i];                  \
    } else {                          \
      _c[i] = _a[i] + (_b[i] >> idx); \
    }                                 \
  }                                   \
  c = vsraq_n_u64(a, b, (IDX + 1));   \
  CHECK_RESULT(validate_uint64(c, _c[0], _c[1]))

  IMM_64_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsrad_n_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vsrad_n_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrsra_n_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (const int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (const int8_t *)impl.test_cases_int_pointer2;
  const int element_num = 8;
  int8_t _c[element_num];
  int8x8_t a = vld1_s8(_a);
  int8x8_t b = vld1_s8(_b);
  int8x8_t c;
  uint8_t round_const;

#define TEST_IMPL(IDX)                                    \
  for (int i = 0; i < element_num; i++) {                 \
    round_const = 1 << ((IDX + 1) - 1);                   \
    _c[i] = _a[i] + ((_b[i] + round_const) >> (IDX + 1)); \
  }                                                       \
  c = vrsra_n_s8(a, b, (IDX + 1));                        \
  CHECK_RESULT(validate_int8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]))

  IMM_8_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrsra_n_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (const int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (const int16_t *)impl.test_cases_int_pointer2;
  const int element_num = 4;
  int16_t _c[element_num];
  int16x4_t a = vld1_s16(_a);
  int16x4_t b = vld1_s16(_b);
  int16x4_t c;
  uint16_t round_const;

#define TEST_IMPL(IDX)                                    \
  for (int i = 0; i < element_num; i++) {                 \
    round_const = 1 << ((IDX + 1) - 1);                   \
    _c[i] = _a[i] + ((_b[i] + round_const) >> (IDX + 1)); \
  }                                                       \
  c = vrsra_n_s16(a, b, (IDX + 1));                       \
  CHECK_RESULT(validate_int16(c, _c[0], _c[1], _c[2], _c[3]))

  IMM_16_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrsra_n_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (const int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (const int32_t *)impl.test_cases_int_pointer2;
  const int element_num = 2;
  int32_t _c[element_num];
  int32x2_t a = vld1_s32(_a);
  int32x2_t b = vld1_s32(_b);
  int32x2_t c;
  uint32_t round_const;

#define TEST_IMPL(IDX)                                              \
  for (int i = 0; i < element_num; i++) {                           \
    round_const = 1 << ((IDX + 1) - 1);                             \
    _c[i] = _a[i] + (((uint64_t)_b[i] + round_const) >> (IDX + 1)); \
  }                                                                 \
  c = vrsra_n_s32(a, b, (IDX + 1));                                 \
  CHECK_RESULT(validate_int32(c, _c[0], _c[1]))

  IMM_32_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrsra_n_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (const int64_t *)impl.test_cases_int_pointer1;
  const int64_t *_b = (const int64_t *)impl.test_cases_int_pointer2;
  const int element_num = 1;
  int64_t _c[element_num];
  int64x1_t a = vld1_s64(_a);
  int64x1_t b = vld1_s64(_b);
  int64x1_t c;
  int64_t round_const;

#define TEST_IMPL(IDX)                              \
  for (int i = 0; i < element_num; i++) {           \
    round_const = 1;                                \
    int64_t tmp = ((_b[i]) >> (IDX)) + round_const; \
    _c[i] = _a[i] + (tmp >> 1);                     \
  }                                                 \
  c = vrsra_n_s64(a, b, (IDX + 1));                 \
  CHECK_RESULT(validate_int64(c, _c[0]))

  IMM_64_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrsra_n_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (const uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (const uint8_t *)impl.test_cases_int_pointer2;
  const int element_num = 8;
  uint8_t _c[element_num];
  uint8x8_t a = vld1_u8(_a);
  uint8x8_t b = vld1_u8(_b);
  uint8x8_t c;
  uint8_t round_const;

#define TEST_IMPL(IDX)                                    \
  for (int i = 0; i < element_num; i++) {                 \
    round_const = 1 << ((IDX + 1) - 1);                   \
    _c[i] = _a[i] + ((_b[i] + round_const) >> (IDX + 1)); \
  }                                                       \
  c = vrsra_n_u8(a, b, (IDX + 1));                        \
  CHECK_RESULT(validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]))

  IMM_8_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrsra_n_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (const uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (const uint16_t *)impl.test_cases_int_pointer2;
  const int element_num = 4;
  uint16_t _c[element_num];
  uint16x4_t a = vld1_u16(_a);
  uint16x4_t b = vld1_u16(_b);
  uint16x4_t c;
  uint16_t round_const;

#define TEST_IMPL(IDX)                                    \
  for (int i = 0; i < element_num; i++) {                 \
    round_const = 1 << ((IDX + 1) - 1);                   \
    _c[i] = _a[i] + ((_b[i] + round_const) >> (IDX + 1)); \
  }                                                       \
  c = vrsra_n_u16(a, b, (IDX + 1));                       \
  CHECK_RESULT(validate_uint16(c, _c[0], _c[1], _c[2], _c[3]))

  IMM_16_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrsra_n_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (const uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (const uint32_t *)impl.test_cases_int_pointer2;
  const int element_num = 2;
  uint32_t _c[element_num];
  uint32x2_t a = vld1_u32(_a);
  uint32x2_t b = vld1_u32(_b);
  uint32x2_t c;
  uint32_t round_const;

#define TEST_IMPL(IDX)                                              \
  for (int i = 0; i < element_num; i++) {                           \
    round_const = 1 << ((IDX + 1) - 1);                             \
    _c[i] = _a[i] + (((uint64_t)_b[i] + round_const) >> (IDX + 1)); \
  }                                                                 \
  c = vrsra_n_u32(a, b, (IDX + 1));                                 \
  CHECK_RESULT(validate_uint32(c, _c[0], _c[1]))

  IMM_32_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrsra_n_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (const uint64_t *)impl.test_cases_int_pointer1;
  const uint64_t *_b = (const uint64_t *)impl.test_cases_int_pointer2;
  const int element_num = 1;
  uint64_t _c[element_num];
  uint64x1_t a = vld1_u64(_a);
  uint64x1_t b = vld1_u64(_b);
  uint64x1_t c;
  uint64_t round_const;

#define TEST_IMPL(IDX)                               \
  for (int i = 0; i < element_num; i++) {            \
    round_const = 1;                                 \
    uint64_t tmp = ((_b[i]) >> (IDX)) + round_const; \
    _c[i] = _a[i] + (tmp >> 1);                      \
  }                                                  \
  c = vrsra_n_u64(a, b, (IDX + 1));                  \
  CHECK_RESULT(validate_uint64(c, _c[0]))

  IMM_64_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrsraq_n_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (const int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (const int8_t *)impl.test_cases_int_pointer2;
  const int element_num = 16;
  int8_t _c[element_num];
  int8x16_t a = vld1q_s8(_a);
  int8x16_t b = vld1q_s8(_b);
  int8x16_t c;
  uint8_t round_const;

#define TEST_IMPL(IDX)                                                                                                \
  for (int i = 0; i < element_num; i++) {                                                                             \
    round_const = 1 << ((IDX + 1) - 1);                                                                               \
    _c[i] = _a[i] + ((_b[i] + round_const) >> (IDX + 1));                                                             \
  }                                                                                                                   \
  c = vrsraq_n_s8(a, b, (IDX + 1));                                                                                   \
  CHECK_RESULT(validate_int8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7], _c[8], _c[9], _c[10], _c[11], \
                             _c[12], _c[13], _c[14], _c[15]))

  IMM_8_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrsraq_n_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (const int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (const int16_t *)impl.test_cases_int_pointer2;
  const int element_num = 8;
  int16_t _c[element_num];
  int16x8_t a = vld1q_s16(_a);
  int16x8_t b = vld1q_s16(_b);
  int16x8_t c;
  uint16_t round_const;

#define TEST_IMPL(IDX)                                    \
  for (int i = 0; i < element_num; i++) {                 \
    round_const = 1 << ((IDX + 1) - 1);                   \
    _c[i] = _a[i] + ((_b[i] + round_const) >> (IDX + 1)); \
  }                                                       \
  c = vrsraq_n_s16(a, b, (IDX + 1));                      \
  CHECK_RESULT(validate_int16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]))

  IMM_16_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrsraq_n_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (const int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (const int32_t *)impl.test_cases_int_pointer2;
  const int element_num = 4;
  int32_t _c[element_num];
  int32x4_t a = vld1q_s32(_a);
  int32x4_t b = vld1q_s32(_b);
  int32x4_t c;
  uint32_t round_const;

#define TEST_IMPL(IDX)                                              \
  for (int i = 0; i < element_num; i++) {                           \
    round_const = 1 << ((IDX + 1) - 1);                             \
    _c[i] = _a[i] + (((uint64_t)_b[i] + round_const) >> (IDX + 1)); \
  }                                                                 \
  c = vrsraq_n_s32(a, b, (IDX + 1));                                \
  CHECK_RESULT(validate_int32(c, _c[0], _c[1], _c[2], _c[3]))

  IMM_32_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrsraq_n_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (const int64_t *)impl.test_cases_int_pointer1;
  const int64_t *_b = (const int64_t *)impl.test_cases_int_pointer2;
  const int element_num = 2;
  int64_t _c[element_num];
  int64x2_t a = vld1q_s64(_a);
  int64x2_t b = vld1q_s64(_b);
  int64x2_t c;
  int64_t round_const;

#define TEST_IMPL(IDX)                              \
  for (int i = 0; i < element_num; i++) {           \
    round_const = 1;                                \
    int64_t tmp = ((_b[i]) >> (IDX)) + round_const; \
    _c[i] = _a[i] + (tmp >> 1);                     \
  }                                                 \
  c = vrsraq_n_s64(a, b, (IDX + 1));                \
  CHECK_RESULT(validate_int64(c, _c[0], _c[1]))

  IMM_64_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrsraq_n_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (const uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (const uint8_t *)impl.test_cases_int_pointer2;
  const int element_num = 16;
  uint8_t _c[element_num];
  uint8x16_t a = vld1q_u8(_a);
  uint8x16_t b = vld1q_u8(_b);
  uint8x16_t c;
  uint8_t round_const;

#define TEST_IMPL(IDX)                                                                                                 \
  for (int i = 0; i < element_num; i++) {                                                                              \
    round_const = 1 << ((IDX + 1) - 1);                                                                                \
    _c[i] = _a[i] + ((_b[i] + round_const) >> (IDX + 1));                                                              \
  }                                                                                                                    \
  c = vrsraq_n_u8(a, b, (IDX + 1));                                                                                    \
  CHECK_RESULT(validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7], _c[8], _c[9], _c[10], _c[11], \
                              _c[12], _c[13], _c[14], _c[15]))

  IMM_8_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrsraq_n_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (const uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (const uint16_t *)impl.test_cases_int_pointer2;
  const int element_num = 8;
  uint16_t _c[element_num];
  uint16x8_t a = vld1q_u16(_a);
  uint16x8_t b = vld1q_u16(_b);
  uint16x8_t c;
  uint16_t round_const;

#define TEST_IMPL(IDX)                                    \
  for (int i = 0; i < element_num; i++) {                 \
    round_const = 1 << ((IDX + 1) - 1);                   \
    _c[i] = _a[i] + ((_b[i] + round_const) >> (IDX + 1)); \
  }                                                       \
  c = vrsraq_n_u16(a, b, (IDX + 1));                      \
  CHECK_RESULT(validate_uint16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]))

  IMM_16_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrsraq_n_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (const uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (const uint32_t *)impl.test_cases_int_pointer2;
  const int element_num = 4;
  uint32_t _c[element_num];
  uint32x4_t a = vld1q_u32(_a);
  uint32x4_t b = vld1q_u32(_b);
  uint32x4_t c;
  uint32_t round_const;

#define TEST_IMPL(IDX)                                              \
  for (int i = 0; i < element_num; i++) {                           \
    round_const = 1 << ((IDX + 1) - 1);                             \
    _c[i] = _a[i] + (((uint64_t)_b[i] + round_const) >> (IDX + 1)); \
  }                                                                 \
  c = vrsraq_n_u32(a, b, (IDX + 1));                                \
  CHECK_RESULT(validate_uint32(c, _c[0], _c[1], _c[2], _c[3]))

  IMM_32_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrsraq_n_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (const uint64_t *)impl.test_cases_int_pointer1;
  const uint64_t *_b = (const uint64_t *)impl.test_cases_int_pointer2;
  const int element_num = 2;
  uint64_t _c[element_num];
  uint64x2_t a = vld1q_u64(_a);
  uint64x2_t b = vld1q_u64(_b);
  uint64x2_t c;
  uint64_t round_const;

#define TEST_IMPL(IDX)                               \
  for (int i = 0; i < element_num; i++) {            \
    round_const = 1;                                 \
    uint64_t tmp = ((_b[i]) >> (IDX)) + round_const; \
    _c[i] = _a[i] + (tmp >> 1);                      \
  }                                                  \
  c = vrsraq_n_u64(a, b, (IDX + 1));                 \
  CHECK_RESULT(validate_uint64(c, _c[0], _c[1]))

  IMM_64_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrsrad_n_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrsrad_n_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vsri_n_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (const int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (const int8_t *)impl.test_cases_int_pointer2;
  int8_t _c[8];
  int8x8_t a = vld1_s8(_a);
  int8x8_t b = vld1_s8(_b);
  int8x8_t c;

#define TEST_IMPL(IDX)                                   \
  for (int i = 0; i < 8; i++) {                          \
    int idx = (IDX + 1);                                 \
    if (idx == 8) {                                      \
      uint8_t mask = 0;                                  \
      _c[i] = (_a[i] & ~mask) | (0 & mask);              \
    } else {                                             \
      uint8_t mask = UINT8_MAX >> idx;                   \
      _c[i] = (_a[i] & ~mask) | ((_b[i] >> idx) & mask); \
    }                                                    \
  }                                                      \
  c = vsri_n_s8(a, b, (IDX + 1));                        \
  CHECK_RESULT(validate_int8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]))

  IMM_8_ITER

#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsri_n_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (const int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (const int16_t *)impl.test_cases_int_pointer2;
  int16_t _c[4];
  int16x4_t a = vld1_s16(_a);
  int16x4_t b = vld1_s16(_b);
  int16x4_t c;

#define TEST_IMPL(IDX)                                   \
  for (int i = 0; i < 4; i++) {                          \
    int idx = (IDX + 1);                                 \
    if (idx == 16) {                                     \
      uint16_t mask = 0;                                 \
      _c[i] = (_a[i] & ~mask) | (0 & mask);              \
    } else {                                             \
      uint16_t mask = UINT16_MAX >> idx;                 \
      _c[i] = (_a[i] & ~mask) | ((_b[i] >> idx) & mask); \
    }                                                    \
  }                                                      \
  c = vsri_n_s16(a, b, (IDX + 1));                       \
  CHECK_RESULT(validate_int16(c, _c[0], _c[1], _c[2], _c[3]))

  IMM_16_ITER

#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsri_n_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (const int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (const int32_t *)impl.test_cases_int_pointer2;
  int32_t _c[2];
  int32x2_t a = vld1_s32(_a);
  int32x2_t b = vld1_s32(_b);
  int32x2_t c;

#define TEST_IMPL(IDX)                                   \
  for (int i = 0; i < 2; i++) {                          \
    int idx = (IDX + 1);                                 \
    if (idx == 32) {                                     \
      uint32_t mask = 0;                                 \
      _c[i] = (_a[i] & ~mask) | (0 & mask);              \
    } else {                                             \
      uint32_t mask = UINT32_MAX >> idx;                 \
      _c[i] = (_a[i] & ~mask) | ((_b[i] >> idx) & mask); \
    }                                                    \
  }                                                      \
  c = vsri_n_s32(a, b, (IDX + 1));                       \
  CHECK_RESULT(validate_int32(c, _c[0], _c[1]))

  IMM_32_ITER

#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsri_n_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (const int64_t *)impl.test_cases_int_pointer1;
  const int64_t *_b = (const int64_t *)impl.test_cases_int_pointer2;
  int64_t _c[1];
  int64x1_t a = vld1_s64(_a);
  int64x1_t b = vld1_s64(_b);
  int64x1_t c;

#define TEST_IMPL(IDX)                                   \
  for (int i = 0; i < 1; i++) {                          \
    int idx = (IDX + 1);                                 \
    if (idx == 64) {                                     \
      uint64_t mask = 0;                                 \
      _c[i] = (_a[i] & ~mask) | (0 & mask);              \
    } else {                                             \
      uint64_t mask = UINT64_MAX >> idx;                 \
      _c[i] = (_a[i] & ~mask) | ((_b[i] >> idx) & mask); \
    }                                                    \
  }                                                      \
  c = vsri_n_s64(a, b, (IDX + 1));                       \
  CHECK_RESULT(validate_int64(c, _c[0]))

  IMM_64_ITER

#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsri_n_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (const uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (const uint8_t *)impl.test_cases_int_pointer2;
  uint8_t _c[8];
  uint8x8_t a = vld1_u8(_a);
  uint8x8_t b = vld1_u8(_b);
  uint8x8_t c;

#define TEST_IMPL(IDX)                                   \
  for (int i = 0; i < 8; i++) {                          \
    int idx = (IDX + 1);                                 \
    if (idx == 8) {                                      \
      uint8_t mask = 0;                                  \
      _c[i] = (_a[i] & ~mask) | (0 & mask);              \
    } else {                                             \
      uint8_t mask = UINT8_MAX >> idx;                   \
      _c[i] = (_a[i] & ~mask) | ((_b[i] >> idx) & mask); \
    }                                                    \
  }                                                      \
  c = vsri_n_u8(a, b, (IDX + 1));                        \
  CHECK_RESULT(validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]))

  IMM_8_ITER

#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsri_n_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (const uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (const uint16_t *)impl.test_cases_int_pointer2;
  uint16_t _c[4];
  uint16x4_t a = vld1_u16(_a);
  uint16x4_t b = vld1_u16(_b);
  uint16x4_t c;

#define TEST_IMPL(IDX)                                   \
  for (int i = 0; i < 4; i++) {                          \
    int idx = (IDX + 1);                                 \
    if (idx == 16) {                                     \
      uint16_t mask = 0;                                 \
      _c[i] = (_a[i] & ~mask) | (0 & mask);              \
    } else {                                             \
      uint16_t mask = UINT16_MAX >> idx;                 \
      _c[i] = (_a[i] & ~mask) | ((_b[i] >> idx) & mask); \
    }                                                    \
  }                                                      \
  c = vsri_n_u16(a, b, (IDX + 1));                       \
  CHECK_RESULT(validate_uint16(c, _c[0], _c[1], _c[2], _c[3]))

  IMM_16_ITER

#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsri_n_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (const uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (const uint32_t *)impl.test_cases_int_pointer2;
  uint32_t _c[2];
  uint32x2_t a = vld1_u32(_a);
  uint32x2_t b = vld1_u32(_b);
  uint32x2_t c;

#define TEST_IMPL(IDX)                                   \
  for (int i = 0; i < 2; i++) {                          \
    int idx = (IDX + 1);                                 \
    if (idx == 32) {                                     \
      uint32_t mask = 0;                                 \
      _c[i] = (_a[i] & ~mask) | (0 & mask);              \
    } else {                                             \
      uint32_t mask = (uint64_t)UINT32_MAX >> idx;       \
      _c[i] = (_a[i] & ~mask) | ((_b[i] >> idx) & mask); \
    }                                                    \
  }                                                      \
  c = vsri_n_u32(a, b, (IDX + 1));                       \
  CHECK_RESULT(validate_uint32(c, _c[0], _c[1]))

  IMM_32_ITER

#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsri_n_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (const uint64_t *)impl.test_cases_int_pointer1;
  const uint64_t *_b = (const uint64_t *)impl.test_cases_int_pointer2;
  uint64_t _c[1];
  uint64x1_t a = vld1_u64(_a);
  uint64x1_t b = vld1_u64(_b);
  uint64x1_t c;

#define TEST_IMPL(IDX)                                   \
  for (int i = 0; i < 1; i++) {                          \
    int idx = (IDX + 1);                                 \
    if (idx == 64) {                                     \
      uint64_t mask = 0;                                 \
      _c[i] = (_a[i] & ~mask) | (0 & mask);              \
    } else {                                             \
      uint64_t mask = UINT64_MAX >> idx;                 \
      _c[i] = (_a[i] & ~mask) | ((_b[i] >> idx) & mask); \
    }                                                    \
  }                                                      \
  c = vsri_n_u64(a, b, (IDX + 1));                       \
  CHECK_RESULT(validate_uint64(c, _c[0]))

  IMM_64_ITER

#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsriq_n_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (const int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (const int8_t *)impl.test_cases_int_pointer2;
  int8_t _c[16];
  int8x16_t a = vld1q_s8(_a);
  int8x16_t b = vld1q_s8(_b);
  int8x16_t c;

#define TEST_IMPL(IDX)                                                                                                \
  for (int i = 0; i < 16; i++) {                                                                                      \
    int idx = (IDX + 1);                                                                                              \
    if (idx == 8) {                                                                                                   \
      uint8_t mask = 0;                                                                                               \
      _c[i] = (_a[i] & ~mask) | (0 & mask);                                                                           \
    } else {                                                                                                          \
      uint8_t mask = UINT8_MAX >> idx;                                                                                \
      _c[i] = (_a[i] & ~mask) | ((_b[i] >> idx) & mask);                                                              \
    }                                                                                                                 \
  }                                                                                                                   \
  c = vsriq_n_s8(a, b, (IDX + 1));                                                                                    \
  CHECK_RESULT(validate_int8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7], _c[8], _c[9], _c[10], _c[11], \
                             _c[12], _c[13], _c[14], _c[15]))

  IMM_8_ITER

#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsriq_n_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (const int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (const int16_t *)impl.test_cases_int_pointer2;
  int16_t _c[8];
  int16x8_t a = vld1q_s16(_a);
  int16x8_t b = vld1q_s16(_b);
  int16x8_t c;

#define TEST_IMPL(IDX)                                   \
  for (int i = 0; i < 8; i++) {                          \
    int idx = (IDX + 1);                                 \
    if (idx == 16) {                                     \
      uint16_t mask = 0;                                 \
      _c[i] = (_a[i] & ~mask) | (0 & mask);              \
    } else {                                             \
      uint16_t mask = UINT16_MAX >> idx;                 \
      _c[i] = (_a[i] & ~mask) | ((_b[i] >> idx) & mask); \
    }                                                    \
  }                                                      \
  c = vsriq_n_s16(a, b, (IDX + 1));                      \
  CHECK_RESULT(validate_int16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]))

  IMM_16_ITER

#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsriq_n_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (const int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (const int32_t *)impl.test_cases_int_pointer2;
  int32_t _c[4];
  int32x4_t a = vld1q_s32(_a);
  int32x4_t b = vld1q_s32(_b);
  int32x4_t c;

#define TEST_IMPL(IDX)                                   \
  for (int i = 0; i < 4; i++) {                          \
    int idx = (IDX + 1);                                 \
    if (idx == 32) {                                     \
      uint32_t mask = 0;                                 \
      _c[i] = (_a[i] & ~mask) | (0 & mask);              \
    } else {                                             \
      uint32_t mask = UINT32_MAX >> idx;                 \
      _c[i] = (_a[i] & ~mask) | ((_b[i] >> idx) & mask); \
    }                                                    \
  }                                                      \
  c = vsriq_n_s32(a, b, (IDX + 1));                      \
  CHECK_RESULT(validate_int32(c, _c[0], _c[1], _c[2], _c[3]))

  IMM_32_ITER

#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsriq_n_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (const int64_t *)impl.test_cases_int_pointer1;
  const int64_t *_b = (const int64_t *)impl.test_cases_int_pointer2;
  int64_t _c[2];
  int64x2_t a = vld1q_s64(_a);
  int64x2_t b = vld1q_s64(_b);
  int64x2_t c;

#define TEST_IMPL(IDX)                                   \
  for (int i = 0; i < 2; i++) {                          \
    int idx = (IDX + 1);                                 \
    if (idx == 64) {                                     \
      uint64_t mask = 0;                                 \
      _c[i] = (_a[i] & ~mask) | (0 & mask);              \
    } else {                                             \
      uint64_t mask = UINT64_MAX >> idx;                 \
      _c[i] = (_a[i] & ~mask) | ((_b[i] >> idx) & mask); \
    }                                                    \
  }                                                      \
  c = vsriq_n_s64(a, b, (IDX + 1));                      \
  CHECK_RESULT(validate_int64(c, _c[0], _c[1]))

  IMM_64_ITER

#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsriq_n_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (const uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (const uint8_t *)impl.test_cases_int_pointer2;
  uint8_t _c[16];
  uint8x16_t a = vld1q_u8(_a);
  uint8x16_t b = vld1q_u8(_b);
  uint8x16_t c;

#define TEST_IMPL(IDX)                                                                                                 \
  for (int i = 0; i < 16; i++) {                                                                                       \
    int idx = (IDX + 1);                                                                                               \
    if (idx == 8) {                                                                                                    \
      uint8_t mask = 0;                                                                                                \
      _c[i] = (_a[i] & ~mask) | (0 & mask);                                                                            \
    } else {                                                                                                           \
      uint8_t mask = UINT8_MAX >> idx;                                                                                 \
      _c[i] = (_a[i] & ~mask) | ((_b[i] >> idx) & mask);                                                               \
    }                                                                                                                  \
  }                                                                                                                    \
  c = vsriq_n_u8(a, b, (IDX + 1));                                                                                     \
  CHECK_RESULT(validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7], _c[8], _c[9], _c[10], _c[11], \
                              _c[12], _c[13], _c[14], _c[15]))

  IMM_8_ITER

#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsriq_n_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (const uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (const uint16_t *)impl.test_cases_int_pointer2;
  uint16_t _c[8];
  uint16x8_t a = vld1q_u16(_a);
  uint16x8_t b = vld1q_u16(_b);
  uint16x8_t c;

#define TEST_IMPL(IDX)                                   \
  for (int i = 0; i < 8; i++) {                          \
    int idx = (IDX + 1);                                 \
    if (idx == 16) {                                     \
      uint16_t mask = 0;                                 \
      _c[i] = (_a[i] & ~mask) | (0 & mask);              \
    } else {                                             \
      uint16_t mask = UINT16_MAX >> idx;                 \
      _c[i] = (_a[i] & ~mask) | ((_b[i] >> idx) & mask); \
    }                                                    \
  }                                                      \
  c = vsriq_n_u16(a, b, (IDX + 1));                      \
  CHECK_RESULT(validate_uint16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]))

  IMM_16_ITER

#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsriq_n_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (const uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (const uint32_t *)impl.test_cases_int_pointer2;
  uint32_t _c[4];
  uint32x4_t a = vld1q_u32(_a);
  uint32x4_t b = vld1q_u32(_b);
  uint32x4_t c;

#define TEST_IMPL(IDX)                                   \
  for (int i = 0; i < 4; i++) {                          \
    int idx = (IDX + 1);                                 \
    if (idx == 32) {                                     \
      uint32_t mask = 0;                                 \
      _c[i] = (_a[i] & ~mask) | (0 & mask);              \
    } else {                                             \
      uint32_t mask = UINT32_MAX >> idx;                 \
      _c[i] = (_a[i] & ~mask) | ((_b[i] >> idx) & mask); \
    }                                                    \
  }                                                      \
  c = vsriq_n_u32(a, b, (IDX + 1));                      \
  CHECK_RESULT(validate_uint32(c, _c[0], _c[1], _c[2], _c[3]))

  IMM_32_ITER

#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsriq_n_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (const uint64_t *)impl.test_cases_int_pointer1;
  const uint64_t *_b = (const uint64_t *)impl.test_cases_int_pointer2;
  uint64_t _c[2];
  uint64x2_t a = vld1q_u64(_a);
  uint64x2_t b = vld1q_u64(_b);
  uint64x2_t c;

#define TEST_IMPL(IDX)                                   \
  for (int i = 0; i < 2; i++) {                          \
    int idx = (IDX + 1);                                 \
    if (idx == 64) {                                     \
      uint64_t mask = 0;                                 \
      _c[i] = (_a[i] & ~mask) | (0 & mask);              \
    } else {                                             \
      uint64_t mask = UINT64_MAX >> idx;                 \
      _c[i] = (_a[i] & ~mask) | ((_b[i] >> idx) & mask); \
    }                                                    \
  }                                                      \
  c = vsriq_n_u64(a, b, (IDX + 1));                      \
  CHECK_RESULT(validate_uint64(c, _c[0], _c[1]))

  IMM_64_ITER

#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsri_n_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vsriq_n_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vsri_n_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vsriq_n_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vsri_n_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vsriq_n_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vsrid_n_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vsrid_n_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vsli_n_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (const int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (const int8_t *)impl.test_cases_int_pointer2;
  int8_t _c[8];
  int8x8_t a = vld1_s8(_a);
  int8x8_t b = vld1_s8(_b);
  int8x8_t c;

#define TEST_IMPL(IDX)                                   \
  for (int i = 0; i < 8; i++) {                          \
    int idx = IDX;                                       \
    if (idx == 8) {                                      \
      uint8_t mask = 0;                                  \
      _c[i] = (_a[i] & ~mask) | (0 & mask);              \
    } else {                                             \
      uint8_t mask = (uint8_t)(UINT8_MAX << idx);        \
      _c[i] = (_a[i] & ~mask) | ((_b[i] << idx) & mask); \
    }                                                    \
  }                                                      \
  c = vsli_n_s8(a, b, IDX);                              \
  CHECK_RESULT(validate_int8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]))

  IMM_8_ITER

#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsli_n_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (const int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (const int16_t *)impl.test_cases_int_pointer2;
  int16_t _c[4];
  int16x4_t a = vld1_s16(_a);
  int16x4_t b = vld1_s16(_b);
  int16x4_t c;

#define TEST_IMPL(IDX)                                   \
  for (int i = 0; i < 4; i++) {                          \
    int idx = IDX;                                       \
    if (idx == 16) {                                     \
      uint16_t mask = 0;                                 \
      _c[i] = (_a[i] & ~mask) | (0 & mask);              \
    } else {                                             \
      uint16_t mask = (uint16_t)(UINT16_MAX << idx);     \
      _c[i] = (_a[i] & ~mask) | ((_b[i] << idx) & mask); \
    }                                                    \
  }                                                      \
  c = vsli_n_s16(a, b, IDX);                             \
  CHECK_RESULT(validate_int16(c, _c[0], _c[1], _c[2], _c[3]))

  IMM_16_ITER

#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsli_n_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (const int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (const int32_t *)impl.test_cases_int_pointer2;
  int32_t _c[2];
  int32x2_t a = vld1_s32(_a);
  int32x2_t b = vld1_s32(_b);
  int32x2_t c;

#define TEST_IMPL(IDX)                                   \
  for (int i = 0; i < 2; i++) {                          \
    int idx = IDX;                                       \
    if (idx == 32) {                                     \
      uint32_t mask = 0;                                 \
      _c[i] = (_a[i] & ~mask) | (0 & mask);              \
    } else {                                             \
      uint32_t mask = (uint32_t)(UINT32_MAX << idx);     \
      _c[i] = (_a[i] & ~mask) | ((_b[i] << idx) & mask); \
    }                                                    \
  }                                                      \
  c = vsli_n_s32(a, b, IDX);                             \
  CHECK_RESULT(validate_int32(c, _c[0], _c[1]))

  IMM_32_ITER

#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsli_n_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (const int64_t *)impl.test_cases_int_pointer1;
  const int64_t *_b = (const int64_t *)impl.test_cases_int_pointer2;
  int64_t _c[1];
  int64x1_t a = vld1_s64(_a);
  int64x1_t b = vld1_s64(_b);
  int64x1_t c;

#define TEST_IMPL(IDX)                                   \
  for (int i = 0; i < 1; i++) {                          \
    int idx = IDX;                                       \
    if (idx == 64) {                                     \
      uint64_t mask = 0;                                 \
      _c[i] = (_a[i] & ~mask) | (0 & mask);              \
    } else {                                             \
      uint64_t mask = (uint64_t)(UINT64_MAX << idx);     \
      _c[i] = (_a[i] & ~mask) | ((_b[i] << idx) & mask); \
    }                                                    \
  }                                                      \
  c = vsli_n_s64(a, b, IDX);                             \
  CHECK_RESULT(validate_int64(c, _c[0]))

  IMM_64_ITER

#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsli_n_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (const uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (const uint8_t *)impl.test_cases_int_pointer2;
  uint8_t _c[8];
  uint8x8_t a = vld1_u8(_a);
  uint8x8_t b = vld1_u8(_b);
  uint8x8_t c;

#define TEST_IMPL(IDX)                                   \
  for (int i = 0; i < 8; i++) {                          \
    int idx = IDX;                                       \
    if (idx == 8) {                                      \
      uint8_t mask = 0;                                  \
      _c[i] = (_a[i] & ~mask) | (0 & mask);              \
    } else {                                             \
      uint8_t mask = (uint8_t)(UINT8_MAX << idx);        \
      _c[i] = (_a[i] & ~mask) | ((_b[i] << idx) & mask); \
    }                                                    \
  }                                                      \
  c = vsli_n_u8(a, b, IDX);                              \
  CHECK_RESULT(validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]))

  IMM_8_ITER

#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsli_n_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (const uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (const uint16_t *)impl.test_cases_int_pointer2;
  uint16_t _c[4];
  uint16x4_t a = vld1_u16(_a);
  uint16x4_t b = vld1_u16(_b);
  uint16x4_t c;

#define TEST_IMPL(IDX)                                   \
  for (int i = 0; i < 4; i++) {                          \
    int idx = IDX;                                       \
    if (idx == 16) {                                     \
      uint16_t mask = 0;                                 \
      _c[i] = (_a[i] & ~mask) | (0 & mask);              \
    } else {                                             \
      uint16_t mask = (uint16_t)(UINT16_MAX << idx);     \
      _c[i] = (_a[i] & ~mask) | ((_b[i] << idx) & mask); \
    }                                                    \
  }                                                      \
  c = vsli_n_u16(a, b, IDX);                             \
  CHECK_RESULT(validate_uint16(c, _c[0], _c[1], _c[2], _c[3]))

  IMM_16_ITER

#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsli_n_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (const uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (const uint32_t *)impl.test_cases_int_pointer2;
  uint32_t _c[2];
  uint32x2_t a = vld1_u32(_a);
  uint32x2_t b = vld1_u32(_b);
  uint32x2_t c;

#define TEST_IMPL(IDX)                                   \
  for (int i = 0; i < 2; i++) {                          \
    int idx = IDX;                                       \
    if (idx == 32) {                                     \
      uint32_t mask = 0;                                 \
      _c[i] = (_a[i] & ~mask) | (0 & mask);              \
    } else {                                             \
      uint32_t mask = (uint32_t)(UINT32_MAX << idx);     \
      _c[i] = (_a[i] & ~mask) | ((_b[i] << idx) & mask); \
    }                                                    \
  }                                                      \
  c = vsli_n_u32(a, b, IDX);                             \
  CHECK_RESULT(validate_uint32(c, _c[0], _c[1]))

  IMM_32_ITER

#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsli_n_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (const uint64_t *)impl.test_cases_int_pointer1;
  const uint64_t *_b = (const uint64_t *)impl.test_cases_int_pointer2;
  uint64_t _c[1];
  uint64x1_t a = vld1_u64(_a);
  uint64x1_t b = vld1_u64(_b);
  uint64x1_t c;

#define TEST_IMPL(IDX)                                   \
  for (int i = 0; i < 1; i++) {                          \
    int idx = IDX;                                       \
    if (idx == 64) {                                     \
      uint64_t mask = 0;                                 \
      _c[i] = (_a[i] & ~mask) | (0 & mask);              \
    } else {                                             \
      uint64_t mask = (uint64_t)(UINT64_MAX << idx);     \
      _c[i] = (_a[i] & ~mask) | ((_b[i] << idx) & mask); \
    }                                                    \
  }                                                      \
  c = vsli_n_u64(a, b, IDX);                             \
  CHECK_RESULT(validate_uint64(c, _c[0]))

  IMM_64_ITER

#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsliq_n_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (const int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (const int8_t *)impl.test_cases_int_pointer2;
  int8_t _c[16];
  int8x16_t a = vld1q_s8(_a);
  int8x16_t b = vld1q_s8(_b);
  int8x16_t c;

#define TEST_IMPL(IDX)                                                                                                \
  for (int i = 0; i < 16; i++) {                                                                                      \
    int idx = IDX;                                                                                                    \
    if (idx == 8) {                                                                                                   \
      uint8_t mask = 0;                                                                                               \
      _c[i] = (_a[i] & ~mask) | (0 & mask);                                                                           \
    } else {                                                                                                          \
      uint8_t mask = (uint8_t)(UINT8_MAX << idx);                                                                     \
      _c[i] = (_a[i] & ~mask) | ((_b[i] << idx) & mask);                                                              \
    }                                                                                                                 \
  }                                                                                                                   \
  c = vsliq_n_s8(a, b, IDX);                                                                                          \
  CHECK_RESULT(validate_int8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7], _c[8], _c[9], _c[10], _c[11], \
                             _c[12], _c[13], _c[14], _c[15]))

  IMM_8_ITER

#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsliq_n_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (const int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (const int16_t *)impl.test_cases_int_pointer2;
  int16_t _c[8];
  int16x8_t a = vld1q_s16(_a);
  int16x8_t b = vld1q_s16(_b);
  int16x8_t c;

#define TEST_IMPL(IDX)                                   \
  for (int i = 0; i < 8; i++) {                          \
    int idx = IDX;                                       \
    if (idx == 16) {                                     \
      uint16_t mask = 0;                                 \
      _c[i] = (_a[i] & ~mask) | (0 & mask);              \
    } else {                                             \
      uint16_t mask = (uint16_t)(UINT16_MAX << idx);     \
      _c[i] = (_a[i] & ~mask) | ((_b[i] << idx) & mask); \
    }                                                    \
  }                                                      \
  c = vsliq_n_s16(a, b, IDX);                            \
  CHECK_RESULT(validate_int16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]))

  IMM_16_ITER

#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsliq_n_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (const int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (const int32_t *)impl.test_cases_int_pointer2;
  int32_t _c[4];
  int32x4_t a = vld1q_s32(_a);
  int32x4_t b = vld1q_s32(_b);
  int32x4_t c;

#define TEST_IMPL(IDX)                                   \
  for (int i = 0; i < 4; i++) {                          \
    int idx = IDX;                                       \
    if (idx == 32) {                                     \
      uint32_t mask = 0;                                 \
      _c[i] = (_a[i] & ~mask) | (0 & mask);              \
    } else {                                             \
      uint32_t mask = (uint32_t)(UINT32_MAX << idx);     \
      _c[i] = (_a[i] & ~mask) | ((_b[i] << idx) & mask); \
    }                                                    \
  }                                                      \
  c = vsliq_n_s32(a, b, IDX);                            \
  CHECK_RESULT(validate_int32(c, _c[0], _c[1], _c[2], _c[3]))

  IMM_32_ITER

#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsliq_n_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (const int64_t *)impl.test_cases_int_pointer1;
  const int64_t *_b = (const int64_t *)impl.test_cases_int_pointer2;
  int64_t _c[2];
  int64x2_t a = vld1q_s64(_a);
  int64x2_t b = vld1q_s64(_b);
  int64x2_t c;

#define TEST_IMPL(IDX)                                   \
  for (int i = 0; i < 2; i++) {                          \
    int idx = IDX;                                       \
    if (idx == 64) {                                     \
      uint64_t mask = 0;                                 \
      _c[i] = (_a[i] & ~mask) | (0 & mask);              \
    } else {                                             \
      uint64_t mask = (uint64_t)(UINT64_MAX << idx);     \
      _c[i] = (_a[i] & ~mask) | ((_b[i] << idx) & mask); \
    }                                                    \
  }                                                      \
  c = vsliq_n_s64(a, b, IDX);                            \
  CHECK_RESULT(validate_int64(c, _c[0], _c[1]))

  IMM_64_ITER

#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsliq_n_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (const uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (const uint8_t *)impl.test_cases_int_pointer2;
  uint8_t _c[16];
  uint8x16_t a = vld1q_u8(_a);
  uint8x16_t b = vld1q_u8(_b);
  uint8x16_t c;

#define TEST_IMPL(IDX)                                                                                                 \
  for (int i = 0; i < 16; i++) {                                                                                       \
    int idx = IDX;                                                                                                     \
    if (idx == 8) {                                                                                                    \
      uint8_t mask = 0;                                                                                                \
      _c[i] = (_a[i] & ~mask) | (0 & mask);                                                                            \
    } else {                                                                                                           \
      uint8_t mask = (uint8_t)(UINT8_MAX << idx);                                                                      \
      _c[i] = (_a[i] & ~mask) | ((_b[i] << idx) & mask);                                                               \
    }                                                                                                                  \
  }                                                                                                                    \
  c = vsliq_n_u8(a, b, IDX);                                                                                           \
  CHECK_RESULT(validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7], _c[8], _c[9], _c[10], _c[11], \
                              _c[12], _c[13], _c[14], _c[15]))

  IMM_8_ITER

#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsliq_n_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (const uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (const uint16_t *)impl.test_cases_int_pointer2;
  uint16_t _c[8];
  uint16x8_t a = vld1q_u16(_a);
  uint16x8_t b = vld1q_u16(_b);
  uint16x8_t c;

#define TEST_IMPL(IDX)                                   \
  for (int i = 0; i < 8; i++) {                          \
    int idx = IDX;                                       \
    if (idx == 16) {                                     \
      uint16_t mask = 0;                                 \
      _c[i] = (_a[i] & ~mask) | (0 & mask);              \
    } else {                                             \
      uint16_t mask = (uint16_t)(UINT16_MAX << idx);     \
      _c[i] = (_a[i] & ~mask) | ((_b[i] << idx) & mask); \
    }                                                    \
  }                                                      \
  c = vsliq_n_u16(a, b, IDX);                            \
  CHECK_RESULT(validate_uint16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]))

  IMM_16_ITER

#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsliq_n_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (const uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (const uint32_t *)impl.test_cases_int_pointer2;
  uint32_t _c[4];
  uint32x4_t a = vld1q_u32(_a);
  uint32x4_t b = vld1q_u32(_b);
  uint32x4_t c;

#define TEST_IMPL(IDX)                                   \
  for (int i = 0; i < 4; i++) {                          \
    int idx = IDX;                                       \
    if (idx == 32) {                                     \
      uint32_t mask = 0;                                 \
      _c[i] = (_a[i] & ~mask) | (0 & mask);              \
    } else {                                             \
      uint32_t mask = (uint32_t)(UINT32_MAX << idx);     \
      _c[i] = (_a[i] & ~mask) | ((_b[i] << idx) & mask); \
    }                                                    \
  }                                                      \
  c = vsliq_n_u32(a, b, IDX);                            \
  CHECK_RESULT(validate_uint32(c, _c[0], _c[1], _c[2], _c[3]))

  IMM_32_ITER

#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsliq_n_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (const uint64_t *)impl.test_cases_int_pointer1;
  const uint64_t *_b = (const uint64_t *)impl.test_cases_int_pointer2;
  uint64_t _c[2];
  uint64x2_t a = vld1q_u64(_a);
  uint64x2_t b = vld1q_u64(_b);
  uint64x2_t c;

#define TEST_IMPL(IDX)                                   \
  for (int i = 0; i < 2; i++) {                          \
    int idx = IDX;                                       \
    if (idx == 64) {                                     \
      uint64_t mask = 0;                                 \
      _c[i] = (_a[i] & ~mask) | (0 & mask);              \
    } else {                                             \
      uint64_t mask = (uint64_t)(UINT64_MAX << idx);     \
      _c[i] = (_a[i] & ~mask) | ((_b[i] << idx) & mask); \
    }                                                    \
  }                                                      \
  c = vsliq_n_u64(a, b, IDX);                            \
  CHECK_RESULT(validate_uint64(c, _c[0], _c[1]))

  IMM_64_ITER

#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsli_n_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vsliq_n_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vsli_n_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vsliq_n_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vsli_n_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vsliq_n_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vslid_n_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vslid_n_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vneg_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (const int8_t *)impl.test_cases_int_pointer1;
  int8_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = -_a[i];
  }

  int8x8_t a = vld1_s8(_a);
  int8x8_t c = vneg_s8(a);
  return validate_int8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vneg_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (const int16_t *)impl.test_cases_int_pointer1;
  int16_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = -_a[i];
  }

  int16x4_t a = vld1_s16(_a);
  int16x4_t c = vneg_s16(a);
  return validate_int16(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vneg_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (const int32_t *)impl.test_cases_int_pointer1;
  int32_t _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = -_a[i];
  }

  int32x2_t a = vld1_s32(_a);
  int32x2_t c = vneg_s32(a);
  return validate_int32(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vneg_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (const float *)impl.test_cases_float_pointer1;
  float _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = -_a[i];
  }

  float32x2_t a = vld1_f32(_a);
  float32x2_t c = vneg_f32(a);
  return validate_float(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vnegq_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (const int8_t *)impl.test_cases_int_pointer1;
  int8_t _c[16];
  for (int i = 0; i < 16; i++) {
    _c[i] = -_a[i];
  }

  int8x16_t a = vld1q_s8(_a);
  int8x16_t c = vnegq_s8(a);
  return validate_int8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7], _c[8], _c[9], _c[10], _c[11], _c[12],
                       _c[13], _c[14], _c[15]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vnegq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (const int16_t *)impl.test_cases_int_pointer1;
  int16_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = -_a[i];
  }

  int16x8_t a = vld1q_s16(_a);
  int16x8_t c = vnegq_s16(a);
  return validate_int16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vnegq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (const int32_t *)impl.test_cases_int_pointer1;
  int32_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = -_a[i];
  }

  int32x4_t a = vld1q_s32(_a);
  int32x4_t c = vnegq_s32(a);
  return validate_int32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vnegq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (const float *)impl.test_cases_float_pointer1;
  float _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = -_a[i];
  }

  float32x4_t a = vld1q_f32(_a);
  float32x4_t c = vnegq_f32(a);
  return validate_float(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vneg_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vnegd_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vnegq_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vneg_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vnegq_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqneg_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (const int8_t *)impl.test_cases_int_pointer1;
  int8_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = saturate_int8(-(int16_t)_a[i]);
  }

  int8x8_t a = vld1_s8(_a);
  int8x8_t c = vqneg_s8(a);
  return validate_int8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqneg_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (const int16_t *)impl.test_cases_int_pointer1;
  int16_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = saturate_int16(-(int32_t)_a[i]);
  }

  int16x4_t a = vld1_s16(_a);
  int16x4_t c = vqneg_s16(a);
  return validate_int16(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqneg_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (const int32_t *)impl.test_cases_int_pointer1;
  int32_t _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = saturate_int32(-(int64_t)_a[i]);
  }

  int32x2_t a = vld1_s32(_a);
  int32x2_t c = vqneg_s32(a);
  return validate_int32(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqnegq_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (const int8_t *)impl.test_cases_int_pointer1;
  int8_t _c[16];
  for (int i = 0; i < 16; i++) {
    _c[i] = saturate_int8(-(int16_t)_a[i]);
  }

  int8x16_t a = vld1q_s8(_a);
  int8x16_t c = vqnegq_s8(a);
  return validate_int8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7], _c[8], _c[9], _c[10], _c[11], _c[12],
                       _c[13], _c[14], _c[15]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqnegq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (const int16_t *)impl.test_cases_int_pointer1;
  int16_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = saturate_int16(-(int32_t)_a[i]);
  }

  int16x8_t a = vld1q_s16(_a);
  int16x8_t c = vqnegq_s16(a);
  return validate_int16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqnegq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (const int32_t *)impl.test_cases_int_pointer1;
  int32_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = saturate_int32(-(int64_t)_a[i]);
  }

  int32x4_t a = vld1q_s32(_a);
  int32x4_t c = vqnegq_s32(a);
  return validate_int32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqneg_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqnegq_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqnegb_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqnegh_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqnegs_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqnegd_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmvn_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (const int8_t *)impl.test_cases_int_pointer1;
  int8_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = ~_a[i];
  }

  int8x8_t a = vld1_s8(_a);
  int8x8_t c = vmvn_s8(a);
  return validate_int8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmvn_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (const int16_t *)impl.test_cases_int_pointer1;
  int16_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = ~_a[i];
  }

  int16x4_t a = vld1_s16(_a);
  int16x4_t c = vmvn_s16(a);
  return validate_int16(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmvn_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (const int32_t *)impl.test_cases_int_pointer1;
  int32_t _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = ~_a[i];
  }

  int32x2_t a = vld1_s32(_a);
  int32x2_t c = vmvn_s32(a);
  return validate_int32(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmvn_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (const uint8_t *)impl.test_cases_int_pointer1;
  uint8_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = ~_a[i];
  }

  uint8x8_t a = vld1_u8(_a);
  uint8x8_t c = vmvn_u8(a);
  return validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmvn_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (const uint16_t *)impl.test_cases_int_pointer1;
  uint16_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = ~_a[i];
  }

  uint16x4_t a = vld1_u16(_a);
  uint16x4_t c = vmvn_u16(a);
  return validate_uint16(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmvn_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (const uint32_t *)impl.test_cases_int_pointer1;
  uint32_t _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = ~_a[i];
  }

  uint32x2_t a = vld1_u32(_a);
  uint32x2_t c = vmvn_u32(a);
  return validate_uint32(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmvnq_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (const int8_t *)impl.test_cases_int_pointer1;
  int8_t _c[16];
  for (int i = 0; i < 16; i++) {
    _c[i] = ~_a[i];
  }

  int8x16_t a = vld1q_s8(_a);
  int8x16_t c = vmvnq_s8(a);
  return validate_int8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7], _c[8], _c[9], _c[10], _c[11], _c[12],
                       _c[13], _c[14], _c[15]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmvnq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (const int16_t *)impl.test_cases_int_pointer1;
  int16_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = ~_a[i];
  }

  int16x8_t a = vld1q_s16(_a);
  int16x8_t c = vmvnq_s16(a);
  return validate_int16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmvnq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (const int32_t *)impl.test_cases_int_pointer1;
  int32_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = ~_a[i];
  }

  int32x4_t a = vld1q_s32(_a);
  int32x4_t c = vmvnq_s32(a);
  return validate_int32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmvnq_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (const uint8_t *)impl.test_cases_int_pointer1;
  uint8_t _c[16];
  for (int i = 0; i < 16; i++) {
    _c[i] = ~_a[i];
  }

  uint8x16_t a = vld1q_u8(_a);
  uint8x16_t c = vmvnq_u8(a);
  return validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7], _c[8], _c[9], _c[10], _c[11], _c[12],
                        _c[13], _c[14], _c[15]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmvnq_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (const uint16_t *)impl.test_cases_int_pointer1;
  uint16_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = ~_a[i];
  }

  uint16x8_t a = vld1q_u16(_a);
  uint16x8_t c = vmvnq_u16(a);
  return validate_uint16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmvnq_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (const uint32_t *)impl.test_cases_int_pointer1;
  uint32_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = ~_a[i];
  }

  uint32x4_t a = vld1q_u32(_a);
  uint32x4_t c = vmvnq_u32(a);
  return validate_uint32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmvn_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmvnq_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcls_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcls_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcls_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vclsq_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vclsq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vclsq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcls_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vclsq_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcls_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vclsq_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcls_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vclsq_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vclz_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (const int8_t *)impl.test_cases_int_pointer1;
  int8_t _c[8];
  for (int i = 0; i < 8; i++) {
    int sum = 0;
    for (int j = 7; j > -1; j--) {
      if (_a[i] & (0x1 << j)) {
        break;
      }
      sum++;
    }
    _c[i] = sum;
  }

  int8x8_t a = vld1_s8(_a);
  int8x8_t c = vclz_s8(a);
  return validate_int8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vclz_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vclz_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vclz_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vclz_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vclz_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vclzq_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vclzq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vclzq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vclzq_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vclzq_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vclzq_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcnt_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (const int8_t *)impl.test_cases_int_pointer1;
  int8_t _c[8];
  const int8_t bit_population_lookup[16] = {0, 1, 1, 2, 1, 2, 2, 3, 1, 2, 2, 3, 2, 3, 3, 4};
  for (int i = 0; i < 8; i++) {
    uint8_t byte = _a[i];
    _c[i] = bit_population_lookup[byte & 0x0F] + bit_population_lookup[byte >> 4];
  }
  int8x8_t a = vld1_s8(_a);
  int8x8_t c = vcnt_s8(a);
  return validate_int8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vcnt_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (const uint8_t *)impl.test_cases_int_pointer1;
  uint8_t _c[8];
  const uint8_t bit_population_lookup[16] = {0, 1, 1, 2, 1, 2, 2, 3, 1, 2, 2, 3, 2, 3, 3, 4};
  for (int i = 0; i < 8; i++) {
    uint8_t byte = _a[i];
    _c[i] = bit_population_lookup[byte & 0x0F] + bit_population_lookup[byte >> 4];
  }
  uint8x8_t a = vld1_u8(_a);
  uint8x8_t c = vcnt_u8(a);
  return validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vcntq_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (const int8_t *)impl.test_cases_int_pointer1;
  int8_t _c[16];
  const int8_t bit_population_lookup[16] = {0, 1, 1, 2, 1, 2, 2, 3, 1, 2, 2, 3, 2, 3, 3, 4};
  for (int i = 0; i < 16; i++) {
    uint8_t byte = _a[i];
    _c[i] = bit_population_lookup[byte & 0x0F] + bit_population_lookup[byte >> 4];
  }
  int8x16_t a = vld1q_s8(_a);
  int8x16_t c = vcntq_s8(a);
  return validate_int8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7], _c[8], _c[9], _c[10], _c[11], _c[12],
                       _c[13], _c[14], _c[15]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vcntq_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (const uint8_t *)impl.test_cases_int_pointer1;
  uint8_t _c[16];
  const uint8_t bit_population_lookup[16] = {0, 1, 1, 2, 1, 2, 2, 3, 1, 2, 2, 3, 2, 3, 3, 4};
  for (int i = 0; i < 16; i++) {
    uint8_t byte = _a[i];
    _c[i] = bit_population_lookup[byte & 0x0F] + bit_population_lookup[byte >> 4];
  }
  uint8x16_t a = vld1q_u8(_a);
  uint8x16_t c = vcntq_u8(a);
  return validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7], _c[8], _c[9], _c[10], _c[11], _c[12],
                        _c[13], _c[14], _c[15]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vcnt_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcntq_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrecpe_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = impl.test_cases_float_pointer1;
  float _c[2];
  _c[0] = 1.0f / _a[0];
  _c[1] = 1.0f / _a[1];

  float32x2_t a = vld1_f32(_a);
  float32x2_t c = vrecpe_f32(a);
  return validate_float_error(c, _c[0], _c[1], 0.01f);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrecpe_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
  const uint32_t *_a = (const uint32_t *)impl.test_cases_int_pointer1;
  uint32_t _c[2];
  const uint32_t sign_bit = 0x80000000;
  const uint32_t input_lower_bound = 0x80000000, input_upper_bound = UINT32_MAX;
  const uint32_t estimate_lower_bound = 0x80000000, estimate_upper_bound = 0xff800000;
  const uint32_t input_range = input_upper_bound - input_lower_bound;
  const uint32_t estimate_range = estimate_upper_bound - estimate_lower_bound;
  for (int i = 0; i < 2; i++) {
    if (!(_a[i] & sign_bit)) {
      _c[i] = UINT32_MAX;
    } else {
      uint32_t diff = UINT32_MAX - _a[i];
      _c[i] = (diff / (input_range) * (estimate_range) + estimate_lower_bound);
    }
  }

  uint32x2_t a = vld1_u32(_a);
  uint32x2_t c = vrecpe_u32(a);
  // print_u32_64("_a", _a);
  // print_u32_64("_c", _c);
  // print_u32_64("-c", c);
  return validate_uint32(c, _c[0], _c[1]);
}

result_t test_vrecpeq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = impl.test_cases_float_pointer1;
  float _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = 1.0f / _a[i];
  }

  float32x4_t a = vld1q_f32(_a);
  float32x4_t c = vrecpeq_f32(a);
  return validate_float_error(c, _c[0], _c[1], _c[2], _c[3], 0.01f);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrecpe_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrecpeq_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrecpes_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrecped_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrecpeq_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrsqrte_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = impl.test_cases_float_pointer1;
  float _c[2];
  _c[0] = 1 / sqrtf(_a[0]);
  _c[1] = 1 / sqrtf(_a[1]);

  float32x2_t a = vld1_f32(_a);
  float32x2_t c = vrsqrte_f32(a);
  return validate_float_error(c, _c[0], _c[1], 0.01f);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrsqrte_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrsqrteq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = impl.test_cases_float_pointer1;
  float _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = 1 / sqrtf(_a[i]);
  }

  float32x4_t a = vld1q_f32(_a);
  float32x4_t c = vrsqrteq_f32(a);
  return validate_float_error(c, _c[0], _c[1], _c[2], _c[3], 0.01f);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrsqrte_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrsqrteq_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrsqrtes_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrsqrted_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrsqrteq_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vget_lane_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  int8x8_t a = vld1_s8(_a);

#define TEST_IMPL(IDX)                   \
  if (vget_lane_s8(a, IDX) != _a[IDX]) { \
    return TEST_FAIL;                    \
  }

  IMM_8_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vget_lane_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  int16x4_t a = vld1_s16(_a);

#define TEST_IMPL(IDX)                    \
  if (vget_lane_s16(a, IDX) != _a[IDX]) { \
    return TEST_FAIL;                     \
  }

  IMM_4_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vget_lane_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  int32x2_t a = vld1_s32(_a);

#define TEST_IMPL(IDX)                    \
  if (vget_lane_s32(a, IDX) != _a[IDX]) { \
    return TEST_FAIL;                     \
  }

  IMM_2_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vget_lane_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (float *)impl.test_cases_float_pointer1;
  float32x2_t a = vld1_f32(_a);

#define TEST_IMPL(IDX)                    \
  if (vget_lane_f32(a, IDX) != _a[IDX]) { \
    return TEST_FAIL;                     \
  }

  IMM_2_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vget_lane_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vget_lane_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (uint8_t *)impl.test_cases_int_pointer1;
  uint8x8_t a = vld1_u8(_a);

#define TEST_IMPL(IDX)                   \
  if (vget_lane_u8(a, IDX) != _a[IDX]) { \
    return TEST_FAIL;                    \
  }

  IMM_8_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vget_lane_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  uint16x4_t a = vld1_u16(_a);

#define TEST_IMPL(IDX)                    \
  if (vget_lane_u16(a, IDX) != _a[IDX]) { \
    return TEST_FAIL;                     \
  }

  IMM_4_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vget_lane_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  uint32x2_t a = vld1_u32(_a);

#define TEST_IMPL(IDX)                    \
  if (vget_lane_u32(a, IDX) != _a[IDX]) { \
    return TEST_FAIL;                     \
  }

  IMM_2_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vget_lane_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (int64_t *)impl.test_cases_int_pointer1;
  int64x1_t a = vld1_s64(_a);

#define TEST_IMPL(IDX)                    \
  if (vget_lane_s64(a, IDX) != _a[IDX]) { \
    return TEST_FAIL;                     \
  }

  IMM_1_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vget_lane_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vget_lane_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vget_lane_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (uint64_t *)impl.test_cases_int_pointer1;
  uint64x1_t a = vld1_u64(_a);

#define TEST_IMPL(IDX)                    \
  if (vget_lane_u64(a, IDX) != _a[IDX]) { \
    return TEST_FAIL;                     \
  }

  IMM_1_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vget_lane_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vgetq_lane_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  int8x16_t a = vld1q_s8(_a);

#define TEST_IMPL(IDX)                    \
  if (vgetq_lane_s8(a, IDX) != _a[IDX]) { \
    return TEST_FAIL;                     \
  }

  IMM_16_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vgetq_lane_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  int16x8_t a = vld1q_s16(_a);

#define TEST_IMPL(IDX)                     \
  if (vgetq_lane_s16(a, IDX) != _a[IDX]) { \
    return TEST_FAIL;                      \
  }

  IMM_8_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vgetq_lane_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  int32x4_t a = vld1q_s32(_a);

#define TEST_IMPL(IDX)                     \
  if (vgetq_lane_s32(a, IDX) != _a[IDX]) { \
    return TEST_FAIL;                      \
  }

  IMM_4_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vgetq_lane_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (float *)impl.test_cases_float_pointer1;
  float32x4_t a = vld1q_f32(_a);

#define TEST_IMPL(IDX)                     \
  if (vgetq_lane_f32(a, IDX) != _a[IDX]) { \
    return TEST_FAIL;                      \
  }

  IMM_4_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vgetq_lane_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vgetq_lane_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (uint8_t *)impl.test_cases_int_pointer1;
  uint8x16_t a = vld1q_u8(_a);

#define TEST_IMPL(IDX)                    \
  if (vgetq_lane_u8(a, IDX) != _a[IDX]) { \
    return TEST_FAIL;                     \
  }

  IMM_16_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vgetq_lane_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  uint16x8_t a = vld1q_u16(_a);

#define TEST_IMPL(IDX)                     \
  if (vgetq_lane_u16(a, IDX) != _a[IDX]) { \
    return TEST_FAIL;                      \
  }

  IMM_8_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vgetq_lane_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  uint32x4_t a = vld1q_u32(_a);

#define TEST_IMPL(IDX)                     \
  if (vgetq_lane_u32(a, IDX) != _a[IDX]) { \
    return TEST_FAIL;                      \
  }

  IMM_4_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vgetq_lane_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (int64_t *)impl.test_cases_int_pointer1;
  int64x2_t a = vld1q_s64(_a);

#define TEST_IMPL(IDX)                     \
  if (vgetq_lane_s64(a, IDX) != _a[IDX]) { \
    return TEST_FAIL;                      \
  }

  IMM_2_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vgetq_lane_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vgetq_lane_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vget_lane_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vgetq_lane_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vgetq_lane_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (uint64_t *)impl.test_cases_int_pointer1;
  uint64x2_t a = vld1q_u64(_a);

#define TEST_IMPL(IDX)                     \
  if (vgetq_lane_u64(a, IDX) != _a[IDX]) { \
    return TEST_FAIL;                      \
  }

  IMM_2_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vgetq_lane_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vset_lane_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (int8_t *)impl.test_cases_int_pointer2;
  int8_t _c[8];
  int8x8_t a = vld1_s8(_a);
  int8x8_t c;

#define TEST_IMPL(IDX)             \
  for (int i = 0; i < 8; i++) {    \
    if (i == IDX) {                \
      _c[i] = _b[0];               \
    } else {                       \
      _c[i] = _a[i];               \
    }                              \
  }                                \
  c = vset_lane_s8(_b[0], a, IDX); \
  CHECK_RESULT(validate_int8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]))

  IMM_8_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vset_lane_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  int16_t _c[4];
  int16x4_t a = vld1_s16(_a);
  int16x4_t c;

#define TEST_IMPL(IDX)              \
  for (int i = 0; i < 4; i++) {     \
    if (i == IDX) {                 \
      _c[i] = _b[0];                \
    } else {                        \
      _c[i] = _a[i];                \
    }                               \
  }                                 \
  c = vset_lane_s16(_b[0], a, IDX); \
  CHECK_RESULT(validate_int16(c, _c[0], _c[1], _c[2], _c[3]))

  IMM_4_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vset_lane_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  int32_t _c[2];
  int32x2_t a = vld1_s32(_a);
  int32x2_t c;

#define TEST_IMPL(IDX)              \
  for (int i = 0; i < 2; i++) {     \
    if (i == IDX) {                 \
      _c[i] = _b[0];                \
    } else {                        \
      _c[i] = _a[i];                \
    }                               \
  }                                 \
  c = vset_lane_s32(_b[0], a, IDX); \
  CHECK_RESULT(validate_int32(c, _c[0], _c[1]))

  IMM_2_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vset_lane_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (float *)impl.test_cases_float_pointer1;
  const float *_b = (float *)impl.test_cases_float_pointer2;
  float _c[2];
  float32x2_t a = vld1_f32(_a);
  float32x2_t c;

#define TEST_IMPL(IDX)              \
  for (int i = 0; i < 2; i++) {     \
    if (i == IDX) {                 \
      _c[i] = _b[0];                \
    } else {                        \
      _c[i] = _a[i];                \
    }                               \
  }                                 \
  c = vset_lane_f32(_b[0], a, IDX); \
  CHECK_RESULT(validate_float(c, _c[0], _c[1]))

  IMM_2_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vset_lane_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vset_lane_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (uint8_t *)impl.test_cases_int_pointer2;
  uint8_t _c[8];
  uint8x8_t a = vld1_u8(_a);
  uint8x8_t c;

#define TEST_IMPL(IDX)             \
  for (int i = 0; i < 8; i++) {    \
    if (i == IDX) {                \
      _c[i] = _b[0];               \
    } else {                       \
      _c[i] = _a[i];               \
    }                              \
  }                                \
  c = vset_lane_u8(_b[0], a, IDX); \
  CHECK_RESULT(validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]))

  IMM_8_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vset_lane_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (uint16_t *)impl.test_cases_int_pointer2;
  uint16_t _c[4];
  uint16x4_t a = vld1_u16(_a);
  uint16x4_t c;

#define TEST_IMPL(IDX)              \
  for (int i = 0; i < 4; i++) {     \
    if (i == IDX) {                 \
      _c[i] = _b[0];                \
    } else {                        \
      _c[i] = _a[i];                \
    }                               \
  }                                 \
  c = vset_lane_u16(_b[0], a, IDX); \
  CHECK_RESULT(validate_uint16(c, _c[0], _c[1], _c[2], _c[3]))

  IMM_4_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vset_lane_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (uint32_t *)impl.test_cases_int_pointer2;
  uint32_t _c[2];
  uint32x2_t a = vld1_u32(_a);
  uint32x2_t c;

#define TEST_IMPL(IDX)              \
  for (int i = 0; i < 2; i++) {     \
    if (i == IDX) {                 \
      _c[i] = _b[0];                \
    } else {                        \
      _c[i] = _a[i];                \
    }                               \
  }                                 \
  c = vset_lane_u32(_b[0], a, IDX); \
  CHECK_RESULT(validate_uint32(c, _c[0], _c[1]))

  IMM_2_ITER
#undef TEST_IMPL
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vset_lane_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (int64_t *)impl.test_cases_int_pointer1;
  const int64_t *_b = (int64_t *)impl.test_cases_int_pointer2;
  int64_t _c[1];
  int64x1_t a = vld1_s64(_a);
  int64x1_t c;

#define TEST_IMPL(IDX)              \
  for (int i = 0; i < 1; i++) {     \
    if (i == IDX) {                 \
      _c[i] = _b[0];                \
    } else {                        \
      _c[i] = _a[i];                \
    }                               \
  }                                 \
  c = vset_lane_s64(_b[0], a, IDX); \
  CHECK_RESULT(validate_int64(c, _c[0]))

  IMM_1_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vset_lane_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vset_lane_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vset_lane_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vsetq_lane_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vset_lane_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (uint64_t *)impl.test_cases_int_pointer1;
  const uint64_t *_b = (uint64_t *)impl.test_cases_int_pointer2;
  uint64_t _c[1];
  uint64x1_t a = vld1_u64(_a);
  uint64x1_t c;

#define TEST_IMPL(IDX)              \
  for (int i = 0; i < 1; i++) {     \
    if (i == IDX) {                 \
      _c[i] = _b[0];                \
    } else {                        \
      _c[i] = _a[i];                \
    }                               \
  }                                 \
  c = vset_lane_u64(_b[0], a, IDX); \
  CHECK_RESULT(validate_uint64(c, _c[0]))

  IMM_1_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vset_lane_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vsetq_lane_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (int8_t *)impl.test_cases_int_pointer2;
  int8_t _c[16];
  int8x16_t a = vld1q_s8(_a);
  int8x16_t c;

#define TEST_IMPL(IDX)                                                                                                \
  for (int i = 0; i < 16; i++) {                                                                                      \
    if (i == IDX) {                                                                                                   \
      _c[i] = _b[0];                                                                                                  \
    } else {                                                                                                          \
      _c[i] = _a[i];                                                                                                  \
    }                                                                                                                 \
  }                                                                                                                   \
  c = vsetq_lane_s8(_b[0], a, IDX);                                                                                   \
  CHECK_RESULT(validate_int8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7], _c[8], _c[9], _c[10], _c[11], \
                             _c[12], _c[13], _c[14], _c[15]))

  IMM_16_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsetq_lane_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  int16_t _c[8];
  int16x8_t a = vld1q_s16(_a);
  int16x8_t c;

#define TEST_IMPL(IDX)               \
  for (int i = 0; i < 8; i++) {      \
    if (i == IDX) {                  \
      _c[i] = _b[0];                 \
    } else {                         \
      _c[i] = _a[i];                 \
    }                                \
  }                                  \
  c = vsetq_lane_s16(_b[0], a, IDX); \
  CHECK_RESULT(validate_int16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]))

  IMM_8_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsetq_lane_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  int32_t _c[4];
  int32x4_t a = vld1q_s32(_a);
  int32x4_t c;

#define TEST_IMPL(IDX)               \
  for (int i = 0; i < 4; i++) {      \
    if (i == IDX) {                  \
      _c[i] = _b[0];                 \
    } else {                         \
      _c[i] = _a[i];                 \
    }                                \
  }                                  \
  c = vsetq_lane_s32(_b[0], a, IDX); \
  CHECK_RESULT(validate_int32(c, _c[0], _c[1], _c[2], _c[3]))

  IMM_4_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsetq_lane_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (float *)impl.test_cases_float_pointer1;
  const float *_b = (float *)impl.test_cases_float_pointer2;
  float _c[4];
  float32x4_t a = vld1q_f32(_a);
  float32x4_t c;

#define TEST_IMPL(IDX)               \
  for (int i = 0; i < 4; i++) {      \
    if (i == IDX) {                  \
      _c[i] = _b[0];                 \
    } else {                         \
      _c[i] = _a[i];                 \
    }                                \
  }                                  \
  c = vsetq_lane_f32(_b[0], a, IDX); \
  CHECK_RESULT(validate_float(c, _c[0], _c[1], _c[2], _c[3]))

  IMM_4_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsetq_lane_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrecpxs_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrecpxd_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vfma_n_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vfmaq_n_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vfms_n_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vfmsq_n_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vfma_n_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vfmaq_n_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vfms_n_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vfmsq_n_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vsetq_lane_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (uint8_t *)impl.test_cases_int_pointer2;
  uint8_t _c[16];
  uint8x16_t a = vld1q_u8(_a);
  uint8x16_t c;

#define TEST_IMPL(IDX)                                                                                                 \
  for (int i = 0; i < 16; i++) {                                                                                       \
    if (i == IDX) {                                                                                                    \
      _c[i] = _b[0];                                                                                                   \
    } else {                                                                                                           \
      _c[i] = _a[i];                                                                                                   \
    }                                                                                                                  \
  }                                                                                                                    \
  c = vsetq_lane_u8(_b[0], a, IDX);                                                                                    \
  CHECK_RESULT(validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7], _c[8], _c[9], _c[10], _c[11], \
                              _c[12], _c[13], _c[14], _c[15]))

  IMM_16_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsetq_lane_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (uint16_t *)impl.test_cases_int_pointer2;
  uint16_t _c[8];
  uint16x8_t a = vld1q_u16(_a);
  uint16x8_t c;

#define TEST_IMPL(IDX)               \
  for (int i = 0; i < 8; i++) {      \
    if (i == IDX) {                  \
      _c[i] = _b[0];                 \
    } else {                         \
      _c[i] = _a[i];                 \
    }                                \
  }                                  \
  c = vsetq_lane_u16(_b[0], a, IDX); \
  CHECK_RESULT(validate_uint16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]))

  IMM_8_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsetq_lane_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (uint32_t *)impl.test_cases_int_pointer2;
  uint32_t _c[4];
  uint32x4_t a = vld1q_u32(_a);
  uint32x4_t c;

#define TEST_IMPL(IDX)               \
  for (int i = 0; i < 4; i++) {      \
    if (i == IDX) {                  \
      _c[i] = _b[0];                 \
    } else {                         \
      _c[i] = _a[i];                 \
    }                                \
  }                                  \
  c = vsetq_lane_u32(_b[0], a, IDX); \
  CHECK_RESULT(validate_uint32(c, _c[0], _c[1], _c[2], _c[3]))

  IMM_4_ITER
#undef TEST_IMPL
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsetq_lane_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (int64_t *)impl.test_cases_int_pointer1;
  const int64_t *_b = (int64_t *)impl.test_cases_int_pointer2;
  int64_t _c[2];
  int64x2_t a = vld1q_s64(_a);
  int64x2_t c;

#define TEST_IMPL(IDX)               \
  for (int i = 0; i < 2; i++) {      \
    if (i == IDX) {                  \
      _c[i] = _b[0];                 \
    } else {                         \
      _c[i] = _a[i];                 \
    }                                \
  }                                  \
  c = vsetq_lane_s64(_b[0], a, IDX); \
  CHECK_RESULT(validate_int64(c, _c[0], _c[1]))

  IMM_2_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsetq_lane_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vsetq_lane_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vsetq_lane_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (uint64_t *)impl.test_cases_int_pointer1;
  const uint64_t *_b = (uint64_t *)impl.test_cases_int_pointer2;
  uint64_t _c[2];
  uint64x2_t a = vld1q_u64(_a);
  uint64x2_t c;

#define TEST_IMPL(IDX)               \
  for (int i = 0; i < 2; i++) {      \
    if (i == IDX) {                  \
      _c[i] = _b[0];                 \
    } else {                         \
      _c[i] = _a[i];                 \
    }                                \
  }                                  \
  c = vsetq_lane_u64(_b[0], a, IDX); \
  CHECK_RESULT(validate_uint64(c, _c[0], _c[1]))

  IMM_2_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vsetq_lane_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcreate_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  int8x8_t c = vcreate_s8(((const uint64_t *)_a)[0]);
  return validate_int8(c, _a[0], _a[1], _a[2], _a[3], _a[4], _a[5], _a[6], _a[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vcreate_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  int16x4_t c = vcreate_s16(((const uint64_t *)_a)[0]);
  return validate_int16(c, _a[0], _a[1], _a[2], _a[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vcreate_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  int32x2_t c = vcreate_s32(((const uint64_t *)_a)[0]);
  return validate_int32(c, _a[0], _a[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vcreate_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (int64_t *)impl.test_cases_int_pointer1;
  int64x1_t c = vcreate_s64(((const uint64_t *)_a)[0]);
  return validate_int64(c, _a[0]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vcreate_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (float *)impl.test_cases_float_pointer1;
  float32x2_t c = vcreate_f32(((const uint64_t *)_a)[0]);
  return validate_float(c, _a[0], _a[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vcreate_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcreate_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcreate_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcreate_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (uint8_t *)impl.test_cases_int_pointer1;
  uint8x8_t c = vcreate_u8(((const uint64_t *)_a)[0]);
  return validate_uint8(c, _a[0], _a[1], _a[2], _a[3], _a[4], _a[5], _a[6], _a[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vcreate_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  uint16x4_t c = vcreate_u16(((const uint64_t *)_a)[0]);
  return validate_uint16(c, _a[0], _a[1], _a[2], _a[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vcreate_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  uint32x2_t c = vcreate_u32(((const uint64_t *)_a)[0]);
  return validate_uint32(c, _a[0], _a[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vcreate_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (uint64_t *)impl.test_cases_int_pointer1;
  uint64x1_t c = vcreate_u64(((const uint64_t *)_a)[0]);
  return validate_uint64(c, _a[0]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vcreate_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcreate_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vdup_n_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (const int8_t *)impl.test_cases_int_pointer1;
  int8x8_t c = vdup_n_s8(_a[0]);
  return validate_int8(c, _a[0], _a[0], _a[0], _a[0], _a[0], _a[0], _a[0], _a[0]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vdup_n_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (const int16_t *)impl.test_cases_int_pointer1;
  int16x4_t c = vdup_n_s16(_a[0]);
  return validate_int16(c, _a[0], _a[0], _a[0], _a[0]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vdup_n_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (const int32_t *)impl.test_cases_int_pointer1;
  int32x2_t c = vdup_n_s32(_a[0]);
  return validate_int32(c, _a[0], _a[0]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vdup_n_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (const float *)impl.test_cases_float_pointer1;
  float32x2_t c = vdup_n_f32(_a[0]);
  return validate_float(c, _a[0], _a[0]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vdup_n_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (const uint8_t *)impl.test_cases_int_pointer1;
  uint8x8_t c = vdup_n_u8(_a[0]);
  return validate_uint8(c, _a[0], _a[0], _a[0], _a[0], _a[0], _a[0], _a[0], _a[0]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vdup_n_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (const uint16_t *)impl.test_cases_int_pointer1;
  uint16x4_t c = vdup_n_u16(_a[0]);
  return validate_uint16(c, _a[0], _a[0], _a[0], _a[0]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vdup_n_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (const uint32_t *)impl.test_cases_int_pointer1;
  uint32x2_t c = vdup_n_u32(_a[0]);
  return validate_uint32(c, _a[0], _a[0]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vdup_n_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (const int64_t *)impl.test_cases_int_pointer1;
  int64x1_t c = vdup_n_s64(_a[0]);
  return validate_int64(c, _a[0]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vdup_n_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (const uint64_t *)impl.test_cases_int_pointer1;
  uint64x1_t c = vdup_n_u64(_a[0]);
  return validate_uint64(c, _a[0]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vdupq_n_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (const int8_t *)impl.test_cases_int_pointer1;
  int8x16_t c = vdupq_n_s8(_a[0]);
  return validate_int8(c, _a[0], _a[0], _a[0], _a[0], _a[0], _a[0], _a[0], _a[0], _a[0], _a[0], _a[0], _a[0], _a[0],
                       _a[0], _a[0], _a[0]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vdupq_n_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (const int16_t *)impl.test_cases_int_pointer1;
  int16x8_t c = vdupq_n_s16(_a[0]);
  return validate_int16(c, _a[0], _a[0], _a[0], _a[0], _a[0], _a[0], _a[0], _a[0]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vdupq_n_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (const int32_t *)impl.test_cases_int_pointer1;
  int32x4_t c = vdupq_n_s32(_a[0]);
  return validate_int32(c, _a[0], _a[0], _a[0], _a[0]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vdupq_n_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (const float *)impl.test_cases_float_pointer1;
  float32x4_t c = vdupq_n_f32(_a[0]);
  return validate_float(c, _a[0], _a[0], _a[0], _a[0]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vdup_n_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vdupq_n_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vdup_n_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vdupq_n_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vdup_n_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vdupq_n_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vdupq_n_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (const uint8_t *)impl.test_cases_int_pointer1;
  uint8x16_t c = vdupq_n_u8(_a[0]);
  return validate_uint8(c, _a[0], _a[0], _a[0], _a[0], _a[0], _a[0], _a[0], _a[0], _a[0], _a[0], _a[0], _a[0], _a[0],
                        _a[0], _a[0], _a[0]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vdupq_n_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (const uint16_t *)impl.test_cases_int_pointer1;
  uint16x8_t c = vdupq_n_u16(_a[0]);
  return validate_uint16(c, _a[0], _a[0], _a[0], _a[0], _a[0], _a[0], _a[0], _a[0]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vdupq_n_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (const uint32_t *)impl.test_cases_int_pointer1;
  uint32x4_t c = vdupq_n_u32(_a[0]);
  return validate_uint32(c, _a[0], _a[0], _a[0], _a[0]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vdupq_n_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (const int64_t *)impl.test_cases_int_pointer1;
  int64x2_t c = vdupq_n_s64(_a[0]);
  return validate_int64(c, _a[0], _a[0]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vdupq_n_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (const uint64_t *)impl.test_cases_int_pointer1;
  uint64x2_t c = vdupq_n_u64(_a[0]);
  return validate_uint64(c, _a[0], _a[0]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vdup_n_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vdupq_n_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmov_n_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t _a = (const int8_t)impl.test_cases_ints[0];
  int8x8_t c = vmov_n_s8(_a);
  return validate_int8(c, _a, _a, _a, _a, _a, _a, _a, _a);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmov_n_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t _a = (const int16_t)impl.test_cases_ints[0];
  int16x4_t c = vmov_n_s16(_a);
  return validate_int16(c, _a, _a, _a, _a);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmov_n_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t _a = (const int32_t)impl.test_cases_ints[0];
  int32x2_t c = vmov_n_s32(_a);
  return validate_int32(c, _a, _a);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmov_n_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float _a = (const float)impl.test_cases_floats[0];
  float32x2_t c = vmov_n_f32(_a);
  return validate_float(c, _a, _a);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmov_n_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t _a = (const uint8_t)impl.test_cases_ints[0];
  uint8x8_t c = vmov_n_u8(_a);
  return validate_uint8(c, _a, _a, _a, _a, _a, _a, _a, _a);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmov_n_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t _a = (const uint16_t)impl.test_cases_ints[0];
  uint16x4_t c = vmov_n_u16(_a);
  return validate_uint16(c, _a, _a, _a, _a);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmov_n_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t _a = (const uint32_t)impl.test_cases_ints[0];
  uint32x2_t c = vmov_n_u32(_a);
  return validate_uint32(c, _a, _a);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmov_n_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t _a = (const int64_t)impl.test_cases_ints[0];
  int64x1_t c = vmov_n_s64(_a);
  return validate_int64(c, _a);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmov_n_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t _a = (const uint64_t)impl.test_cases_ints[0];
  uint64x1_t c = vmov_n_u64(_a);
  return validate_uint64(c, _a);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmovq_n_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t _a = (const int8_t)impl.test_cases_ints[0];
  int8x16_t c = vmovq_n_s8(_a);
  return validate_int8(c, _a, _a, _a, _a, _a, _a, _a, _a, _a, _a, _a, _a, _a, _a, _a, _a);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmovq_n_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t _a = (const int16_t)impl.test_cases_ints[0];
  int16x8_t c = vmovq_n_s16(_a);
  return validate_int16(c, _a, _a, _a, _a, _a, _a, _a, _a);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmovq_n_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t _a = (const int32_t)impl.test_cases_ints[0];
  int32x4_t c = vmovq_n_s32(_a);
  return validate_int32(c, _a, _a, _a, _a);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmovq_n_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float _a = (const float)impl.test_cases_floats[0];
  float32x4_t c = vmovq_n_f32(_a);
  return validate_float(c, _a, _a, _a, _a);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmov_n_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmovq_n_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmov_n_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmovq_n_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmov_n_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmovq_n_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmovq_n_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t _a = (const uint8_t)impl.test_cases_ints[0];
  uint8x16_t c = vmovq_n_u8(_a);
  return validate_uint8(c, _a, _a, _a, _a, _a, _a, _a, _a, _a, _a, _a, _a, _a, _a, _a, _a);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmovq_n_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t _a = (const uint16_t)impl.test_cases_ints[0];
  uint16x8_t c = vmovq_n_u16(_a);
  return validate_uint16(c, _a, _a, _a, _a, _a, _a, _a, _a);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmovq_n_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t _a = (const uint32_t)impl.test_cases_ints[0];
  uint32x4_t c = vmovq_n_u32(_a);
  return validate_uint32(c, _a, _a, _a, _a);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmovq_n_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t _a = (const int64_t)impl.test_cases_ints[0];
  int64x2_t c = vmovq_n_s64(_a);
  return validate_int64(c, _a, _a);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmovq_n_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t _a = (const uint64_t)impl.test_cases_ints[0];
  uint64x2_t c = vmovq_n_u64(_a);
  return validate_uint64(c, _a, _a);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vdup_lane_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  int8x8_t a = vld1_s8(_a);
  int8x8_t c;

#define TEST_IMPL(IDX)      \
  c = vdup_lane_s8(a, IDX); \
  CHECK_RESULT(validate_int8(c, _a[IDX], _a[IDX], _a[IDX], _a[IDX], _a[IDX], _a[IDX], _a[IDX], _a[IDX]))

  IMM_8_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vdup_lane_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  int16x4_t a = vld1_s16(_a);
  int16x4_t c;

#define TEST_IMPL(IDX)       \
  c = vdup_lane_s16(a, IDX); \
  CHECK_RESULT(validate_int16(c, _a[IDX], _a[IDX], _a[IDX], _a[IDX]))

  IMM_4_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vdup_lane_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  int32x2_t a = vld1_s32(_a);
  int32x2_t c;

#define TEST_IMPL(IDX)       \
  c = vdup_lane_s32(a, IDX); \
  CHECK_RESULT(validate_int32(c, _a[IDX], _a[IDX]))

  IMM_2_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vdup_lane_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (float *)impl.test_cases_float_pointer1;
  float32x2_t a = vld1_f32(_a);
  float32x2_t c;

#define TEST_IMPL(IDX)       \
  c = vdup_lane_f32(a, IDX); \
  CHECK_RESULT(validate_float(c, _a[IDX], _a[IDX]))

  IMM_2_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vdup_lane_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (uint8_t *)impl.test_cases_int_pointer1;
  uint8x8_t a = vld1_u8(_a);
  uint8x8_t c;

#define TEST_IMPL(IDX)      \
  c = vdup_lane_u8(a, IDX); \
  CHECK_RESULT(validate_uint8(c, _a[IDX], _a[IDX], _a[IDX], _a[IDX], _a[IDX], _a[IDX], _a[IDX], _a[IDX]))

  IMM_8_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vdup_lane_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  uint16x4_t a = vld1_u16(_a);
  uint16x4_t c;

#define TEST_IMPL(IDX)       \
  c = vdup_lane_u16(a, IDX); \
  CHECK_RESULT(validate_uint16(c, _a[IDX], _a[IDX], _a[IDX], _a[IDX]))

  IMM_4_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vdup_lane_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  uint32x2_t a = vld1_u32(_a);
  uint32x2_t c;

#define TEST_IMPL(IDX)       \
  c = vdup_lane_u32(a, IDX); \
  CHECK_RESULT(validate_uint32(c, _a[IDX], _a[IDX]))

  IMM_2_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vdup_lane_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (int64_t *)impl.test_cases_int_pointer1;
  int64x1_t a = vld1_s64(_a);
  int64x1_t c;

#define TEST_IMPL(IDX)       \
  c = vdup_lane_s64(a, IDX); \
  CHECK_RESULT(validate_int64(c, _a[IDX]))

  IMM_1_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vdup_lane_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (uint64_t *)impl.test_cases_int_pointer1;
  uint64x1_t a = vld1_u64(_a);
  uint64x1_t c;

#define TEST_IMPL(IDX)       \
  c = vdup_lane_u64(a, IDX); \
  CHECK_RESULT(validate_uint64(c, _a[IDX]))

  IMM_1_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vdupq_lane_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  int8x8_t a = vld1_s8(_a);
  int8x16_t c;

#define TEST_IMPL(IDX)                                                                                           \
  c = vdupq_lane_s8(a, IDX);                                                                                     \
  CHECK_RESULT(validate_int8(c, _a[IDX], _a[IDX], _a[IDX], _a[IDX], _a[IDX], _a[IDX], _a[IDX], _a[IDX], _a[IDX], \
                             _a[IDX], _a[IDX], _a[IDX], _a[IDX], _a[IDX], _a[IDX], _a[IDX]))

  IMM_8_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vdupq_lane_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  int16x4_t a = vld1_s16(_a);
  int16x8_t c;

#define TEST_IMPL(IDX)        \
  c = vdupq_lane_s16(a, IDX); \
  CHECK_RESULT(validate_int16(c, _a[IDX], _a[IDX], _a[IDX], _a[IDX], _a[IDX], _a[IDX], _a[IDX], _a[IDX]))

  IMM_4_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vdupq_lane_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  int32x2_t a = vld1_s32(_a);
  int32x4_t c;

#define TEST_IMPL(IDX)        \
  c = vdupq_lane_s32(a, IDX); \
  CHECK_RESULT(validate_int32(c, _a[IDX], _a[IDX], _a[IDX], _a[IDX]))

  IMM_2_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vdupq_lane_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (float *)impl.test_cases_float_pointer1;
  float32x2_t a = vld1_f32(_a);
  float32x4_t c;

#define TEST_IMPL(IDX)        \
  c = vdupq_lane_f32(a, IDX); \
  CHECK_RESULT(validate_float(c, _a[IDX], _a[IDX], _a[IDX], _a[IDX]))

  IMM_2_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vdup_lane_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vdupq_lane_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vdup_lane_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vdupq_lane_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vdup_lane_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vdupq_lane_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vdup_laneq_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vdupq_laneq_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vdup_laneq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vdupq_laneq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vdup_laneq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vdupq_laneq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vdup_laneq_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vdupq_laneq_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vdup_laneq_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vdupq_laneq_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vdup_laneq_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vdupq_laneq_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vdup_laneq_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vdupq_laneq_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vdup_laneq_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vdupq_laneq_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vdup_laneq_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vdupq_laneq_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vdup_laneq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vdupq_laneq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vdup_laneq_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vdupq_laneq_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vdup_laneq_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vdupq_laneq_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vdup_laneq_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vdupq_laneq_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vdupq_lane_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (uint8_t *)impl.test_cases_int_pointer1;
  uint8x8_t a = vld1_u8(_a);
  uint8x16_t c;

#define TEST_IMPL(IDX)                                                                                            \
  c = vdupq_lane_u8(a, IDX);                                                                                      \
  CHECK_RESULT(validate_uint8(c, _a[IDX], _a[IDX], _a[IDX], _a[IDX], _a[IDX], _a[IDX], _a[IDX], _a[IDX], _a[IDX], \
                              _a[IDX], _a[IDX], _a[IDX], _a[IDX], _a[IDX], _a[IDX], _a[IDX]))

  IMM_8_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vdupq_lane_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  uint16x4_t a = vld1_u16(_a);
  uint16x8_t c;

#define TEST_IMPL(IDX)        \
  c = vdupq_lane_u16(a, IDX); \
  CHECK_RESULT(validate_uint16(c, _a[IDX], _a[IDX], _a[IDX], _a[IDX], _a[IDX], _a[IDX], _a[IDX], _a[IDX]))

  IMM_4_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vdupq_lane_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  uint32x2_t a = vld1_u32(_a);
  uint32x4_t c;

#define TEST_IMPL(IDX)        \
  c = vdupq_lane_u32(a, IDX); \
  CHECK_RESULT(validate_uint32(c, _a[IDX], _a[IDX], _a[IDX], _a[IDX]))

  IMM_2_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vdupq_lane_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (int64_t *)impl.test_cases_int_pointer1;
  int64x1_t a = vld1_s64(_a);
  int64x2_t c;

#define TEST_IMPL(IDX)        \
  c = vdupq_lane_s64(a, IDX); \
  CHECK_RESULT(validate_int64(c, _a[IDX], _a[IDX]))

  IMM_1_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vdupq_lane_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (uint64_t *)impl.test_cases_int_pointer1;
  uint64x1_t a = vld1_u64(_a);
  uint64x2_t c;

#define TEST_IMPL(IDX)        \
  c = vdupq_lane_u64(a, IDX); \
  CHECK_RESULT(validate_uint64(c, _a[IDX], _a[IDX]))

  IMM_1_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vdup_lane_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vdupq_lane_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcombine_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (int8_t *)impl.test_cases_int_pointer2;
  int8_t _c[16];
  for (int i = 0; i < 8; i++) {
    _c[i] = _a[i];
    _c[i + 8] = _b[i];
  }
  int8x8_t a = vld1_s8(_a);
  int8x8_t b = vld1_s8(_b);
  int8x16_t c = vcombine_s8(a, b);

  return validate_int8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7], _c[8], _c[9], _c[10], _c[11], _c[12],
                       _c[13], _c[14], _c[15]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vcombine_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  int16_t _c[8];
  for (int i = 0; i < 4; i++) {
    _c[i] = _a[i];
    _c[i + 4] = _b[i];
  }
  int16x4_t a = vld1_s16(_a);
  int16x4_t b = vld1_s16(_b);
  int16x8_t c = vcombine_s16(a, b);

  return validate_int16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vcombine_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  int32_t _c[4];
  for (int i = 0; i < 2; i++) {
    _c[i] = _a[i];
    _c[i + 2] = _b[i];
  }
  int32x2_t a = vld1_s32(_a);
  int32x2_t b = vld1_s32(_b);
  int32x4_t c = vcombine_s32(a, b);

  return validate_int32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vcombine_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (int64_t *)impl.test_cases_int_pointer1;
  const int64_t *_b = (int64_t *)impl.test_cases_int_pointer2;
  int64_t _c[2];
  for (int i = 0; i < 1; i++) {
    _c[i] = _a[i];
    _c[i + 1] = _b[i];
  }
  int64x1_t a = vld1_s64(_a);
  int64x1_t b = vld1_s64(_b);
  int64x2_t c = vcombine_s64(a, b);

  return validate_int64(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vcombine_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (float *)impl.test_cases_float_pointer1;
  const float *_b = (float *)impl.test_cases_float_pointer2;
  float _c[4];
  for (int i = 0; i < 2; i++) {
    _c[i] = _a[i];
    _c[i + 2] = _b[i];
  }
  float32x2_t a = vld1_f32(_a);
  float32x2_t b = vld1_f32(_b);
  float32x4_t c = vcombine_f32(a, b);

  return validate_float(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vcombine_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcombine_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcombine_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcombine_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (uint8_t *)impl.test_cases_int_pointer2;
  uint8_t _c[16];
  for (int i = 0; i < 8; i++) {
    _c[i] = _a[i];
    _c[i + 8] = _b[i];
  }
  uint8x8_t a = vld1_u8(_a);
  uint8x8_t b = vld1_u8(_b);
  uint8x16_t c = vcombine_u8(a, b);

  return validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7], _c[8], _c[9], _c[10], _c[11], _c[12],
                        _c[13], _c[14], _c[15]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vcombine_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (uint16_t *)impl.test_cases_int_pointer2;
  uint16_t _c[8];
  for (int i = 0; i < 4; i++) {
    _c[i] = _a[i];
    _c[i + 4] = _b[i];
  }
  uint16x4_t a = vld1_u16(_a);
  uint16x4_t b = vld1_u16(_b);
  uint16x8_t c = vcombine_u16(a, b);

  return validate_uint16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vcombine_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (uint32_t *)impl.test_cases_int_pointer2;
  uint32_t _c[4];
  for (int i = 0; i < 2; i++) {
    _c[i] = _a[i];
    _c[i + 2] = _b[i];
  }
  uint32x2_t a = vld1_u32(_a);
  uint32x2_t b = vld1_u32(_b);
  uint32x4_t c = vcombine_u32(a, b);

  return validate_uint32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vcombine_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (uint64_t *)impl.test_cases_int_pointer1;
  const uint64_t *_b = (uint64_t *)impl.test_cases_int_pointer2;
  uint64_t _c[2];
  for (int i = 0; i < 1; i++) {
    _c[i] = _a[i];
    _c[i + 1] = _b[i];
  }
  uint64x1_t a = vld1_u64(_a);
  uint64x1_t b = vld1_u64(_b);
  uint64x2_t c = vcombine_u64(a, b);

  return validate_uint64(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vcombine_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcombine_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vget_high_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  int8_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = _a[i + 8];
  }
  int8x16_t a = vld1q_s8(_a);
  int8x8_t c = vget_high_s8(a);

  return validate_int8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vget_high_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  int16_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = _a[i + 4];
  }
  int16x8_t a = vld1q_s16(_a);
  int16x4_t c = vget_high_s16(a);

  return validate_int16(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vget_high_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  int32_t _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = _a[i + 2];
  }
  int32x4_t a = vld1q_s32(_a);
  int32x2_t c = vget_high_s32(a);

  return validate_int32(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vget_high_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (int64_t *)impl.test_cases_int_pointer1;
  int64_t _c[1];
  for (int i = 0; i < 1; i++) {
    _c[i] = _a[i + 1];
  }
  int64x2_t a = vld1q_s64(_a);
  int64x1_t c = vget_high_s64(a);

  return validate_int64(c, _c[0]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vget_high_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (float *)impl.test_cases_float_pointer1;
  float _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = _a[i + 2];
  }
  float32x4_t a = vld1q_f32(_a);
  float32x2_t c = vget_high_f32(a);

  return validate_float(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vget_high_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vget_high_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vget_high_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vget_high_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (uint8_t *)impl.test_cases_int_pointer1;
  uint8_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = _a[i + 8];
  }
  uint8x16_t a = vld1q_u8(_a);
  uint8x8_t c = vget_high_u8(a);

  return validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vget_high_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  uint16_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = _a[i + 4];
  }
  uint16x8_t a = vld1q_u16(_a);
  uint16x4_t c = vget_high_u16(a);

  return validate_uint16(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vget_high_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  uint32_t _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = _a[i + 2];
  }
  uint32x4_t a = vld1q_u32(_a);
  uint32x2_t c = vget_high_u32(a);

  return validate_uint32(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vget_high_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (uint64_t *)impl.test_cases_int_pointer1;
  uint64_t _c[1];
  for (int i = 0; i < 1; i++) {
    _c[i] = _a[i + 1];
  }
  uint64x2_t a = vld1q_u64(_a);
  uint64x1_t c = vget_high_u64(a);

  return validate_uint64(c, _c[0]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vget_high_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vget_high_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vget_low_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  int8_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = _a[i];
  }
  int8x16_t a = vld1q_s8(_a);
  int8x8_t c = vget_low_s8(a);

  return validate_int8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vget_low_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  int16_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = _a[i];
  }
  int16x8_t a = vld1q_s16(_a);
  int16x4_t c = vget_low_s16(a);

  return validate_int16(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vget_low_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  int32_t _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = _a[i];
  }
  int32x4_t a = vld1q_s32(_a);
  int32x2_t c = vget_low_s32(a);

  return validate_int32(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vget_low_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (float *)impl.test_cases_float_pointer1;
  float _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = _a[i];
  }
  float32x4_t a = vld1q_f32(_a);
  float32x2_t c = vget_low_f32(a);

  return validate_float(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vget_low_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vget_low_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vget_low_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vdupb_lane_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vduph_lane_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vdups_lane_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vdupd_lane_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vdupb_lane_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vduph_lane_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vdups_lane_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vdupd_lane_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vdups_lane_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vdupd_lane_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vdupb_lane_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vduph_lane_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vdupb_laneq_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vduph_laneq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vdups_laneq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vdupd_laneq_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vdupb_laneq_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vduph_laneq_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vdups_laneq_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vdupd_laneq_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vdups_laneq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vdupd_laneq_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vdupb_laneq_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vduph_laneq_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vget_low_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (uint8_t *)impl.test_cases_int_pointer1;
  uint8_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = _a[i];
  }
  uint8x16_t a = vld1q_u8(_a);
  uint8x8_t c = vget_low_u8(a);

  return validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vget_low_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  uint16_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = _a[i];
  }
  uint16x8_t a = vld1q_u16(_a);
  uint16x4_t c = vget_low_u16(a);

  return validate_uint16(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vget_low_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  uint32_t _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = _a[i];
  }
  uint32x4_t a = vld1q_u32(_a);
  uint32x2_t c = vget_low_u32(a);

  return validate_uint32(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vget_low_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (int64_t *)impl.test_cases_int_pointer1;
  int64_t _c[1];
  for (int i = 0; i < 1; i++) {
    _c[i] = _a[i];
  }
  int64x2_t a = vld1q_s64(_a);
  int64x1_t c = vget_low_s64(a);

  return validate_int64(c, _c[0]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vget_low_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (uint64_t *)impl.test_cases_int_pointer1;
  uint64_t _c[1];
  for (int i = 0; i < 1; i++) {
    _c[i] = _a[i];
  }
  uint64x2_t a = vld1q_u64(_a);
  uint64x1_t c = vget_low_u64(a);

  return validate_uint64(c, _c[0]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vget_low_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vget_low_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvt_s32_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (const float *)impl.test_cases_float_pointer1;
  int32_t _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = _a[i];
  }

  float32x2_t a = vld1_f32(_a);
  int32x2_t c = vcvt_s32_f32(a);
  return validate_int32(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vcvt_f32_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (const int32_t *)impl.test_cases_int_pointer1;
  float _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = _a[i];
  }

  int32x2_t a = vld1_s32(_a);
  float32x2_t c = vcvt_f32_s32(a);
  return validate_float(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vcvt_f32_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (const uint32_t *)impl.test_cases_int_pointer1;
  float _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = _a[i];
  }

  uint32x2_t a = vld1_u32(_a);
  float32x2_t c = vcvt_f32_u32(a);
  return validate_float(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vcvt_u32_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (const float *)impl.test_cases_float_pointer1;
  uint32_t _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = _a[i];
  }

  float32x2_t a = vld1_f32(_a);
  uint32x2_t c = vcvt_u32_f32(a);
  return validate_uint32(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vcvtq_s32_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (const float *)impl.test_cases_float_pointer1;
  int32_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = _a[i];
  }

  float32x4_t a = vld1q_f32(_a);
  int32x4_t c = vcvtq_s32_f32(a);
  return validate_int32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vcvtq_f32_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (const int32_t *)impl.test_cases_int_pointer1;
  float _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = _a[i];
  }

  int32x4_t a = vld1q_s32(_a);
  float32x4_t c = vcvtq_f32_s32(a);
  return validate_float(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vcvtq_f32_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (const uint32_t *)impl.test_cases_int_pointer1;
  float _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = _a[i];
  }

  uint32x4_t a = vld1q_u32(_a);
  float32x4_t c = vcvtq_f32_u32(a);
  return validate_float(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vcvts_f32_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvts_f32_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvt_f64_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtq_f64_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvt_f64_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtq_f64_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtd_f64_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtd_f64_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtq_u32_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (const float *)impl.test_cases_float_pointer1;
  uint32_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = _a[i];
  }

  float32x4_t a = vld1q_f32(_a);
  uint32x4_t c = vcvtq_u32_f32(a);
  return validate_uint32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vcvtn_s32_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtnq_s32_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtn_u32_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtnq_u32_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtm_s32_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtmq_s32_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtm_u32_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtmq_u32_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtp_s32_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtpq_s32_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtp_u32_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtpq_u32_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvta_s32_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtaq_s32_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvta_u32_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtaq_u32_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvts_s32_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvts_u32_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtns_s32_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtns_u32_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtms_s32_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtms_u32_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtps_s32_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtps_u32_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtas_s32_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtas_u32_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvt_s64_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtq_s64_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvt_u64_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtq_u64_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtn_s64_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtnq_s64_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtn_u64_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtnq_u64_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtm_s64_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtmq_s64_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtm_u64_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtmq_u64_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtp_s64_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtpq_s64_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtp_u64_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtpq_u64_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvta_s64_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtaq_s64_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvta_u64_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtaq_u64_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtd_s64_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtd_u64_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtnd_s64_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtnd_u64_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtmd_s64_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtmd_u64_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtpd_s64_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtpd_u64_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtad_s64_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtad_u64_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvt_n_s32_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (const float *)impl.test_cases_float_pointer1;
  int32_t _c[2];
  float32x2_t a = vld1_f32(_a);
  int32x2_t c;

#define TEST_IMPL(IDX)                  \
  for (int i = 0; i < 2; i++) {         \
    _c[i] = _a[i] * powf(2, (IDX + 1)); \
  }                                     \
  c = vcvt_n_s32_f32(a, (IDX + 1));     \
  CHECK_RESULT(validate_int32(c, _c[0], _c[1]))

  IMM_32_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vcvt_n_f32_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvt_n_f32_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvt_n_u32_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtq_n_s32_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtq_n_f32_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtq_n_f32_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvts_n_f32_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvts_n_f32_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvt_n_f64_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtq_n_f64_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvt_n_f64_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtq_n_f64_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtd_n_f64_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtd_n_f64_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvt_f16_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvt_high_f16_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvt_f32_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvt_high_f32_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvt_f32_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvt_high_f32_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvt_f64_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvt_high_f64_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtx_f32_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtxd_f32_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtx_high_f32_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtq_n_u32_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvts_n_s32_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvts_n_u32_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvt_n_s64_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtq_n_s64_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvt_n_u64_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtq_n_u64_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtd_n_s64_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtd_n_u64_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmovn_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  int8_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = _a[i] & UINT8_MAX;
  }
  int16x8_t a = vld1q_s16(_a);
  int8x8_t c = vmovn_s16(a);
  return validate_int8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmovn_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  int16_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = _a[i] & UINT16_MAX;
  }
  int32x4_t a = vld1q_s32(_a);
  int16x4_t c = vmovn_s32(a);
  return validate_int16(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmovn_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (int64_t *)impl.test_cases_int_pointer1;
  int32_t _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = _a[i] & UINT32_MAX;
  }
  int64x2_t a = vld1q_s64(_a);
  int32x2_t c = vmovn_s64(a);
  return validate_int32(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmovn_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  uint8_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = _a[i] & UINT8_MAX;
  }
  uint16x8_t a = vld1q_u16(_a);
  uint8x8_t c = vmovn_u16(a);
  return validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmovn_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  uint16_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = _a[i] & UINT16_MAX;
  }
  uint32x4_t a = vld1q_u32(_a);
  uint16x4_t c = vmovn_u32(a);
  return validate_uint16(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmovn_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (uint64_t *)impl.test_cases_int_pointer1;
  uint32_t _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = _a[i] & UINT32_MAX;
  }
  uint64x2_t a = vld1q_u64(_a);
  uint32x2_t c = vmovn_u64(a);
  return validate_uint32(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmovn_high_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmovn_high_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmovn_high_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmovn_high_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmovn_high_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmovn_high_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqmovn_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  int8_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = saturate_int8(_a[i]);
  }
  int16x8_t a = vld1q_s16(_a);
  int8x8_t c = vqmovn_s16(a);
  return validate_int8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqmovn_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  int16_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = saturate_int16(_a[i]);
  }
  int32x4_t a = vld1q_s32(_a);
  int16x4_t c = vqmovn_s32(a);
  return validate_int16(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqmovn_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (int64_t *)impl.test_cases_int_pointer1;
  int32_t _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = saturate_int32(_a[i]);
  }
  int64x2_t a = vld1q_s64(_a);
  int32x2_t c = vqmovn_s64(a);
  return validate_int32(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqmovn_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  uint8_t _c[8];
  for (int i = 0; i < 8; i++) {
    if (_a[i] < 0) {
    }
    _c[i] = saturate_uint8(_a[i]);
  }
  uint16x8_t a = vld1q_u16(_a);
  uint8x8_t c = vqmovn_u16(a);
  return validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqmovn_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  uint16_t _c[4];
  for (int i = 0; i < 4; i++) {
    if (_a[i] > UINT16_MAX) {
      _c[i] = UINT16_MAX;
    } else {
      _c[i] = _a[i];
    }
  }
  uint32x4_t a = vld1q_u32(_a);
  uint16x4_t c = vqmovn_u32(a);
  return validate_uint16(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqmovn_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (uint64_t *)impl.test_cases_int_pointer1;
  uint32_t _c[2];
  for (int i = 0; i < 2; i++) {
    if (_a[i] > UINT32_MAX) {
      _c[i] = UINT32_MAX;
    } else {
      _c[i] = _a[i];
    }
  }
  uint64x2_t a = vld1q_u64(_a);
  uint32x2_t c = vqmovn_u64(a);
  return validate_uint32(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqmovnh_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqmovns_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqmovnd_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqmovnh_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqmovns_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqmovnd_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqmovn_high_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqmovn_high_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqmovn_high_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqmovn_high_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqmovn_high_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqmovn_high_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqmovun_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  int8_t _c[8];
  for (int i = 0; i < 8; i++) {
    if (_a[i] < 0) {
      _c[i] = 0;
    } else if (_a[i] > UINT8_MAX) {
      _c[i] = UINT8_MAX;
    } else {
      _c[i] = _a[i];
    }
  }
  int16x8_t a = vld1q_s16(_a);
  uint8x8_t c = vqmovun_s16(a);
  return validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqmovun_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  int16_t _c[4];
  for (int i = 0; i < 4; i++) {
    if (_a[i] < 0) {
      _c[i] = 0;
    } else if (_a[i] > UINT16_MAX) {
      _c[i] = UINT16_MAX;
    } else {
      _c[i] = _a[i];
    }
  }
  int32x4_t a = vld1q_s32(_a);
  uint16x4_t c = vqmovun_s32(a);
  return validate_uint16(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqmovun_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (int64_t *)impl.test_cases_int_pointer1;
  int32_t _c[2];
  for (int i = 0; i < 2; i++) {
    if (_a[i] < 0) {
      _c[i] = 0;
    } else if (_a[i] > UINT32_MAX) {
      _c[i] = UINT32_MAX;
    } else {
      _c[i] = _a[i];
    }
  }
  int64x2_t a = vld1q_s64(_a);
  uint32x2_t c = vqmovun_s64(a);
  return validate_uint32(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqmovunh_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqmovuns_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqmovund_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqmovun_high_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqmovun_high_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqmovun_high_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmovl_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  int16_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = _a[i];
  }
  int8x8_t a = vld1_s8(_a);
  int16x8_t c = vmovl_s8(a);
  return validate_int16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmovl_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  int32_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = _a[i];
  }
  int16x4_t a = vld1_s16(_a);
  int32x4_t c = vmovl_s16(a);
  return validate_int32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmovl_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  int64_t _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = _a[i];
  }
  int32x2_t a = vld1_s32(_a);
  int64x2_t c = vmovl_s32(a);
  return validate_int64(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmovl_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (uint8_t *)impl.test_cases_int_pointer1;
  uint16_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = _a[i];
  }
  uint8x8_t a = vld1_u8(_a);
  uint16x8_t c = vmovl_u8(a);
  return validate_uint16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmovl_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  uint32_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = _a[i];
  }
  uint16x4_t a = vld1_u16(_a);
  uint32x4_t c = vmovl_u16(a);
  return validate_uint32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmovl_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  uint64_t _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = _a[i];
  }
  uint32x2_t a = vld1_u32(_a);
  uint64x2_t c = vmovl_u32(a);
  return validate_uint64(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmovl_high_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmovl_high_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmovl_high_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmovl_high_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmovl_high_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmovl_high_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vtbl1_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (int8_t *)impl.test_cases_int_pointer2;
  int8_t _c[8];
  for (int i = 0; i < 8; i++) {
    if (_b[i] > 7 || _b[i] < 0) {
      _c[i] = 0;
    } else {
      _c[i] = _a[_b[i]];
    }
  }

  int8x8_t a = vld1_s8(_a);
  int8x8_t b = vld1_s8(_b);
  int8x8_t c = vtbl1_s8(a, b);
  return validate_int8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vtbl1_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (uint8_t *)impl.test_cases_int_pointer2;
  uint8_t _c[8];
  for (int i = 0; i < 8; i++) {
    if (_b[i] > 7 || _b[i] < 0) {
      _c[i] = 0;
    } else {
      _c[i] = _a[_b[i]];
    }
  }

  uint8x8_t a = vld1_u8(_a);
  uint8x8_t b = vld1_u8(_b);
  uint8x8_t c = vtbl1_u8(a, b);
  return validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vtbl1_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vtbl2_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (int8_t *)impl.test_cases_int_pointer2;
  int8_t _a2[16];
  int8_t _c[16];
  // organize input array
  for (int i = 0; i < 8; i++) {
    _a2[i] = _a[2 * i];
    _a2[i + 8] = _a[2 * i + 1];
  }

  for (int i = 0; i < 8; i++) {
    if (_b[i] > 15 || _b[i] < 0) {
      _c[i] = 0;
    } else {
      _c[i] = _a2[_b[i]];
    }
  }
  int8x8x2_t a = vld2_s8(_a);
  int8x8_t b = vld1_s8(_b);
  int8x8_t c = vtbl2_s8(a, b);
  return validate_int8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vtbl2_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (uint8_t *)impl.test_cases_int_pointer2;
  uint8_t _a2[16];
  uint8_t _c[8];
  // organize input array
  for (int i = 0; i < 8; i++) {
    _a2[i] = _a[2 * i];
    _a2[i + 8] = _a[2 * i + 1];
  }

  for (int i = 0; i < 8; i++) {
    if (_b[i] > 15 || _b[i] < 0) {
      _c[i] = 0;
    } else {
      _c[i] = _a2[_b[i]];
    }
  }

  uint8x8x2_t a = vld2_u8(_a);
  uint8x8_t b = vld1_u8(_b);
  uint8x8_t c = vtbl2_u8(a, b);
  return validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vtbl2_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vtbl3_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *in1 = (int8_t *)impl.test_cases_int_pointer1;
  const int8_t *in2 = (int8_t *)impl.test_cases_int_pointer2;
  const int8_t *_b = (int8_t *)impl.test_cases_int_pointer3;
  const size_t reg_elt_num = 8;
  int8_t _in_interleave[32];
  int8_t _a[24];
  int8_t _c[8];
  merge_arrays(in1, in2, _in_interleave, reg_elt_num);
  // organize input array
  for (int i = 0; i < 8; i++) {
    _a[i] = _in_interleave[3 * i];
    _a[i + 8] = _in_interleave[3 * i + 1];
    _a[i + 16] = _in_interleave[3 * i + 2];
  }
  for (int i = 0; i < 8; i++) {
    if (_b[i] > 23 || _b[i] < 0) {
      _c[i] = 0;
    } else {
      _c[i] = _a[_b[i]];
    }
  }

  int8x8x3_t a = vld3_s8(_in_interleave);
  int8x8_t b = vld1_s8(_b);
  int8x8_t c = vtbl3_s8(a, b);
  return validate_int8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vtbl3_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *in1 = (uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *in2 = (uint8_t *)impl.test_cases_int_pointer2;
  const uint8_t *_b = (uint8_t *)impl.test_cases_int_pointer3;
  const size_t reg_elt_num = 8;
  uint8_t _in_interleave[32];
  uint8_t _a[24];
  uint8_t _c[8];
  merge_arrays(in1, in2, _in_interleave, reg_elt_num);
  // organize input array
  for (int i = 0; i < 8; i++) {
    _a[i] = _in_interleave[3 * i];
    _a[i + 8] = _in_interleave[3 * i + 1];
    _a[i + 16] = _in_interleave[3 * i + 2];
  }
  for (int i = 0; i < 8; i++) {
    if (_b[i] > 23 || _b[i] < 0) {
      _c[i] = 0;
    } else {
      _c[i] = _a[_b[i]];
    }
  }

  uint8x8x3_t a = vld3_u8(_in_interleave);
  uint8x8_t b = vld1_u8(_b);
  uint8x8_t c = vtbl3_u8(a, b);
  return validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vtbl3_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vtbl4_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *in1 = (int8_t *)impl.test_cases_int_pointer1;
  const int8_t *in2 = (int8_t *)impl.test_cases_int_pointer2;
  const int8_t *_b = (int8_t *)impl.test_cases_int_pointer3;
  const size_t reg_elt_num = 8;
  int8_t _in_interleave[32];
  int8_t _a[32];
  int8_t _c[8];
  merge_arrays(in1, in2, _in_interleave, reg_elt_num);
  // organize input array
  for (int i = 0; i < 8; i++) {
    _a[i] = _in_interleave[4 * i];
    _a[i + 8] = _in_interleave[4 * i + 1];
    _a[i + 16] = _in_interleave[4 * i + 2];
    _a[i + 24] = _in_interleave[4 * i + 3];
  }
  for (int i = 0; i < 8; i++) {
    if (_b[i] > 31 || _b[i] < 0) {
      _c[i] = 0;
    } else {
      _c[i] = _a[_b[i]];
    }
  }

  int8x8x4_t a = vld4_s8(_in_interleave);
  int8x8_t b = vld1_s8(_b);
  int8x8_t c = vtbl4_s8(a, b);
  return validate_int8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vtbl4_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *in1 = (uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *in2 = (uint8_t *)impl.test_cases_int_pointer2;
  const uint8_t *_b = (uint8_t *)impl.test_cases_int_pointer3;
  const size_t reg_elt_num = 8;
  uint8_t _in_interleave[32];
  uint8_t _a[32];
  uint8_t _c[8];
  merge_arrays(in1, in2, _in_interleave, reg_elt_num);
  // organize input array
  for (int i = 0; i < 8; i++) {
    _a[i] = _in_interleave[4 * i];
    _a[i + 8] = _in_interleave[4 * i + 1];
    _a[i + 16] = _in_interleave[4 * i + 2];
    _a[i + 24] = _in_interleave[4 * i + 3];
  }
  for (int i = 0; i < 8; i++) {
    if (_b[i] > 31 || _b[i] < 0) {
      _c[i] = 0;
    } else {
      _c[i] = _a[_b[i]];
    }
  }

  uint8x8x4_t a = vld4_u8(_in_interleave);
  uint8x8_t b = vld1_u8(_b);
  uint8x8_t c = vtbl4_u8(a, b);
  return validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vtbl4_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vtbx1_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (int8_t *)impl.test_cases_int_pointer2;
  const int8_t *_c = (int8_t *)impl.test_cases_int_pointer3;
  int8_t _d[8];
  for (int i = 0; i < 8; i++) {
    if (_c[i] > 7 || _c[i] < 0) {
      _d[i] = _a[i];
    } else {
      _d[i] = _b[_c[i]];
    }
  }

  int8x8_t a = vld1_s8(_a);
  int8x8_t b = vld1_s8(_b);
  int8x8_t c = vld1_s8(_c);
  int8x8_t d = vtbx1_s8(a, b, c);
  return validate_int8(d, _d[0], _d[1], _d[2], _d[3], _d[4], _d[5], _d[6], _d[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vtbx1_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (uint8_t *)impl.test_cases_int_pointer2;
  const uint8_t *_c = (uint8_t *)impl.test_cases_int_pointer3;
  uint8_t _d[8];
  for (int i = 0; i < 8; i++) {
    if (_c[i] > 7 || _c[i] < 0) {
      _d[i] = _a[i];
    } else {
      _d[i] = _b[_c[i]];
    }
  }

  uint8x8_t a = vld1_u8(_a);
  uint8x8_t b = vld1_u8(_b);
  uint8x8_t c = vld1_u8(_c);
  uint8x8_t d = vtbx1_u8(a, b, c);
  return validate_uint8(d, _d[0], _d[1], _d[2], _d[3], _d[4], _d[5], _d[6], _d[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vtbx1_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vtbx2_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  const int8_t *in1 = (int8_t *)impl.test_cases_int_pointer2;
  const int8_t *in2 = (int8_t *)impl.test_cases_int_pointer3;
  const int8_t *_c = (int8_t *)impl.test_cases_int_pointer4;
  const size_t reg_elt_num = 8;
  int8_t _in_interleave[32];
  int8_t _b[16];
  int8_t _d[8];
  merge_arrays(in1, in2, _in_interleave, reg_elt_num);
  // organize input array
  for (int i = 0; i < 8; i++) {
    _b[i] = _in_interleave[2 * i];
    _b[i + 8] = _in_interleave[2 * i + 1];
  }
  for (int i = 0; i < 8; i++) {
    if (_c[i] > 15 || _c[i] < 0) {
      _d[i] = _a[i];
    } else {
      _d[i] = _b[_c[i]];
    }
  }

  int8x8_t a = vld1_s8(_a);
  int8x8x2_t b = vld2_s8(_in_interleave);
  int8x8_t c = vld1_s8(_c);
  int8x8_t d = vtbx2_s8(a, b, c);
  return validate_int8(d, _d[0], _d[1], _d[2], _d[3], _d[4], _d[5], _d[6], _d[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vtbx2_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *in1 = (uint8_t *)impl.test_cases_int_pointer2;
  const uint8_t *in2 = (uint8_t *)impl.test_cases_int_pointer3;
  const uint8_t *_c = (uint8_t *)impl.test_cases_int_pointer4;
  const size_t reg_elt_num = 8;
  uint8_t _in_interleave[32];
  uint8_t _b[16];
  uint8_t _d[8];
  merge_arrays(in1, in2, _in_interleave, reg_elt_num);
  // organize input array
  for (int i = 0; i < 8; i++) {
    _b[i] = _in_interleave[2 * i];
    _b[i + 8] = _in_interleave[2 * i + 1];
  }
  for (int i = 0; i < 8; i++) {
    if (_c[i] > 15 || _c[i] < 0) {
      _d[i] = _a[i];
    } else {
      _d[i] = _b[_c[i]];
    }
  }

  uint8x8_t a = vld1_u8(_a);
  uint8x8x2_t b = vld2_u8(_in_interleave);
  uint8x8_t c = vld1_u8(_c);
  uint8x8_t d = vtbx2_u8(a, b, c);
  return validate_uint8(d, _d[0], _d[1], _d[2], _d[3], _d[4], _d[5], _d[6], _d[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vtbx2_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vtbx3_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  const int8_t *in1 = (int8_t *)impl.test_cases_int_pointer2;
  const int8_t *in2 = (int8_t *)impl.test_cases_int_pointer3;
  const int8_t *_c = (int8_t *)impl.test_cases_int_pointer4;
  const size_t reg_elt_num = 8;
  int8_t _in_interleave[32];
  int8_t _b[24];
  int8_t _d[8];
  merge_arrays(in1, in2, _in_interleave, reg_elt_num);
  // organize input array
  for (int i = 0; i < 8; i++) {
    _b[i] = _in_interleave[3 * i];
    _b[i + 8] = _in_interleave[3 * i + 1];
    _b[i + 16] = _in_interleave[3 * i + 2];
  }
  for (int i = 0; i < 8; i++) {
    if (_c[i] > 23 || _c[i] < 0) {
      _d[i] = _a[i];
    } else {
      _d[i] = _b[_c[i]];
    }
  }

  int8x8_t a = vld1_s8(_a);
  int8x8x3_t b = vld3_s8(_in_interleave);
  int8x8_t c = vld1_s8(_c);
  int8x8_t d = vtbx3_s8(a, b, c);
  return validate_int8(d, _d[0], _d[1], _d[2], _d[3], _d[4], _d[5], _d[6], _d[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vtbx3_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *in1 = (uint8_t *)impl.test_cases_int_pointer2;
  const uint8_t *in2 = (uint8_t *)impl.test_cases_int_pointer3;
  const uint8_t *_c = (uint8_t *)impl.test_cases_int_pointer4;
  const size_t reg_elt_num = 8;
  uint8_t _in_interleave[32];
  uint8_t _b[24];
  uint8_t _d[8];
  merge_arrays(in1, in2, _in_interleave, reg_elt_num);
  // organize input array
  for (int i = 0; i < 8; i++) {
    _b[i] = _in_interleave[3 * i];
    _b[i + 8] = _in_interleave[3 * i + 1];
    _b[i + 16] = _in_interleave[3 * i + 2];
  }
  for (int i = 0; i < 8; i++) {
    if (_c[i] > 23 || _c[i] < 0) {
      _d[i] = _a[i];
    } else {
      _d[i] = _b[_c[i]];
    }
  }

  uint8x8_t a = vld1_u8(_a);
  uint8x8x3_t b = vld3_u8(_in_interleave);
  uint8x8_t c = vld1_u8(_c);
  uint8x8_t d = vtbx3_u8(a, b, c);
  return validate_uint8(d, _d[0], _d[1], _d[2], _d[3], _d[4], _d[5], _d[6], _d[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vtbx3_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vtbx4_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  const int8_t *in1 = (int8_t *)impl.test_cases_int_pointer2;
  const int8_t *in2 = (int8_t *)impl.test_cases_int_pointer3;
  const int8_t *_c = (int8_t *)impl.test_cases_int_pointer4;
  const size_t reg_elt_num = 8;
  int8_t _in_interleave[32];
  int8_t _b[32];
  int8_t _d[8];
  merge_arrays(in1, in2, _in_interleave, reg_elt_num);
  // organize input array
  for (int i = 0; i < 8; i++) {
    _b[i] = _in_interleave[4 * i];
    _b[i + 8] = _in_interleave[4 * i + 1];
    _b[i + 16] = _in_interleave[4 * i + 2];
    _b[i + 24] = _in_interleave[4 * i + 3];
  }
  for (int i = 0; i < 8; i++) {
    if (_c[i] > 31 || _c[i] < 0) {
      _d[i] = _a[i];
    } else {
      _d[i] = _b[_c[i]];
    }
  }

  int8x8_t a = vld1_s8(_a);
  int8x8x4_t b = vld4_s8(_in_interleave);
  int8x8_t c = vld1_s8(_c);
  int8x8_t d = vtbx4_s8(a, b, c);
  return validate_int8(d, _d[0], _d[1], _d[2], _d[3], _d[4], _d[5], _d[6], _d[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vtbx4_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *in1 = (uint8_t *)impl.test_cases_int_pointer2;
  const uint8_t *in2 = (uint8_t *)impl.test_cases_int_pointer3;
  const uint8_t *_c = (uint8_t *)impl.test_cases_int_pointer4;
  const size_t reg_elt_num = 8;
  uint8_t _in_interleave[32];
  uint8_t _b[32];
  uint8_t _d[8];
  merge_arrays(in1, in2, _in_interleave, reg_elt_num);
  // organize input array
  for (int i = 0; i < 8; i++) {
    _b[i] = _in_interleave[4 * i];
    _b[i + 8] = _in_interleave[4 * i + 1];
    _b[i + 16] = _in_interleave[4 * i + 2];
    _b[i + 24] = _in_interleave[4 * i + 3];
  }
  for (int i = 0; i < 8; i++) {
    if (_c[i] > 31 || _c[i] < 0) {
      _d[i] = _a[i];
    } else {
      _d[i] = _b[_c[i]];
    }
  }

  uint8x8_t a = vld1_u8(_a);
  uint8x8x4_t b = vld4_u8(_in_interleave);
  uint8x8_t c = vld1_u8(_c);
  uint8x8_t d = vtbx4_u8(a, b, c);
  return validate_uint8(d, _d[0], _d[1], _d[2], _d[3], _d[4], _d[5], _d[6], _d[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vtbx4_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqtbl1_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqtbl1q_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqtbl1_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqtbl1q_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqtbl1_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqtbl1q_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqtbx1_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqtbx1q_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqtbx1_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqtbx1q_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqtbx1_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqtbx1q_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqtbl2_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqtbl2q_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqtbl2_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqtbl2q_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqtbl2_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqtbl2q_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqtbl3_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqtbl3q_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqtbl3_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqtbl3q_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqtbl3_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqtbl3q_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqtbl4_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqtbl4q_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqtbl4_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqtbl4q_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqtbl4_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqtbl4q_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqtbx2_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqtbx2q_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqtbx2_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqtbx2q_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqtbx2_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqtbx2q_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqtbx3_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqtbx3q_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqtbx3_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqtbx3q_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqtbx3_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqtbx3q_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqtbx4_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqtbx4q_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqtbx4_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqtbx4q_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqtbx4_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqtbx4q_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmul_lane_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  int16_t _c[4];
  int16x4_t a = vld1_s16(_a);
  int16x4_t b = vld1_s16(_b);
  int16x4_t c;

#define TEST_IMPL(IDX)          \
  for (int i = 0; i < 4; i++) { \
    _c[i] = _a[i] * _b[IDX];    \
  }                             \
  c = vmul_lane_s16(a, b, IDX); \
  CHECK_RESULT(validate_int16(c, _c[0], _c[1], _c[2], _c[3]))

  IMM_4_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;

#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmul_lane_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  int32_t _c[2];
  int32x2_t a = vld1_s32(_a);
  int32x2_t b = vld1_s32(_b);
  int32x2_t c;

#define TEST_IMPL(IDX)          \
  for (int i = 0; i < 2; i++) { \
    _c[i] = _a[i] * _b[IDX];    \
  }                             \
  c = vmul_lane_s32(a, b, IDX); \
  CHECK_RESULT(validate_int32(c, _c[0], _c[1]))

  IMM_2_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;

#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmul_lane_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (float *)impl.test_cases_float_pointer1;
  const float *_b = (float *)impl.test_cases_float_pointer2;
  float _c[2];
  float32x2_t a = vld1_f32(_a);
  float32x2_t b = vld1_f32(_b);
  float32x2_t c;

#define TEST_IMPL(IDX)          \
  for (int i = 0; i < 2; i++) { \
    _c[i] = _a[i] * _b[IDX];    \
  }                             \
  c = vmul_lane_f32(a, b, IDX); \
  CHECK_RESULT(validate_float(c, _c[0], _c[1]))

  IMM_2_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;

#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmul_lane_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (uint16_t *)impl.test_cases_int_pointer2;
  uint16_t _c[4];
  uint16x4_t a = vld1_u16(_a);
  uint16x4_t b = vld1_u16(_b);
  uint16x4_t c;

#define TEST_IMPL(IDX)          \
  for (int i = 0; i < 4; i++) { \
    _c[i] = _a[i] * _b[IDX];    \
  }                             \
  c = vmul_lane_u16(a, b, IDX); \
  CHECK_RESULT(validate_uint16(c, _c[0], _c[1], _c[2], _c[3]))

  IMM_4_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;

#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmul_lane_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (uint32_t *)impl.test_cases_int_pointer2;
  uint32_t _c[2];
  uint32x2_t a = vld1_u32(_a);
  uint32x2_t b = vld1_u32(_b);
  uint32x2_t c;

#define TEST_IMPL(IDX)          \
  for (int i = 0; i < 2; i++) { \
    _c[i] = _a[i] * _b[IDX];    \
  }                             \
  c = vmul_lane_u32(a, b, IDX); \
  CHECK_RESULT(validate_uint32(c, _c[0], _c[1]))

  IMM_2_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;

#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmulq_lane_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  int16_t _c[8];
  int16x8_t a = vld1q_s16(_a);
  int16x4_t b = vld1_s16(_b);
  int16x8_t c;

#define TEST_IMPL(IDX)           \
  for (int i = 0; i < 8; i++) {  \
    _c[i] = _a[i] * _b[IDX];     \
  }                              \
  c = vmulq_lane_s16(a, b, IDX); \
  CHECK_RESULT(validate_int16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]))

  IMM_4_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;

#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmulq_lane_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  int32_t _c[4];
  int32x4_t a = vld1q_s32(_a);
  int32x2_t b = vld1_s32(_b);
  int32x4_t c;

#define TEST_IMPL(IDX)           \
  for (int i = 0; i < 4; i++) {  \
    _c[i] = _a[i] * _b[IDX];     \
  }                              \
  c = vmulq_lane_s32(a, b, IDX); \
  CHECK_RESULT(validate_int32(c, _c[0], _c[1], _c[2], _c[3]))

  IMM_2_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;

#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmulq_lane_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (float *)impl.test_cases_float_pointer1;
  const float *_b = (float *)impl.test_cases_float_pointer2;
  float _c[4];
  float32x4_t a = vld1q_f32(_a);
  float32x2_t b = vld1_f32(_b);
  float32x4_t c;

#define TEST_IMPL(IDX)           \
  for (int i = 0; i < 4; i++) {  \
    _c[i] = _a[i] * _b[IDX];     \
  }                              \
  c = vmulq_lane_f32(a, b, IDX); \
  CHECK_RESULT(validate_float(c, _c[0], _c[1], _c[2], _c[3]))

  IMM_2_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;

#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmul_lane_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmulq_lane_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmuls_lane_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmuld_lane_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmul_laneq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmulq_laneq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmul_laneq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmulq_laneq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmul_laneq_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmulq_laneq_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmul_laneq_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmulq_laneq_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmul_laneq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmulq_laneq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmul_laneq_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmulq_laneq_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmuls_laneq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmuld_laneq_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmulq_lane_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (uint16_t *)impl.test_cases_int_pointer2;
  uint16_t _c[8];
  uint16x8_t a = vld1q_u16(_a);
  uint16x4_t b = vld1_u16(_b);
  uint16x8_t c;

#define TEST_IMPL(IDX)           \
  for (int i = 0; i < 8; i++) {  \
    _c[i] = _a[i] * _b[IDX];     \
  }                              \
  c = vmulq_lane_u16(a, b, IDX); \
  CHECK_RESULT(validate_uint16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]))

  IMM_4_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;

#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmulq_lane_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (uint32_t *)impl.test_cases_int_pointer2;
  uint32_t _c[4];
  uint32x4_t a = vld1q_u32(_a);
  uint32x2_t b = vld1_u32(_b);
  uint32x4_t c;

#define TEST_IMPL(IDX)           \
  for (int i = 0; i < 4; i++) {  \
    _c[i] = _a[i] * _b[IDX];     \
  }                              \
  c = vmulq_lane_u32(a, b, IDX); \
  CHECK_RESULT(validate_uint32(c, _c[0], _c[1], _c[2], _c[3]))

  IMM_2_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;

#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmla_lane_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  const int16_t *_c = (int16_t *)impl.test_cases_int_pointer3;
  int16_t _d[4];
  int16x4_t a = vld1_s16(_a);
  int16x4_t b = vld1_s16(_b);
  int16x4_t c = vld1_s16(_c);
  int16x4_t d;

#define TEST_IMPL(IDX)               \
  for (int i = 0; i < 4; i++) {      \
    _d[i] = _a[i] + _b[i] * _c[IDX]; \
  }                                  \
  d = vmla_lane_s16(a, b, c, IDX);   \
  CHECK_RESULT(validate_int16(d, _d[0], _d[1], _d[2], _d[3]))

  IMM_4_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmla_lane_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmla_lane_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmla_lane_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmla_lane_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmlaq_lane_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  const int16_t *_c = (int16_t *)impl.test_cases_int_pointer3;
  int16_t _d[8];
  int16x8_t a = vld1q_s16(_a);
  int16x8_t b = vld1q_s16(_b);
  int16x4_t c = vld1_s16(_c);
  int16x8_t d;

#define TEST_IMPL(IDX)               \
  for (int i = 0; i < 8; i++) {      \
    _d[i] = _a[i] + _b[i] * _c[IDX]; \
  }                                  \
  d = vmlaq_lane_s16(a, b, c, IDX);  \
  CHECK_RESULT(validate_int16(d, _d[0], _d[1], _d[2], _d[3], _d[4], _d[5], _d[6], _d[7]))

  IMM_4_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmlaq_lane_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  const int32_t *_c = (int32_t *)impl.test_cases_int_pointer3;
  int32_t _d[4];
  int32x4_t a = vld1q_s32(_a);
  int32x4_t b = vld1q_s32(_b);
  int32x2_t c = vld1_s32(_c);
  int32x4_t d;

#define TEST_IMPL(IDX)               \
  for (int i = 0; i < 4; i++) {      \
    _d[i] = _a[i] + _b[i] * _c[IDX]; \
  }                                  \
  d = vmlaq_lane_s32(a, b, c, IDX);  \
  CHECK_RESULT(validate_int32(d, _d[0], _d[1], _d[2], _d[3]))

  IMM_2_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmlaq_lane_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (float *)impl.test_cases_float_pointer1;
  const float *_b = (float *)impl.test_cases_float_pointer2;
  const float *_c = (float *)impl.test_cases_float_pointer3;
  float _d[4];
  float32x4_t a = vld1q_f32(_a);
  float32x4_t b = vld1q_f32(_b);
  float32x2_t c = vld1_f32(_c);
  float32x4_t d;

#define TEST_IMPL(IDX)               \
  for (int i = 0; i < 4; i++) {      \
    _d[i] = _a[i] + _b[i] * _c[IDX]; \
  }                                  \
  d = vmlaq_lane_f32(a, b, c, IDX);  \
  CHECK_RESULT(validate_float_error(d, _d[0], _d[1], _d[2], _d[3], 0.00001f))

  IMM_2_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmla_laneq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmlaq_laneq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmla_laneq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmlaq_laneq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmla_laneq_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmlaq_laneq_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmla_laneq_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmlaq_laneq_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmla_laneq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmlaq_laneq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmlaq_lane_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (uint16_t *)impl.test_cases_int_pointer2;
  const uint16_t *_c = (uint16_t *)impl.test_cases_int_pointer3;
  uint16_t _d[8];
  uint16x8_t a = vld1q_u16(_a);
  uint16x8_t b = vld1q_u16(_b);
  uint16x4_t c = vld1_u16(_c);
  uint16x8_t d;

#define TEST_IMPL(IDX)               \
  for (int i = 0; i < 8; i++) {      \
    _d[i] = _a[i] + _b[i] * _c[IDX]; \
  }                                  \
  d = vmlaq_lane_u16(a, b, c, IDX);  \
  CHECK_RESULT(validate_uint16(d, _d[0], _d[1], _d[2], _d[3], _d[4], _d[5], _d[6], _d[7]))

  IMM_4_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmlaq_lane_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (uint32_t *)impl.test_cases_int_pointer2;
  const uint32_t *_c = (uint32_t *)impl.test_cases_int_pointer3;
  uint32_t _d[4];
  uint32x4_t a = vld1q_u32(_a);
  uint32x4_t b = vld1q_u32(_b);
  uint32x2_t c = vld1_u32(_c);
  uint32x4_t d;

#define TEST_IMPL(IDX)               \
  for (int i = 0; i < 4; i++) {      \
    _d[i] = _a[i] + _b[i] * _c[IDX]; \
  }                                  \
  d = vmlaq_lane_u32(a, b, c, IDX);  \
  CHECK_RESULT(validate_uint32(d, _d[0], _d[1], _d[2], _d[3]))

  IMM_2_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmlal_lane_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  const int16_t *_c = (int16_t *)impl.test_cases_int_pointer3;
  int32_t _d[4];
  int32x4_t a = vld1q_s32(_a);
  int16x4_t b = vld1_s16(_b);
  int16x4_t c = vld1_s16(_c);
  int32x4_t d;

#define TEST_IMPL(IDX)                                 \
  for (int i = 0; i < 4; i++) {                        \
    _d[i] = _a[i] + (int32_t)_b[i] * (int32_t)_c[IDX]; \
  }                                                    \
  d = vmlal_lane_s16(a, b, c, IDX);                    \
  CHECK_RESULT(validate_int32(d, _d[0], _d[1], _d[2], _d[3]))

  IMM_4_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmlal_lane_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (int64_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  const int32_t *_c = (int32_t *)impl.test_cases_int_pointer3;
  int64_t _d[2];
  int64x2_t a = vld1q_s64(_a);
  int32x2_t b = vld1_s32(_b);
  int32x2_t c = vld1_s32(_c);
  int64x2_t d;

#define TEST_IMPL(IDX)                                 \
  for (int i = 0; i < 2; i++) {                        \
    _d[i] = _a[i] + (int64_t)_b[i] * (int64_t)_c[IDX]; \
  }                                                    \
  d = vmlal_lane_s32(a, b, c, IDX);                    \
  CHECK_RESULT(validate_int64(d, _d[0], _d[1]))

  IMM_2_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmlal_lane_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (uint16_t *)impl.test_cases_int_pointer2;
  const uint16_t *_c = (uint16_t *)impl.test_cases_int_pointer3;
  uint32_t _d[4];
  uint32x4_t a = vld1q_u32(_a);
  uint16x4_t b = vld1_u16(_b);
  uint16x4_t c = vld1_u16(_c);
  uint32x4_t d;

#define TEST_IMPL(IDX)                                   \
  for (int i = 0; i < 4; i++) {                          \
    _d[i] = _a[i] + (uint32_t)_b[i] * (uint32_t)_c[IDX]; \
  }                                                      \
  d = vmlal_lane_u16(a, b, c, IDX);                      \
  CHECK_RESULT(validate_uint32(d, _d[0], _d[1], _d[2], _d[3]))

  IMM_4_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmlal_lane_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (uint64_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (uint32_t *)impl.test_cases_int_pointer2;
  const uint32_t *_c = (uint32_t *)impl.test_cases_int_pointer3;
  uint64_t _d[2];
  uint64x2_t a = vld1q_u64(_a);
  uint32x2_t b = vld1_u32(_b);
  uint32x2_t c = vld1_u32(_c);
  uint64x2_t d;

#define TEST_IMPL(IDX)                                   \
  for (int i = 0; i < 2; i++) {                          \
    _d[i] = _a[i] + (uint64_t)_b[i] * (uint64_t)_c[IDX]; \
  }                                                      \
  d = vmlal_lane_u32(a, b, c, IDX);                      \
  CHECK_RESULT(validate_uint64(d, _d[0], _d[1]))

  IMM_2_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmlal_high_lane_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmlal_high_lane_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmlal_high_lane_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmlal_high_lane_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmlal_laneq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmlal_laneq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmlal_laneq_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmlal_laneq_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmlal_high_laneq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmlal_high_laneq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmlal_high_laneq_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmlal_high_laneq_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqdmlal_lane_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  const int16_t *_c = (int16_t *)impl.test_cases_int_pointer3;
  int32x4_t a, d;
  int16x4_t b, c;
  int32_t _d[4];
#define TEST_IMPL(IDX)                                  \
  for (int i = 0; i < 4; i++) {                         \
    int32_t bcx2 = saturate_int32(2 * _b[i] * _c[IDX]); \
    _d[i] = saturate_int32(_a[i] + bcx2);               \
  }                                                     \
                                                        \
  a = vld1q_s32(_a);                                    \
  b = vld1_s16(_b);                                     \
  c = vld1_s16(_c);                                     \
  d = vqdmlal_lane_s16(a, b, c, IDX);                   \
  CHECK_RESULT(validate_int32(d, _d[0], _d[1], _d[2], _d[3]))

  IMM_4_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqdmlal_lane_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (int64_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  const int32_t *_c = (int32_t *)impl.test_cases_int_pointer3;
  int64x2_t a, d;
  int32x2_t b, c;
  int64_t _d[2];

#define TEST_IMPL(IDX)                                                             \
  for (int i = 0; i < 2; i++) {                                                    \
    int64_t tmp = (((int64_t)_b[i] * (int64_t)_c[IDX]) >> 32) * 2 + (_a[i] >> 32); \
    if (tmp > INT64_MAX) {                                                         \
      _d[i] = INT64_MAX;                                                           \
    } else if (tmp < INT64_MIN) {                                                  \
      _d[i] = INT64_MIN;                                                           \
    } else {                                                                       \
      _d[i] = (int64_t)_b[i] * (int64_t)_c[IDX] * 2 + _a[i];                       \
    }                                                                              \
  }                                                                                \
                                                                                   \
  a = vld1q_s64(_a);                                                               \
  b = vld1_s32(_b);                                                                \
  c = vld1_s32(_c);                                                                \
  d = vqdmlal_lane_s32(a, b, c, IDX);                                              \
  CHECK_RESULT(validate_int64(d, _d[0], _d[1]))

  IMM_2_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqdmlalh_lane_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqdmlals_lane_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqdmlal_high_lane_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqdmlal_high_lane_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqdmlal_laneq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqdmlal_laneq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqdmlalh_laneq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqdmlals_laneq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqdmlal_high_laneq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqdmlal_high_laneq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmls_lane_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  const int16_t *_c = (int16_t *)impl.test_cases_int_pointer3;
  int16_t _d[4];
  int16x4_t a = vld1_s16(_a);
  int16x4_t b = vld1_s16(_b);
  int16x4_t c = vld1_s16(_c);
  int16x4_t d;

#define TEST_IMPL(IDX)               \
  for (int i = 0; i < 4; i++) {      \
    _d[i] = _a[i] - _b[i] * _c[IDX]; \
  }                                  \
  d = vmls_lane_s16(a, b, c, IDX);   \
  CHECK_RESULT(validate_int16(d, _d[0], _d[1], _d[2], _d[3]))

  IMM_4_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmls_lane_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  const int32_t *_c = (int32_t *)impl.test_cases_int_pointer3;
  int32_t _d[2];
  int32x2_t a = vld1_s32(_a);
  int32x2_t b = vld1_s32(_b);
  int32x2_t c = vld1_s32(_c);
  int32x2_t d;

#define TEST_IMPL(IDX)               \
  for (int i = 0; i < 2; i++) {      \
    _d[i] = _a[i] - _b[i] * _c[IDX]; \
  }                                  \
  d = vmls_lane_s32(a, b, c, IDX);   \
  CHECK_RESULT(validate_int32(d, _d[0], _d[1]))

  IMM_2_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmls_lane_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (float *)impl.test_cases_float_pointer1;
  const float *_b = (float *)impl.test_cases_float_pointer2;
  const float *_c = (float *)impl.test_cases_float_pointer3;
  float _d[2];
  float32x2_t a = vld1_f32(_a);
  float32x2_t b = vld1_f32(_b);
  float32x2_t c = vld1_f32(_c);
  float32x2_t d;

#define TEST_IMPL(IDX)               \
  for (int i = 0; i < 2; i++) {      \
    _d[i] = _a[i] - _b[i] * _c[IDX]; \
  }                                  \
  d = vmls_lane_f32(a, b, c, IDX);   \
  CHECK_RESULT(validate_float_error(d, _d[0], _d[1], 0.001f))

  IMM_2_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmls_lane_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (uint16_t *)impl.test_cases_int_pointer2;
  const uint16_t *_c = (uint16_t *)impl.test_cases_int_pointer3;
  uint16_t _d[4];
  uint16x4_t a = vld1_u16(_a);
  uint16x4_t b = vld1_u16(_b);
  uint16x4_t c = vld1_u16(_c);
  uint16x4_t d;

#define TEST_IMPL(IDX)               \
  for (int i = 0; i < 4; i++) {      \
    _d[i] = _a[i] - _b[i] * _c[IDX]; \
  }                                  \
  d = vmls_lane_u16(a, b, c, IDX);   \
  CHECK_RESULT(validate_uint16(d, _d[0], _d[1], _d[2], _d[3]))

  IMM_4_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmls_lane_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (uint32_t *)impl.test_cases_int_pointer2;
  const uint32_t *_c = (uint32_t *)impl.test_cases_int_pointer3;
  uint32_t _d[2];
  uint32x2_t a = vld1_u32(_a);
  uint32x2_t b = vld1_u32(_b);
  uint32x2_t c = vld1_u32(_c);
  uint32x2_t d;

#define TEST_IMPL(IDX)               \
  for (int i = 0; i < 2; i++) {      \
    _d[i] = _a[i] - _b[i] * _c[IDX]; \
  }                                  \
  d = vmls_lane_u32(a, b, c, IDX);   \
  CHECK_RESULT(validate_uint32(d, _d[0], _d[1]))

  IMM_2_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmlsq_lane_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  const int16_t *_c = (int16_t *)impl.test_cases_int_pointer3;
  int16_t _d[8];
  int16x8_t a = vld1q_s16(_a);
  int16x8_t b = vld1q_s16(_b);
  int16x4_t c = vld1_s16(_c);
  int16x8_t d;

#define TEST_IMPL(IDX)               \
  for (int i = 0; i < 8; i++) {      \
    _d[i] = _a[i] - _b[i] * _c[IDX]; \
  }                                  \
  d = vmlsq_lane_s16(a, b, c, IDX);  \
  CHECK_RESULT(validate_int16(d, _d[0], _d[1], _d[2], _d[3], _d[4], _d[5], _d[6], _d[7]))

  IMM_4_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmlsq_lane_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  const int32_t *_c = (int32_t *)impl.test_cases_int_pointer3;
  int32_t _d[4];
  int32x4_t a = vld1q_s32(_a);
  int32x4_t b = vld1q_s32(_b);
  int32x2_t c = vld1_s32(_c);
  int32x4_t d;

#define TEST_IMPL(IDX)               \
  for (int i = 0; i < 4; i++) {      \
    _d[i] = _a[i] - _b[i] * _c[IDX]; \
  }                                  \
  d = vmlsq_lane_s32(a, b, c, IDX);  \
  CHECK_RESULT(validate_int32(d, _d[0], _d[1], _d[2], _d[3]))

  IMM_2_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmlsq_lane_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (float *)impl.test_cases_float_pointer1;
  const float *_b = (float *)impl.test_cases_float_pointer2;
  const float *_c = (float *)impl.test_cases_float_pointer3;
  float _d[4];
  float32x4_t a = vld1q_f32(_a);
  float32x4_t b = vld1q_f32(_b);
  float32x2_t c = vld1_f32(_c);
  float32x4_t d;

#define TEST_IMPL(IDX)               \
  for (int i = 0; i < 4; i++) {      \
    _d[i] = _a[i] - _b[i] * _c[IDX]; \
  }                                  \
  d = vmlsq_lane_f32(a, b, c, IDX);  \
  CHECK_RESULT(validate_float_error(d, _d[0], _d[1], _d[2], _d[3], 0.001f))

  IMM_2_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmls_laneq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmlsq_laneq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmls_laneq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmlsq_laneq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmls_laneq_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmlsq_laneq_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmls_laneq_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmlsq_laneq_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmls_laneq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmlsq_laneq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmlsq_lane_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (uint16_t *)impl.test_cases_int_pointer2;
  const uint16_t *_c = (uint16_t *)impl.test_cases_int_pointer3;
  uint16_t _d[8];
  uint16x8_t a = vld1q_u16(_a);
  uint16x8_t b = vld1q_u16(_b);
  uint16x4_t c = vld1_u16(_c);
  uint16x8_t d;

#define TEST_IMPL(IDX)               \
  for (int i = 0; i < 8; i++) {      \
    _d[i] = _a[i] - _b[i] * _c[IDX]; \
  }                                  \
  d = vmlsq_lane_u16(a, b, c, IDX);  \
  CHECK_RESULT(validate_uint16(d, _d[0], _d[1], _d[2], _d[3], _d[4], _d[5], _d[6], _d[7]))

  IMM_4_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmlsq_lane_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (uint32_t *)impl.test_cases_int_pointer2;
  const uint32_t *_c = (uint32_t *)impl.test_cases_int_pointer3;
  uint32_t _d[4];
  uint32x4_t a = vld1q_u32(_a);
  uint32x4_t b = vld1q_u32(_b);
  uint32x2_t c = vld1_u32(_c);
  uint32x4_t d;

#define TEST_IMPL(IDX)               \
  for (int i = 0; i < 4; i++) {      \
    _d[i] = _a[i] - _b[i] * _c[IDX]; \
  }                                  \
  d = vmlsq_lane_u32(a, b, c, IDX);  \
  CHECK_RESULT(validate_uint32(d, _d[0], _d[1], _d[2], _d[3]))

  IMM_2_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmlsl_lane_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  const int16_t *_c = (int16_t *)impl.test_cases_int_pointer3;
  int32_t _d[4];
  int32x4_t a = vld1q_s32(_a);
  int16x4_t b = vld1_s16(_b);
  int16x4_t c = vld1_s16(_c);
  int32x4_t d;

#define TEST_IMPL(IDX)                                 \
  for (int i = 0; i < 4; i++) {                        \
    _d[i] = _a[i] - (int32_t)_b[i] * (int32_t)_c[IDX]; \
  }                                                    \
  d = vmlsl_lane_s16(a, b, c, IDX);                    \
  CHECK_RESULT(validate_int32(d, _d[0], _d[1], _d[2], _d[3]))

  IMM_4_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmlsl_lane_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (int64_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  const int32_t *_c = (int32_t *)impl.test_cases_int_pointer3;
  int64_t _d[2];
  int64x2_t a = vld1q_s64(_a);
  int32x2_t b = vld1_s32(_b);
  int32x2_t c = vld1_s32(_c);
  int64x2_t d;

#define TEST_IMPL(IDX)                                 \
  for (int i = 0; i < 2; i++) {                        \
    _d[i] = _a[i] - (int64_t)_b[i] * (int64_t)_c[IDX]; \
  }                                                    \
  d = vmlsl_lane_s32(a, b, c, IDX);                    \
  CHECK_RESULT(validate_int64(d, _d[0], _d[1]))

  IMM_2_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmlsl_lane_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (uint16_t *)impl.test_cases_int_pointer2;
  const uint16_t *_c = (uint16_t *)impl.test_cases_int_pointer3;
  uint32_t _d[4];
  uint32x4_t a = vld1q_u32(_a);
  uint16x4_t b = vld1_u16(_b);
  uint16x4_t c = vld1_u16(_c);
  uint32x4_t d;

#define TEST_IMPL(IDX)                                   \
  for (int i = 0; i < 4; i++) {                          \
    _d[i] = _a[i] - (uint32_t)_b[i] * (uint32_t)_c[IDX]; \
  }                                                      \
  d = vmlsl_lane_u16(a, b, c, IDX);                      \
  CHECK_RESULT(validate_uint32(d, _d[0], _d[1], _d[2], _d[3]))

  IMM_4_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmlsl_lane_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (uint64_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (uint32_t *)impl.test_cases_int_pointer2;
  const uint32_t *_c = (uint32_t *)impl.test_cases_int_pointer3;
  uint64_t _d[2];
  uint64x2_t a = vld1q_u64(_a);
  uint32x2_t b = vld1_u32(_b);
  uint32x2_t c = vld1_u32(_c);
  uint64x2_t d;

#define TEST_IMPL(IDX)                                   \
  for (int i = 0; i < 2; i++) {                          \
    _d[i] = _a[i] - (uint64_t)_b[i] * (uint64_t)_c[IDX]; \
  }                                                      \
  d = vmlsl_lane_u32(a, b, c, IDX);                      \
  CHECK_RESULT(validate_uint64(d, _d[0], _d[1]))

  IMM_2_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmlsl_high_lane_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmlsl_high_lane_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmlsl_high_lane_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmlsl_high_lane_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmlsl_laneq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmlsl_laneq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmlsl_laneq_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmlsl_laneq_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmlsl_high_laneq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmlsl_high_laneq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmlsl_high_laneq_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmlsl_high_laneq_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqdmlsl_lane_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  const int16_t *_c = (int16_t *)impl.test_cases_int_pointer3;
  int32x4_t a = vld1q_s32(_a);
  int16x4_t b = vld1_s16(_b);
  int16x4_t c = vld1_s16(_c);
  int32x4_t d;
  int32_t _d[4];

#define TEST_IMPL(IDX)                                  \
  for (int i = 0; i < 4; i++) {                         \
    int32_t bcx2 = saturate_int32(2 * _b[i] * _c[IDX]); \
    _d[i] = saturate_int32(_a[i] - bcx2);               \
  }                                                     \
  d = vqdmlsl_lane_s16(a, b, c, IDX);                   \
  CHECK_RESULT(validate_int32(d, _d[0], _d[1], _d[2], _d[3]))

  IMM_2_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqdmlsl_lane_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (int64_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  const int32_t *_c = (int32_t *)impl.test_cases_int_pointer3;
  int64x2_t a = vld1q_s64(_a);
  int32x2_t b = vld1_s32(_b);
  int32x2_t c = vld1_s32(_c);
  int64x2_t d;
  int64_t _d[2], tmp;
  float b_f, c_f, max_f = (float)INT64_MAX, min_f = (float)INT64_MIN;

#define TEST_IMPL(IDX)                                                                  \
  for (int i = 0; i < 2; i++) {                                                         \
    b_f = _b[i];                                                                        \
    c_f = _c[IDX];                                                                      \
    if ((b_f * c_f > 0) && (2 * b_f * c_f > max_f)) {                                   \
      tmp = INT64_MAX;                                                                  \
    } else if (2 * b_f * c_f < min_f) {                                                 \
      tmp = INT64_MIN;                                                                  \
    } else {                                                                            \
      tmp = 2 * (int64_t)_b[i] * (int64_t)_c[IDX];                                      \
    }                                                                                   \
    if ((tmp > 0 && _a[i] < INT64_MIN + tmp) || (tmp < 0 && _a[i] > INT64_MAX + tmp)) { \
      _d[i] = (tmp > 0) ? INT64_MAX : INT64_MIN;                                        \
    } else {                                                                            \
      _d[i] = (int64_t)_a[i] - tmp;                                                     \
    }                                                                                   \
  }                                                                                     \
  d = vqdmlsl_lane_s32(a, b, c, IDX);                                                   \
  CHECK_RESULT(validate_int64(d, _d[0], _d[1]))

  IMM_2_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqdmlslh_lane_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqdmlsls_lane_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqdmlsl_high_lane_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqdmlsl_high_lane_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqdmlsl_laneq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqdmlsl_laneq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqdmlslh_laneq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqdmlsls_laneq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqdmlsl_high_laneq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqdmlsl_high_laneq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmull_lane_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  int16x4_t a = vld1_s16(_a);
  int16x4_t b = vld1_s16(_b);
  int32x4_t c;
  int32_t _c[4];

#define TEST_IMPL(IDX)                         \
  for (int i = 0; i < 4; i++) {                \
    _c[i] = (int32_t)_a[i] * (int32_t)_b[IDX]; \
  }                                            \
  c = vmull_lane_s16(a, b, IDX);               \
  CHECK_RESULT(validate_int32(c, _c[0], _c[1], _c[2], _c[3]))

  IMM_4_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmull_lane_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  int32x2_t a = vld1_s32(_a);
  int32x2_t b = vld1_s32(_b);
  int64x2_t c;
  int64_t _c[2];

#define TEST_IMPL(IDX)                         \
  for (int i = 0; i < 2; i++) {                \
    _c[i] = (int64_t)_a[i] * (int64_t)_b[IDX]; \
  }                                            \
  c = vmull_lane_s32(a, b, IDX);               \
  CHECK_RESULT(validate_int64(c, _c[0], _c[1]))

  IMM_2_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmull_lane_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (uint16_t *)impl.test_cases_int_pointer2;
  uint16x4_t a = vld1_u16(_a);
  uint16x4_t b = vld1_u16(_b);
  uint32x4_t c;
  uint32_t _c[4];

#define TEST_IMPL(IDX)                           \
  for (int i = 0; i < 4; i++) {                  \
    _c[i] = (uint32_t)_a[i] * (uint32_t)_b[IDX]; \
  }                                              \
  c = vmull_lane_u16(a, b, IDX);                 \
  CHECK_RESULT(validate_uint32(c, _c[0], _c[1], _c[2], _c[3]))

  IMM_4_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmull_lane_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (uint32_t *)impl.test_cases_int_pointer2;
  uint32x2_t a = vld1_u32(_a);
  uint32x2_t b = vld1_u32(_b);
  uint64x2_t c;
  uint64_t _c[2];

#define TEST_IMPL(IDX)                           \
  for (int i = 0; i < 2; i++) {                  \
    _c[i] = (uint64_t)_a[i] * (uint64_t)_b[IDX]; \
  }                                              \
  c = vmull_lane_u32(a, b, IDX);                 \
  CHECK_RESULT(validate_uint64(c, _c[0], _c[1]))

  IMM_2_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmull_high_lane_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmull_high_lane_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmull_high_lane_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmull_high_lane_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmull_laneq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmull_laneq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmull_laneq_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmull_laneq_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmull_high_laneq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmull_high_laneq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmull_high_laneq_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmull_high_laneq_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqdmull_lane_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  int32_t _c[4];
  int16x4_t a = vld1_s16(_a);
  int16x4_t b = vld1_s16(_b);
  int32x4_t c;

#define TEST_IMPL(IDX)                           \
  for (int i = 0; i < 4; i++) {                  \
    _c[i] = saturate_int32(2 * _a[i] * _b[IDX]); \
  }                                              \
  c = vqdmull_lane_s16(a, b, IDX);               \
  CHECK_RESULT(validate_int32(c, _c[0], _c[1], _c[2], _c[3]))

  IMM_4_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqdmull_lane_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  int64_t _c[2];
  int32x2_t a = vld1_s32(_a);
  int32x2_t b = vld1_s32(_b);
  int64x2_t c;
  float a_f, b_f, max_f = (float)INT64_MAX, min_f = (float)INT64_MIN;

#define TEST_IMPL(IDX)                                \
  for (int i = 0; i < 2; i++) {                       \
    a_f = _a[i];                                      \
    b_f = _b[IDX];                                    \
    if ((a_f * b_f > 0) && (2 * a_f * b_f > max_f)) { \
      _c[i] = INT64_MAX;                              \
    } else if (2 * a_f * b_f < min_f) {               \
      _c[i] = INT64_MIN;                              \
    } else {                                          \
      _c[i] = 2 * (int64_t)_a[i] * (int64_t)_b[IDX];  \
    }                                                 \
  }                                                   \
  c = vqdmull_lane_s32(a, b, IDX);                    \
  CHECK_RESULT(validate_int64(c, _c[0], _c[1]))

  IMM_2_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqdmullh_lane_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqdmulls_lane_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqdmull_high_lane_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqdmull_high_lane_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqdmull_laneq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqdmull_laneq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqdmullh_laneq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqdmulls_laneq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqdmull_high_laneq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqdmull_high_laneq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqdmulhq_lane_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  int16x8_t a, c;
  int16x4_t b;
  int16_t _c[8];

#define TEST_IMPL(IDX)                                                   \
  for (int i = 0; i < 8; i++) {                                          \
    _c[i] = saturate_int16(2 * (int32_t)_a[i] * (int32_t)_b[IDX] >> 16); \
  }                                                                      \
                                                                         \
  a = vld1q_s16(_a);                                                     \
  b = vld1_s16(_b);                                                      \
  c = vqdmulhq_lane_s16(a, b, IDX);                                      \
  CHECK_RESULT(validate_int16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]))

  IMM_4_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqdmulhq_lane_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  int32x4_t a, c;
  int32x2_t b;
  int32_t _c[4];

#define TEST_IMPL(IDX)                                                   \
  for (int i = 0; i < 4; i++) {                                          \
    _c[i] = saturate_int32(2 * (int64_t)_a[i] * (int64_t)_b[IDX] >> 32); \
  }                                                                      \
                                                                         \
  a = vld1q_s32(_a);                                                     \
  b = vld1_s32(_b);                                                      \
  c = vqdmulhq_lane_s32(a, b, IDX);                                      \
  CHECK_RESULT(validate_int32(c, _c[0], _c[1], _c[2], _c[3]))

  IMM_2_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqdmulhh_lane_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqdmulhs_lane_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqdmulh_laneq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqdmulhq_laneq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqdmulh_laneq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqdmulhq_laneq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqdmulhh_laneq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqdmulhs_laneq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqdmulh_lane_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  int16x4_t a, b, c;
  int16_t _c[4];

#define TEST_IMPL(IDX)                                                   \
  for (int i = 0; i < 4; i++) {                                          \
    _c[i] = saturate_int16(2 * (int32_t)_a[i] * (int32_t)_b[IDX] >> 16); \
  }                                                                      \
                                                                         \
  a = vld1_s16(_a);                                                      \
  b = vld1_s16(_b);                                                      \
  c = vqdmulh_lane_s16(a, b, IDX);                                       \
  CHECK_RESULT(validate_int16(c, _c[0], _c[1], _c[2], _c[3]))

  IMM_4_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqdmulh_lane_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  int32x2_t a, b, c;
  int32_t _c[2];

#define TEST_IMPL(IDX)                                                   \
  for (int i = 0; i < 2; i++) {                                          \
    _c[i] = saturate_int32(2 * (int64_t)_a[i] * (int64_t)_b[IDX] >> 32); \
  }                                                                      \
                                                                         \
  a = vld1_s32(_a);                                                      \
  b = vld1_s32(_b);                                                      \
  c = vqdmulh_lane_s32(a, b, IDX);                                       \
  CHECK_RESULT(validate_int32(c, _c[0], _c[1]))

  IMM_2_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqrdmulhq_lane_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  int16_t _c[8];
  int16x8_t a, c;
  int16x4_t b;
  const int32_t round = 1 << 15;

#define TEST_IMPL(IDX)                                           \
  for (int i = 0; i < 8; i++) {                                  \
    int32_t tmp = 2 * (int32_t)_a[i] * (int32_t)_b[IDX] + round; \
    _c[i] = saturate_int16(tmp >> 16);                           \
  }                                                              \
                                                                 \
  a = vld1q_s16(_a);                                             \
  b = vld1_s16(_b);                                              \
  c = vqrdmulhq_lane_s16(a, b, IDX);                             \
  CHECK_RESULT(validate_int16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]))

  IMM_4_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqrdmulhq_lane_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  int32_t _c[4];
  int32x4_t a, c;
  int32x2_t b;
  const int64_t round = 1;

#define TEST_IMPL(IDX)                                   \
  for (int i = 0; i < 4; i++) {                          \
    int64_t tmp = 2 * (int64_t)_a[i] * (int64_t)_b[IDX]; \
    tmp = tmp >> 31;                                     \
    tmp += round;                                        \
    _c[i] = saturate_int32(tmp >> 1);                    \
  }                                                      \
  a = vld1q_s32(_a);                                     \
  b = vld1_s32(_b);                                      \
  c = vqrdmulhq_lane_s32(a, b, IDX);                     \
  CHECK_RESULT(validate_int32(c, _c[0], _c[1], _c[2], _c[3]))

  IMM_2_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqrdmulhh_lane_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqrdmulhs_lane_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqrdmulh_laneq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqrdmulhq_laneq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqrdmulh_laneq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqrdmulhq_laneq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqrdmulhh_laneq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqrdmulhs_laneq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqrdmulh_lane_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  int16_t _c[4];
  int16x4_t a, b, c;
  const int32_t round = 1 << 15;

#define TEST_IMPL(IDX)                                           \
  for (int i = 0; i < 4; i++) {                                  \
    int32_t tmp = 2 * (int32_t)_a[i] * (int32_t)_b[IDX] + round; \
    _c[i] = saturate_int16(tmp >> 16);                           \
  }                                                              \
                                                                 \
  a = vld1_s16(_a);                                              \
  b = vld1_s16(_b);                                              \
  c = vqrdmulh_lane_s16(a, b, IDX);                              \
  CHECK_RESULT(validate_int16(c, _c[0], _c[1], _c[2], _c[3]))

  IMM_4_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqrdmulh_lane_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  int32_t _c[2];
  int32x2_t a, b, c;
  const int64_t round = 1;

#define TEST_IMPL(IDX)                                   \
  for (int i = 0; i < 2; i++) {                          \
    int64_t tmp = 2 * (int64_t)_a[i] * (int64_t)_b[IDX]; \
    tmp = tmp >> 31;                                     \
    tmp += round;                                        \
    _c[i] = saturate_int32(tmp >> 1);                    \
  }                                                      \
  a = vld1_s32(_a);                                      \
  b = vld1_s32(_b);                                      \
  c = vqrdmulh_lane_s32(a, b, IDX);                      \
  CHECK_RESULT(validate_int32(c, _c[0], _c[1]))

  IMM_2_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqrdmlahq_lane_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
#if defined(__GNUC__)
  return TEST_UNIMPL;
#else
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  const int16_t *_c = (int16_t *)impl.test_cases_int_pointer3;
  int16_t _d[8];
  const int32_t round_const = 1 << 15;
  int16x8_t a, b, d;
  int16x4_t c;
#define TEST_IMPL(IDX)                                                 \
  for (int i = 0; i < 8; i++) {                                        \
    int32_t tmp = 2 * (int32_t)_b[i] * (int32_t)_c[IDX] + round_const; \
    _d[i] = saturate_int16(_a[i] + (tmp >> 16));                       \
  }                                                                    \
  a = vld1q_s16(_a);                                                   \
  b = vld1q_s16(_b);                                                   \
  c = vld1_s16(_c);                                                    \
  d = vqrdmlahq_lane_s16(a, b, c, IDX);

  IMM_4_ITER
#undef TEST_IMPL

  return validate_int16(d, _d[0], _d[1], _d[2], _d[3], _d[4], _d[5], _d[6], _d[7]);
#endif
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqrdmlah_laneq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqrdmlahq_laneq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqrdmlahq_lane_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
#if defined(__GNUC__)
  return TEST_UNIMPL;
#else
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  const int32_t *_c = (int32_t *)impl.test_cases_int_pointer3;
  int32_t _d[4];
  const int64_t round_const = (int64_t)1 << 31;
  int32x4_t a, b, d;
  int32x2_t c;
#define TEST_IMPL(IDX)                                                 \
  for (int i = 0; i < 4; i++) {                                        \
    int64_t tmp = 2 * (int64_t)_b[i] * (int64_t)_c[IDX] + round_const; \
    _d[i] = saturate_int32(_a[i] + (tmp >> 32));                       \
  }                                                                    \
  a = vld1q_s32(_a);                                                   \
  b = vld1q_s32(_b);                                                   \
  c = vld1_s32(_c);                                                    \
  d = vqrdmlahq_lane_s32(a, b, c, IDX);

  IMM_2_ITER
#undef TEST_IMPL

  return validate_int32(d, _d[0], _d[1], _d[2], _d[3]);
#endif
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqrdmlah_laneq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqrdmlahq_laneq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqrdmlah_lane_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
#if defined(__GNUC__)
  return TEST_UNIMPL;
#else
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  const int16_t *_c = (int16_t *)impl.test_cases_int_pointer3;
  int16_t _d[4];
  const int32_t round_const = 1 << 15;
  int16x4_t a, b, c, d;
#define TEST_IMPL(IDX)                                                 \
  for (int i = 0; i < 4; i++) {                                        \
    int32_t tmp = 2 * (int32_t)_b[i] * (int32_t)_c[IDX] + round_const; \
    _d[i] = saturate_int16(_a[i] + (tmp >> 16));                       \
  }                                                                    \
  a = vld1_s16(_a);                                                    \
  b = vld1_s16(_b);                                                    \
  c = vld1_s16(_c);                                                    \
  d = vqrdmlah_lane_s16(a, b, c, IDX);

  IMM_4_ITER
#undef TEST_IMPL

  return validate_int16(d, _d[0], _d[1], _d[2], _d[3]);
#endif
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqrdmlah_lane_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
#if defined(__GNUC__)
  return TEST_UNIMPL;
#else
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  const int32_t *_c = (int32_t *)impl.test_cases_int_pointer3;
  int32_t _d[2];
  const int64_t round_const = (int64_t)1 << 31;
  int32x2_t a, b, c, d;
#define TEST_IMPL(IDX)                                                 \
  for (int i = 0; i < 2; i++) {                                        \
    int64_t tmp = 2 * (int64_t)_b[i] * (int64_t)_c[IDX] + round_const; \
    _d[i] = saturate_int32(_a[i] + (tmp >> 32));                       \
  }                                                                    \
  a = vld1_s32(_a);                                                    \
  b = vld1_s32(_b);                                                    \
  c = vld1_s32(_c);                                                    \
  d = vqrdmlah_lane_s32(a, b, c, IDX);

  IMM_2_ITER
#undef TEST_IMPL

  return validate_int32(d, _d[0], _d[1]);
#endif
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqrdmlshq_lane_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
#if defined(__GNUC__)
  return TEST_UNIMPL;
#else
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  const int16_t *_c = (int16_t *)impl.test_cases_int_pointer3;
  int16_t _d[8];
  const int32_t round_const = 1 << 15;
  int16x8_t a, b, d;
  int16x4_t c;
#define TEST_IMPL(IDX)                                                  \
  for (int i = 0; i < 8; i++) {                                         \
    int32_t tmp = -2 * (int32_t)_b[i] * (int32_t)_c[IDX] + round_const; \
    _d[i] = saturate_int16(_a[i] - (tmp >> 16));                        \
  }                                                                     \
  a = vld1q_s16(_a);                                                    \
  b = vld1q_s16(_b);                                                    \
  c = vld1_s16(_c);                                                     \
  d = vqrdmlshq_lane_s16(a, b, c, IDX);

  IMM_4_ITER
#undef TEST_IMPL

  return validate_int16(d, _d[0], _d[1], _d[2], _d[3], _d[4], _d[5], _d[6], _d[7]);
#endif
#else
  return TEST_UNIMPL;
#endif
}

result_t test_vqrdmlsh_laneq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqrdmlshq_laneq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqrdmlshq_lane_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
#if defined(__GNUC__)
  return TEST_UNIMPL;
#else
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  const int32_t *_c = (int32_t *)impl.test_cases_int_pointer3;
  int32_t _d[4];
  const int64_t round_const = (int64_t)1 << 31;
  int32x4_t a, b, d;
  int32x2_t c;
#define TEST_IMPL(IDX)                                                  \
  for (int i = 0; i < 4; i++) {                                         \
    int64_t tmp = -2 * (int64_t)_b[i] * (int64_t)_c[IDX] + round_const; \
    _d[i] = saturate_int32(_a[i] - (tmp >> 32));                        \
  }                                                                     \
  a = vld1q_s32(_a);                                                    \
  b = vld1q_s32(_b);                                                    \
  c = vld1_s32(_c);                                                     \
  d = vqrdmlshq_lane_s32(a, b, c, IDX);

  IMM_2_ITER
#undef TEST_IMPL

  return validate_int32(d, _d[0], _d[1], _d[2], _d[3]);
#endif
#else
  return TEST_UNIMPL;
#endif
}

result_t test_vqrdmlsh_laneq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqrdmlshq_laneq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqrdmlahh_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqrdmlahs_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqrdmlshh_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqrdmlshs_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqrdmlahh_lane_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqrdmlahh_laneq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqrdmlahs_lane_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqrdmlahs_laneq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqrdmlshh_lane_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqrdmlshh_laneq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqrdmlshs_lane_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqrdmlshs_laneq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vabsh_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vceqzh_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcgezh_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcgtzh_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vclezh_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcltzh_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvth_f16_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvth_f16_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvth_f16_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvth_f16_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvth_f16_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvth_f16_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvth_s16_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvth_s32_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvth_s64_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvth_u16_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvth_u32_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvth_u64_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtah_s16_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtah_s32_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtah_s64_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtah_u16_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtah_u32_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtah_u64_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtmh_s16_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtmh_s32_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtmh_s64_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtmh_u16_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtmh_u32_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtmh_u64_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtnh_s16_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtnh_s32_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtnh_s64_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtnh_u16_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtnh_u32_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtnh_u64_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtph_s16_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtph_s32_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtph_s64_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtph_u16_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtph_u32_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtph_u64_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vnegh_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrecpeh_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrecpxh_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrndh_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrndah_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrndih_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrndmh_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrndnh_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrndph_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrndxh_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrsqrteh_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vsqrth_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vaddh_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vabdh_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcageh_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcagth_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcaleh_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcalth_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vceqh_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcgeh_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcgth_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcleh_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vclth_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvth_n_f16_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvth_n_f16_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvth_n_f16_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvth_n_f16_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvth_n_f16_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvth_n_f16_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvth_n_s16_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvth_n_s32_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvth_n_s64_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvth_n_u16_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvth_n_u32_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvth_n_u64_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vdivh_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmaxh_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmaxnmh_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vminh_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vminnmh_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmulh_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmulxh_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrecpsh_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrsqrtsh_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vsubh_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vfmah_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vfmsh_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vabs_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vabsq_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vceqz_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vceqzq_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcgez_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcgezq_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcgtz_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcgtzq_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vclez_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vclezq_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcltz_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcltzq_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvt_f16_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtq_f16_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvt_f16_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtq_f16_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvt_s16_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtq_s16_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvt_u16_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtq_u16_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvta_s16_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtaq_s16_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvta_u16_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtaq_u16_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtm_s16_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtmq_s16_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtm_u16_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtmq_u16_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtn_s16_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtnq_s16_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtn_u16_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtnq_u16_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtp_s16_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtpq_s16_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtp_u16_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtpq_u16_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vneg_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vnegq_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrecpe_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrecpeq_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrnd_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrndq_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrnda_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrndaq_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrndi_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrndiq_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrndm_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrndmq_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrndn_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrndnq_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrndp_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrndpq_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrndx_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrndxq_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrsqrte_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrsqrteq_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vsqrt_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vsqrtq_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vadd_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vaddq_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vabd_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vabdq_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcage_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcageq_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcagt_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcagtq_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcale_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcaleq_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcalt_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcaltq_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vceq_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vceqq_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcge_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcgeq_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcgt_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcgtq_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcle_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcleq_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vclt_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcltq_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvt_n_f16_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtq_n_f16_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvt_n_f16_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtq_n_f16_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvt_n_s16_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtq_n_s16_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvt_n_u16_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtq_n_u16_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vdiv_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vdivq_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmax_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmaxq_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmaxnm_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmaxnmq_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmin_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vminq_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vminnm_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vminnmq_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmul_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmulq_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmulx_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmulxq_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vpadd_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vpaddq_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vpmax_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vpmaxq_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vpmaxnm_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vpmaxnmq_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vpmin_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vpminq_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vpminnm_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vpminnmq_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrecps_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrecpsq_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrsqrts_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrsqrtsq_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vsub_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vsubq_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vfma_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vfmaq_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vfms_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vfmsq_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vfma_lane_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vfmaq_lane_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vfma_laneq_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vfmaq_laneq_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vfma_n_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vfmaq_n_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vfmah_lane_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vfmah_laneq_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vfms_lane_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vfmsq_lane_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vfms_laneq_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vfmsq_laneq_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vfms_n_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vfmsq_n_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vfmsh_lane_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vfmsh_laneq_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmul_lane_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmulq_lane_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmul_laneq_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmulq_laneq_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmul_n_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmulq_n_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmulh_lane_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmulh_laneq_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmulx_lane_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmulxq_lane_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmulx_laneq_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmulxq_laneq_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmulx_n_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmulxq_n_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmulxh_lane_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmulxh_laneq_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmaxv_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmaxvq_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vminv_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vminvq_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmaxnmv_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmaxnmvq_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vminnmv_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vminnmvq_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vbsl_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vbslq_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vzip_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vzipq_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vuzp_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vuzpq_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vtrn_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vtrnq_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmov_n_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmovq_n_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vdup_n_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vdupq_n_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vdup_lane_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vdupq_lane_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vext_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vextq_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrev64_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrev64q_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vzip1_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vzip1q_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vzip2_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vzip2q_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vuzp1_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vuzp1q_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vuzp2_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vuzp2q_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vtrn1_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vtrn1q_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vtrn2_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vtrn2q_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vdup_laneq_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vdupq_laneq_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vduph_lane_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vduph_laneq_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vdot_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vdot_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vdotq_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vdotq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vdot_lane_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vdot_lane_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vdotq_laneq_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vdotq_laneq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vdot_laneq_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vdot_laneq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vdotq_lane_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vdotq_lane_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vsha512hq_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vsha512h2q_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vsha512su0q_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vsha512su1q_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_veor3q_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_veor3q_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_veor3q_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_veor3q_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_veor3q_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_veor3q_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_veor3q_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_veor3q_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrax1q_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vxarq_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vbcaxq_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vbcaxq_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vbcaxq_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vbcaxq_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vbcaxq_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vbcaxq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vbcaxq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vbcaxq_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vsm3ss1q_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vsm3tt1aq_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vsm3tt1bq_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vsm3tt2aq_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vsm3tt2bq_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vsm3partw1q_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vsm3partw2q_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vsm4eq_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vsm4ekeyq_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vfmlal_low_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vfmlsl_low_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vfmlalq_low_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vfmlslq_low_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vfmlal_high_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vfmlsl_high_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vfmlalq_high_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vfmlslq_high_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vfmlal_lane_low_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vfmlal_laneq_low_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vfmlalq_lane_low_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vfmlalq_laneq_low_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vfmlsl_lane_low_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vfmlsl_laneq_low_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vfmlslq_lane_low_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vfmlslq_laneq_low_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vfmlal_lane_high_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vfmlsl_lane_high_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vfmlalq_lane_high_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vfmlslq_lane_high_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vfmlal_laneq_high_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vfmlsl_laneq_high_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vfmlalq_laneq_high_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vfmlslq_laneq_high_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcadd_rot90_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcadd_rot90_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcaddq_rot90_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcaddq_rot90_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcaddq_rot90_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcadd_rot270_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcadd_rot270_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcaddq_rot270_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcaddq_rot270_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcaddq_rot270_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcmla_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcmla_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcmla_lane_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcmla_lane_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcmla_laneq_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcmla_laneq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcmlaq_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcmlaq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcmlaq_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcmlaq_lane_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcmlaq_lane_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcmlaq_laneq_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcmlaq_laneq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcmla_rot90_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcmla_rot90_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcmla_rot90_lane_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcmla_rot90_lane_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcmla_rot90_laneq_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcmla_rot90_laneq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcmlaq_rot90_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcmlaq_rot90_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcmlaq_rot90_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcmlaq_rot90_lane_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcmlaq_rot90_lane_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcmlaq_rot90_laneq_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcmlaq_rot90_laneq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcmla_rot180_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcmla_rot180_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcmla_rot180_lane_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcmla_rot180_lane_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcmla_rot180_laneq_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcmla_rot180_laneq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcmlaq_rot180_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcmlaq_rot180_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcmlaq_rot180_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcmlaq_rot180_lane_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcmlaq_rot180_lane_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcmlaq_rot180_laneq_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcmlaq_rot180_laneq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcmla_rot270_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcmla_rot270_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcmla_rot270_lane_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcmla_rot270_lane_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcmla_rot270_laneq_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcmla_rot270_laneq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcmlaq_rot270_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcmlaq_rot270_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcmlaq_rot270_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcmlaq_rot270_lane_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcmlaq_rot270_lane_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcmlaq_rot270_laneq_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcmlaq_rot270_laneq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrnd32z_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrnd32zq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrnd32z_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrnd32zq_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrnd64z_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrnd64zq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrnd64z_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrnd64zq_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrnd32x_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrnd32xq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrnd32x_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrnd32xq_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrnd64x_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrnd64xq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrnd64x_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrnd64xq_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmmlaq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmmlaq_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vusmmlaq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vusdot_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vusdot_lane_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vsudot_lane_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vusdot_laneq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vsudot_laneq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vusdotq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vusdotq_lane_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vsudotq_lane_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vusdotq_laneq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vsudotq_laneq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcreate_bf16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vdup_n_bf16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vdupq_n_bf16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vdup_lane_bf16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vdupq_lane_bf16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vdup_laneq_bf16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vdupq_laneq_bf16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcombine_bf16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vget_high_bf16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vget_low_bf16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vget_lane_bf16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vgetq_lane_bf16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vset_lane_bf16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vsetq_lane_bf16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vduph_lane_bf16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vduph_laneq_bf16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1_bf16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1q_bf16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1_lane_bf16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1q_lane_bf16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1_dup_bf16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1q_dup_bf16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1_bf16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1q_bf16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1_lane_bf16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1q_lane_bf16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld2_bf16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld2q_bf16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld3_bf16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld3q_bf16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld4_bf16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld4q_bf16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld2_dup_bf16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld2q_dup_bf16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld3_dup_bf16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld3q_dup_bf16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld4_dup_bf16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld4q_dup_bf16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst2_bf16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst2q_bf16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst3_bf16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst3q_bf16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst4_bf16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst4q_bf16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld2_lane_bf16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld2q_lane_bf16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld3_lane_bf16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld3q_lane_bf16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld4_lane_bf16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld4q_lane_bf16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst2_lane_bf16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst2q_lane_bf16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst3_lane_bf16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst3q_lane_bf16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst4_lane_bf16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst4q_lane_bf16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1_bf16_x2(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1q_bf16_x2(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1_bf16_x3(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1q_bf16_x3(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1_bf16_x4(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1q_bf16_x4(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1_bf16_x2(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1q_bf16_x2(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1_bf16_x3(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1q_bf16_x3(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1_bf16_x4(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1q_bf16_x4(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_bf16_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_bf16_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_bf16_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_bf16_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_bf16_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_bf16_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_bf16_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_bf16_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_bf16_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_bf16_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_bf16_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_bf16_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_bf16_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_bf16_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_bf16_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_bf16_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_bf16_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_bf16_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_bf16_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_bf16_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_bf16_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_bf16_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_bf16_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_bf16_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_bf16_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_bf16_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_bf16_p128(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_s8_bf16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_s16_bf16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_s32_bf16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_f32_bf16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_u8_bf16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_u16_bf16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_u32_bf16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_p8_bf16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_p16_bf16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_u64_bf16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_s64_bf16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_f64_bf16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_p64_bf16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_s8_bf16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_s16_bf16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_s32_bf16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_f32_bf16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_u8_bf16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_u16_bf16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_u32_bf16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_p8_bf16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_p16_bf16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_u64_bf16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_s64_bf16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_f64_bf16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_p64_bf16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_p128_bf16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvt_f32_bf16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtq_low_f32_bf16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtq_high_f32_bf16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvt_bf16_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtq_low_bf16_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtq_high_bf16_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvth_bf16_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcvtah_f32_bf16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcopy_lane_bf16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcopyq_lane_bf16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcopy_laneq_bf16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcopyq_laneq_bf16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vbfdot_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vbfdotq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vbfdot_lane_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vbfdotq_laneq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vbfdot_laneq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vbfdotq_lane_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vbfmmlaq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vbfmlalbq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vbfmlaltq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vbfmlalbq_lane_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vbfmlalbq_laneq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vbfmlaltq_lane_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vbfmlaltq_laneq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqrdmlsh_lane_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
#if defined(__GNUC__)
  return TEST_UNIMPL;
#else
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  const int16_t *_c = (int16_t *)impl.test_cases_int_pointer3;
  int16_t _d[4];
  const int32_t round_const = 1 << 15;
  int16x4_t a, b, c, d;
#define TEST_IMPL(IDX)                                                  \
  for (int i = 0; i < 4; i++) {                                         \
    int32_t tmp = -2 * (int32_t)_b[i] * (int32_t)_c[IDX] + round_const; \
    _d[i] = saturate_int16(_a[i] - (tmp >> 16));                        \
  }                                                                     \
  a = vld1_s16(_a);                                                     \
  b = vld1_s16(_b);                                                     \
  c = vld1_s16(_c);                                                     \
  d = vqrdmlsh_lane_s16(a, b, c, IDX);

  IMM_4_ITER
#undef TEST_IMPL

  return validate_int16(d, _d[0], _d[1], _d[2], _d[3]);
#endif
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqrdmlsh_lane_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
#if defined(__GNUC__)
  return TEST_UNIMPL;
#else
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  const int32_t *_c = (int32_t *)impl.test_cases_int_pointer3;
  int32_t _d[2];
  const int64_t round_const = (int64_t)1 << 31;
  int32x2_t a, b, c, d;
#define TEST_IMPL(IDX)                                                  \
  for (int i = 0; i < 2; i++) {                                         \
    int64_t tmp = -2 * (int64_t)_b[i] * (int64_t)_c[IDX] + round_const; \
    _d[i] = saturate_int32(_a[i] - (tmp >> 32));                        \
  }                                                                     \
  a = vld1_s32(_a);                                                     \
  b = vld1_s32(_b);                                                     \
  c = vld1_s32(_c);                                                     \
  d = vqrdmlsh_lane_s32(a, b, c, IDX);

  IMM_2_ITER
#undef TEST_IMPL

  return validate_int32(d, _d[0], _d[1]);
#endif
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmul_n_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  int16_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = _a[i] * _b[0];
  }

  int16x4_t a = vld1_s16(_a);
  int16x4_t c = vmul_n_s16(a, _b[0]);
  return validate_int16(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmul_n_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  int32_t _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = _a[i] * _b[0];
  }

  int32x2_t a = vld1_s32(_a);
  int32x2_t c = vmul_n_s32(a, _b[0]);
  return validate_int32(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmul_n_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (float *)impl.test_cases_float_pointer1;
  const float *_b = (float *)impl.test_cases_float_pointer2;
  float _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = _a[i] * _b[0];
  }

  float32x2_t a = vld1_f32(_a);
  float32x2_t c = vmul_n_f32(a, _b[0]);
  return validate_float(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmul_n_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (uint16_t *)impl.test_cases_int_pointer2;
  uint16_t _d[4];
  for (int i = 0; i < 4; i++) {
    _d[i] = _a[i] * _b[0];
  }

  uint16x4_t a = vld1_u16(_a);
  uint16x4_t c = vmul_n_u16(a, _b[0]);
  return validate_uint16(c, _d[0], _d[1], _d[2], _d[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmul_n_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (uint32_t *)impl.test_cases_int_pointer2;
  uint32_t _d[2];
  for (int i = 0; i < 2; i++) {
    _d[i] = _a[i] * _b[0];
  }

  uint32x2_t a = vld1_u32(_a);
  uint32x2_t c = vmul_n_u32(a, _b[0]);
  return validate_uint32(c, _d[0], _d[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmulq_n_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  int16_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = _a[i] * _b[0];
  }

  int16x8_t a = vld1q_s16(_a);
  int16x8_t c = vmulq_n_s16(a, _b[0]);
  return validate_int16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmulq_n_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  int32_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = _a[i] * _b[0];
  }

  int32x4_t a = vld1q_s32(_a);
  int32x4_t c = vmulq_n_s32(a, _b[0]);
  return validate_int32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmulq_n_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (float *)impl.test_cases_float_pointer1;
  const float *_b = (float *)impl.test_cases_float_pointer2;
  float _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = _a[i] * _b[0];
  }

  float32x4_t a = vld1q_f32(_a);
  float32x4_t c = vmulq_n_f32(a, _b[0]);
  return validate_float(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmul_n_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmulq_n_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmulq_n_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (uint16_t *)impl.test_cases_int_pointer2;
  uint16_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = _a[i] * _b[0];
  }

  uint16x8_t a = vld1q_u16(_a);
  uint16x8_t c = vmulq_n_u16(a, _b[0]);
  return validate_uint16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmulq_n_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (uint32_t *)impl.test_cases_int_pointer2;
  uint32_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = _a[i] * _b[0];
  }

  uint32x4_t a = vld1q_u32(_a);
  uint32x4_t c = vmulq_n_u32(a, _b[0]);
  return validate_uint32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmull_n_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  int32_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = (int32_t)_a[i] * (int32_t)_b[0];
  }

  int16x4_t a = vld1_s16(_a);
  int32x4_t c = vmull_n_s16(a, _b[0]);
  return validate_int32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmull_n_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  int64_t _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = (int64_t)_a[i] * (int64_t)_b[0];
  }

  int32x2_t a = vld1_s32(_a);
  int64x2_t c = vmull_n_s32(a, _b[0]);
  return validate_int64(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmull_n_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (uint16_t *)impl.test_cases_int_pointer2;
  uint32_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = (uint32_t)_a[i] * (uint32_t)_b[0];
  }

  uint16x4_t a = vld1_u16(_a);
  uint32x4_t c = vmull_n_u16(a, _b[0]);
  return validate_uint32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmull_n_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (uint32_t *)impl.test_cases_int_pointer2;
  uint64_t _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = (uint64_t)_a[i] * (uint64_t)_b[0];
  }

  uint32x2_t a = vld1_u32(_a);
  uint64x2_t c = vmull_n_u32(a, _b[0]);
  return validate_uint64(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmull_high_n_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmull_high_n_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmull_high_n_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmull_high_n_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqdmull_n_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  int32_t _c[4];
  int16x4_t a = vld1_s16(_a);

  for (int i = 0; i < 4; i++) {
    _c[i] = saturate_int32(2 * _a[i] * _b[0]);
  }
  int32x4_t c = vqdmull_n_s16(a, _b[0]);
  return validate_int32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqdmull_n_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  int64_t _c[2];
  int32x2_t a = vld1_s32(_a);

  float max_f = (float)INT64_MAX, min_f = (float)INT64_MIN;
  for (int i = 0; i < 2; i++) {
    float a_f = _a[i];
    float b_f = _b[0];
    if ((a_f * b_f > 0) && (2 * a_f * b_f > max_f)) {
      _c[i] = INT64_MAX;
    } else if (2 * a_f * b_f < min_f) {
      _c[i] = INT64_MIN;
    } else {
      _c[i] = 2 * (int64_t)_a[i] * (int64_t)_b[0];
    }
  }
  int64x2_t c = vqdmull_n_s32(a, _b[0]);
  return validate_int64(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqdmull_high_n_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqdmull_high_n_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqdmulhq_n_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  int16_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = saturate_int16(2 * (int32_t)_a[i] * (int32_t)_b[0] >> 16);
  }

  int16x8_t a = vld1q_s16(_a);
  int16x8_t c = vqdmulhq_n_s16(a, _b[0]);
  return validate_int16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqdmulhq_n_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  int32_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = saturate_int32(2 * (int64_t)_a[i] * (int64_t)_b[0] >> 32);
  }

  int32x4_t a = vld1q_s32(_a);
  int32x4_t c = vqdmulhq_n_s32(a, _b[0]);
  return validate_int32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqdmulh_n_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  int16_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = saturate_int16(2 * (int32_t)_a[i] * (int32_t)_b[0] >> 16);
  }

  int16x4_t a = vld1_s16(_a);
  int16x4_t c = vqdmulh_n_s16(a, _b[0]);
  return validate_int16(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqdmulh_n_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  int32_t _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = saturate_int32(2 * (int64_t)_a[i] * (int64_t)_b[0] >> 32);
  }

  int32x2_t a = vld1_s32(_a);
  int32x2_t c = vqdmulh_n_s32(a, _b[0]);
  return validate_int32(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqrdmulhq_n_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  int16_t _c[8];
  const int32_t round = 1 << 15;
  for (int i = 0; i < 8; i++) {
    int32_t tmp = 2 * (int32_t)_a[i] * (int32_t)_b[0] + round;
    _c[i] = saturate_int16(tmp >> 16);
  }

  int16x8_t a = vld1q_s16(_a);
  int16x8_t c = vqrdmulhq_n_s16(a, _b[0]);
  return validate_int16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqrdmulhq_n_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  int32_t _c[4];
  int32_t round = 1;
  for (int i = 0; i < 4; i++) {
    int64_t tmp = 2 * (int64_t)_a[i] * (int64_t)_b[0];
    tmp = tmp >> 31;
    tmp += round;
    _c[i] = saturate_int32(tmp >> 1);
  }

  int32x4_t a = vld1q_s32(_a);
  int32x4_t c = vqrdmulhq_n_s32(a, _b[0]);
  return validate_int32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqrdmulh_n_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  int16_t _c[4];
  const int32_t round = 1 << 15;
  for (int i = 0; i < 4; i++) {
    int32_t tmp = 2 * (int32_t)_a[i] * (int32_t)_b[0] + round;
    _c[i] = saturate_int16(tmp >> 16);
  }

  int16x4_t a = vld1_s16(_a);
  int16x4_t c = vqrdmulh_n_s16(a, _b[0]);
  return validate_int16(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqrdmulh_n_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  int32_t _c[2];
  int32_t round = 1;
  for (int i = 0; i < 2; i++) {
    int64_t tmp = 2 * (int64_t)_a[i] * (int64_t)_b[0];
    tmp = tmp >> 31;
    tmp += round;
    _c[i] = saturate_int32(tmp >> 1);
  }

  int32x2_t a = vld1_s32(_a);
  int32x2_t c = vqrdmulh_n_s32(a, _b[0]);
  return validate_int32(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmla_n_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  const int16_t *_c = (int16_t *)impl.test_cases_int_pointer3;
  int16_t _d[4];
  for (int i = 0; i < 4; i++) {
    _d[i] = _a[i] + _b[i] * _c[0];
  }

  int16x4_t a = vld1_s16(_a);
  int16x4_t b = vld1_s16(_b);
  int16x4_t d = vmla_n_s16(a, b, _c[0]);
  return validate_int16(d, _d[0], _d[1], _d[2], _d[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmla_n_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  const int32_t *_c = (int32_t *)impl.test_cases_int_pointer3;
  int32_t _d[2];
  for (int i = 0; i < 2; i++) {
    _d[i] = _a[i] + _b[i] * _c[0];
  }

  int32x2_t a = vld1_s32(_a);
  int32x2_t b = vld1_s32(_b);
  int32x2_t d = vmla_n_s32(a, b, _c[0]);
  return validate_int32(d, _d[0], _d[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmla_n_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (float *)impl.test_cases_int_pointer1;
  const float *_b = (float *)impl.test_cases_int_pointer2;
  const float *_c = (float *)impl.test_cases_int_pointer3;
  float _d[2];
  for (int i = 0; i < 2; i++) {
    _d[i] = _a[i] + _b[i] * _c[0];
  }

  float32x2_t a = vld1_f32(_a);
  float32x2_t b = vld1_f32(_b);
  float32x2_t d = vmla_n_f32(a, b, _c[0]);
  return validate_float_error(d, _d[0], _d[1], 0.00001f);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmla_n_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (uint16_t *)impl.test_cases_int_pointer2;
  const uint16_t *_c = (uint16_t *)impl.test_cases_int_pointer3;
  uint16_t _d[4];
  for (int i = 0; i < 4; i++) {
    _d[i] = _a[i] + _b[i] * _c[0];
  }

  uint16x4_t a = vld1_u16(_a);
  uint16x4_t b = vld1_u16(_b);
  uint16x4_t d = vmla_n_u16(a, b, _c[0]);
  return validate_uint16(d, _d[0], _d[1], _d[2], _d[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmla_n_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (uint32_t *)impl.test_cases_int_pointer2;
  const uint32_t *_c = (uint32_t *)impl.test_cases_int_pointer3;
  uint32_t _d[2];
  for (int i = 0; i < 2; i++) {
    _d[i] = _a[i] + _b[i] * _c[0];
  }

  uint32x2_t a = vld1_u32(_a);
  uint32x2_t b = vld1_u32(_b);
  uint32x2_t d = vmla_n_u32(a, b, _c[0]);
  return validate_uint32(d, _d[0], _d[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmlaq_n_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  const int16_t *_c = (int16_t *)impl.test_cases_int_pointer3;
  int16_t _d[8];
  for (int i = 0; i < 8; i++) {
    _d[i] = _a[i] + _b[i] * _c[0];
  }

  int16x8_t a = vld1q_s16(_a);
  int16x8_t b = vld1q_s16(_b);
  int16x8_t d = vmlaq_n_s16(a, b, _c[0]);
  return validate_int16(d, _d[0], _d[1], _d[2], _d[3], _d[4], _d[5], _d[6], _d[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmlaq_n_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  const int32_t *_c = (int32_t *)impl.test_cases_int_pointer3;
  int32_t _d[4];
  for (int i = 0; i < 4; i++) {
    _d[i] = _a[i] + _b[i] * _c[0];
  }

  int32x4_t a = vld1q_s32(_a);
  int32x4_t b = vld1q_s32(_b);
  int32x4_t d = vmlaq_n_s32(a, b, _c[0]);
  return validate_int32(d, _d[0], _d[1], _d[2], _d[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmlaq_n_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (float *)impl.test_cases_int_pointer1;
  const float *_b = (float *)impl.test_cases_int_pointer2;
  const float *_c = (float *)impl.test_cases_int_pointer3;
  float _d[4];
  for (int i = 0; i < 4; i++) {
    _d[i] = _a[i] + _b[i] * _c[0];
  }

  float32x4_t a = vld1q_f32(_a);
  float32x4_t b = vld1q_f32(_b);
  float32x4_t d = vmlaq_n_f32(a, b, _c[0]);
  return validate_float_error(d, _d[0], _d[1], _d[2], _d[3], 0.00001f);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmlaq_n_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (uint16_t *)impl.test_cases_int_pointer2;
  const uint16_t *_c = (uint16_t *)impl.test_cases_int_pointer3;
  uint16_t _d[8];
  for (int i = 0; i < 8; i++) {
    _d[i] = _a[i] + _b[i] * _c[0];
  }

  uint16x8_t a = vld1q_u16(_a);
  uint16x8_t b = vld1q_u16(_b);
  uint16x8_t d = vmlaq_n_u16(a, b, _c[0]);
  return validate_uint16(d, _d[0], _d[1], _d[2], _d[3], _d[4], _d[5], _d[6], _d[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmlaq_n_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (uint32_t *)impl.test_cases_int_pointer2;
  const uint32_t *_c = (uint32_t *)impl.test_cases_int_pointer3;
  uint32_t _d[4];
  for (int i = 0; i < 4; i++) {
    _d[i] = _a[i] + _b[i] * _c[0];
  }

  uint32x4_t a = vld1q_u32(_a);
  uint32x4_t b = vld1q_u32(_b);
  uint32x4_t d = vmlaq_n_u32(a, b, _c[0]);
  return validate_uint32(d, _d[0], _d[1], _d[2], _d[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmlal_n_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  const int16_t *_c = (int16_t *)impl.test_cases_int_pointer3;
  int32_t _d[4];
  for (int i = 0; i < 4; i++) {
    _d[i] = _a[i] + (int32_t)_b[i] * (int32_t)_c[0];
  }

  int32x4_t a = vld1q_s32(_a);
  int16x4_t b = vld1_s16(_b);
  int32x4_t d = vmlal_n_s16(a, b, _c[0]);
  return validate_int32(d, _d[0], _d[1], _d[2], _d[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmlal_n_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (int64_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  const int32_t *_c = (int32_t *)impl.test_cases_int_pointer3;
  int64_t _d[2];
  for (int i = 0; i < 2; i++) {
    _d[i] = _a[i] + (int64_t)_b[i] * (int64_t)_c[0];
  }

  int64x2_t a = vld1q_s64(_a);
  int32x2_t b = vld1_s32(_b);
  int64x2_t d = vmlal_n_s32(a, b, _c[0]);
  return validate_int64(d, _d[0], _d[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmlal_n_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (uint16_t *)impl.test_cases_int_pointer2;
  const uint16_t *_c = (uint16_t *)impl.test_cases_int_pointer3;
  uint32_t _d[4];
  for (int i = 0; i < 4; i++) {
    _d[i] = _a[i] + (uint32_t)_b[i] * (uint32_t)_c[0];
  }

  uint32x4_t a = vld1q_u32(_a);
  uint16x4_t b = vld1_u16(_b);
  uint32x4_t d = vmlal_n_u16(a, b, _c[0]);
  return validate_uint32(d, _d[0], _d[1], _d[2], _d[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmlal_n_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (uint64_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (uint32_t *)impl.test_cases_int_pointer2;
  const uint32_t *_c = (uint32_t *)impl.test_cases_int_pointer3;
  uint64_t _d[2];
  for (int i = 0; i < 2; i++) {
    _d[i] = _a[i] + (uint64_t)_b[i] * (uint64_t)_c[0];
  }

  uint64x2_t a = vld1q_u64(_a);
  uint32x2_t b = vld1_u32(_b);
  uint64x2_t d = vmlal_n_u32(a, b, _c[0]);
  return validate_uint64(d, _d[0], _d[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmlal_high_n_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmlal_high_n_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmlal_high_n_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmlal_high_n_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqdmlal_n_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  const int16_t *_c = (int16_t *)impl.test_cases_int_pointer3;
  int32_t _d[4];
  for (int i = 0; i < 4; i++) {
    int32_t bcx2 = saturate_int32(2 * _b[i] * _c[0]);
    _d[i] = saturate_int32(_a[i] + bcx2);
  }

  int32x4_t a = vld1q_s32(_a);
  int16x4_t b = vld1_s16(_b);
  int32x4_t d = vqdmlal_n_s16(a, b, _c[0]);
  return validate_int32(d, _d[0], _d[1], _d[2], _d[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqdmlal_n_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (int64_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  const int32_t *_c = (int32_t *)impl.test_cases_int_pointer3;
  int64_t _d[2];
  for (int i = 0; i < 2; i++) {
    int64_t tmp = (((int64_t)_b[i] * (int64_t)_c[0]) >> 32) * 2 + (_a[i] >> 32);
    if (tmp > INT64_MAX) {
      _d[i] = INT64_MAX;
    } else if (tmp < INT64_MIN) {
      _d[i] = INT64_MIN;
    } else {
      _d[i] = (int64_t)_b[i] * (int64_t)_c[0] * 2 + _a[i];
    }
  }

  int64x2_t a = vld1q_s64(_a);
  int32x2_t b = vld1_s32(_b);
  int64x2_t d = vqdmlal_n_s32(a, b, _c[0]);
  return validate_int64(d, _d[0], _d[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqdmlal_high_n_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqdmlal_high_n_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmls_n_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  const int16_t *_c = (int16_t *)impl.test_cases_int_pointer3;
  int16_t _d[4];
  for (int i = 0; i < 4; i++) {
    _d[i] = _a[i] - _b[i] * _c[0];
  }

  int16x4_t a = vld1_s16(_a);
  int16x4_t b = vld1_s16(_b);
  int16x4_t d = vmls_n_s16(a, b, _c[0]);
  return validate_int16(d, _d[0], _d[1], _d[2], _d[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmls_n_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  const int32_t *_c = (int32_t *)impl.test_cases_int_pointer3;
  int32_t _d[2];
  for (int i = 0; i < 2; i++) {
    _d[i] = _a[i] - _b[i] * _c[0];
  }

  int32x2_t a = vld1_s32(_a);
  int32x2_t b = vld1_s32(_b);
  int32x2_t d = vmls_n_s32(a, b, _c[0]);
  return validate_int32(d, _d[0], _d[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmls_n_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (float *)impl.test_cases_float_pointer1;
  const float *_b = (float *)impl.test_cases_float_pointer2;
  const float *_c = (float *)impl.test_cases_float_pointer3;
  float _d[2];
  for (int i = 0; i < 2; i++) {
    _d[i] = _a[i] - _b[i] * _c[0];
  }

  float32x2_t a = vld1_f32(_a);
  float32x2_t b = vld1_f32(_b);
  float32x2_t d = vmls_n_f32(a, b, _c[0]);
  return validate_float_error(d, _d[0], _d[1], 0.0001f);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmls_n_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (uint16_t *)impl.test_cases_int_pointer2;
  const uint16_t *_c = (uint16_t *)impl.test_cases_int_pointer3;
  uint16_t _d[4];
  for (int i = 0; i < 4; i++) {
    _d[i] = _a[i] - _b[i] * _c[0];
  }

  uint16x4_t a = vld1_u16(_a);
  uint16x4_t b = vld1_u16(_b);
  uint16x4_t d = vmls_n_u16(a, b, _c[0]);
  return validate_uint16(d, _d[0], _d[1], _d[2], _d[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmls_n_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (uint32_t *)impl.test_cases_int_pointer2;
  const uint32_t *_c = (uint32_t *)impl.test_cases_int_pointer3;
  uint32_t _d[2];
  for (int i = 0; i < 2; i++) {
    _d[i] = _a[i] - _b[i] * _c[0];
  }

  uint32x2_t a = vld1_u32(_a);
  uint32x2_t b = vld1_u32(_b);
  uint32x2_t d = vmls_n_u32(a, b, _c[0]);
  return validate_uint32(d, _d[0], _d[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmlsq_n_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  const int16_t *_c = (int16_t *)impl.test_cases_int_pointer3;
  int16_t _d[8];
  for (int i = 0; i < 8; i++) {
    _d[i] = _a[i] - _b[i] * _c[0];
  }

  int16x8_t a = vld1q_s16(_a);
  int16x8_t b = vld1q_s16(_b);
  int16x8_t d = vmlsq_n_s16(a, b, _c[0]);
  return validate_int16(d, _d[0], _d[1], _d[2], _d[3], _d[4], _d[5], _d[6], _d[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmlsq_n_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  const int32_t *_c = (int32_t *)impl.test_cases_int_pointer3;
  int32_t _d[4];
  for (int i = 0; i < 4; i++) {
    _d[i] = _a[i] - _b[i] * _c[0];
  }

  int32x4_t a = vld1q_s32(_a);
  int32x4_t b = vld1q_s32(_b);
  int32x4_t d = vmlsq_n_s32(a, b, _c[0]);
  return validate_int32(d, _d[0], _d[1], _d[2], _d[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmlsq_n_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (float *)impl.test_cases_float_pointer1;
  const float *_b = (float *)impl.test_cases_float_pointer2;
  const float *_c = (float *)impl.test_cases_float_pointer3;
  float _d[4];
  for (int i = 0; i < 4; i++) {
    _d[i] = _a[i] - _b[i] * _c[0];
  }

  float32x4_t a = vld1q_f32(_a);
  float32x4_t b = vld1q_f32(_b);
  float32x4_t d = vmlsq_n_f32(a, b, _c[0]);
  return validate_float_error(d, _d[0], _d[1], _d[2], _d[3], 0.0001f);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmlsq_n_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (uint16_t *)impl.test_cases_int_pointer2;
  const uint16_t *_c = (uint16_t *)impl.test_cases_int_pointer3;
  uint16_t _d[8];
  for (int i = 0; i < 8; i++) {
    _d[i] = _a[i] - _b[i] * _c[0];
  }

  uint16x8_t a = vld1q_u16(_a);
  uint16x8_t b = vld1q_u16(_b);
  uint16x8_t d = vmlsq_n_u16(a, b, _c[0]);
  return validate_uint16(d, _d[0], _d[1], _d[2], _d[3], _d[4], _d[5], _d[6], _d[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmlsq_n_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (uint32_t *)impl.test_cases_int_pointer2;
  const uint32_t *_c = (uint32_t *)impl.test_cases_int_pointer3;
  uint32_t _d[4];
  for (int i = 0; i < 4; i++) {
    _d[i] = _a[i] - _b[i] * _c[0];
  }

  uint32x4_t a = vld1q_u32(_a);
  uint32x4_t b = vld1q_u32(_b);
  uint32x4_t d = vmlsq_n_u32(a, b, _c[0]);
  return validate_uint32(d, _d[0], _d[1], _d[2], _d[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmlsl_n_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  const int16_t *_c = (int16_t *)impl.test_cases_int_pointer3;
  int32_t _d[4];
  for (int i = 0; i < 4; i++) {
    _d[i] = _a[i] - (int32_t)_b[i] * (int32_t)_c[0];
  }

  int32x4_t a = vld1q_s32(_a);
  int16x4_t b = vld1_s16(_b);
  int32x4_t d = vmlsl_n_s16(a, b, _c[0]);
  return validate_int32(d, _d[0], _d[1], _d[2], _d[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmlsl_n_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (int64_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  const int32_t *_c = (int32_t *)impl.test_cases_int_pointer3;
  int64_t _d[2];
  for (int i = 0; i < 2; i++) {
    _d[i] = _a[i] - (int64_t)_b[i] * (int64_t)_c[0];
  }

  int64x2_t a = vld1q_s64(_a);
  int32x2_t b = vld1_s32(_b);
  int64x2_t d = vmlsl_n_s32(a, b, _c[0]);
  return validate_int64(d, _d[0], _d[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmlsl_n_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (uint16_t *)impl.test_cases_int_pointer2;
  const uint16_t *_c = (uint16_t *)impl.test_cases_int_pointer3;
  uint32_t _d[4];
  for (int i = 0; i < 4; i++) {
    _d[i] = _a[i] - (uint32_t)_b[i] * (uint32_t)_c[0];
  }

  uint32x4_t a = vld1q_u32(_a);
  uint16x4_t b = vld1_u16(_b);
  uint32x4_t d = vmlsl_n_u16(a, b, _c[0]);
  return validate_uint32(d, _d[0], _d[1], _d[2], _d[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmlsl_n_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (uint64_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (uint32_t *)impl.test_cases_int_pointer2;
  const uint32_t *_c = (uint32_t *)impl.test_cases_int_pointer3;
  uint64_t _d[2];
  for (int i = 0; i < 2; i++) {
    _d[i] = _a[i] - (uint64_t)_b[i] * (uint64_t)_c[0];
  }

  uint64x2_t a = vld1q_u64(_a);
  uint32x2_t b = vld1_u32(_b);
  uint64x2_t d = vmlsl_n_u32(a, b, _c[0]);
  return validate_uint64(d, _d[0], _d[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vmlsl_high_n_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmlsl_high_n_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmlsl_high_n_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmlsl_high_n_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqdmlsl_n_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  const int16_t *_c = (int16_t *)impl.test_cases_int_pointer3;
  int32_t _d[4];
  for (int i = 0; i < 4; i++) {
    int32_t bcx2 = saturate_int32(2 * _b[i] * _c[0]);
    _d[i] = saturate_int32(_a[i] - bcx2);
  }

  int32x4_t a = vld1q_s32(_a);
  int16x4_t b = vld1_s16(_b);
  int32x4_t d = vqdmlsl_n_s16(a, b, _c[0]);
  return validate_int32(d, _d[0], _d[1], _d[2], _d[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqdmlsl_n_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (int64_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  const int32_t *_c = (int32_t *)impl.test_cases_int_pointer3;
  int64_t _d[2];
  float max_f = (float)INT64_MAX, min_f = (float)INT64_MIN;
  for (int i = 0; i < 2; i++) {
    float b_f = _b[i];
    float c_f = _c[0];
    int64_t tmp;
    if ((b_f * c_f > 0) && (2 * b_f * c_f > max_f)) {
      tmp = INT64_MAX;
    } else if (2 * b_f * c_f < min_f) {
      tmp = INT64_MIN;
    } else {
      tmp = 2 * (int64_t)_b[i] * (int64_t)_c[0];
    }
    if ((tmp > 0 && _a[i] < INT64_MIN + tmp) || (tmp < 0 && _a[i] > INT64_MAX + tmp)) {
      _d[i] = (tmp > 0) ? INT64_MAX : INT64_MIN;
    } else {
      _d[i] = (int64_t)_a[i] - tmp;
    }
  }

  int64x2_t a = vld1q_s64(_a);
  int32x2_t b = vld1_s32(_b);
  int64x2_t d = vqdmlsl_n_s32(a, b, _c[0]);
  return validate_int64(d, _d[0], _d[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vqdmlsl_high_n_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vqdmlsl_high_n_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vext_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (int8_t *)impl.test_cases_int_pointer2;
  const int elt_num = 8;
  int8_t _c[elt_num];
  int8x8_t a, b, c;

  int8_t temp_arr[elt_num * 2];
  for (int i = 0; i < elt_num; i++) {
    temp_arr[i] = _a[i];
    temp_arr[i + elt_num] = _b[i];
  }

#define TEST_IMPL(IDX)                \
  for (int i = 0; i < elt_num; i++) { \
    _c[i] = temp_arr[i + IDX];        \
  }                                   \
  a = vld1_s8(_a);                    \
  b = vld1_s8(_b);                    \
  c = vext_s8(a, b, IDX);             \
  CHECK_RESULT(validate_int8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]))

  IMM_8_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vext_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  const int elt_num = 4;
  int16_t _c[elt_num];
  int16x4_t a, b, c;

  int16_t temp_arr[elt_num * 2];
  for (int i = 0; i < elt_num; i++) {
    temp_arr[i] = _a[i];
    temp_arr[i + elt_num] = _b[i];
  }

#define TEST_IMPL(IDX)                \
  for (int i = 0; i < elt_num; i++) { \
    _c[i] = temp_arr[i + IDX];        \
  }                                   \
  a = vld1_s16(_a);                   \
  b = vld1_s16(_b);                   \
  c = vext_s16(a, b, IDX);            \
  CHECK_RESULT(validate_int16(c, _c[0], _c[1], _c[2], _c[3]))

  IMM_4_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vext_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  const int elt_num = 2;
  int32_t _c[elt_num];
  int32x2_t a, b, c;

  int32_t temp_arr[elt_num * 2];
  for (int i = 0; i < elt_num; i++) {
    temp_arr[i] = _a[i];
    temp_arr[i + elt_num] = _b[i];
  }

#define TEST_IMPL(IDX)                \
  for (int i = 0; i < elt_num; i++) { \
    _c[i] = temp_arr[i + IDX];        \
  }                                   \
  a = vld1_s32(_a);                   \
  b = vld1_s32(_b);                   \
  c = vext_s32(a, b, IDX);            \
  CHECK_RESULT(validate_int32(c, _c[0], _c[1]))

  IMM_2_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vext_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (int64_t *)impl.test_cases_int_pointer1;
  const int64_t *_b = (int64_t *)impl.test_cases_int_pointer2;
  const int elt_num = 1;
  int64_t _c[elt_num];
  int64x1_t a, b, c;

  int64_t temp_arr[elt_num * 2];
  for (int i = 0; i < elt_num; i++) {
    temp_arr[i] = _a[i];
    temp_arr[i + elt_num] = _b[i];
  }

#define TEST_IMPL(IDX)                \
  for (int i = 0; i < elt_num; i++) { \
    _c[i] = temp_arr[i + IDX];        \
  }                                   \
  a = vld1_s64(_a);                   \
  b = vld1_s64(_b);                   \
  c = vext_s64(a, b, IDX);            \
  CHECK_RESULT(validate_int64(c, _c[0]))

  IMM_1_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vext_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (float *)impl.test_cases_float_pointer1;
  const float *_b = (float *)impl.test_cases_float_pointer2;
  const int elt_num = 2;
  float _c[elt_num];
  float32x2_t a, b, c;

  float temp_arr[elt_num * 2];
  for (int i = 0; i < elt_num; i++) {
    temp_arr[i] = _a[i];
    temp_arr[i + elt_num] = _b[i];
  }

#define TEST_IMPL(IDX)                \
  for (int i = 0; i < elt_num; i++) { \
    _c[i] = temp_arr[i + IDX];        \
  }                                   \
  a = vld1_f32(_a);                   \
  b = vld1_f32(_b);                   \
  c = vext_f32(a, b, IDX);            \
  CHECK_RESULT(validate_float(c, _c[0], _c[1]))

  IMM_2_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vext_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (uint8_t *)impl.test_cases_int_pointer2;
  const int elt_num = 8;
  uint8_t _c[elt_num];
  uint8x8_t a, b, c;

  uint8_t temp_arr[elt_num * 2];
  for (int i = 0; i < elt_num; i++) {
    temp_arr[i] = _a[i];
    temp_arr[i + elt_num] = _b[i];
  }

#define TEST_IMPL(IDX)                \
  for (int i = 0; i < elt_num; i++) { \
    _c[i] = temp_arr[i + IDX];        \
  }                                   \
  a = vld1_u8(_a);                    \
  b = vld1_u8(_b);                    \
  c = vext_u8(a, b, IDX);             \
  CHECK_RESULT(validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]))

  IMM_8_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vext_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (uint16_t *)impl.test_cases_int_pointer2;
  const int elt_num = 4;
  uint16_t _c[elt_num];
  uint16x4_t a, b, c;

  uint16_t temp_arr[elt_num * 2];
  for (int i = 0; i < elt_num; i++) {
    temp_arr[i] = _a[i];
    temp_arr[i + elt_num] = _b[i];
  }

#define TEST_IMPL(IDX)                \
  for (int i = 0; i < elt_num; i++) { \
    _c[i] = temp_arr[i + IDX];        \
  }                                   \
  a = vld1_u16(_a);                   \
  b = vld1_u16(_b);                   \
  c = vext_u16(a, b, IDX);            \
  CHECK_RESULT(validate_uint16(c, _c[0], _c[1], _c[2], _c[3]))

  IMM_4_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vext_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (uint32_t *)impl.test_cases_int_pointer2;
  const int elt_num = 2;
  uint32_t _c[elt_num];
  uint32x2_t a, b, c;

  uint32_t temp_arr[elt_num * 2];
  for (int i = 0; i < elt_num; i++) {
    temp_arr[i] = _a[i];
    temp_arr[i + elt_num] = _b[i];
  }

#define TEST_IMPL(IDX)                \
  for (int i = 0; i < elt_num; i++) { \
    _c[i] = temp_arr[i + IDX];        \
  }                                   \
  a = vld1_u32(_a);                   \
  b = vld1_u32(_b);                   \
  c = vext_u32(a, b, IDX);            \
  CHECK_RESULT(validate_uint32(c, _c[0], _c[1]))

  IMM_2_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vext_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (uint64_t *)impl.test_cases_int_pointer1;
  const uint64_t *_b = (uint64_t *)impl.test_cases_int_pointer2;
  const int elt_num = 1;
  uint64_t _c[elt_num];
  uint64x1_t a, b, c;

  uint64_t temp_arr[elt_num * 2];
  for (int i = 0; i < elt_num; i++) {
    temp_arr[i] = _a[i];
    temp_arr[i + elt_num] = _b[i];
  }

#define TEST_IMPL(IDX)                \
  for (int i = 0; i < elt_num; i++) { \
    _c[i] = temp_arr[i + IDX];        \
  }                                   \
  a = vld1_u64(_a);                   \
  b = vld1_u64(_b);                   \
  c = vext_u64(a, b, IDX);            \
  CHECK_RESULT(validate_uint64(c, _c[0]))

  IMM_1_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vextq_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (int8_t *)impl.test_cases_int_pointer2;
  const int elt_num = 16;
  int8_t _c[elt_num];
  int8x16_t a, b, c;

  int8_t temp_arr[elt_num * 2];
  for (int i = 0; i < elt_num; i++) {
    temp_arr[i] = _a[i];
    temp_arr[i + elt_num] = _b[i];
  }

#define TEST_IMPL(IDX)                                                                                                \
  for (int i = 0; i < elt_num; i++) {                                                                                 \
    _c[i] = temp_arr[i + IDX];                                                                                        \
  }                                                                                                                   \
  a = vld1q_s8(_a);                                                                                                   \
  b = vld1q_s8(_b);                                                                                                   \
  c = vextq_s8(a, b, IDX);                                                                                            \
  CHECK_RESULT(validate_int8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7], _c[8], _c[9], _c[10], _c[11], \
                             _c[12], _c[13], _c[14], _c[15]))

  IMM_8_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vextq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  const int elt_num = 8;
  int16_t _c[elt_num];
  int16x8_t a, b, c;

  int16_t temp_arr[elt_num * 2];
  for (int i = 0; i < elt_num; i++) {
    temp_arr[i] = _a[i];
    temp_arr[i + elt_num] = _b[i];
  }

#define TEST_IMPL(IDX)                \
  for (int i = 0; i < elt_num; i++) { \
    _c[i] = temp_arr[i + IDX];        \
  }                                   \
  a = vld1q_s16(_a);                  \
  b = vld1q_s16(_b);                  \
  c = vextq_s16(a, b, IDX);           \
  CHECK_RESULT(validate_int16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]))

  IMM_4_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vextq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  const int elt_num = 4;
  int32_t _c[elt_num];
  int32x4_t a, b, c;

  int32_t temp_arr[elt_num * 2];
  for (int i = 0; i < elt_num; i++) {
    temp_arr[i] = _a[i];
    temp_arr[i + elt_num] = _b[i];
  }

#define TEST_IMPL(IDX)                \
  for (int i = 0; i < elt_num; i++) { \
    _c[i] = temp_arr[i + IDX];        \
  }                                   \
  a = vld1q_s32(_a);                  \
  b = vld1q_s32(_b);                  \
  c = vextq_s32(a, b, IDX);           \
  CHECK_RESULT(validate_int32(c, _c[0], _c[1], _c[2], _c[3]))

  IMM_2_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vextq_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (int64_t *)impl.test_cases_int_pointer1;
  const int64_t *_b = (int64_t *)impl.test_cases_int_pointer2;
  const int elt_num = 2;
  int64_t _c[elt_num];
  int64x2_t a, b, c;

  int64_t temp_arr[elt_num * 2];
  for (int i = 0; i < elt_num; i++) {
    temp_arr[i] = _a[i];
    temp_arr[i + elt_num] = _b[i];
  }

#define TEST_IMPL(IDX)                \
  for (int i = 0; i < elt_num; i++) { \
    _c[i] = temp_arr[i + IDX];        \
  }                                   \
  a = vld1q_s64(_a);                  \
  b = vld1q_s64(_b);                  \
  c = vextq_s64(a, b, IDX);           \
  CHECK_RESULT(validate_int64(c, _c[0], _c[1]))

  IMM_1_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vextq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (float *)impl.test_cases_float_pointer1;
  const float *_b = (float *)impl.test_cases_float_pointer2;
  const int elt_num = 4;
  float _c[elt_num];
  float32x4_t a, b, c;

  float temp_arr[elt_num * 2];
  for (int i = 0; i < elt_num; i++) {
    temp_arr[i] = _a[i];
    temp_arr[i + elt_num] = _b[i];
  }

#define TEST_IMPL(IDX)                \
  for (int i = 0; i < elt_num; i++) { \
    _c[i] = temp_arr[i + IDX];        \
  }                                   \
  a = vld1q_f32(_a);                  \
  b = vld1q_f32(_b);                  \
  c = vextq_f32(a, b, IDX);           \
  CHECK_RESULT(validate_float(c, _c[0], _c[1], _c[2], _c[3]))

  IMM_2_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vext_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vextq_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vext_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vextq_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vext_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vextq_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vextq_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (uint8_t *)impl.test_cases_int_pointer2;
  const int elt_num = 16;
  uint8_t _c[elt_num];
  uint8x16_t a, b, c;

  uint8_t temp_arr[elt_num * 2];
  for (int i = 0; i < elt_num; i++) {
    temp_arr[i] = _a[i];
    temp_arr[i + elt_num] = _b[i];
  }

#define TEST_IMPL(IDX)                                                                                                 \
  for (int i = 0; i < elt_num; i++) {                                                                                  \
    _c[i] = temp_arr[i + IDX];                                                                                         \
  }                                                                                                                    \
  a = vld1q_u8(_a);                                                                                                    \
  b = vld1q_u8(_b);                                                                                                    \
  c = vextq_u8(a, b, IDX);                                                                                             \
  CHECK_RESULT(validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7], _c[8], _c[9], _c[10], _c[11], \
                              _c[12], _c[13], _c[14], _c[15]))

  IMM_8_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vextq_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (uint16_t *)impl.test_cases_int_pointer2;
  const int elt_num = 8;
  uint16_t _c[elt_num];
  uint16x8_t a, b, c;

  uint16_t temp_arr[elt_num * 2];
  for (int i = 0; i < elt_num; i++) {
    temp_arr[i] = _a[i];
    temp_arr[i + elt_num] = _b[i];
  }

#define TEST_IMPL(IDX)                \
  for (int i = 0; i < elt_num; i++) { \
    _c[i] = temp_arr[i + IDX];        \
  }                                   \
  a = vld1q_u16(_a);                  \
  b = vld1q_u16(_b);                  \
  c = vextq_u16(a, b, IDX);           \
  CHECK_RESULT(validate_uint16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]))

  IMM_4_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vextq_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (uint32_t *)impl.test_cases_int_pointer2;
  const int elt_num = 4;
  uint32_t _c[elt_num];
  uint32x4_t a, b, c;

  uint32_t temp_arr[elt_num * 2];
  for (int i = 0; i < elt_num; i++) {
    temp_arr[i] = _a[i];
    temp_arr[i + elt_num] = _b[i];
  }

#define TEST_IMPL(IDX)                \
  for (int i = 0; i < elt_num; i++) { \
    _c[i] = temp_arr[i + IDX];        \
  }                                   \
  a = vld1q_u32(_a);                  \
  b = vld1q_u32(_b);                  \
  c = vextq_u32(a, b, IDX);           \
  CHECK_RESULT(validate_uint32(c, _c[0], _c[1], _c[2], _c[3]))

  IMM_2_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vextq_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (uint64_t *)impl.test_cases_int_pointer1;
  const uint64_t *_b = (uint64_t *)impl.test_cases_int_pointer2;
  const int elt_num = 2;
  uint64_t _c[elt_num];
  uint64x2_t a, b, c;

  uint64_t temp_arr[elt_num * 2];
  for (int i = 0; i < elt_num; i++) {
    temp_arr[i] = _a[i];
    temp_arr[i + elt_num] = _b[i];
  }

#define TEST_IMPL(IDX)                \
  for (int i = 0; i < elt_num; i++) { \
    _c[i] = temp_arr[i + IDX];        \
  }                                   \
  a = vld1q_u64(_a);                  \
  b = vld1q_u64(_b);                  \
  c = vextq_u64(a, b, IDX);           \
  CHECK_RESULT(validate_uint64(c, _c[0], _c[1]))

  IMM_1_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vext_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vextq_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrev64_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  int8_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = _a[7 - i];
  }

  int8x8_t a = vld1_s8(_a);
  int8x8_t c = vrev64_s8(a);
  return validate_int8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrev64_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  int16_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = _a[3 - i];
  }

  int16x4_t a = vld1_s16(_a);
  int16x4_t c = vrev64_s16(a);
  return validate_int16(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrev64_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  int32_t _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = _a[1 - i];
  }

  int32x2_t a = vld1_s32(_a);
  int32x2_t c = vrev64_s32(a);
  return validate_int32(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrev64_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (float *)impl.test_cases_float_pointer1;
  float _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = _a[1 - i];
  }

  float32x2_t a = vld1_f32(_a);
  float32x2_t c = vrev64_f32(a);
  return validate_float(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrev64_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (uint8_t *)impl.test_cases_int_pointer1;
  uint8_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = _a[7 - i];
  }

  uint8x8_t a = vld1_u8(_a);
  uint8x8_t c = vrev64_u8(a);
  return validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrev64_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  uint16_t _c[4];
  for (int i = 0; i < 4; i++) {
    _c[i] = _a[3 - i];
  }

  uint16x4_t a = vld1_u16(_a);
  uint16x4_t c = vrev64_u16(a);
  return validate_uint16(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrev64_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  uint32_t _c[2];
  for (int i = 0; i < 2; i++) {
    _c[i] = _a[1 - i];
  }

  uint32x2_t a = vld1_u32(_a);
  uint32x2_t c = vrev64_u32(a);
  return validate_uint32(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrev64q_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  int8_t _c[16];
  for (int i = 0; i < 8; i++) {
    _c[i] = _a[7 - i];
    _c[i + 8] = _a[7 - i + 8];
  }

  int8x16_t a = vld1q_s8(_a);
  int8x16_t c = vrev64q_s8(a);
  return validate_int8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7], _c[8], _c[9], _c[10], _c[11], _c[12],
                       _c[13], _c[14], _c[15]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrev64q_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  int16_t _c[8];
  for (int i = 0; i < 4; i++) {
    _c[i] = _a[3 - i];
    _c[i + 4] = _a[3 - i + 4];
  }

  int16x8_t a = vld1q_s16(_a);
  int16x8_t c = vrev64q_s16(a);
  return validate_int16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrev64q_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  int32_t _c[4];
  for (int i = 0; i < 2; i++) {
    _c[i] = _a[1 - i];
    _c[i + 2] = _a[1 - i + 2];
  }

  int32x4_t a = vld1q_s32(_a);
  int32x4_t c = vrev64q_s32(a);
  return validate_int32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrev64q_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (float *)impl.test_cases_float_pointer1;
  float _c[4];
  for (int i = 0; i < 2; i++) {
    _c[i] = _a[1 - i];
    _c[i + 2] = _a[1 - i + 2];
  }

  float32x4_t a = vld1q_f32(_a);
  float32x4_t c = vrev64q_f32(a);
  return validate_float(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrev64_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrev64q_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrev64_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrev64q_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrev64q_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (uint8_t *)impl.test_cases_int_pointer1;
  uint8_t _c[16];
  for (int i = 0; i < 8; i++) {
    _c[i] = _a[7 - i];
    _c[i + 8] = _a[7 - i + 8];
  }

  uint8x16_t a = vld1q_u8(_a);
  uint8x16_t c = vrev64q_u8(a);
  return validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7], _c[8], _c[9], _c[10], _c[11], _c[12],
                        _c[13], _c[14], _c[15]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrev64q_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  uint16_t _c[8];
  for (int i = 0; i < 4; i++) {
    _c[i] = _a[3 - i];
    _c[i + 4] = _a[3 - i + 4];
  }

  uint16x8_t a = vld1q_u16(_a);
  uint16x8_t c = vrev64q_u16(a);
  return validate_uint16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrev64q_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  uint32_t _c[4];
  for (int i = 0; i < 2; i++) {
    _c[i] = _a[1 - i];
    _c[i + 2] = _a[1 - i + 2];
  }

  uint32x4_t a = vld1q_u32(_a);
  uint32x4_t c = vrev64q_u32(a);
  return validate_uint32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrev32_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  int half_32_num = 4;
  int8_t _c[half_32_num * 2];
  for (int i = 0; i < half_32_num; i++) {
    _c[i] = _a[(half_32_num - 1) - i];
    _c[i + half_32_num] = _a[(half_32_num - 1) - i + half_32_num];
  }

  int8x8_t a = vld1_s8(_a);
  int8x8_t c = vrev32_s8(a);
  return validate_int8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrev32_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  int half_32_num = 2;
  int16_t _c[half_32_num * 2];
  for (int i = 0; i < half_32_num; i++) {
    _c[i] = _a[(half_32_num - 1) - i];
    _c[i + half_32_num] = _a[(half_32_num - 1) - i + half_32_num];
  }

  int16x4_t a = vld1_s16(_a);
  int16x4_t c = vrev32_s16(a);
  return validate_int16(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrev32_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (uint8_t *)impl.test_cases_int_pointer1;
  int half_32_num = 4;
  uint8_t _c[half_32_num * 2];
  for (int i = 0; i < half_32_num; i++) {
    _c[i] = _a[(half_32_num - 1) - i];
    _c[i + half_32_num] = _a[(half_32_num - 1) - i + half_32_num];
  }

  uint8x8_t a = vld1_u8(_a);
  uint8x8_t c = vrev32_u8(a);
  return validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrev32_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  int half_32_num = 2;
  uint16_t _c[half_32_num * 2];
  for (int i = 0; i < half_32_num; i++) {
    _c[i] = _a[(half_32_num - 1) - i];
    _c[i + half_32_num] = _a[(half_32_num - 1) - i + half_32_num];
  }

  uint16x4_t a = vld1_u16(_a);
  uint16x4_t c = vrev32_u16(a);
  return validate_uint16(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrev32q_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  int half_32_num = 4;
  int8_t _c[half_32_num * 4];
  for (int i = 0; i < half_32_num; i++) {
    _c[i] = _a[(half_32_num - 1) - i];
    _c[i + half_32_num] = _a[(half_32_num - 1) - i + half_32_num];
    _c[i + half_32_num * 2] = _a[(half_32_num - 1) - i + half_32_num * 2];
    _c[i + half_32_num * 3] = _a[(half_32_num - 1) - i + half_32_num * 3];
  }

  int8x16_t a = vld1q_s8(_a);
  int8x16_t c = vrev32q_s8(a);
  return validate_int8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7], _c[8], _c[9], _c[10], _c[11], _c[12],
                       _c[13], _c[14], _c[15]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrev32q_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  int half_32_num = 2;
  int16_t _c[half_32_num * 4];
  for (int i = 0; i < half_32_num; i++) {
    _c[i] = _a[(half_32_num - 1) - i];
    _c[i + half_32_num] = _a[(half_32_num - 1) - i + half_32_num];
    _c[i + half_32_num * 2] = _a[(half_32_num - 1) - i + half_32_num * 2];
    _c[i + half_32_num * 3] = _a[(half_32_num - 1) - i + half_32_num * 3];
  }

  int16x8_t a = vld1q_s16(_a);
  int16x8_t c = vrev32q_s16(a);
  return validate_int16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrev32q_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (uint8_t *)impl.test_cases_int_pointer1;
  int half_32_num = 4;
  uint8_t _c[half_32_num * 4];
  for (int i = 0; i < half_32_num; i++) {
    _c[i] = _a[(half_32_num - 1) - i];
    _c[i + half_32_num] = _a[(half_32_num - 1) - i + half_32_num];
    _c[i + half_32_num * 2] = _a[(half_32_num - 1) - i + half_32_num * 2];
    _c[i + half_32_num * 3] = _a[(half_32_num - 1) - i + half_32_num * 3];
  }

  uint8x16_t a = vld1q_u8(_a);
  uint8x16_t c = vrev32q_u8(a);
  return validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7], _c[8], _c[9], _c[10], _c[11], _c[12],
                        _c[13], _c[14], _c[15]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrev32q_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  int half_32_num = 2;
  uint16_t _c[half_32_num * 4];
  for (int i = 0; i < half_32_num; i++) {
    _c[i] = _a[(half_32_num - 1) - i];
    _c[i + half_32_num] = _a[(half_32_num - 1) - i + half_32_num];
    _c[i + half_32_num * 2] = _a[(half_32_num - 1) - i + half_32_num * 2];
    _c[i + half_32_num * 3] = _a[(half_32_num - 1) - i + half_32_num * 3];
  }

  uint16x8_t a = vld1q_u16(_a);
  uint16x8_t c = vrev32q_u16(a);
  return validate_uint16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrev32_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrev32q_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrev32_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrev32q_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrev16_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  int8_t _c[8];
  for (int i = 0; i < 4; i++) {
    _c[2 * i] = _a[2 * i + 1];
    _c[2 * i + 1] = _a[2 * i];
  }
  int8x8_t a = vld1_s8(_a);
  int8x8_t c = vrev16_s8(a);
  return validate_int8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrev16_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (uint8_t *)impl.test_cases_int_pointer1;
  uint8_t _c[8];
  for (int i = 0; i < 4; i++) {
    _c[2 * i] = _a[2 * i + 1];
    _c[2 * i + 1] = _a[2 * i];
  }
  uint8x8_t a = vld1_u8(_a);
  uint8x8_t c = vrev16_u8(a);
  return validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrev16q_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  int8_t _c[16];
  for (int i = 0; i < 8; i++) {
    _c[2 * i] = _a[2 * i + 1];
    _c[2 * i + 1] = _a[2 * i];
  }
  int8x16_t a = vld1q_s8(_a);
  int8x16_t c = vrev16q_s8(a);
  return validate_int8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7], _c[8], _c[9], _c[10], _c[11], _c[12],
                       _c[13], _c[14], _c[15]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrev16q_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (uint8_t *)impl.test_cases_int_pointer1;
  uint8_t _c[16];
  for (int i = 0; i < 8; i++) {
    _c[2 * i] = _a[2 * i + 1];
    _c[2 * i + 1] = _a[2 * i];
  }
  uint8x16_t a = vld1q_u8(_a);
  uint8x16_t c = vrev16q_u8(a);
  return validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7], _c[8], _c[9], _c[10], _c[11], _c[12],
                        _c[13], _c[14], _c[15]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vrev16_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrev16q_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vzip1_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vzip1q_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vzip1_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vzip1q_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vzip1_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vzip1q_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vzip1q_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vzip1_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vzip1q_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vzip1_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vzip1q_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vzip1_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vzip1q_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vzip1q_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vzip1q_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vzip1_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vzip1q_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vzip1q_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vzip1_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vzip1q_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vzip1_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vzip1q_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vzip2_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vzip2q_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vzip2_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vzip2q_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vzip2_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vzip2q_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vzip2q_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vzip2_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vzip2q_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vzip2_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vzip2q_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vzip2_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vzip2q_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vzip2q_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vzip2q_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vzip2_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vzip2q_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vzip2q_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vzip2_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vzip2q_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vzip2_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vzip2q_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vuzp1_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vuzp1q_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vuzp1_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vuzp1q_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vuzp1_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vuzp1q_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vuzp1q_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vuzp1_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vuzp1q_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vuzp1_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vuzp1q_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vuzp1_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vuzp1q_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vuzp1q_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vuzp1q_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vuzp1_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vuzp1q_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vuzp1q_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vuzp1_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vuzp1q_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vuzp1_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vuzp1q_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vuzp2_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vuzp2q_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vuzp2_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vuzp2q_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vuzp2_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vuzp2q_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vuzp2q_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vuzp2_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vuzp2q_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vuzp2_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vuzp2q_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vuzp2_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vuzp2q_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vuzp2q_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vuzp2q_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vuzp2_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vuzp2q_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vuzp2q_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vuzp2_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vuzp2q_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vuzp2_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vuzp2q_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vtrn1_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vtrn1q_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vtrn1_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vtrn1q_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vtrn1_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vtrn1q_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vtrn1q_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vtrn1_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vtrn1q_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vtrn1_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vtrn1q_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vtrn1_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vtrn1q_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vtrn1q_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vtrn1q_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vtrn1_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vtrn1q_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vtrn1q_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vtrn1_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vtrn1q_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vtrn1_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vtrn1q_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vtrn2_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vtrn2q_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vtrn2_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vtrn2q_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vtrn2_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vtrn2q_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vtrn2q_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vtrn2_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vtrn2q_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vtrn2_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vtrn2q_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vtrn2_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vtrn2q_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vtrn2q_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vtrn2q_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vtrn2_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vtrn2q_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vtrn2q_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vtrn2_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vtrn2q_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vtrn2_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vtrn2q_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vbsl_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (int8_t *)impl.test_cases_int_pointer2;
  const int8_t *_c = (int8_t *)impl.test_cases_int_pointer3;
  int8_t _d[8];
  for (int i = 0; i < 8; i++) {
    _d[i] = _c[i] ^ ((_c[i] ^ _b[i]) & _a[i]);
  }
  uint8x8_t a = vld1_u8((const uint8_t *)_a);
  int8x8_t b = vld1_s8(_b);
  int8x8_t c = vld1_s8(_c);
  int8x8_t d = vbsl_s8(a, b, c);
  return validate_int8(d, _d[0], _d[1], _d[2], _d[3], _d[4], _d[5], _d[6], _d[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vbsl_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  const int16_t *_c = (int16_t *)impl.test_cases_int_pointer3;
  int16_t _d[4];
  for (int i = 0; i < 4; i++) {
    _d[i] = _c[i] ^ ((_c[i] ^ _b[i]) & _a[i]);
  }
  uint16x4_t a = vld1_u16((const uint16_t *)_a);
  int16x4_t b = vld1_s16(_b);
  int16x4_t c = vld1_s16(_c);
  int16x4_t d = vbsl_s16(a, b, c);
  return validate_int16(d, _d[0], _d[1], _d[2], _d[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vbsl_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  const int32_t *_c = (int32_t *)impl.test_cases_int_pointer3;
  int32_t _d[2];
  for (int i = 0; i < 2; i++) {
    _d[i] = _c[i] ^ ((_c[i] ^ _b[i]) & _a[i]);
  }
  uint32x2_t a = vld1_u32((const uint32_t *)_a);
  int32x2_t b = vld1_s32(_b);
  int32x2_t c = vld1_s32(_c);
  int32x2_t d = vbsl_s32(a, b, c);
  return validate_int32(d, _d[0], _d[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vbsl_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (int64_t *)impl.test_cases_int_pointer1;
  const int64_t *_b = (int64_t *)impl.test_cases_int_pointer2;
  const int64_t *_c = (int64_t *)impl.test_cases_int_pointer3;
  int64_t _d[1];
  for (int i = 0; i < 1; i++) {
    _d[i] = _c[i] ^ ((_c[i] ^ _b[i]) & _a[i]);
  }
  uint64x1_t a = vld1_u64((const uint64_t *)_a);
  int64x1_t b = vld1_s64(_b);
  int64x1_t c = vld1_s64(_c);
  int64x1_t d = vbsl_s64(a, b, c);
  return validate_int64(d, _d[0]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vbsl_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  const float *_b = (float *)impl.test_cases_float_pointer1;
  const float *_c = (float *)impl.test_cases_float_pointer2;
  uint32_t _d[2];
  for (int i = 0; i < 2; i++) {
    uint32_t b_u = (*(const uint32_t *)&_b[i]);
    uint32_t c_u = (*(const uint32_t *)&_c[i]);
    _d[i] = (c_u ^ ((c_u ^ b_u) & _a[i]));
  }
  uint32x2_t a = vld1_u32(_a);
  float32x2_t b = vld1_f32(_b);
  float32x2_t c = vld1_f32(_c);
  uint32x2_t d = vreinterpret_u32_f32(vbsl_f32(a, b, c));
  return validate_uint32(d, _d[0], _d[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vbsl_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (uint8_t *)impl.test_cases_int_pointer2;
  const uint8_t *_c = (uint8_t *)impl.test_cases_int_pointer3;
  uint8_t _d[8];
  for (int i = 0; i < 8; i++) {
    _d[i] = _c[i] ^ ((_c[i] ^ _b[i]) & _a[i]);
  }
  uint8x8_t a = vld1_u8((const uint8_t *)_a);
  uint8x8_t b = vld1_u8(_b);
  uint8x8_t c = vld1_u8(_c);
  uint8x8_t d = vbsl_u8(a, b, c);
  return validate_uint8(d, _d[0], _d[1], _d[2], _d[3], _d[4], _d[5], _d[6], _d[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vbsl_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (uint16_t *)impl.test_cases_int_pointer2;
  const uint16_t *_c = (uint16_t *)impl.test_cases_int_pointer3;
  uint16_t _d[4];
  for (int i = 0; i < 4; i++) {
    _d[i] = _c[i] ^ ((_c[i] ^ _b[i]) & _a[i]);
  }
  uint16x4_t a = vld1_u16((const uint16_t *)_a);
  uint16x4_t b = vld1_u16(_b);
  uint16x4_t c = vld1_u16(_c);
  uint16x4_t d = vbsl_u16(a, b, c);
  return validate_uint16(d, _d[0], _d[1], _d[2], _d[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vbsl_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (uint32_t *)impl.test_cases_int_pointer2;
  const uint32_t *_c = (uint32_t *)impl.test_cases_int_pointer3;
  uint32_t _d[2];
  for (int i = 0; i < 2; i++) {
    _d[i] = _c[i] ^ ((_c[i] ^ _b[i]) & _a[i]);
  }
  uint32x2_t a = vld1_u32((const uint32_t *)_a);
  uint32x2_t b = vld1_u32(_b);
  uint32x2_t c = vld1_u32(_c);
  uint32x2_t d = vbsl_u32(a, b, c);
  return validate_uint32(d, _d[0], _d[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vbsl_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (uint64_t *)impl.test_cases_int_pointer1;
  const uint64_t *_b = (uint64_t *)impl.test_cases_int_pointer2;
  const uint64_t *_c = (uint64_t *)impl.test_cases_int_pointer3;
  uint64_t _d[1];
  for (int i = 0; i < 1; i++) {
    _d[i] = _c[i] ^ ((_c[i] ^ _b[i]) & _a[i]);
  }
  uint64x1_t a = vld1_u64((const uint64_t *)_a);
  uint64x1_t b = vld1_u64(_b);
  uint64x1_t c = vld1_u64(_c);
  uint64x1_t d = vbsl_u64(a, b, c);
  return validate_uint64(d, _d[0]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vbslq_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (int8_t *)impl.test_cases_int_pointer2;
  const int8_t *_c = (int8_t *)impl.test_cases_int_pointer3;
  int8_t _d[16];
  for (int i = 0; i < 16; i++) {
    _d[i] = _c[i] ^ ((_c[i] ^ _b[i]) & _a[i]);
  }
  uint8x16_t a = vld1q_u8((const uint8_t *)_a);
  int8x16_t b = vld1q_s8(_b);
  int8x16_t c = vld1q_s8(_c);
  int8x16_t d = vbslq_s8(a, b, c);
  return validate_int8(d, _d[0], _d[1], _d[2], _d[3], _d[4], _d[5], _d[6], _d[7], _d[8], _d[9], _d[10], _d[11], _d[12],
                       _d[13], _d[14], _d[15]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vbslq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  const int16_t *_c = (int16_t *)impl.test_cases_int_pointer3;
  int16_t _d[8];
  for (int i = 0; i < 8; i++) {
    _d[i] = _c[i] ^ ((_c[i] ^ _b[i]) & _a[i]);
  }
  uint16x8_t a = vld1q_u16((const uint16_t *)_a);
  int16x8_t b = vld1q_s16(_b);
  int16x8_t c = vld1q_s16(_c);
  int16x8_t d = vbslq_s16(a, b, c);
  return validate_int16(d, _d[0], _d[1], _d[2], _d[3], _d[4], _d[5], _d[6], _d[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vbslq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  const int32_t *_c = (int32_t *)impl.test_cases_int_pointer3;
  int32_t _d[4];
  for (int i = 0; i < 4; i++) {
    _d[i] = _c[i] ^ ((_c[i] ^ _b[i]) & _a[i]);
  }
  uint32x4_t a = vld1q_u32((const uint32_t *)_a);
  int32x4_t b = vld1q_s32(_b);
  int32x4_t c = vld1q_s32(_c);
  int32x4_t d = vbslq_s32(a, b, c);
  return validate_int32(d, _d[0], _d[1], _d[2], _d[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vbslq_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (int64_t *)impl.test_cases_int_pointer1;
  const int64_t *_b = (int64_t *)impl.test_cases_int_pointer2;
  const int64_t *_c = (int64_t *)impl.test_cases_int_pointer3;
  int64_t _d[2];
  for (int i = 0; i < 2; i++) {
    _d[i] = _c[i] ^ ((_c[i] ^ _b[i]) & _a[i]);
  }
  uint64x2_t a = vld1q_u64((const uint64_t *)_a);
  int64x2_t b = vld1q_s64(_b);
  int64x2_t c = vld1q_s64(_c);
  int64x2_t d = vbslq_s64(a, b, c);
  return validate_int64(d, _d[0], _d[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vbslq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  const float *_b = (float *)impl.test_cases_float_pointer1;
  const float *_c = (float *)impl.test_cases_float_pointer2;
  uint32_t _d[4];
  for (int i = 0; i < 4; i++) {
    uint32_t b_u = (*(const uint32_t *)&_b[i]);
    uint32_t c_u = (*(const uint32_t *)&_c[i]);
    _d[i] = (c_u ^ ((c_u ^ b_u) & _a[i]));
  }
  uint32x4_t a = vld1q_u32(_a);
  float32x4_t b = vld1q_f32(_b);
  float32x4_t c = vld1q_f32(_c);
  uint32x4_t d = vreinterpretq_u32_f32(vbslq_f32(a, b, c));
  return validate_uint32(d, _d[0], _d[1], _d[2], _d[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vbsl_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vbslq_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vbsl_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vbslq_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vbsl_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vbslq_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcopy_lane_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcopyq_lane_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcopy_lane_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcopyq_lane_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcopy_lane_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcopyq_lane_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcopy_lane_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcopyq_lane_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcopy_lane_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcopyq_lane_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcopy_lane_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcopyq_lane_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcopy_lane_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcopyq_lane_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcopy_lane_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcopyq_lane_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcopy_lane_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcopyq_lane_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcopy_lane_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcopyq_lane_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcopy_lane_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcopyq_lane_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcopy_lane_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcopyq_lane_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcopy_lane_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcopyq_lane_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcopy_laneq_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcopyq_laneq_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcopy_laneq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcopyq_laneq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcopy_laneq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcopyq_laneq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcopy_laneq_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcopyq_laneq_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcopy_laneq_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcopyq_laneq_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcopy_laneq_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcopyq_laneq_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcopy_laneq_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcopyq_laneq_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcopy_laneq_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcopyq_laneq_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcopy_laneq_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcopyq_laneq_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcopy_laneq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcopyq_laneq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcopy_laneq_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcopyq_laneq_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcopy_laneq_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcopyq_laneq_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcopy_laneq_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vcopyq_laneq_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrbit_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrbitq_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrbit_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrbitq_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrbit_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vrbitq_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vbslq_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (uint8_t *)impl.test_cases_int_pointer2;
  const uint8_t *_c = (uint8_t *)impl.test_cases_int_pointer3;
  uint8_t _d[16];
  for (int i = 0; i < 16; i++) {
    _d[i] = _c[i] ^ ((_c[i] ^ _b[i]) & _a[i]);
  }
  uint8x16_t a = vld1q_u8((const uint8_t *)_a);
  uint8x16_t b = vld1q_u8(_b);
  uint8x16_t c = vld1q_u8(_c);
  uint8x16_t d = vbslq_u8(a, b, c);
  return validate_uint8(d, _d[0], _d[1], _d[2], _d[3], _d[4], _d[5], _d[6], _d[7], _d[8], _d[9], _d[10], _d[11], _d[12],
                        _d[13], _d[14], _d[15]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vbslq_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (uint16_t *)impl.test_cases_int_pointer2;
  const uint16_t *_c = (uint16_t *)impl.test_cases_int_pointer3;
  uint16_t _d[8];
  for (int i = 0; i < 8; i++) {
    _d[i] = _c[i] ^ ((_c[i] ^ _b[i]) & _a[i]);
  }
  uint16x8_t a = vld1q_u16((const uint16_t *)_a);
  uint16x8_t b = vld1q_u16(_b);
  uint16x8_t c = vld1q_u16(_c);
  uint16x8_t d = vbslq_u16(a, b, c);
  return validate_uint16(d, _d[0], _d[1], _d[2], _d[3], _d[4], _d[5], _d[6], _d[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vbslq_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (uint32_t *)impl.test_cases_int_pointer2;
  const uint32_t *_c = (uint32_t *)impl.test_cases_int_pointer3;
  uint32_t _d[4];
  for (int i = 0; i < 4; i++) {
    _d[i] = _c[i] ^ ((_c[i] ^ _b[i]) & _a[i]);
  }
  uint32x4_t a = vld1q_u32((const uint32_t *)_a);
  uint32x4_t b = vld1q_u32(_b);
  uint32x4_t c = vld1q_u32(_c);
  uint32x4_t d = vbslq_u32(a, b, c);
  return validate_uint32(d, _d[0], _d[1], _d[2], _d[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vbslq_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (uint64_t *)impl.test_cases_int_pointer1;
  const uint64_t *_b = (uint64_t *)impl.test_cases_int_pointer2;
  const uint64_t *_c = (uint64_t *)impl.test_cases_int_pointer3;
  uint64_t _d[2];
  for (int i = 0; i < 2; i++) {
    _d[i] = _c[i] ^ ((_c[i] ^ _b[i]) & _a[i]);
  }
  uint64x2_t a = vld1q_u64((const uint64_t *)_a);
  uint64x2_t b = vld1q_u64(_b);
  uint64x2_t c = vld1q_u64(_c);
  uint64x2_t d = vbslq_u64(a, b, c);
  return validate_uint64(d, _d[0], _d[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vbsl_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vbslq_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vtrn_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (int8_t *)impl.test_cases_int_pointer2;
  const int half_lane_num = 4;
  int8_t _c[2][half_lane_num * 2];
  for (int i = 0; i < half_lane_num; i++) {
    _c[0][2 * i] = _a[2 * i];
    _c[0][2 * i + 1] = _b[2 * i];
    _c[1][2 * i] = _a[2 * i + 1];
    _c[1][2 * i + 1] = _b[2 * i + 1];
  }

  int8x8_t a = vld1_s8(_a);
  int8x8_t b = vld1_s8(_b);
  int8x8x2_t c = vtrn_s8(a, b);

  return validate_int8(c, _c[0][0], _c[0][1], _c[0][2], _c[0][3], _c[0][4], _c[0][5], _c[0][6], _c[0][7], _c[1][0],
                       _c[1][1], _c[1][2], _c[1][3], _c[1][4], _c[1][5], _c[1][6], _c[1][7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vtrn_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  const int half_lane_num = 2;
  int16_t _c[2][half_lane_num * 2];
  for (int i = 0; i < half_lane_num; i++) {
    _c[0][2 * i] = _a[2 * i];
    _c[0][2 * i + 1] = _b[2 * i];
    _c[1][2 * i] = _a[2 * i + 1];
    _c[1][2 * i + 1] = _b[2 * i + 1];
  }

  int16x4_t a = vld1_s16(_a);
  int16x4_t b = vld1_s16(_b);
  int16x4x2_t c = vtrn_s16(a, b);

  return validate_int16(c, _c[0][0], _c[0][1], _c[0][2], _c[0][3], _c[1][0], _c[1][1], _c[1][2], _c[1][3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vtrn_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (uint8_t *)impl.test_cases_int_pointer2;
  const int half_lane_num = 4;
  uint8_t _c[2][half_lane_num * 2];
  for (int i = 0; i < half_lane_num; i++) {
    _c[0][2 * i] = _a[2 * i];
    _c[0][2 * i + 1] = _b[2 * i];
    _c[1][2 * i] = _a[2 * i + 1];
    _c[1][2 * i + 1] = _b[2 * i + 1];
  }

  uint8x8_t a = vld1_u8(_a);
  uint8x8_t b = vld1_u8(_b);
  uint8x8x2_t c = vtrn_u8(a, b);

  return validate_uint8(c, _c[0][0], _c[0][1], _c[0][2], _c[0][3], _c[0][4], _c[0][5], _c[0][6], _c[0][7], _c[1][0],
                        _c[1][1], _c[1][2], _c[1][3], _c[1][4], _c[1][5], _c[1][6], _c[1][7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vtrn_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (uint16_t *)impl.test_cases_int_pointer2;
  const int half_lane_num = 2;
  uint16_t _c[2][half_lane_num * 2];
  for (int i = 0; i < half_lane_num; i++) {
    _c[0][2 * i] = _a[2 * i];
    _c[0][2 * i + 1] = _b[2 * i];
    _c[1][2 * i] = _a[2 * i + 1];
    _c[1][2 * i + 1] = _b[2 * i + 1];
  }

  uint16x4_t a = vld1_u16(_a);
  uint16x4_t b = vld1_u16(_b);
  uint16x4x2_t c = vtrn_u16(a, b);

  return validate_uint16(c, _c[0][0], _c[0][1], _c[0][2], _c[0][3], _c[1][0], _c[1][1], _c[1][2], _c[1][3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vtrn_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vtrn_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vtrn_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;

  int32_t c10 = _a[0];
  int32_t c11 = _b[0];

  int32_t c20 = _a[1];
  int32_t c21 = _b[1];

  int32x2_t a = vld1_s32(_a);
  int32x2_t b = vld1_s32(_b);
  int32x2x2_t c = vtrn_s32(a, b);

  return validate_int32(c, c10, c11, c20, c21);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vtrn_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (float *)impl.test_cases_float_pointer1;
  const float *_b = (float *)impl.test_cases_float_pointer2;

  float c10 = _a[0];
  float c11 = _b[0];

  float c20 = _a[1];
  float c21 = _b[1];

  float32x2_t a = vld1_f32(_a);
  float32x2_t b = vld1_f32(_b);
  float32x2x2_t c = vtrn_f32(a, b);

  return validate_float(c, c10, c11, c20, c21);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vtrn_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (uint32_t *)impl.test_cases_int_pointer2;

  uint32_t c10 = _a[0];
  uint32_t c11 = _b[0];

  uint32_t c20 = _a[1];
  uint32_t c21 = _b[1];

  uint32x2_t a = vld1_u32(_a);
  uint32x2_t b = vld1_u32(_b);
  uint32x2x2_t c = vtrn_u32(a, b);

  return validate_uint32(c, c10, c11, c20, c21);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vtrnq_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (int8_t *)impl.test_cases_int_pointer2;
  const int half_lane_num = 8;
  int8_t _c[2][half_lane_num * 2];
  for (int i = 0; i < half_lane_num; i++) {
    _c[0][2 * i] = _a[2 * i];
    _c[0][2 * i + 1] = _b[2 * i];
    _c[1][2 * i] = _a[2 * i + 1];
    _c[1][2 * i + 1] = _b[2 * i + 1];
  }

  int8x16_t a = vld1q_s8(_a);
  int8x16_t b = vld1q_s8(_b);
  int8x16x2_t c = vtrnq_s8(a, b);

  return validate_int8(c, _c[0][0], _c[0][1], _c[0][2], _c[0][3], _c[0][4], _c[0][5], _c[0][6], _c[0][7], _c[0][8],
                       _c[0][9], _c[0][10], _c[0][11], _c[0][12], _c[0][13], _c[0][14], _c[0][15], _c[1][0], _c[1][1],
                       _c[1][2], _c[1][3], _c[1][4], _c[1][5], _c[1][6], _c[1][7], _c[1][8], _c[1][9], _c[1][10],
                       _c[1][11], _c[1][12], _c[1][13], _c[1][14], _c[1][15]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vtrnq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  const int half_lane_num = 4;
  int16_t _c[2][half_lane_num * 2];
  for (int i = 0; i < half_lane_num; i++) {
    _c[0][2 * i] = _a[2 * i];
    _c[0][2 * i + 1] = _b[2 * i];
    _c[1][2 * i] = _a[2 * i + 1];
    _c[1][2 * i + 1] = _b[2 * i + 1];
  }

  int16x8_t a = vld1q_s16(_a);
  int16x8_t b = vld1q_s16(_b);
  int16x8x2_t c = vtrnq_s16(a, b);

  return validate_int16(c, _c[0][0], _c[0][1], _c[0][2], _c[0][3], _c[0][4], _c[0][5], _c[0][6], _c[0][7], _c[1][0],
                        _c[1][1], _c[1][2], _c[1][3], _c[1][4], _c[1][5], _c[1][6], _c[1][7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vtrnq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  const int half_lane_num = 2;
  int32_t _c[2][half_lane_num * 2];
  for (int i = 0; i < half_lane_num; i++) {
    _c[0][2 * i] = _a[2 * i];
    _c[0][2 * i + 1] = _b[2 * i];
    _c[1][2 * i] = _a[2 * i + 1];
    _c[1][2 * i + 1] = _b[2 * i + 1];
  }

  int32x4_t a = vld1q_s32(_a);
  int32x4_t b = vld1q_s32(_b);
  int32x4x2_t c = vtrnq_s32(a, b);

  return validate_int32(c, _c[0][0], _c[0][1], _c[0][2], _c[0][3], _c[1][0], _c[1][1], _c[1][2], _c[1][3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vtrnq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (float *)impl.test_cases_float_pointer1;
  const float *_b = (float *)impl.test_cases_float_pointer2;
  const int half_lane_num = 2;
  float _c[2][half_lane_num * 2];
  for (int i = 0; i < half_lane_num; i++) {
    _c[0][2 * i] = _a[2 * i];
    _c[0][2 * i + 1] = _b[2 * i];
    _c[1][2 * i] = _a[2 * i + 1];
    _c[1][2 * i + 1] = _b[2 * i + 1];
  }

  float32x4_t a = vld1q_f32(_a);
  float32x4_t b = vld1q_f32(_b);
  float32x4x2_t c = vtrnq_f32(a, b);

  return validate_float(c, _c[0][0], _c[0][1], _c[0][2], _c[0][3], _c[1][0], _c[1][1], _c[1][2], _c[1][3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vtrnq_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (uint8_t *)impl.test_cases_int_pointer2;
  const int half_lane_num = 8;
  uint8_t _c[2][half_lane_num * 2];
  for (int i = 0; i < half_lane_num; i++) {
    _c[0][2 * i] = _a[2 * i];
    _c[0][2 * i + 1] = _b[2 * i];
    _c[1][2 * i] = _a[2 * i + 1];
    _c[1][2 * i + 1] = _b[2 * i + 1];
  }

  uint8x16_t a = vld1q_u8(_a);
  uint8x16_t b = vld1q_u8(_b);
  uint8x16x2_t c = vtrnq_u8(a, b);

  return validate_uint8(c, _c[0][0], _c[0][1], _c[0][2], _c[0][3], _c[0][4], _c[0][5], _c[0][6], _c[0][7], _c[0][8],
                        _c[0][9], _c[0][10], _c[0][11], _c[0][12], _c[0][13], _c[0][14], _c[0][15], _c[1][0], _c[1][1],
                        _c[1][2], _c[1][3], _c[1][4], _c[1][5], _c[1][6], _c[1][7], _c[1][8], _c[1][9], _c[1][10],
                        _c[1][11], _c[1][12], _c[1][13], _c[1][14], _c[1][15]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vtrnq_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (uint16_t *)impl.test_cases_int_pointer2;
  const int half_lane_num = 4;
  uint16_t _c[2][half_lane_num * 2];
  for (int i = 0; i < half_lane_num; i++) {
    _c[0][2 * i] = _a[2 * i];
    _c[0][2 * i + 1] = _b[2 * i];
    _c[1][2 * i] = _a[2 * i + 1];
    _c[1][2 * i + 1] = _b[2 * i + 1];
  }

  uint16x8_t a = vld1q_u16(_a);
  uint16x8_t b = vld1q_u16(_b);
  uint16x8x2_t c = vtrnq_u16(a, b);

  return validate_uint16(c, _c[0][0], _c[0][1], _c[0][2], _c[0][3], _c[0][4], _c[0][5], _c[0][6], _c[0][7], _c[1][0],
                         _c[1][1], _c[1][2], _c[1][3], _c[1][4], _c[1][5], _c[1][6], _c[1][7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vtrnq_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (uint32_t *)impl.test_cases_int_pointer2;
  const int half_lane_num = 2;
  uint32_t _c[2][half_lane_num * 2];
  for (int i = 0; i < half_lane_num; i++) {
    _c[0][2 * i] = _a[2 * i];
    _c[0][2 * i + 1] = _b[2 * i];
    _c[1][2 * i] = _a[2 * i + 1];
    _c[1][2 * i + 1] = _b[2 * i + 1];
  }

  uint32x4_t a = vld1q_u32(_a);
  uint32x4_t b = vld1q_u32(_b);
  uint32x4x2_t c = vtrnq_u32(a, b);

  return validate_uint32(c, _c[0][0], _c[0][1], _c[0][2], _c[0][3], _c[1][0], _c[1][1], _c[1][2], _c[1][3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vtrnq_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vtrnq_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vzip_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (int8_t *)impl.test_cases_int_pointer2;
  const int half_lane_num = 4;
  int8_t _c[2][half_lane_num * 2];
  for (int i = 0; i < half_lane_num; i++) {
    _c[0][2 * i] = _a[i];
    _c[0][2 * i + 1] = _b[i];
    _c[1][2 * i] = _a[i + half_lane_num];
    _c[1][2 * i + 1] = _b[i + half_lane_num];
  }

  int8x8_t a = vld1_s8(_a);
  int8x8_t b = vld1_s8(_b);
  int8x8x2_t c = vzip_s8(a, b);
  return validate_int8(c, _c[0][0], _c[0][1], _c[0][2], _c[0][3], _c[0][4], _c[0][5], _c[0][6], _c[0][7], _c[1][0],
                       _c[1][1], _c[1][2], _c[1][3], _c[1][4], _c[1][5], _c[1][6], _c[1][7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vzip_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  const int half_lane_num = 2;
  int16_t _c[2][half_lane_num * 2];
  for (int i = 0; i < half_lane_num; i++) {
    _c[0][2 * i] = _a[i];
    _c[0][2 * i + 1] = _b[i];
    _c[1][2 * i] = _a[i + half_lane_num];
    _c[1][2 * i + 1] = _b[i + half_lane_num];
  }

  int16x4_t a = vld1_s16(_a);
  int16x4_t b = vld1_s16(_b);
  int16x4x2_t c = vzip_s16(a, b);
  return validate_int16(c, _c[0][0], _c[0][1], _c[0][2], _c[0][3], _c[1][0], _c[1][1], _c[1][2], _c[1][3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vzip_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (uint8_t *)impl.test_cases_int_pointer2;
  const int half_lane_num = 4;
  uint8_t _c[2][half_lane_num * 2];
  for (int i = 0; i < half_lane_num; i++) {
    _c[0][2 * i] = _a[i];
    _c[0][2 * i + 1] = _b[i];
    _c[1][2 * i] = _a[i + half_lane_num];
    _c[1][2 * i + 1] = _b[i + half_lane_num];
  }

  uint8x8_t a = vld1_u8(_a);
  uint8x8_t b = vld1_u8(_b);
  uint8x8x2_t c = vzip_u8(a, b);
  return validate_uint8(c, _c[0][0], _c[0][1], _c[0][2], _c[0][3], _c[0][4], _c[0][5], _c[0][6], _c[0][7], _c[1][0],
                        _c[1][1], _c[1][2], _c[1][3], _c[1][4], _c[1][5], _c[1][6], _c[1][7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vzip_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (uint16_t *)impl.test_cases_int_pointer2;
  const int half_lane_num = 2;
  uint16_t _c[2][half_lane_num * 2];
  for (int i = 0; i < half_lane_num; i++) {
    _c[0][2 * i] = _a[i];
    _c[0][2 * i + 1] = _b[i];
    _c[1][2 * i] = _a[i + half_lane_num];
    _c[1][2 * i + 1] = _b[i + half_lane_num];
  }

  uint16x4_t a = vld1_u16(_a);
  uint16x4_t b = vld1_u16(_b);
  uint16x4x2_t c = vzip_u16(a, b);
  return validate_uint16(c, _c[0][0], _c[0][1], _c[0][2], _c[0][3], _c[1][0], _c[1][1], _c[1][2], _c[1][3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vzip_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vzip_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vzip_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  int32_t _c[2][2];
  _c[0][0] = _a[0];
  _c[0][1] = _b[0];

  _c[1][0] = _a[1];
  _c[1][1] = _b[1];

  int32x2_t a = vld1_s32(_a);
  int32x2_t b = vld1_s32(_b);
  int32x2x2_t c = vzip_s32(a, b);
  return validate_int32(c, _c[0][0], _c[0][1], _c[1][0], _c[1][1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vzip_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (float *)impl.test_cases_float_pointer1;
  const float *_b = (float *)impl.test_cases_float_pointer2;
  float _c[2][2];
  _c[0][0] = _a[0];
  _c[0][1] = _b[0];

  _c[1][0] = _a[1];
  _c[1][1] = _b[1];

  float32x2_t a = vld1_f32(_a);
  float32x2_t b = vld1_f32(_b);
  float32x2x2_t c = vzip_f32(a, b);
  return validate_float(c, _c[0][0], _c[0][1], _c[1][0], _c[1][1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vzip_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (uint32_t *)impl.test_cases_int_pointer2;
  uint32_t _c[2][2];
  _c[0][0] = _a[0];
  _c[0][1] = _b[0];

  _c[1][0] = _a[1];
  _c[1][1] = _b[1];

  uint32x2_t a = vld1_u32(_a);
  uint32x2_t b = vld1_u32(_b);
  uint32x2x2_t c = vzip_u32(a, b);
  return validate_uint32(c, _c[0][0], _c[0][1], _c[1][0], _c[1][1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vzipq_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (int8_t *)impl.test_cases_int_pointer2;
  const int half_lane_num = 8;
  int8_t _c[2][half_lane_num * 2];
  for (int i = 0; i < half_lane_num; i++) {
    _c[0][2 * i] = _a[i];
    _c[0][2 * i + 1] = _b[i];
    _c[1][2 * i] = _a[i + half_lane_num];
    _c[1][2 * i + 1] = _b[i + half_lane_num];
  }

  int8x16_t a = vld1q_s8(_a);
  int8x16_t b = vld1q_s8(_b);
  int8x16x2_t c = vzipq_s8(a, b);
  return validate_int8(c, _c[0][0], _c[0][1], _c[0][2], _c[0][3], _c[0][4], _c[0][5], _c[0][6], _c[0][7], _c[0][8],
                       _c[0][9], _c[0][10], _c[0][11], _c[0][12], _c[0][13], _c[0][14], _c[0][15], _c[1][0], _c[1][1],
                       _c[1][2], _c[1][3], _c[1][4], _c[1][5], _c[1][6], _c[1][7], _c[1][8], _c[1][9], _c[1][10],
                       _c[1][11], _c[1][12], _c[1][13], _c[1][14], _c[1][15]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vzipq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  const int half_lane_num = 4;
  int16_t _c[2][half_lane_num * 2];
  for (int i = 0; i < half_lane_num; i++) {
    _c[0][2 * i] = _a[i];
    _c[0][2 * i + 1] = _b[i];
    _c[1][2 * i] = _a[i + half_lane_num];
    _c[1][2 * i + 1] = _b[i + half_lane_num];
  }

  int16x8_t a = vld1q_s16(_a);
  int16x8_t b = vld1q_s16(_b);
  int16x8x2_t c = vzipq_s16(a, b);
  return validate_int16(c, _c[0][0], _c[0][1], _c[0][2], _c[0][3], _c[0][4], _c[0][5], _c[0][6], _c[0][7], _c[1][0],
                        _c[1][1], _c[1][2], _c[1][3], _c[1][4], _c[1][5], _c[1][6], _c[1][7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vzipq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  const int half_lane_num = 2;
  int32_t _c[2][half_lane_num * 2];
  for (int i = 0; i < half_lane_num; i++) {
    _c[0][2 * i] = _a[i];
    _c[0][2 * i + 1] = _b[i];
    _c[1][2 * i] = _a[i + half_lane_num];
    _c[1][2 * i + 1] = _b[i + half_lane_num];
  }

  int32x4_t a = vld1q_s32(_a);
  int32x4_t b = vld1q_s32(_b);
  int32x4x2_t c = vzipq_s32(a, b);
  return validate_int32(c, _c[0][0], _c[0][1], _c[0][2], _c[0][3], _c[1][0], _c[1][1], _c[1][2], _c[1][3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vzipq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (float *)impl.test_cases_float_pointer1;
  const float *_b = (float *)impl.test_cases_float_pointer2;
  const int half_lane_num = 2;
  float _c[2][half_lane_num * 2];
  for (int i = 0; i < half_lane_num; i++) {
    _c[0][2 * i] = _a[i];
    _c[0][2 * i + 1] = _b[i];
    _c[1][2 * i] = _a[i + half_lane_num];
    _c[1][2 * i + 1] = _b[i + half_lane_num];
  }

  float32x4_t a = vld1q_f32(_a);
  float32x4_t b = vld1q_f32(_b);
  float32x4x2_t c = vzipq_f32(a, b);
  return validate_float(c, _c[0][0], _c[0][1], _c[0][2], _c[0][3], _c[1][0], _c[1][1], _c[1][2], _c[1][3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vzipq_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (uint8_t *)impl.test_cases_int_pointer2;
  const int half_lane_num = 8;
  uint8_t _c[2][half_lane_num * 2];
  for (int i = 0; i < half_lane_num; i++) {
    _c[0][2 * i] = _a[i];
    _c[0][2 * i + 1] = _b[i];
    _c[1][2 * i] = _a[i + half_lane_num];
    _c[1][2 * i + 1] = _b[i + half_lane_num];
  }

  uint8x16_t a = vld1q_u8(_a);
  uint8x16_t b = vld1q_u8(_b);
  uint8x16x2_t c = vzipq_u8(a, b);
  return validate_uint8(c, _c[0][0], _c[0][1], _c[0][2], _c[0][3], _c[0][4], _c[0][5], _c[0][6], _c[0][7], _c[0][8],
                        _c[0][9], _c[0][10], _c[0][11], _c[0][12], _c[0][13], _c[0][14], _c[0][15], _c[1][0], _c[1][1],
                        _c[1][2], _c[1][3], _c[1][4], _c[1][5], _c[1][6], _c[1][7], _c[1][8], _c[1][9], _c[1][10],
                        _c[1][11], _c[1][12], _c[1][13], _c[1][14], _c[1][15]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vzipq_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (uint16_t *)impl.test_cases_int_pointer2;
  const int half_lane_num = 4;
  uint16_t _c[2][half_lane_num * 2];
  for (int i = 0; i < half_lane_num; i++) {
    _c[0][2 * i] = _a[i];
    _c[0][2 * i + 1] = _b[i];
    _c[1][2 * i] = _a[i + half_lane_num];
    _c[1][2 * i + 1] = _b[i + half_lane_num];
  }

  uint16x8_t a = vld1q_u16(_a);
  uint16x8_t b = vld1q_u16(_b);
  uint16x8x2_t c = vzipq_u16(a, b);
  return validate_uint16(c, _c[0][0], _c[0][1], _c[0][2], _c[0][3], _c[0][4], _c[0][5], _c[0][6], _c[0][7], _c[1][0],
                         _c[1][1], _c[1][2], _c[1][3], _c[1][4], _c[1][5], _c[1][6], _c[1][7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vzipq_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (uint32_t *)impl.test_cases_int_pointer2;
  const int half_lane_num = 2;
  uint32_t _c[2][half_lane_num * 2];
  for (int i = 0; i < half_lane_num; i++) {
    _c[0][2 * i] = _a[i];
    _c[0][2 * i + 1] = _b[i];
    _c[1][2 * i] = _a[i + half_lane_num];
    _c[1][2 * i + 1] = _b[i + half_lane_num];
  }

  uint32x4_t a = vld1q_u32(_a);
  uint32x4_t b = vld1q_u32(_b);
  uint32x4x2_t c = vzipq_u32(a, b);
  return validate_uint32(c, _c[0][0], _c[0][1], _c[0][2], _c[0][3], _c[1][0], _c[1][1], _c[1][2], _c[1][3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vzipq_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vzipq_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vuzp_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (int8_t *)impl.test_cases_int_pointer2;
  const int half_lane_num = 4;
  int8_t _c[2][half_lane_num * 2];
  for (int i = 0; i < half_lane_num; i++) {
    _c[0][i] = _a[2 * i];
    _c[0][i + half_lane_num] = _b[2 * i];
    _c[1][i] = _a[2 * i + 1];
    _c[1][i + half_lane_num] = _b[2 * i + 1];
  }

  int8x8_t a = vld1_s8(_a);
  int8x8_t b = vld1_s8(_b);
  int8x8x2_t c = vuzp_s8(a, b);
  return validate_int8(c, _c[0][0], _c[0][1], _c[0][2], _c[0][3], _c[0][4], _c[0][5], _c[0][6], _c[0][7], _c[1][0],
                       _c[1][1], _c[1][2], _c[1][3], _c[1][4], _c[1][5], _c[1][6], _c[1][7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vuzp_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  const int half_lane_num = 2;
  int16_t _c[2][half_lane_num * 2];
  for (int i = 0; i < half_lane_num; i++) {
    _c[0][i] = _a[2 * i];
    _c[0][i + half_lane_num] = _b[2 * i];
    _c[1][i] = _a[2 * i + 1];
    _c[1][i + half_lane_num] = _b[2 * i + 1];
  }

  int16x4_t a = vld1_s16(_a);
  int16x4_t b = vld1_s16(_b);
  int16x4x2_t c = vuzp_s16(a, b);
  return validate_int16(c, _c[0][0], _c[0][1], _c[0][2], _c[0][3], _c[1][0], _c[1][1], _c[1][2], _c[1][3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vuzp_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  const int half_lane_num = 1;
  int32_t _c[2][half_lane_num * 2];
  for (int i = 0; i < half_lane_num; i++) {
    _c[0][i] = _a[2 * i];
    _c[0][i + half_lane_num] = _b[2 * i];
    _c[1][i] = _a[2 * i + 1];
    _c[1][i + half_lane_num] = _b[2 * i + 1];
  }

  int32x2_t a = vld1_s32(_a);
  int32x2_t b = vld1_s32(_b);
  int32x2x2_t c = vuzp_s32(a, b);
  return validate_int32(c, _c[0][0], _c[0][1], _c[1][0], _c[1][1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vuzp_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (float *)impl.test_cases_float_pointer1;
  const float *_b = (float *)impl.test_cases_float_pointer2;
  const int half_lane_num = 1;
  float _c[2][half_lane_num * 2];
  for (int i = 0; i < half_lane_num; i++) {
    _c[0][i] = _a[2 * i];
    _c[0][i + half_lane_num] = _b[2 * i];
    _c[1][i] = _a[2 * i + 1];
    _c[1][i + half_lane_num] = _b[2 * i + 1];
  }

  float32x2_t a = vld1_f32(_a);
  float32x2_t b = vld1_f32(_b);
  float32x2x2_t c = vuzp_f32(a, b);
  return validate_float(c, _c[0][0], _c[0][1], _c[1][0], _c[1][1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vuzp_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (uint8_t *)impl.test_cases_int_pointer2;
  const int half_lane_num = 4;
  uint8_t _c[2][half_lane_num * 2];
  for (int i = 0; i < half_lane_num; i++) {
    _c[0][i] = _a[2 * i];
    _c[0][i + half_lane_num] = _b[2 * i];
    _c[1][i] = _a[2 * i + 1];
    _c[1][i + half_lane_num] = _b[2 * i + 1];
  }

  uint8x8_t a = vld1_u8(_a);
  uint8x8_t b = vld1_u8(_b);
  uint8x8x2_t c = vuzp_u8(a, b);
  return validate_uint8(c, _c[0][0], _c[0][1], _c[0][2], _c[0][3], _c[0][4], _c[0][5], _c[0][6], _c[0][7], _c[1][0],
                        _c[1][1], _c[1][2], _c[1][3], _c[1][4], _c[1][5], _c[1][6], _c[1][7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vuzp_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (uint16_t *)impl.test_cases_int_pointer2;
  const int half_lane_num = 2;
  uint16_t _c[2][half_lane_num * 2];
  for (int i = 0; i < half_lane_num; i++) {
    _c[0][i] = _a[2 * i];
    _c[0][i + half_lane_num] = _b[2 * i];
    _c[1][i] = _a[2 * i + 1];
    _c[1][i + half_lane_num] = _b[2 * i + 1];
  }

  uint16x4_t a = vld1_u16(_a);
  uint16x4_t b = vld1_u16(_b);
  uint16x4x2_t c = vuzp_u16(a, b);
  return validate_uint16(c, _c[0][0], _c[0][1], _c[0][2], _c[0][3], _c[1][0], _c[1][1], _c[1][2], _c[1][3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vuzp_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (uint32_t *)impl.test_cases_int_pointer2;
  const int half_lane_num = 1;
  uint32_t _c[2][half_lane_num * 2];
  for (int i = 0; i < half_lane_num; i++) {
    _c[0][i] = _a[2 * i];
    _c[0][i + half_lane_num] = _b[2 * i];
    _c[1][i] = _a[2 * i + 1];
    _c[1][i + half_lane_num] = _b[2 * i + 1];
  }

  uint32x2_t a = vld1_u32(_a);
  uint32x2_t b = vld1_u32(_b);
  uint32x2x2_t c = vuzp_u32(a, b);
  return validate_uint32(c, _c[0][0], _c[0][1], _c[1][0], _c[1][1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vuzp_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vuzp_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vuzpq_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (int8_t *)impl.test_cases_int_pointer2;
  const int half_lane_num = 8;
  int8_t _c[2][half_lane_num * 2];
  for (int i = 0; i < half_lane_num; i++) {
    _c[0][i] = _a[2 * i];
    _c[0][i + half_lane_num] = _b[2 * i];
    _c[1][i] = _a[2 * i + 1];
    _c[1][i + half_lane_num] = _b[2 * i + 1];
  }

  int8x16_t a = vld1q_s8(_a);
  int8x16_t b = vld1q_s8(_b);
  int8x16x2_t c = vuzpq_s8(a, b);
  return validate_int8(c, _c[0][0], _c[0][1], _c[0][2], _c[0][3], _c[0][4], _c[0][5], _c[0][6], _c[0][7], _c[0][8],
                       _c[0][9], _c[0][10], _c[0][11], _c[0][12], _c[0][13], _c[0][14], _c[0][15], _c[1][0], _c[1][1],
                       _c[1][2], _c[1][3], _c[1][4], _c[1][5], _c[1][6], _c[1][7], _c[1][8], _c[1][9], _c[1][10],
                       _c[1][11], _c[1][12], _c[1][13], _c[1][14], _c[1][15]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vuzpq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  const int half_lane_num = 4;
  int16_t _c[2][half_lane_num * 2];
  for (int i = 0; i < half_lane_num; i++) {
    _c[0][i] = _a[2 * i];
    _c[0][i + half_lane_num] = _b[2 * i];
    _c[1][i] = _a[2 * i + 1];
    _c[1][i + half_lane_num] = _b[2 * i + 1];
  }

  int16x8_t a = vld1q_s16(_a);
  int16x8_t b = vld1q_s16(_b);
  int16x8x2_t c = vuzpq_s16(a, b);
  return validate_int16(c, _c[0][0], _c[0][1], _c[0][2], _c[0][3], _c[0][4], _c[0][5], _c[0][6], _c[0][7], _c[1][0],
                        _c[1][1], _c[1][2], _c[1][3], _c[1][4], _c[1][5], _c[1][6], _c[1][7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vuzpq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  const int half_lane_num = 2;
  int32_t _c[2][half_lane_num * 2];
  for (int i = 0; i < half_lane_num; i++) {
    _c[0][i] = _a[2 * i];
    _c[0][i + half_lane_num] = _b[2 * i];
    _c[1][i] = _a[2 * i + 1];
    _c[1][i + half_lane_num] = _b[2 * i + 1];
  }

  int32x4_t a = vld1q_s32(_a);
  int32x4_t b = vld1q_s32(_b);
  int32x4x2_t c = vuzpq_s32(a, b);
  return validate_int32(c, _c[0][0], _c[0][1], _c[0][2], _c[0][3], _c[1][0], _c[1][1], _c[1][2], _c[1][3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vuzpq_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (float *)impl.test_cases_float_pointer1;
  const float *_b = (float *)impl.test_cases_float_pointer2;
  const int half_lane_num = 2;
  float _c[2][half_lane_num * 2];
  for (int i = 0; i < half_lane_num; i++) {
    _c[0][i] = _a[2 * i];
    _c[0][i + half_lane_num] = _b[2 * i];
    _c[1][i] = _a[2 * i + 1];
    _c[1][i + half_lane_num] = _b[2 * i + 1];
  }

  float32x4_t a = vld1q_f32(_a);
  float32x4_t b = vld1q_f32(_b);
  float32x4x2_t c = vuzpq_f32(a, b);
  return validate_float(c, _c[0][0], _c[0][1], _c[0][2], _c[0][3], _c[1][0], _c[1][1], _c[1][2], _c[1][3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vuzpq_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (uint8_t *)impl.test_cases_int_pointer2;
  const int half_lane_num = 8;
  uint8_t _c[2][half_lane_num * 2];
  for (int i = 0; i < half_lane_num; i++) {
    _c[0][i] = _a[2 * i];
    _c[0][i + half_lane_num] = _b[2 * i];
    _c[1][i] = _a[2 * i + 1];
    _c[1][i + half_lane_num] = _b[2 * i + 1];
  }

  uint8x16_t a = vld1q_u8(_a);
  uint8x16_t b = vld1q_u8(_b);
  uint8x16x2_t c = vuzpq_u8(a, b);
  return validate_uint8(c, _c[0][0], _c[0][1], _c[0][2], _c[0][3], _c[0][4], _c[0][5], _c[0][6], _c[0][7], _c[0][8],
                        _c[0][9], _c[0][10], _c[0][11], _c[0][12], _c[0][13], _c[0][14], _c[0][15], _c[1][0], _c[1][1],
                        _c[1][2], _c[1][3], _c[1][4], _c[1][5], _c[1][6], _c[1][7], _c[1][8], _c[1][9], _c[1][10],
                        _c[1][11], _c[1][12], _c[1][13], _c[1][14], _c[1][15]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vuzpq_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (uint16_t *)impl.test_cases_int_pointer2;
  const int half_lane_num = 4;
  uint16_t _c[2][half_lane_num * 2];
  for (int i = 0; i < half_lane_num; i++) {
    _c[0][i] = _a[2 * i];
    _c[0][i + half_lane_num] = _b[2 * i];
    _c[1][i] = _a[2 * i + 1];
    _c[1][i + half_lane_num] = _b[2 * i + 1];
  }

  uint16x8_t a = vld1q_u16(_a);
  uint16x8_t b = vld1q_u16(_b);
  uint16x8x2_t c = vuzpq_u16(a, b);
  return validate_uint16(c, _c[0][0], _c[0][1], _c[0][2], _c[0][3], _c[0][4], _c[0][5], _c[0][6], _c[0][7], _c[1][0],
                         _c[1][1], _c[1][2], _c[1][3], _c[1][4], _c[1][5], _c[1][6], _c[1][7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vuzpq_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (uint32_t *)impl.test_cases_int_pointer2;
  const int half_lane_num = 2;
  uint32_t _c[2][half_lane_num * 2];
  for (int i = 0; i < half_lane_num; i++) {
    _c[0][i] = _a[2 * i];
    _c[0][i + half_lane_num] = _b[2 * i];
    _c[1][i] = _a[2 * i + 1];
    _c[1][i + half_lane_num] = _b[2 * i + 1];
  }

  uint32x4_t a = vld1q_u32(_a);
  uint32x4_t b = vld1q_u32(_b);
  uint32x4x2_t c = vuzpq_u32(a, b);
  return validate_uint32(c, _c[0][0], _c[0][1], _c[0][2], _c[0][3], _c[1][0], _c[1][1], _c[1][2], _c[1][3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vuzpq_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vuzpq_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  int8x8_t c = vld1_s8(_a);
  return validate_int8(c, _a[0], _a[1], _a[2], _a[3], _a[4], _a[5], _a[6], _a[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld1_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  int16x4_t c = vld1_s16(_a);
  return validate_int16(c, _a[0], _a[1], _a[2], _a[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld1_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  int32x2_t c = vld1_s32(_a);
  return validate_int32(c, _a[0], _a[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld1_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (int64_t *)impl.test_cases_int_pointer1;
  int64x1_t c = vld1_s64(_a);
  return validate_int64(c, _a[0]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld1_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = impl.test_cases_float_pointer1;
  float32x2_t c = vld1_f32(_a);
  return validate_float(c, _a[0], _a[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld1_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (uint8_t *)impl.test_cases_int_pointer1;
  uint8x8_t c = vld1_u8(_a);
  return validate_uint8(c, _a[0], _a[1], _a[2], _a[3], _a[4], _a[5], _a[6], _a[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld1_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  uint16x4_t c = vld1_u16(_a);
  return validate_uint16(c, _a[0], _a[1], _a[2], _a[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld1_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  uint32x2_t c = vld1_u32(_a);
  return validate_uint32(c, _a[0], _a[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld1_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (uint64_t *)impl.test_cases_int_pointer1;
  uint64x1_t c = vld1_u64(_a);
  return validate_uint64(c, _a[0]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld1q_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  int8x16_t c = vld1q_s8(_a);
  return validate_int8(c, _a[0], _a[1], _a[2], _a[3], _a[4], _a[5], _a[6], _a[7], _a[8], _a[9], _a[10], _a[11], _a[12],
                       _a[13], _a[14], _a[15]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld1q_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  int16x8_t c = vld1q_s16(_a);
  return validate_int16(c, _a[0], _a[1], _a[2], _a[3], _a[4], _a[5], _a[6], _a[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld1q_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  int32x4_t c = vld1q_s32(_a);
  return validate_int32(c, _a[0], _a[1], _a[2], _a[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld1q_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (int64_t *)impl.test_cases_int_pointer1;
  int64x2_t c = vld1q_s64(_a);
  return validate_int64(c, _a[0], _a[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld1q_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = impl.test_cases_float_pointer1;
  float32x4_t c = vld1q_f32(_a);
  return validate_float(c, _a[0], _a[1], _a[2], _a[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld1_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1q_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1q_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const double *_a = (double *)impl.test_cases_float_pointer1;
  float64x1_t c = vld1_f64(_a);
  return validate_double(c, _a[0]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld1q_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const double *_a = (double *)impl.test_cases_float_pointer1;
  float64x2_t c = vld1q_f64(_a);
  return validate_double(c, _a[0], _a[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld1q_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (uint8_t *)impl.test_cases_int_pointer1;
  uint8x16_t c = vld1q_u8(_a);
  return validate_uint8(c, _a[0], _a[1], _a[2], _a[3], _a[4], _a[5], _a[6], _a[7], _a[8], _a[9], _a[10], _a[11], _a[12],
                        _a[13], _a[14], _a[15]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld1q_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  uint16x8_t c = vld1q_u16(_a);
  return validate_uint16(c, _a[0], _a[1], _a[2], _a[3], _a[4], _a[5], _a[6], _a[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld1q_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  uint32x4_t c = vld1q_u32(_a);
  return validate_uint32(c, _a[0], _a[1], _a[2], _a[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld1q_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (uint64_t *)impl.test_cases_int_pointer1;
  uint64x2_t c = vld1q_u64(_a);
  return validate_uint64(c, _a[0], _a[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld1_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1q_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1q_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1_lane_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (int8_t *)impl.test_cases_int_pointer2;
  int8_t _c[8];
  int8x8_t c;
  int8x8_t b = vld1_s8(_b);
#define TEST_IMPL(IDX)          \
  for (int i = 0; i < 8; i++) { \
    if (i != IDX) {             \
      _c[i] = _b[i];            \
    } else {                    \
      _c[i] = _a[0];            \
    }                           \
  }                             \
  c = vld1_lane_s8(_a, b, IDX); \
  CHECK_RESULT(validate_int8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]))

  IMM_8_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld1_lane_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  int16_t _c[4];
  int16x4_t c;
  int16x4_t b = vld1_s16(_b);
#define TEST_IMPL(IDX)           \
  for (int i = 0; i < 4; i++) {  \
    if (i != IDX) {              \
      _c[i] = _b[i];             \
    } else {                     \
      _c[i] = _a[0];             \
    }                            \
  }                              \
  c = vld1_lane_s16(_a, b, IDX); \
  CHECK_RESULT(validate_int16(c, _c[0], _c[1], _c[2], _c[3]))

  IMM_4_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld1_lane_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  int32_t _c[2];
  int32x2_t c;
  int32x2_t b = vld1_s32(_b);
#define TEST_IMPL(IDX)           \
  for (int i = 0; i < 2; i++) {  \
    if (i != IDX) {              \
      _c[i] = _b[i];             \
    } else {                     \
      _c[i] = _a[0];             \
    }                            \
  }                              \
  c = vld1_lane_s32(_a, b, IDX); \
  CHECK_RESULT(validate_int32(c, _c[0], _c[1]))

  IMM_2_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld1_lane_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (float *)impl.test_cases_float_pointer1;
  const float *_b = (float *)impl.test_cases_float_pointer2;
  float _c[2];
  float32x2_t c;
  float32x2_t b = vld1_f32(_b);
#define TEST_IMPL(IDX)           \
  for (int i = 0; i < 2; i++) {  \
    if (i != IDX) {              \
      _c[i] = _b[i];             \
    } else {                     \
      _c[i] = _a[0];             \
    }                            \
  }                              \
  c = vld1_lane_f32(_a, b, IDX); \
  CHECK_RESULT(validate_float(c, _c[0], _c[1]))

  IMM_2_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld1_lane_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (uint8_t *)impl.test_cases_int_pointer2;
  uint8_t _c[8];
  uint8x8_t c;
  uint8x8_t b = vld1_u8(_b);
#define TEST_IMPL(IDX)          \
  for (int i = 0; i < 8; i++) { \
    if (i != IDX) {             \
      _c[i] = _b[i];            \
    } else {                    \
      _c[i] = _a[0];            \
    }                           \
  }                             \
  c = vld1_lane_u8(_a, b, IDX); \
  CHECK_RESULT(validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]))

  IMM_8_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld1_lane_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (uint16_t *)impl.test_cases_int_pointer2;
  uint16_t _c[4];
  uint16x4_t c;
  uint16x4_t b = vld1_u16(_b);
#define TEST_IMPL(IDX)           \
  for (int i = 0; i < 4; i++) {  \
    if (i != IDX) {              \
      _c[i] = _b[i];             \
    } else {                     \
      _c[i] = _a[0];             \
    }                            \
  }                              \
  c = vld1_lane_u16(_a, b, IDX); \
  CHECK_RESULT(validate_uint16(c, _c[0], _c[1], _c[2], _c[3]))

  IMM_4_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld1_lane_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (uint32_t *)impl.test_cases_int_pointer2;
  uint32_t _c[2];
  uint32x2_t c;
  uint32x2_t b = vld1_u32(_b);
#define TEST_IMPL(IDX)           \
  for (int i = 0; i < 2; i++) {  \
    if (i != IDX) {              \
      _c[i] = _b[i];             \
    } else {                     \
      _c[i] = _a[0];             \
    }                            \
  }                              \
  c = vld1_lane_u32(_a, b, IDX); \
  CHECK_RESULT(validate_uint32(c, _c[0], _c[1]))

  IMM_2_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld1_lane_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (int64_t *)impl.test_cases_int_pointer1;
  const int64_t *_b = (int64_t *)impl.test_cases_int_pointer2;
  uint64_t _c[1];
  int64x1_t c;
  int64x1_t b = vld1_s64(_b);
#define TEST_IMPL(IDX)           \
  for (int i = 0; i < 1; i++) {  \
    if (i != IDX) {              \
      _c[i] = _b[i];             \
    } else {                     \
      _c[i] = _a[0];             \
    }                            \
  }                              \
  c = vld1_lane_s64(_a, b, IDX); \
  CHECK_RESULT(validate_int64(c, _c[0]))

  IMM_1_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld1_lane_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (uint64_t *)impl.test_cases_int_pointer1;
  const uint64_t *_b = (uint64_t *)impl.test_cases_int_pointer2;
  uint64_t _c[1];
  uint64x1_t c;
  uint64x1_t b = vld1_u64(_b);
#define TEST_IMPL(IDX)           \
  for (int i = 0; i < 1; i++) {  \
    if (i != IDX) {              \
      _c[i] = _b[i];             \
    } else {                     \
      _c[i] = _a[0];             \
    }                            \
  }                              \
  c = vld1_lane_u64(_a, b, IDX); \
  CHECK_RESULT(validate_uint64(c, _c[0]))

  IMM_1_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld1q_lane_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (int8_t *)impl.test_cases_int_pointer2;
  int8_t _c[16];
  int8x16_t c;
  int8x16_t b = vld1q_s8(_b);
#define TEST_IMPL(IDX)                                                                                                \
  for (int i = 0; i < 16; i++) {                                                                                      \
    if (i != IDX) {                                                                                                   \
      _c[i] = _b[i];                                                                                                  \
    } else {                                                                                                          \
      _c[i] = _a[0];                                                                                                  \
    }                                                                                                                 \
  }                                                                                                                   \
  c = vld1q_lane_s8(_a, b, IDX);                                                                                      \
  CHECK_RESULT(validate_int8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7], _c[8], _c[9], _c[10], _c[11], \
                             _c[12], _c[13], _c[14], _c[15]))

  IMM_8_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld1q_lane_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  int16_t _c[8];
  int16x8_t c;
  int16x8_t b = vld1q_s16(_b);
#define TEST_IMPL(IDX)            \
  for (int i = 0; i < 8; i++) {   \
    if (i != IDX) {               \
      _c[i] = _b[i];              \
    } else {                      \
      _c[i] = _a[0];              \
    }                             \
  }                               \
  c = vld1q_lane_s16(_a, b, IDX); \
  CHECK_RESULT(validate_int16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]))

  IMM_4_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld1q_lane_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  int32_t _c[4];
  int32x4_t c;
  int32x4_t b = vld1q_s32(_b);
#define TEST_IMPL(IDX)            \
  for (int i = 0; i < 4; i++) {   \
    if (i != IDX) {               \
      _c[i] = _b[i];              \
    } else {                      \
      _c[i] = _a[0];              \
    }                             \
  }                               \
  c = vld1q_lane_s32(_a, b, IDX); \
  CHECK_RESULT(validate_int32(c, _c[0], _c[1], _c[2], _c[3]))

  IMM_2_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld1q_lane_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (float *)impl.test_cases_float_pointer1;
  const float *_b = (float *)impl.test_cases_float_pointer2;
  float _c[4];
  float32x4_t c;
  float32x4_t b = vld1q_f32(_b);
#define TEST_IMPL(IDX)            \
  for (int i = 0; i < 4; i++) {   \
    if (i != IDX) {               \
      _c[i] = _b[i];              \
    } else {                      \
      _c[i] = _a[0];              \
    }                             \
  }                               \
  c = vld1q_lane_f32(_a, b, IDX); \
  CHECK_RESULT(validate_float(c, _c[0], _c[1], _c[2], _c[3]))

  IMM_2_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld1_lane_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1q_lane_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1_lane_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1q_lane_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1_lane_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1q_lane_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1q_lane_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (uint8_t *)impl.test_cases_int_pointer2;
  uint8_t _c[16];
  uint8x16_t c;
  uint8x16_t b = vld1q_u8(_b);
#define TEST_IMPL(IDX)                                                                                                 \
  for (int i = 0; i < 16; i++) {                                                                                       \
    if (i != IDX) {                                                                                                    \
      _c[i] = _b[i];                                                                                                   \
    } else {                                                                                                           \
      _c[i] = _a[0];                                                                                                   \
    }                                                                                                                  \
  }                                                                                                                    \
  c = vld1q_lane_u8(_a, b, IDX);                                                                                       \
  CHECK_RESULT(validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7], _c[8], _c[9], _c[10], _c[11], \
                              _c[12], _c[13], _c[14], _c[15]))

  IMM_8_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld1q_lane_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (uint16_t *)impl.test_cases_int_pointer2;
  uint16_t _c[8];
  uint16x8_t c;
  uint16x8_t b = vld1q_u16(_b);
#define TEST_IMPL(IDX)            \
  for (int i = 0; i < 8; i++) {   \
    if (i != IDX) {               \
      _c[i] = _b[i];              \
    } else {                      \
      _c[i] = _a[0];              \
    }                             \
  }                               \
  c = vld1q_lane_u16(_a, b, IDX); \
  CHECK_RESULT(validate_uint16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]))

  IMM_4_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld1q_lane_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (uint32_t *)impl.test_cases_int_pointer2;
  uint32_t _c[4];
  uint32x4_t c;
  uint32x4_t b = vld1q_u32(_b);
#define TEST_IMPL(IDX)            \
  for (int i = 0; i < 4; i++) {   \
    if (i != IDX) {               \
      _c[i] = _b[i];              \
    } else {                      \
      _c[i] = _a[0];              \
    }                             \
  }                               \
  c = vld1q_lane_u32(_a, b, IDX); \
  CHECK_RESULT(validate_uint32(c, _c[0], _c[1], _c[2], _c[3]))

  IMM_2_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld1q_lane_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (int64_t *)impl.test_cases_int_pointer1;
  const int64_t *_b = (int64_t *)impl.test_cases_int_pointer2;
  uint64_t _c[2];
  int64x2_t c;
  int64x2_t b = vld1q_s64(_b);
#define TEST_IMPL(IDX)            \
  for (int i = 0; i < 2; i++) {   \
    if (i != IDX) {               \
      _c[i] = _b[i];              \
    } else {                      \
      _c[i] = _a[0];              \
    }                             \
  }                               \
  c = vld1q_lane_s64(_a, b, IDX); \
  CHECK_RESULT(validate_int64(c, _c[0], _c[1]))

  IMM_2_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld1q_lane_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (uint64_t *)impl.test_cases_int_pointer1;
  const uint64_t *_b = (uint64_t *)impl.test_cases_int_pointer2;
  uint64_t _c[2];
  uint64x2_t c;
  uint64x2_t b = vld1q_u64(_b);
#define TEST_IMPL(IDX)            \
  for (int i = 0; i < 2; i++) {   \
    if (i != IDX) {               \
      _c[i] = _b[i];              \
    } else {                      \
      _c[i] = _a[0];              \
    }                             \
  }                               \
  c = vld1q_lane_u64(_a, b, IDX); \
  CHECK_RESULT(validate_uint64(c, _c[0], _c[1]))

  IMM_2_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld1_lane_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1q_lane_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1_lane_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1q_lane_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1_dup_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (const int8_t *)impl.test_cases_int_pointer1;
  int8x8_t c = vld1_dup_s8(_a);
  return validate_int8(c, _a[0], _a[0], _a[0], _a[0], _a[0], _a[0], _a[0], _a[0]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld1_dup_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (const int16_t *)impl.test_cases_int_pointer1;
  int16x4_t c = vld1_dup_s16(_a);
  return validate_int16(c, _a[0], _a[0], _a[0], _a[0]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld1_dup_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (const int32_t *)impl.test_cases_int_pointer1;
  int32x2_t c = vld1_dup_s32(_a);
  return validate_int32(c, _a[0], _a[0]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld1_dup_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (const float *)impl.test_cases_float_pointer1;
  float32x2_t c = vld1_dup_f32(_a);
  return validate_float(c, _a[0], _a[0]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld1_dup_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (const uint8_t *)impl.test_cases_int_pointer1;
  uint8x8_t c = vld1_dup_u8(_a);
  return validate_uint8(c, _a[0], _a[0], _a[0], _a[0], _a[0], _a[0], _a[0], _a[0]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld1_dup_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (const uint16_t *)impl.test_cases_int_pointer1;
  uint16x4_t c = vld1_dup_u16(_a);
  return validate_uint16(c, _a[0], _a[0], _a[0], _a[0]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld1_dup_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (const uint32_t *)impl.test_cases_int_pointer1;
  uint32x2_t c = vld1_dup_u32(_a);
  return validate_uint32(c, _a[0], _a[0]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld1_dup_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (const int64_t *)impl.test_cases_int_pointer1;
  int64x1_t c = vld1_dup_s64(_a);
  return validate_int64(c, _a[0]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld1_dup_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (const uint64_t *)impl.test_cases_int_pointer1;
  uint64x1_t c = vld1_dup_u64(_a);
  return validate_uint64(c, _a[0]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld1q_dup_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (const int8_t *)impl.test_cases_int_pointer1;
  int8x16_t c = vld1q_dup_s8(_a);
  return validate_int8(c, _a[0], _a[0], _a[0], _a[0], _a[0], _a[0], _a[0], _a[0], _a[0], _a[0], _a[0], _a[0], _a[0],
                       _a[0], _a[0], _a[0]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld1q_dup_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (const int16_t *)impl.test_cases_int_pointer1;
  int16x8_t c = vld1q_dup_s16(_a);
  return validate_int16(c, _a[0], _a[0], _a[0], _a[0], _a[0], _a[0], _a[0], _a[0]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld1q_dup_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (const int32_t *)impl.test_cases_int_pointer1;
  int32x4_t c = vld1q_dup_s32(_a);
  return validate_int32(c, _a[0], _a[0], _a[0], _a[0]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld1q_dup_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (const float *)impl.test_cases_float_pointer1;
  float32x4_t c = vld1q_dup_f32(_a);
  return validate_float(c, _a[0], _a[0], _a[0], _a[0]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld1_dup_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1q_dup_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1_dup_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1q_dup_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1_dup_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1q_dup_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1q_dup_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (const uint8_t *)impl.test_cases_int_pointer1;
  uint8x16_t c = vld1q_dup_u8(_a);
  return validate_uint8(c, _a[0], _a[0], _a[0], _a[0], _a[0], _a[0], _a[0], _a[0], _a[0], _a[0], _a[0], _a[0], _a[0],
                        _a[0], _a[0], _a[0]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld1q_dup_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (const uint16_t *)impl.test_cases_int_pointer1;
  uint16x8_t c = vld1q_dup_u16(_a);
  return validate_uint16(c, _a[0], _a[0], _a[0], _a[0], _a[0], _a[0], _a[0], _a[0]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld1q_dup_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (const uint32_t *)impl.test_cases_int_pointer1;
  uint32x4_t c = vld1q_dup_u32(_a);
  return validate_uint32(c, _a[0], _a[0], _a[0], _a[0]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld1q_dup_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (const int64_t *)impl.test_cases_int_pointer1;
  int64x2_t c = vld1q_dup_s64(_a);
  return validate_int64(c, _a[0], _a[0]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld1q_dup_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (const uint64_t *)impl.test_cases_int_pointer1;
  uint64x2_t c = vld1q_dup_u64(_a);
  return validate_uint64(c, _a[0], _a[0]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld1_dup_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1q_dup_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1_dup_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1q_dup_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  int8x8_t a = vld1_s8(_a);
  return validate_int8(a, _a[0], _a[1], _a[2], _a[3], _a[4], _a[5], _a[6], _a[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst1_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  int16x4_t a = vld1_s16(_a);
  return validate_int16(a, _a[0], _a[1], _a[2], _a[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst1_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  int32x2_t a = vld1_s32(_a);
  return validate_int32(a, _a[0], _a[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst1_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (int64_t *)impl.test_cases_int_pointer1;
  int64x1_t a = vld1_s64(_a);
  return validate_int64(a, _a[0]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst1_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (float *)impl.test_cases_float_pointer1;
  float32x2_t a = vld1_f32(_a);
  return validate_float(a, _a[0], _a[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst1_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (uint8_t *)impl.test_cases_int_pointer1;
  uint8x8_t a = vld1_u8(_a);
  return validate_uint8(a, _a[0], _a[1], _a[2], _a[3], _a[4], _a[5], _a[6], _a[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst1_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  uint16x4_t a = vld1_u16(_a);
  return validate_uint16(a, _a[0], _a[1], _a[2], _a[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst1_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  uint32x2_t a = vld1_u32(_a);
  return validate_uint32(a, _a[0], _a[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst1_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (uint64_t *)impl.test_cases_int_pointer1;
  uint64x1_t a = vld1_u64(_a);
  return validate_uint64(a, _a[0]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst1q_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  int8x16_t a = vld1q_s8(_a);
  return validate_int8(a, _a[0], _a[1], _a[2], _a[3], _a[4], _a[5], _a[6], _a[7], _a[8], _a[9], _a[10], _a[11], _a[12],
                       _a[13], _a[14], _a[15]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst1q_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  int16x8_t a = vld1q_s16(_a);
  return validate_int16(a, _a[0], _a[1], _a[2], _a[3], _a[4], _a[5], _a[6], _a[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst1q_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  int32x4_t a = vld1q_s32(_a);
  return validate_int32(a, _a[0], _a[1], _a[2], _a[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst1q_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (int64_t *)impl.test_cases_int_pointer1;
  int64x2_t a = vld1q_s64(_a);
  return validate_int64(a, _a[0], _a[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst1q_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (float *)impl.test_cases_float_pointer1;
  float32x4_t a = vld1q_f32(_a);
  return validate_float(a, _a[0], _a[1], _a[2], _a[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst1_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1q_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1q_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1q_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1q_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (uint8_t *)impl.test_cases_int_pointer1;
  uint8x16_t a = vld1q_u8(_a);
  return validate_uint8(a, _a[0], _a[1], _a[2], _a[3], _a[4], _a[5], _a[6], _a[7], _a[8], _a[9], _a[10], _a[11], _a[12],
                        _a[13], _a[14], _a[15]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst1q_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  uint16x8_t a = vld1q_u16(_a);
  return validate_uint16(a, _a[0], _a[1], _a[2], _a[3], _a[4], _a[5], _a[6], _a[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst1q_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  uint32x4_t a = vld1q_u32(_a);
  return validate_uint32(a, _a[0], _a[1], _a[2], _a[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst1q_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (uint64_t *)impl.test_cases_int_pointer1;
  uint64x2_t a = vld1q_u64(_a);
  return validate_uint64(a, _a[0], _a[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst1_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1q_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1q_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1_lane_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  int8_t _a[8];
  const int8_t *_b = (const int8_t *)impl.test_cases_int_pointer1;
  int8x8_t b;
  int8x8_t a;

#define TEST_IMPL(IDX)      \
  b = vld1_s8(_b);          \
  vst1_lane_s8(_a, b, IDX); \
  a = vld1_s8(_a);          \
  CHECK_RESULT(validate_int8(a, _b[IDX], _a[1], _a[2], _a[3], _a[4], _a[5], _a[6], _a[7]))

  IMM_8_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst1_lane_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  int16_t _a[4];
  const int16_t *_b = (const int16_t *)impl.test_cases_int_pointer1;
  int16x4_t b;
  int16x4_t a;

#define TEST_IMPL(IDX)       \
  b = vld1_s16(_b);          \
  vst1_lane_s16(_a, b, IDX); \
  a = vld1_s16(_a);          \
  CHECK_RESULT(validate_int16(a, _b[IDX], _a[1], _a[2], _a[3]))

  IMM_4_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst1_lane_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  int32_t _a[2];
  const int32_t *_b = (const int32_t *)impl.test_cases_int_pointer1;
  int32x2_t b;
  int32x2_t a;

#define TEST_IMPL(IDX)       \
  b = vld1_s32(_b);          \
  vst1_lane_s32(_a, b, IDX); \
  a = vld1_s32(_a);          \
  CHECK_RESULT(validate_int32(a, _b[IDX], _a[1]))

  IMM_2_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst1_lane_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  float _a[2];
  const float *_b = (const float *)impl.test_cases_float_pointer1;
  float32x2_t b;
  float32x2_t a;

#define TEST_IMPL(IDX)       \
  b = vld1_f32(_b);          \
  vst1_lane_f32(_a, b, IDX); \
  a = vld1_f32(_a);          \
  CHECK_RESULT(validate_float(a, _b[IDX], _a[1]))

  IMM_2_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst1_lane_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  uint8_t _a[8];
  const uint8_t *_b = (const uint8_t *)impl.test_cases_int_pointer1;
  uint8x8_t b;
  uint8x8_t a;

#define TEST_IMPL(IDX)      \
  b = vld1_u8(_b);          \
  vst1_lane_u8(_a, b, IDX); \
  a = vld1_u8(_a);          \
  CHECK_RESULT(validate_uint8(a, _b[IDX], _a[1], _a[2], _a[3], _a[4], _a[5], _a[6], _a[7]))

  IMM_8_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst1_lane_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  uint16_t _a[4];
  const uint16_t *_b = (const uint16_t *)impl.test_cases_int_pointer1;
  uint16x4_t b;
  uint16x4_t a;

#define TEST_IMPL(IDX)       \
  b = vld1_u16(_b);          \
  vst1_lane_u16(_a, b, IDX); \
  a = vld1_u16(_a);          \
  CHECK_RESULT(validate_uint16(a, _b[IDX], _a[1], _a[2], _a[3]))

  IMM_4_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst1_lane_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  uint32_t _a[2];
  const uint32_t *_b = (const uint32_t *)impl.test_cases_int_pointer1;
  uint32x2_t b;
  uint32x2_t a;

#define TEST_IMPL(IDX)       \
  b = vld1_u32(_b);          \
  vst1_lane_u32(_a, b, IDX); \
  a = vld1_u32(_a);          \
  CHECK_RESULT(validate_uint32(a, _b[IDX], _a[1]))

  IMM_2_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst1_lane_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  int64_t _a[1];
  const int64_t *_b = (const int64_t *)impl.test_cases_int_pointer1;
  int64x1_t b;
  int64x1_t a;

#define TEST_IMPL(IDX)       \
  b = vld1_s64(_b);          \
  vst1_lane_s64(_a, b, IDX); \
  a = vld1_s64(_a);          \
  CHECK_RESULT(validate_int64(a, _b[IDX]))

  IMM_1_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst1_lane_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  uint64_t _a[1];
  const uint64_t *_b = (const uint64_t *)impl.test_cases_int_pointer1;
  uint64x1_t b;
  uint64x1_t a;

#define TEST_IMPL(IDX)       \
  b = vld1_u64(_b);          \
  vst1_lane_u64(_a, b, IDX); \
  a = vld1_u64(_a);          \
  CHECK_RESULT(validate_uint64(a, _b[IDX]))

  IMM_1_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst1q_lane_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  int8_t _a[16];
  const int8_t *_b = (const int8_t *)impl.test_cases_int_pointer1;
  int8x16_t b;
  int8x16_t a;

#define TEST_IMPL(IDX)                                                                                          \
  b = vld1q_s8(_b);                                                                                             \
  vst1q_lane_s8(_a, b, IDX);                                                                                    \
  a = vld1q_s8(_a);                                                                                             \
  CHECK_RESULT(validate_int8(a, _b[IDX], _a[1], _a[2], _a[3], _a[4], _a[5], _a[6], _a[7], _a[8], _a[9], _a[10], \
                             _a[11], _a[12], _a[13], _a[14], _a[15]))

  IMM_16_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst1q_lane_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  int16_t _a[8];
  const int16_t *_b = (const int16_t *)impl.test_cases_int_pointer1;
  int16x8_t b;
  int16x8_t a;

#define TEST_IMPL(IDX)        \
  b = vld1q_s16(_b);          \
  vst1q_lane_s16(_a, b, IDX); \
  a = vld1q_s16(_a);          \
  CHECK_RESULT(validate_int16(a, _b[IDX], _a[1], _a[2], _a[3], _a[4], _a[5], _a[6], _a[7]))

  IMM_8_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst1q_lane_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  int32_t _a[4];
  const int32_t *_b = (const int32_t *)impl.test_cases_int_pointer1;
  int32x4_t b;
  int32x4_t a;

#define TEST_IMPL(IDX)        \
  b = vld1q_s32(_b);          \
  vst1q_lane_s32(_a, b, IDX); \
  a = vld1q_s32(_a);          \
  CHECK_RESULT(validate_int32(a, _b[IDX], _a[1], _a[2], _a[3]))

  IMM_4_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst1q_lane_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  float _a[4];
  const float *_b = (const float *)impl.test_cases_float_pointer1;
  float32x4_t b;
  float32x4_t a;

#define TEST_IMPL(IDX)        \
  b = vld1q_f32(_b);          \
  vst1q_lane_f32(_a, b, IDX); \
  a = vld1q_f32(_a);          \
  CHECK_RESULT(validate_float(a, _b[IDX], _a[1], _a[2], _a[3]))

  IMM_4_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst1_lane_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1q_lane_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1_lane_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1q_lane_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1_lane_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1q_lane_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1q_lane_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  uint8_t _a[16];
  const uint8_t *_b = (const uint8_t *)impl.test_cases_int_pointer1;
  uint8x16_t b;
  uint8x16_t a;

#define TEST_IMPL(IDX)                                                                                           \
  b = vld1q_u8(_b);                                                                                              \
  vst1q_lane_u8(_a, b, IDX);                                                                                     \
  a = vld1q_u8(_a);                                                                                              \
  CHECK_RESULT(validate_uint8(a, _b[IDX], _a[1], _a[2], _a[3], _a[4], _a[5], _a[6], _a[7], _a[8], _a[9], _a[10], \
                              _a[11], _a[12], _a[13], _a[14], _a[15]))

  IMM_16_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst1q_lane_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  uint16_t _a[8];
  const uint16_t *_b = (const uint16_t *)impl.test_cases_int_pointer1;
  uint16x8_t b;
  uint16x8_t a;

#define TEST_IMPL(IDX)        \
  b = vld1q_u16(_b);          \
  vst1q_lane_u16(_a, b, IDX); \
  a = vld1q_u16(_a);          \
  CHECK_RESULT(validate_uint16(a, _b[IDX], _a[1], _a[2], _a[3], _a[4], _a[5], _a[6], _a[7]))

  IMM_8_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst1q_lane_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  uint32_t _a[4];
  const uint32_t *_b = (const uint32_t *)impl.test_cases_int_pointer1;
  uint32x4_t b;
  uint32x4_t a;

#define TEST_IMPL(IDX)        \
  b = vld1q_u32(_b);          \
  vst1q_lane_u32(_a, b, IDX); \
  a = vld1q_u32(_a);          \
  CHECK_RESULT(validate_uint32(a, _b[IDX], _a[1], _a[2], _a[3]))

  IMM_4_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst1q_lane_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  int64_t _a[2];
  const int64_t *_b = (const int64_t *)impl.test_cases_int_pointer1;
  int64x2_t b;
  int64x2_t a;

#define TEST_IMPL(IDX)        \
  b = vld1q_s64(_b);          \
  vst1q_lane_s64(_a, b, IDX); \
  a = vld1q_s64(_a);          \
  CHECK_RESULT(validate_int64(a, _b[IDX], _a[1]))

  IMM_2_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst1q_lane_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  uint64_t _a[2];
  const uint64_t *_b = (const uint64_t *)impl.test_cases_int_pointer1;
  uint64x2_t b;
  uint64x2_t a;

#define TEST_IMPL(IDX)        \
  b = vld1q_u64(_b);          \
  vst1q_lane_u64(_a, b, IDX); \
  a = vld1q_u64(_a);          \
  CHECK_RESULT(validate_uint64(a, _b[IDX], _a[1]))

  IMM_2_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst1_lane_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1q_lane_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1_lane_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1q_lane_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld2_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  int8_t _c[16];
  int8x8x2_t c = vld2_s8(_a);
  for (int i = 0; i < 8; i++) {
    _c[i] = _a[2 * i];
    _c[i + 8] = _a[2 * i + 1];
  }
  return validate_int8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7], _c[8], _c[9], _c[10], _c[11], _c[12],
                       _c[13], _c[14], _c[15]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld2_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  int16_t _c[8];
  int16x4x2_t c = vld2_s16(_a);
  for (int i = 0; i < 4; i++) {
    _c[i] = _a[2 * i];
    _c[i + 4] = _a[2 * i + 1];
  }
  return validate_int16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld2_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  int32_t _c[4];
  int32x2x2_t c = vld2_s32(_a);
  for (int i = 0; i < 2; i++) {
    _c[i] = _a[2 * i];
    _c[i + 2] = _a[2 * i + 1];
  }
  return validate_int32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld2_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (float *)impl.test_cases_float_pointer1;
  float _c[4];
  float32x2x2_t c = vld2_f32(_a);
  for (int i = 0; i < 2; i++) {
    _c[i] = _a[2 * i];
    _c[i + 2] = _a[2 * i + 1];
  }
  return validate_float(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld2_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (uint8_t *)impl.test_cases_int_pointer1;
  uint8_t _c[16];
  uint8x8x2_t c = vld2_u8(_a);
  for (int i = 0; i < 8; i++) {
    _c[i] = _a[2 * i];
    _c[i + 8] = _a[2 * i + 1];
  }
  return validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7], _c[8], _c[9], _c[10], _c[11], _c[12],
                        _c[13], _c[14], _c[15]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld2_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  uint16_t _c[8];
  uint16x4x2_t c = vld2_u16(_a);
  for (int i = 0; i < 4; i++) {
    _c[i] = _a[2 * i];
    _c[i + 4] = _a[2 * i + 1];
  }
  return validate_uint16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld2_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  uint32_t _c[4];
  uint32x2x2_t c = vld2_u32(_a);
  for (int i = 0; i < 2; i++) {
    _c[i] = _a[2 * i];
    _c[i + 2] = _a[2 * i + 1];
  }
  return validate_uint32(c, _c[0], _c[1], _c[2], _c[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld2_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (int64_t *)impl.test_cases_int_pointer1;
  int64_t _c[4];
  int64x1x2_t c = vld2_s64(_a);
  for (int i = 0; i < 1; i++) {
    _c[i] = _a[2 * i];
    _c[i + 1] = _a[2 * i + 1];
  }
  return validate_int64(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld2_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (uint64_t *)impl.test_cases_int_pointer1;
  uint64_t _c[2];
  uint64x1x2_t c = vld2_u64(_a);
  for (int i = 0; i < 1; i++) {
    _c[i] = _a[2 * i];
    _c[i + 1] = _a[2 * i + 1];
  }
  return validate_uint64(c, _c[0], _c[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld2_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld2q_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld2q_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld2q_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld2_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld2q_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld2q_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  int8_t _c[32];
  int8x16x2_t c = vld2q_s8(_a);
  for (int i = 0; i < 16; i++) {
    _c[i] = _a[2 * i];
    _c[i + 16] = _a[2 * i + 1];
  }
  return validate_int8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7], _c[8], _c[9], _c[10], _c[11], _c[12],
                       _c[13], _c[14], _c[15], _c[16], _c[17], _c[18], _c[19], _c[20], _c[21], _c[22], _c[23], _c[24],
                       _c[25], _c[26], _c[27], _c[28], _c[29], _c[30], _c[31]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld2q_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  int16_t _c[16];
  int16x8x2_t c = vld2q_s16(_a);
  for (int i = 0; i < 8; i++) {
    _c[i] = _a[2 * i];
    _c[i + 8] = _a[2 * i + 1];
  }
  return validate_int16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7], _c[8], _c[9], _c[10], _c[11], _c[12],
                        _c[13], _c[14], _c[15]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld2q_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  int32_t _c[8];
  int32x4x2_t c = vld2q_s32(_a);
  for (int i = 0; i < 4; i++) {
    _c[i] = _a[2 * i];
    _c[i + 4] = _a[2 * i + 1];
  }
  return validate_int32(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld2q_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (float *)impl.test_cases_float_pointer1;
  float _c[8];
  float32x4x2_t c = vld2q_f32(_a);
  for (int i = 0; i < 4; i++) {
    _c[i] = _a[2 * i];
    _c[i + 4] = _a[2 * i + 1];
  }
  return validate_float(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld2_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld2q_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld2_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld2q_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld2q_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (uint8_t *)impl.test_cases_int_pointer1;
  uint8_t _c[32];
  uint8x16x2_t c = vld2q_u8(_a);
  for (int i = 0; i < 16; i++) {
    _c[i] = _a[2 * i];
    _c[i + 16] = _a[2 * i + 1];
  }
  return validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7], _c[8], _c[9], _c[10], _c[11], _c[12],
                        _c[13], _c[14], _c[15], _c[16], _c[17], _c[18], _c[19], _c[20], _c[21], _c[22], _c[23], _c[24],
                        _c[25], _c[26], _c[27], _c[28], _c[29], _c[30], _c[31]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld2q_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  uint16_t _c[16];
  uint16x8x2_t c = vld2q_u16(_a);
  for (int i = 0; i < 8; i++) {
    _c[i] = _a[2 * i];
    _c[i + 8] = _a[2 * i + 1];
  }
  return validate_uint16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7], _c[8], _c[9], _c[10], _c[11],
                         _c[12], _c[13], _c[14], _c[15]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld2q_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  uint32_t _c[8];
  uint32x4x2_t c = vld2q_u32(_a);
  for (int i = 0; i < 4; i++) {
    _c[i] = _a[2 * i];
    _c[i + 4] = _a[2 * i + 1];
  }
  return validate_uint32(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld2_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld2q_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld2_lane_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (int8_t *)impl.test_cases_int_pointer2;
  int8_t _c[16];
  int8x8x2_t c;
  int8x8x2_t b = vld2_s8(_b);

#define TEST_IMPL(IDX)                                                                                                \
  for (int i = 0; i < 8; i++) {                                                                                       \
    if (i != IDX) {                                                                                                   \
      _c[i] = _b[2 * i];                                                                                              \
      _c[i + 8] = _b[2 * i + 1];                                                                                      \
    } else {                                                                                                          \
      _c[i] = _a[0];                                                                                                  \
      _c[i + 8] = _a[1];                                                                                              \
    }                                                                                                                 \
  }                                                                                                                   \
  c = vld2_lane_s8(_a, b, IDX);                                                                                       \
  CHECK_RESULT(validate_int8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7], _c[8], _c[9], _c[10], _c[11], \
                             _c[12], _c[13], _c[14], _c[15]))

  IMM_8_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld2_lane_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  int16_t _c[8];
  int16x4x2_t c;
  int16x4x2_t b = vld2_s16(_b);

#define TEST_IMPL(IDX)           \
  for (int i = 0; i < 4; i++) {  \
    if (i != IDX) {              \
      _c[i] = _b[2 * i];         \
      _c[i + 4] = _b[2 * i + 1]; \
    } else {                     \
      _c[i] = _a[0];             \
      _c[i + 4] = _a[1];         \
    }                            \
  }                              \
  c = vld2_lane_s16(_a, b, IDX); \
  CHECK_RESULT(validate_int16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]))

  IMM_4_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld2_lane_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  int32_t _c[4];
  int32x2x2_t c;
  int32x2x2_t b = vld2_s32(_b);

#define TEST_IMPL(IDX)           \
  for (int i = 0; i < 2; i++) {  \
    if (i != IDX) {              \
      _c[i] = _b[2 * i];         \
      _c[i + 2] = _b[2 * i + 1]; \
    } else {                     \
      _c[i] = _a[0];             \
      _c[i + 2] = _a[1];         \
    }                            \
  }                              \
  c = vld2_lane_s32(_a, b, IDX); \
  CHECK_RESULT(validate_int32(c, _c[0], _c[1], _c[2], _c[3]))

  IMM_2_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld2_lane_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (float *)impl.test_cases_int_pointer1;
  const float *_b = (float *)impl.test_cases_int_pointer2;
  float _c[4];
  float32x2x2_t c;
  float32x2x2_t b = vld2_f32(_b);

#define TEST_IMPL(IDX)           \
  for (int i = 0; i < 2; i++) {  \
    if (i != IDX) {              \
      _c[i] = _b[2 * i];         \
      _c[i + 2] = _b[2 * i + 1]; \
    } else {                     \
      _c[i] = _a[0];             \
      _c[i + 2] = _a[1];         \
    }                            \
  }                              \
  c = vld2_lane_f32(_a, b, IDX); \
  CHECK_RESULT(validate_float(c, _c[0], _c[1], _c[2], _c[3]))

  IMM_2_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld2_lane_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (uint8_t *)impl.test_cases_int_pointer2;
  uint8_t _c[16];
  uint8x8x2_t c;
  uint8x8x2_t b = vld2_u8(_b);

#define TEST_IMPL(IDX)                                                                                                 \
  for (int i = 0; i < 8; i++) {                                                                                        \
    if (i != IDX) {                                                                                                    \
      _c[i] = _b[2 * i];                                                                                               \
      _c[i + 8] = _b[2 * i + 1];                                                                                       \
    } else {                                                                                                           \
      _c[i] = _a[0];                                                                                                   \
      _c[i + 8] = _a[1];                                                                                               \
    }                                                                                                                  \
  }                                                                                                                    \
  c = vld2_lane_u8(_a, b, IDX);                                                                                        \
  CHECK_RESULT(validate_uint8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7], _c[8], _c[9], _c[10], _c[11], \
                              _c[12], _c[13], _c[14], _c[15]))

  IMM_8_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld2_lane_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld2q_lane_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld2q_lane_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld2q_lane_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld2_lane_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld2q_lane_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld2_lane_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld2q_lane_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld2_lane_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld2q_lane_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld2_lane_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld2q_lane_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld2_lane_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (uint16_t *)impl.test_cases_int_pointer2;
  uint16_t _c[8];
  uint16x4x2_t c;
  uint16x4x2_t b = vld2_u16(_b);

#define TEST_IMPL(IDX)           \
  for (int i = 0; i < 4; i++) {  \
    if (i != IDX) {              \
      _c[i] = _b[2 * i];         \
      _c[i + 4] = _b[2 * i + 1]; \
    } else {                     \
      _c[i] = _a[0];             \
      _c[i + 4] = _a[1];         \
    }                            \
  }                              \
  c = vld2_lane_u16(_a, b, IDX); \
  CHECK_RESULT(validate_uint16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]))

  IMM_4_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld2_lane_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (uint32_t *)impl.test_cases_int_pointer2;
  uint32_t _c[4];
  uint32x2x2_t c;
  uint32x2x2_t b = vld2_u32(_b);

#define TEST_IMPL(IDX)           \
  for (int i = 0; i < 2; i++) {  \
    if (i != IDX) {              \
      _c[i] = _b[2 * i];         \
      _c[i + 2] = _b[2 * i + 1]; \
    } else {                     \
      _c[i] = _a[0];             \
      _c[i + 2] = _a[1];         \
    }                            \
  }                              \
  c = vld2_lane_u32(_a, b, IDX); \
  CHECK_RESULT(validate_uint32(c, _c[0], _c[1], _c[2], _c[3]))

  IMM_2_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld2q_lane_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  int16_t _c[16];
  int16x8x2_t c;
  int16x8x2_t b = vld2q_s16(_b);

#define TEST_IMPL(IDX)                                                                                                 \
  for (int i = 0; i < 8; i++) {                                                                                        \
    if (i != IDX) {                                                                                                    \
      _c[i] = _b[2 * i];                                                                                               \
      _c[i + 8] = _b[2 * i + 1];                                                                                       \
    } else {                                                                                                           \
      _c[i] = _a[0];                                                                                                   \
      _c[i + 8] = _a[1];                                                                                               \
    }                                                                                                                  \
  }                                                                                                                    \
  c = vld2q_lane_s16(_a, b, IDX);                                                                                      \
  CHECK_RESULT(validate_int16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7], _c[8], _c[9], _c[10], _c[11], \
                              _c[12], _c[13], _c[14], _c[15]))

  IMM_8_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld2q_lane_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  int32_t _c[8];
  int32x4x2_t c;
  int32x4x2_t b = vld2q_s32(_b);

#define TEST_IMPL(IDX)            \
  for (int i = 0; i < 4; i++) {   \
    if (i != IDX) {               \
      _c[i] = _b[2 * i];          \
      _c[i + 4] = _b[2 * i + 1];  \
    } else {                      \
      _c[i] = _a[0];              \
      _c[i + 4] = _a[1];          \
    }                             \
  }                               \
  c = vld2q_lane_s32(_a, b, IDX); \
  CHECK_RESULT(validate_int32(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]))

  IMM_4_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld2q_lane_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (float *)impl.test_cases_int_pointer1;
  const float *_b = (float *)impl.test_cases_int_pointer2;
  float _c[8];
  float32x4x2_t c;
  float32x4x2_t b = vld2q_f32(_b);

#define TEST_IMPL(IDX)            \
  for (int i = 0; i < 4; i++) {   \
    if (i != IDX) {               \
      _c[i] = _b[2 * i];          \
      _c[i + 4] = _b[2 * i + 1];  \
    } else {                      \
      _c[i] = _a[0];              \
      _c[i + 4] = _a[1];          \
    }                             \
  }                               \
  c = vld2q_lane_f32(_a, b, IDX); \
  CHECK_RESULT(validate_float(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]))

  IMM_4_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld2_lane_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld2q_lane_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld2q_lane_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (uint16_t *)impl.test_cases_int_pointer2;
  uint16_t _c[16];
  uint16x8x2_t c;
  uint16x8x2_t b = vld2q_u16(_b);

#define TEST_IMPL(IDX)                                                                                          \
  for (int i = 0; i < 8; i++) {                                                                                 \
    if (i != IDX) {                                                                                             \
      _c[i] = _b[2 * i];                                                                                        \
      _c[i + 8] = _b[2 * i + 1];                                                                                \
    } else {                                                                                                    \
      _c[i] = _a[0];                                                                                            \
      _c[i + 8] = _a[1];                                                                                        \
    }                                                                                                           \
  }                                                                                                             \
  c = vld2q_lane_u16(_a, b, IDX);                                                                               \
  CHECK_RESULT(validate_uint16(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7], _c[8], _c[9], _c[10], \
                               _c[11], _c[12], _c[13], _c[14], _c[15]))

  IMM_8_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld2q_lane_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (uint32_t *)impl.test_cases_int_pointer2;
  uint32_t _c[8];
  uint32x4x2_t c;
  uint32x4x2_t b = vld2q_u32(_b);

#define TEST_IMPL(IDX)            \
  for (int i = 0; i < 4; i++) {   \
    if (i != IDX) {               \
      _c[i] = _b[2 * i];          \
      _c[i + 4] = _b[2 * i + 1];  \
    } else {                      \
      _c[i] = _a[0];              \
      _c[i + 4] = _a[1];          \
    }                             \
  }                               \
  c = vld2q_lane_u32(_a, b, IDX); \
  CHECK_RESULT(validate_uint32(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]))

  IMM_4_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld2_lane_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld2q_lane_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld2_dup_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (const int8_t *)impl.test_cases_int_pointer1;
  int8x8_t c0, c1;
  int8x8x2_t c = vld2_dup_s8(_a);
  int8x2_get_int8(c, &c0, &c1);
  CHECK_RESULT(validate_int8(c0, _a[0], _a[0], _a[0], _a[0], _a[0], _a[0], _a[0], _a[0]))
  CHECK_RESULT(validate_int8(c1, _a[1], _a[1], _a[1], _a[1], _a[1], _a[1], _a[1], _a[1]))
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld2q_dup_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld2_dup_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (const int16_t *)impl.test_cases_int_pointer1;
  int16x4_t c0, c1;
  int16x4x2_t c = vld2_dup_s16(_a);
  int16x2_get_int16(c, &c0, &c1);
  CHECK_RESULT(validate_int16(c0, _a[0], _a[0], _a[0], _a[0]))
  CHECK_RESULT(validate_int16(c1, _a[1], _a[1], _a[1], _a[1]))
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld2q_dup_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld2_dup_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (const int32_t *)impl.test_cases_int_pointer1;
  int32x2_t c0, c1;
  int32x2x2_t c = vld2_dup_s32(_a);
  int32x2_get_int32(c, &c0, &c1);
  CHECK_RESULT(validate_int32(c0, _a[0], _a[0]))
  CHECK_RESULT(validate_int32(c1, _a[1], _a[1]))
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld2q_dup_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld2_dup_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (const float *)impl.test_cases_float_pointer1;
  float32x2_t c0, c1;
  float32x2x2_t c = vld2_dup_f32(_a);
  float32x2_get_float32(c, &c0, &c1);
  CHECK_RESULT(validate_float(c0, _a[0], _a[0]))
  CHECK_RESULT(validate_float(c1, _a[1], _a[1]))
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld2q_dup_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld2_dup_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld2q_dup_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld2_dup_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld2q_dup_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld2_dup_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (const uint8_t *)impl.test_cases_int_pointer1;
  uint8x8_t c0, c1;
  uint8x8x2_t c = vld2_dup_u8(_a);
  uint8x2_get_uint8(c, &c0, &c1);
  CHECK_RESULT(validate_uint8(c0, _a[0], _a[0], _a[0], _a[0], _a[0], _a[0], _a[0], _a[0]))
  CHECK_RESULT(validate_uint8(c1, _a[1], _a[1], _a[1], _a[1], _a[1], _a[1], _a[1], _a[1]))
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld2q_dup_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld2_dup_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (const uint16_t *)impl.test_cases_int_pointer1;
  uint16x4_t c0, c1;
  uint16x4x2_t c = vld2_dup_u16(_a);
  uint16x2_get_uint16(c, &c0, &c1);
  CHECK_RESULT(validate_uint16(c0, _a[0], _a[0], _a[0], _a[0]))
  CHECK_RESULT(validate_uint16(c1, _a[1], _a[1], _a[1], _a[1]))
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld2q_dup_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld2_dup_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (const uint32_t *)impl.test_cases_int_pointer1;
  uint32x2_t c0, c1;
  uint32x2x2_t c = vld2_dup_u32(_a);
  uint32x2_get_uint32(c, &c0, &c1);
  CHECK_RESULT(validate_uint32(c0, _a[0], _a[0]))
  CHECK_RESULT(validate_uint32(c1, _a[1], _a[1]))
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld2q_dup_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld2_dup_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld2q_dup_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld2_dup_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (const int64_t *)impl.test_cases_int_pointer1;
  int64x1_t c0, c1;
  int64x1x2_t c = vld2_dup_s64(_a);
  int64x2_get_int64(c, &c0, &c1);
  CHECK_RESULT(validate_int64(c0, _a[0]))
  CHECK_RESULT(validate_int64(c1, _a[1]))
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld2_dup_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (const uint64_t *)impl.test_cases_int_pointer1;
  uint64x1_t c0, c1;
  uint64x1x2_t c = vld2_dup_u64(_a);
  uint64x2_get_uint64(c, &c0, &c1);
  CHECK_RESULT(validate_uint64(c0, _a[0]))
  CHECK_RESULT(validate_uint64(c1, _a[1]))
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld2_dup_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld2q_dup_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld2q_dup_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld2q_dup_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld2_dup_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld2q_dup_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst2_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  int8_t _b[16];
  int8x8x2_t a = vld2_s8(_a);
  // vld2_s8 and vst2_s8 do the opposite behabior, so the result would be the same
  vst2_s8(_b, a);
  for (int i = 0; i < 8; i++) {
    if (_a[i] != _b[i]) {
      return TEST_FAIL;
    }
  }
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst2_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  int16_t _b[8];
  int16x4x2_t a = vld2_s16(_a);
  vst2_s16(_b, a);
  for (int i = 0; i < 4; i++) {
    if (_a[i] != _b[i]) {
      return TEST_FAIL;
    }
  }
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst2_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  int32_t _b[4];
  int32x2x2_t a = vld2_s32(_a);
  vst2_s32(_b, a);
  for (int i = 0; i < 2; i++) {
    if (_a[i] != _b[i]) {
      return TEST_FAIL;
    }
  }
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst2_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (float *)impl.test_cases_float_pointer1;
  float _b[4];
  float32x2x2_t a = vld2_f32(_a);
  vst2_f32(_b, a);
  for (int i = 0; i < 2; i++) {
    if (_a[i] != _b[i]) {
      return TEST_FAIL;
    }
  }
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst2_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (uint8_t *)impl.test_cases_int_pointer1;
  uint8_t _b[16];
  uint8x8x2_t a = vld2_u8(_a);
  vst2_u8(_b, a);
  for (int i = 0; i < 8; i++) {
    if (_a[i] != _b[i]) {
      return TEST_FAIL;
    }
  }
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst2_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  uint16_t _b[8];
  uint16x4x2_t a = vld2_u16(_a);
  vst2_u16(_b, a);
  for (int i = 0; i < 4; i++) {
    if (_a[i] != _b[i]) {
      return TEST_FAIL;
    }
  }
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst2_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  uint32_t _b[4];
  uint32x2x2_t a = vld2_u32(_a);
  vst2_u32(_b, a);
  for (int i = 0; i < 2; i++) {
    if (_a[i] != _b[i]) {
      return TEST_FAIL;
    }
  }
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst2_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (int64_t *)impl.test_cases_int_pointer1;
  int64_t _b[2];
  int64x1x2_t a = vld2_s64(_a);
  vst2_s64(_b, a);
  for (int i = 0; i < 1; i++) {
    if (_a[i] != _b[i]) {
      return TEST_FAIL;
    }
  }
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst2_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (uint64_t *)impl.test_cases_int_pointer1;
  uint64_t _b[2];
  uint64x1x2_t a = vld2_u64(_a);
  vst2_u64(_b, a);
  for (int i = 0; i < 1; i++) {
    if (_a[i] != _b[i]) {
      return TEST_FAIL;
    }
  }
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst2_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst2q_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst2q_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst2q_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst2_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst2q_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst2q_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  int8_t _b[32];
  int8x16x2_t a = vld2q_s8(_a);
  vst2q_s8(_b, a);
  for (int i = 0; i < 16; i++) {
    if (_a[i] != _b[i]) {
      return TEST_FAIL;
    }
  }
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst2q_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  int16_t _b[16];
  int16x8x2_t a = vld2q_s16(_a);
  vst2q_s16(_b, a);
  for (int i = 0; i < 8; i++) {
    if (_a[i] != _b[i]) {
      return TEST_FAIL;
    }
  }
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst2q_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  int32_t _b[8];
  int32x4x2_t a = vld2q_s32(_a);
  vst2q_s32(_b, a);
  for (int i = 0; i < 4; i++) {
    if (_a[i] != _b[i]) {
      return TEST_FAIL;
    }
  }
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst2q_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (float *)impl.test_cases_float_pointer1;
  float _b[8];
  float32x4x2_t a = vld2q_f32(_a);
  vst2q_f32(_b, a);
  for (int i = 0; i < 4; i++) {
    if (_a[i] != _b[i]) {
      return TEST_FAIL;
    }
  }
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst2_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst2q_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst2_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst2q_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst2q_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (uint8_t *)impl.test_cases_int_pointer1;
  uint8_t _b[32];
  uint8x16x2_t a = vld2q_u8(_a);
  vst2q_u8(_b, a);
  for (int i = 0; i < 16; i++) {
    if (_a[i] != _b[i]) {
      return TEST_FAIL;
    }
  }
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst2q_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  uint16_t _b[16];
  uint16x8x2_t a = vld2q_u16(_a);
  vst2q_u16(_b, a);
  for (int i = 0; i < 8; i++) {
    if (_a[i] != _b[i]) {
      return TEST_FAIL;
    }
  }
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst2q_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  uint32_t _b[8];
  uint32x4x2_t a = vld2q_u32(_a);
  vst2q_u32(_b, a);
  for (int i = 0; i < 4; i++) {
    if (_a[i] != _b[i]) {
      return TEST_FAIL;
    }
  }
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst2_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst2q_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst2_lane_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int reg_elt_num = 8;
  int8_t _a[reg_elt_num * 2];
  const int8_t *_in1 = (int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_in2 = (int8_t *)impl.test_cases_int_pointer1;
  int8_t _b[reg_elt_num * 2];
  int8_t in[reg_elt_num * 4];
  merge_arrays(_in1, _in2, in, reg_elt_num);
  int8x8x2_t b;

  for (int i = 0; i < reg_elt_num; i++) {
    _b[i] = in[2 * i];
    _b[i + reg_elt_num] = in[2 * i + 1];
  }

#define TEST_IMPL(IDX)                                          \
  b = vld2_s8(in);                                              \
  vst2_lane_s8(_a, b, IDX);                                     \
  if ((_a[0] != _b[IDX]) || (_a[1] != _b[IDX + reg_elt_num])) { \
    return TEST_FAIL;                                           \
  }

  IMM_8_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst2_lane_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int reg_elt_num = 4;
  int16_t _a[reg_elt_num * 2];
  const int16_t *_in1 = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_in2 = (int16_t *)impl.test_cases_int_pointer1;
  int16_t _b[reg_elt_num * 2];
  int16_t in[reg_elt_num * 4];
  merge_arrays(_in1, _in2, in, reg_elt_num);
  int16x4x2_t b;

  for (int i = 0; i < reg_elt_num; i++) {
    _b[i] = in[2 * i];
    _b[i + reg_elt_num] = in[2 * i + 1];
  }

#define TEST_IMPL(IDX)                                          \
  b = vld2_s16(in);                                             \
  vst2_lane_s16(_a, b, IDX);                                    \
  if ((_a[0] != _b[IDX]) || (_a[1] != _b[IDX + reg_elt_num])) { \
    return TEST_FAIL;                                           \
  }

  IMM_4_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst2_lane_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int reg_elt_num = 2;
  int32_t _a[reg_elt_num * 2];
  const int32_t *_in1 = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_in2 = (int32_t *)impl.test_cases_int_pointer1;
  int32_t _b[reg_elt_num * 2];
  int32_t in[reg_elt_num * 4];
  merge_arrays(_in1, _in2, in, reg_elt_num);
  int32x2x2_t b;

  for (int i = 0; i < reg_elt_num; i++) {
    _b[i] = in[2 * i];
    _b[i + reg_elt_num] = in[2 * i + 1];
  }

#define TEST_IMPL(IDX)                                          \
  b = vld2_s32(in);                                             \
  vst2_lane_s32(_a, b, IDX);                                    \
  if ((_a[0] != _b[IDX]) || (_a[1] != _b[IDX + reg_elt_num])) { \
    return TEST_FAIL;                                           \
  }

  IMM_2_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst2_lane_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int reg_elt_num = 2;
  float _a[reg_elt_num * 2];
  const float *_in1 = (float *)impl.test_cases_float_pointer1;
  const float *_in2 = (float *)impl.test_cases_float_pointer1;
  float _b[reg_elt_num * 2];
  float in[reg_elt_num * 4];
  merge_arrays(_in1, _in2, in, reg_elt_num);
  float32x2x2_t b;

  for (int i = 0; i < reg_elt_num; i++) {
    _b[i] = in[2 * i];
    _b[i + reg_elt_num] = in[2 * i + 1];
  }

#define TEST_IMPL(IDX)                                          \
  b = vld2_f32(in);                                             \
  vst2_lane_f32(_a, b, IDX);                                    \
  if ((_a[0] != _b[IDX]) || (_a[1] != _b[IDX + reg_elt_num])) { \
    return TEST_FAIL;                                           \
  }

  IMM_2_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst2_lane_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int reg_elt_num = 8;
  uint8_t _a[reg_elt_num * 2];
  const uint8_t *_in1 = (uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_in2 = (uint8_t *)impl.test_cases_int_pointer1;
  uint8_t _b[reg_elt_num * 2];
  uint8_t in[reg_elt_num * 4];
  merge_arrays(_in1, _in2, in, reg_elt_num);
  uint8x8x2_t b;

  for (int i = 0; i < reg_elt_num; i++) {
    _b[i] = in[2 * i];
    _b[i + reg_elt_num] = in[2 * i + 1];
  }

#define TEST_IMPL(IDX)                                          \
  b = vld2_u8(in);                                              \
  vst2_lane_u8(_a, b, IDX);                                     \
  if ((_a[0] != _b[IDX]) || (_a[1] != _b[IDX + reg_elt_num])) { \
    return TEST_FAIL;                                           \
  }

  IMM_8_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst2_lane_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst2_lane_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int reg_elt_num = 4;
  uint16_t _a[reg_elt_num * 2];
  const uint16_t *_in1 = (uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_in2 = (uint16_t *)impl.test_cases_int_pointer1;
  uint16_t _b[reg_elt_num * 2];
  uint16_t in[reg_elt_num * 4];
  merge_arrays(_in1, _in2, in, reg_elt_num);
  uint16x4x2_t b;

  for (int i = 0; i < reg_elt_num; i++) {
    _b[i] = in[2 * i];
    _b[i + reg_elt_num] = in[2 * i + 1];
  }

#define TEST_IMPL(IDX)                                          \
  b = vld2_u16(in);                                             \
  vst2_lane_u16(_a, b, IDX);                                    \
  if ((_a[0] != _b[IDX]) || (_a[1] != _b[IDX + reg_elt_num])) { \
    return TEST_FAIL;                                           \
  }

  IMM_4_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst2_lane_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int reg_elt_num = 2;
  uint32_t _a[reg_elt_num * 2];
  const uint32_t *_in1 = (uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_in2 = (uint32_t *)impl.test_cases_int_pointer2;
  uint32_t _b[reg_elt_num * 2];
  uint32_t in[reg_elt_num * 4];
  merge_arrays(_in1, _in2, in, reg_elt_num);
  uint32x2x2_t b;

  for (int i = 0; i < reg_elt_num; i++) {
    _b[i] = in[2 * i];
    _b[i + reg_elt_num] = in[2 * i + 1];
  }

#define TEST_IMPL(IDX)                                          \
  b = vld2_u32(in);                                             \
  vst2_lane_u32(_a, b, IDX);                                    \
  if ((_a[0] != _b[IDX]) || (_a[1] != _b[IDX + reg_elt_num])) { \
    return TEST_FAIL;                                           \
  }

  IMM_2_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst2q_lane_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int reg_elt_num = 8;
  int16_t _a[reg_elt_num * 2];
  const int16_t *_in1 = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_in2 = (int16_t *)impl.test_cases_int_pointer2;
  int16_t _b[reg_elt_num * 2];
  int16_t in[reg_elt_num * 4];
  merge_arrays(_in1, _in2, in, reg_elt_num);
  int16x8x2_t b;

  for (int i = 0; i < reg_elt_num; i++) {
    _b[i] = in[2 * i];
    _b[i + reg_elt_num] = in[2 * i + 1];
  }

#define TEST_IMPL(IDX)                                          \
  b = vld2q_s16(in);                                            \
  vst2q_lane_s16(_a, b, IDX);                                   \
  if ((_a[0] != _b[IDX]) || (_a[1] != _b[IDX + reg_elt_num])) { \
    return TEST_FAIL;                                           \
  }

  IMM_8_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst2q_lane_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int reg_elt_num = 4;
  int32_t _a[reg_elt_num * 2];
  const int32_t *_in1 = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_in2 = (int32_t *)impl.test_cases_int_pointer2;
  int32_t _b[reg_elt_num * 2];
  int32_t in[reg_elt_num * 4];
  merge_arrays(_in1, _in2, in, reg_elt_num);
  int32x4x2_t b;

  for (int i = 0; i < reg_elt_num; i++) {
    _b[i] = in[2 * i];
    _b[i + reg_elt_num] = in[2 * i + 1];
  }

#define TEST_IMPL(IDX)                                          \
  b = vld2q_s32(in);                                            \
  vst2q_lane_s32(_a, b, IDX);                                   \
  if ((_a[0] != _b[IDX]) || (_a[1] != _b[IDX + reg_elt_num])) { \
    return TEST_FAIL;                                           \
  }

  IMM_4_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst2q_lane_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int reg_elt_num = 4;
  float _a[reg_elt_num * 2];
  const float *_in1 = (float *)impl.test_cases_float_pointer1;
  const float *_in2 = (float *)impl.test_cases_float_pointer2;
  float _b[reg_elt_num * 2];
  float in[reg_elt_num * 4];
  merge_arrays(_in1, _in2, in, reg_elt_num);
  float32x4x2_t b;

  for (int i = 0; i < reg_elt_num; i++) {
    _b[i] = in[2 * i];
    _b[i + reg_elt_num] = in[2 * i + 1];
  }

#define TEST_IMPL(IDX)                                          \
  b = vld2q_f32(in);                                            \
  vst2q_lane_f32(_a, b, IDX);                                   \
  if ((_a[0] != _b[IDX]) || (_a[1] != _b[IDX + reg_elt_num])) { \
    return TEST_FAIL;                                           \
  }

  IMM_4_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst2_lane_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst2q_lane_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst2q_lane_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst2q_lane_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst2q_lane_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst2_lane_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst2q_lane_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst2_lane_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst2q_lane_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst2_lane_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst2q_lane_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst2_lane_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst2q_lane_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst2q_lane_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int reg_elt_num = 8;
  uint16_t _a[reg_elt_num * 2];
  const uint16_t *_in1 = (uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_in2 = (uint16_t *)impl.test_cases_int_pointer2;
  uint16_t _b[reg_elt_num * 2];
  uint16_t in[reg_elt_num * 4];
  merge_arrays(_in1, _in2, in, reg_elt_num);
  uint16x8x2_t b;

  for (int i = 0; i < reg_elt_num; i++) {
    _b[i] = in[2 * i];
    _b[i + reg_elt_num] = in[2 * i + 1];
  }

#define TEST_IMPL(IDX)                                          \
  b = vld2q_u16(in);                                            \
  vst2q_lane_u16(_a, b, IDX);                                   \
  if ((_a[0] != _b[IDX]) || (_a[1] != _b[IDX + reg_elt_num])) { \
    return TEST_FAIL;                                           \
  }

  IMM_8_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst2q_lane_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int reg_elt_num = 4;
  uint32_t _a[reg_elt_num * 2];
  const uint32_t *_in1 = (uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_in2 = (uint32_t *)impl.test_cases_int_pointer2;
  uint32_t _b[reg_elt_num * 2];
  uint32_t in[reg_elt_num * 4];
  merge_arrays(_in1, _in2, in, reg_elt_num);
  uint32x4x2_t b;

  for (int i = 0; i < reg_elt_num; i++) {
    _b[i] = in[2 * i];
    _b[i + reg_elt_num] = in[2 * i + 1];
  }

#define TEST_IMPL(IDX)                                          \
  b = vld2q_u32(in);                                            \
  vst2q_lane_u32(_a, b, IDX);                                   \
  if ((_a[0] != _b[IDX]) || (_a[1] != _b[IDX + reg_elt_num])) { \
    return TEST_FAIL;                                           \
  }

  IMM_4_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst2_lane_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst2q_lane_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld3_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (int8_t *)impl.test_cases_int_pointer2;
  const int reg_elt_num = 8;
  int8_t in[reg_elt_num * 4];
  merge_arrays(_a, _b, in, reg_elt_num);
  int8_t _c[reg_elt_num * 3];

  int8x8x3_t c = vld3_s8(_a);
  for (int i = 0; i < reg_elt_num; i++) {
    _c[i] = _a[3 * i];
    _c[i + reg_elt_num] = _a[3 * i + 1];
    _c[i + reg_elt_num * 2] = _a[3 * i + 2];
  }
#if defined(__riscv) || defined(__riscv__)
  vint8m1_t a0 = __riscv_vget_v_i8m1x3_i8m1(c, 0);
  vint8m1_t a1 = __riscv_vget_v_i8m1x3_i8m1(c, 1);
  vint8m1_t a2 = __riscv_vget_v_i8m1x3_i8m1(c, 2);
  const int8_t *t0 = (const int8_t *)&a0;
  const int8_t *t1 = (const int8_t *)&a1;
  const int8_t *t2 = (const int8_t *)&a2;
#elif defined(__aarch64__) || defined(_M_ARM64)
  const int8_t *t0 = (const int8_t *)&c.val[0];
  const int8_t *t1 = (const int8_t *)&c.val[1];
  const int8_t *t2 = (const int8_t *)&c.val[2];
#endif

  for (int i = 0; i < reg_elt_num; i++) {
    if ((t0[i] != _c[i]) || (t1[i] != _c[i + reg_elt_num]) || (t2[i] != _c[i + reg_elt_num * 2])) {
      return TEST_FAIL;
    }
  }
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld3_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  const int reg_elt_num = 4;
  int16_t in[reg_elt_num * 4];
  merge_arrays(_a, _b, in, reg_elt_num);
  int16_t _c[reg_elt_num * 3];

  int16x4x3_t c = vld3_s16(_a);
  for (int i = 0; i < reg_elt_num; i++) {
    _c[i] = _a[3 * i];
    _c[i + reg_elt_num] = _a[3 * i + 1];
    _c[i + reg_elt_num * 2] = _a[3 * i + 2];
  }
#if defined(__riscv) || defined(__riscv__)
  vint16m1_t a0 = __riscv_vget_v_i16m1x3_i16m1(c, 0);
  vint16m1_t a1 = __riscv_vget_v_i16m1x3_i16m1(c, 1);
  vint16m1_t a2 = __riscv_vget_v_i16m1x3_i16m1(c, 2);
  const int16_t *t0 = (const int16_t *)&a0;
  const int16_t *t1 = (const int16_t *)&a1;
  const int16_t *t2 = (const int16_t *)&a2;
#elif defined(__aarch64__) || defined(_M_ARM64)
  const int16_t *t0 = (const int16_t *)&c.val[0];
  const int16_t *t1 = (const int16_t *)&c.val[1];
  const int16_t *t2 = (const int16_t *)&c.val[2];
#endif

  for (int i = 0; i < reg_elt_num; i++) {
    if ((t0[i] != _c[i]) || (t1[i] != _c[i + reg_elt_num]) || (t2[i] != _c[i + reg_elt_num * 2])) {
      return TEST_FAIL;
    }
  }
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld3_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  const int reg_elt_num = 2;
  int32_t in[reg_elt_num * 4];
  merge_arrays(_a, _b, in, reg_elt_num);
  int32_t _c[reg_elt_num * 3];

  int32x2x3_t c = vld3_s32(_a);
  for (int i = 0; i < reg_elt_num; i++) {
    _c[i] = _a[3 * i];
    _c[i + reg_elt_num] = _a[3 * i + 1];
    _c[i + reg_elt_num * 2] = _a[3 * i + 2];
  }
#if defined(__riscv) || defined(__riscv__)
  vint32m1_t a0 = __riscv_vget_v_i32m1x3_i32m1(c, 0);
  vint32m1_t a1 = __riscv_vget_v_i32m1x3_i32m1(c, 1);
  vint32m1_t a2 = __riscv_vget_v_i32m1x3_i32m1(c, 2);
  const int32_t *t0 = (const int32_t *)&a0;
  const int32_t *t1 = (const int32_t *)&a1;
  const int32_t *t2 = (const int32_t *)&a2;
#elif defined(__aarch64__) || defined(_M_ARM64)
  const int32_t *t0 = (const int32_t *)&c.val[0];
  const int32_t *t1 = (const int32_t *)&c.val[1];
  const int32_t *t2 = (const int32_t *)&c.val[2];
#endif

  for (int i = 0; i < reg_elt_num; i++) {
    if ((t0[i] != _c[i]) || (t1[i] != _c[i + reg_elt_num]) || (t2[i] != _c[i + reg_elt_num * 2])) {
      return TEST_FAIL;
    }
  }
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld3_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (float *)impl.test_cases_int_pointer1;
  const float *_b = (float *)impl.test_cases_int_pointer2;
  const int reg_elt_num = 2;
  float in[reg_elt_num * 4];
  merge_arrays(_a, _b, in, reg_elt_num);
  float _c[reg_elt_num * 3];

  float32x2x3_t c = vld3_f32(_a);
  for (int i = 0; i < reg_elt_num; i++) {
    _c[i] = _a[3 * i];
    _c[i + reg_elt_num] = _a[3 * i + 1];
    _c[i + reg_elt_num * 2] = _a[3 * i + 2];
  }
#if defined(__riscv) || defined(__riscv__)
  vfloat32m1_t a0 = __riscv_vget_v_f32m1x3_f32m1(c, 0);
  vfloat32m1_t a1 = __riscv_vget_v_f32m1x3_f32m1(c, 1);
  vfloat32m1_t a2 = __riscv_vget_v_f32m1x3_f32m1(c, 2);
  const float *t0 = (const float *)&a0;
  const float *t1 = (const float *)&a1;
  const float *t2 = (const float *)&a2;
#elif defined(__aarch64__) || defined(_M_ARM64)
  const float *t0 = (const float *)&c.val[0];
  const float *t1 = (const float *)&c.val[1];
  const float *t2 = (const float *)&c.val[2];
#endif

  for (int i = 0; i < reg_elt_num; i++) {
    if (validate_float_pair(t0[i], _c[i]) == TEST_FAIL ||
        validate_float_pair(t1[i], _c[i + reg_elt_num]) == TEST_FAIL ||
        validate_float_pair(t2[i], _c[i + reg_elt_num * 2]) == TEST_FAIL) {
      return TEST_FAIL;
    }
  }
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld3_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (uint8_t *)impl.test_cases_int_pointer2;
  const int reg_elt_num = 8;
  uint8_t in[reg_elt_num * 4];
  merge_arrays(_a, _b, in, reg_elt_num);
  uint8_t _c[reg_elt_num * 3];

  uint8x8x3_t c = vld3_u8(_a);
  for (int i = 0; i < reg_elt_num; i++) {
    _c[i] = _a[3 * i];
    _c[i + reg_elt_num] = _a[3 * i + 1];
    _c[i + reg_elt_num * 2] = _a[3 * i + 2];
  }
#if defined(__riscv) || defined(__riscv__)
  vuint8m1_t a0 = __riscv_vget_v_u8m1x3_u8m1(c, 0);
  vuint8m1_t a1 = __riscv_vget_v_u8m1x3_u8m1(c, 1);
  vuint8m1_t a2 = __riscv_vget_v_u8m1x3_u8m1(c, 2);
  const uint8_t *t0 = (const uint8_t *)&a0;
  const uint8_t *t1 = (const uint8_t *)&a1;
  const uint8_t *t2 = (const uint8_t *)&a2;
#elif defined(__aarch64__) || defined(_M_ARM64)
  const uint8_t *t0 = (const uint8_t *)&c.val[0];
  const uint8_t *t1 = (const uint8_t *)&c.val[1];
  const uint8_t *t2 = (const uint8_t *)&c.val[2];
#endif

  for (int i = 0; i < reg_elt_num; i++) {
    if ((t0[i] != _c[i]) || (t1[i] != _c[i + reg_elt_num]) || (t2[i] != _c[i + reg_elt_num * 2])) {
      return TEST_FAIL;
    }
  }
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld3_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (uint16_t *)impl.test_cases_int_pointer2;
  const int reg_elt_num = 4;
  uint16_t in[reg_elt_num * 4];
  merge_arrays(_a, _b, in, reg_elt_num);
  uint16_t _c[reg_elt_num * 3];

  uint16x4x3_t c = vld3_u16(_a);
  for (int i = 0; i < reg_elt_num; i++) {
    _c[i] = _a[3 * i];
    _c[i + reg_elt_num] = _a[3 * i + 1];
    _c[i + reg_elt_num * 2] = _a[3 * i + 2];
  }
#if defined(__riscv) || defined(__riscv__)
  vuint16m1_t a0 = __riscv_vget_v_u16m1x3_u16m1(c, 0);
  vuint16m1_t a1 = __riscv_vget_v_u16m1x3_u16m1(c, 1);
  vuint16m1_t a2 = __riscv_vget_v_u16m1x3_u16m1(c, 2);
  const uint16_t *t0 = (const uint16_t *)&a0;
  const uint16_t *t1 = (const uint16_t *)&a1;
  const uint16_t *t2 = (const uint16_t *)&a2;
#elif defined(__aarch64__) || defined(_M_ARM64)
  const uint16_t *t0 = (const uint16_t *)&c.val[0];
  const uint16_t *t1 = (const uint16_t *)&c.val[1];
  const uint16_t *t2 = (const uint16_t *)&c.val[2];
#endif

  for (int i = 0; i < reg_elt_num; i++) {
    if ((t0[i] != _c[i]) || (t1[i] != _c[i + reg_elt_num]) || (t2[i] != _c[i + reg_elt_num * 2])) {
      return TEST_FAIL;
    }
  }
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld3_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (uint32_t *)impl.test_cases_int_pointer2;
  const int reg_elt_num = 2;
  uint32_t in[reg_elt_num * 4];
  merge_arrays(_a, _b, in, reg_elt_num);
  uint32_t _c[reg_elt_num * 3];

  uint32x2x3_t c = vld3_u32(_a);
  for (int i = 0; i < reg_elt_num; i++) {
    _c[i] = _a[3 * i];
    _c[i + reg_elt_num] = _a[3 * i + 1];
    _c[i + reg_elt_num * 2] = _a[3 * i + 2];
  }
#if defined(__riscv) || defined(__riscv__)
  vuint32m1_t a0 = __riscv_vget_v_u32m1x3_u32m1(c, 0);
  vuint32m1_t a1 = __riscv_vget_v_u32m1x3_u32m1(c, 1);
  vuint32m1_t a2 = __riscv_vget_v_u32m1x3_u32m1(c, 2);
  const uint32_t *t0 = (const uint32_t *)&a0;
  const uint32_t *t1 = (const uint32_t *)&a1;
  const uint32_t *t2 = (const uint32_t *)&a2;
#elif defined(__aarch64__) || defined(_M_ARM64)
  const uint32_t *t0 = (const uint32_t *)&c.val[0];
  const uint32_t *t1 = (const uint32_t *)&c.val[1];
  const uint32_t *t2 = (const uint32_t *)&c.val[2];
#endif

  for (int i = 0; i < reg_elt_num; i++) {
    if ((t0[i] != _c[i]) || (t1[i] != _c[i + reg_elt_num]) || (t2[i] != _c[i + reg_elt_num * 2])) {
      return TEST_FAIL;
    }
  }
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld3_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (int64_t *)impl.test_cases_int_pointer1;
  const int64_t *_b = (int64_t *)impl.test_cases_int_pointer2;
  const int reg_elt_num = 1;
  int64_t in[reg_elt_num * 4];
  merge_arrays(_a, _b, in, reg_elt_num);
  int64_t _c[reg_elt_num * 3];

  int64x1x3_t c = vld3_s64(_a);
  for (int i = 0; i < reg_elt_num; i++) {
    _c[i] = _a[3 * i];
    _c[i + reg_elt_num] = _a[3 * i + 1];
    _c[i + reg_elt_num * 2] = _a[3 * i + 2];
  }
#if defined(__riscv) || defined(__riscv__)
  vint64m1_t a0 = __riscv_vget_v_i64m1x3_i64m1(c, 0);
  vint64m1_t a1 = __riscv_vget_v_i64m1x3_i64m1(c, 1);
  vint64m1_t a2 = __riscv_vget_v_i64m1x3_i64m1(c, 2);
  const int64_t *t0 = (const int64_t *)&a0;
  const int64_t *t1 = (const int64_t *)&a1;
  const int64_t *t2 = (const int64_t *)&a2;
#elif defined(__aarch64__) || defined(_M_ARM64)
  const int64_t *t0 = (const int64_t *)&c.val[0];
  const int64_t *t1 = (const int64_t *)&c.val[1];
  const int64_t *t2 = (const int64_t *)&c.val[2];
#endif

  for (int i = 0; i < reg_elt_num; i++) {
    if ((t0[i] != _c[i]) || (t1[i] != _c[i + reg_elt_num]) || (t2[i] != _c[i + reg_elt_num * 2])) {
      return TEST_FAIL;
    }
  }
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld3_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (uint64_t *)impl.test_cases_int_pointer1;
  const uint64_t *_b = (uint64_t *)impl.test_cases_int_pointer2;
  const int reg_elt_num = 1;
  uint64_t in[reg_elt_num * 4];
  merge_arrays(_a, _b, in, reg_elt_num);
  uint64_t _c[reg_elt_num * 3];

  uint64x1x3_t c = vld3_u64(_a);
  for (int i = 0; i < reg_elt_num; i++) {
    _c[i] = _a[3 * i];
    _c[i + reg_elt_num] = _a[3 * i + 1];
    _c[i + reg_elt_num * 2] = _a[3 * i + 2];
  }
#if defined(__riscv) || defined(__riscv__)
  vuint64m1_t a0 = __riscv_vget_v_u64m1x3_u64m1(c, 0);
  vuint64m1_t a1 = __riscv_vget_v_u64m1x3_u64m1(c, 1);
  vuint64m1_t a2 = __riscv_vget_v_u64m1x3_u64m1(c, 2);
  const uint64_t *t0 = (const uint64_t *)&a0;
  const uint64_t *t1 = (const uint64_t *)&a1;
  const uint64_t *t2 = (const uint64_t *)&a2;
#elif defined(__aarch64__) || defined(_M_ARM64)
  const uint64_t *t0 = (const uint64_t *)&c.val[0];
  const uint64_t *t1 = (const uint64_t *)&c.val[1];
  const uint64_t *t2 = (const uint64_t *)&c.val[2];
#endif

  for (int i = 0; i < reg_elt_num; i++) {
    if ((t0[i] != _c[i]) || (t1[i] != _c[i + reg_elt_num]) || (t2[i] != _c[i + reg_elt_num * 2])) {
      return TEST_FAIL;
    }
  }
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld3_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld3q_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld3q_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld3q_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld3_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld3q_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld3q_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (int8_t *)impl.test_cases_int_pointer2;
  const int reg_elt_num = 8 * 2;
  int8_t in[reg_elt_num * 4];
  merge_arrays(_a, _b, in, reg_elt_num);
  int8_t _c[reg_elt_num * 3];

  int8x16x3_t c = vld3q_s8(_a);
  for (int i = 0; i < reg_elt_num; i++) {
    _c[i] = _a[3 * i];
    _c[i + reg_elt_num] = _a[3 * i + 1];
    _c[i + reg_elt_num * 2] = _a[3 * i + 2];
  }
#if defined(__riscv) || defined(__riscv__)
  vint8m1_t a0 = __riscv_vget_v_i8m1x3_i8m1(c, 0);
  vint8m1_t a1 = __riscv_vget_v_i8m1x3_i8m1(c, 1);
  vint8m1_t a2 = __riscv_vget_v_i8m1x3_i8m1(c, 2);
  const int8_t *t0 = (const int8_t *)&a0;
  const int8_t *t1 = (const int8_t *)&a1;
  const int8_t *t2 = (const int8_t *)&a2;
#elif defined(__aarch64__) || defined(_M_ARM64)
  const int8_t *t0 = (const int8_t *)&c.val[0];
  const int8_t *t1 = (const int8_t *)&c.val[1];
  const int8_t *t2 = (const int8_t *)&c.val[2];
#endif

  for (int i = 0; i < reg_elt_num; i++) {
    if ((t0[i] != _c[i]) || (t1[i] != _c[i + reg_elt_num]) || (t2[i] != _c[i + reg_elt_num * 2])) {
      return TEST_FAIL;
    }
  }
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld3q_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  const int reg_elt_num = 4 * 2;
  int16_t in[reg_elt_num * 4];
  merge_arrays(_a, _b, in, reg_elt_num);
  int16_t _c[reg_elt_num * 3];

  int16x8x3_t c = vld3q_s16(_a);
  for (int i = 0; i < reg_elt_num; i++) {
    _c[i] = _a[3 * i];
    _c[i + reg_elt_num] = _a[3 * i + 1];
    _c[i + reg_elt_num * 2] = _a[3 * i + 2];
  }
#if defined(__riscv) || defined(__riscv__)
  vint16m1_t a0 = __riscv_vget_v_i16m1x3_i16m1(c, 0);
  vint16m1_t a1 = __riscv_vget_v_i16m1x3_i16m1(c, 1);
  vint16m1_t a2 = __riscv_vget_v_i16m1x3_i16m1(c, 2);
  const int16_t *t0 = (const int16_t *)&a0;
  const int16_t *t1 = (const int16_t *)&a1;
  const int16_t *t2 = (const int16_t *)&a2;
#elif defined(__aarch64__) || defined(_M_ARM64)
  const int16_t *t0 = (const int16_t *)&c.val[0];
  const int16_t *t1 = (const int16_t *)&c.val[1];
  const int16_t *t2 = (const int16_t *)&c.val[2];
#endif

  for (int i = 0; i < reg_elt_num; i++) {
    if ((t0[i] != _c[i]) || (t1[i] != _c[i + reg_elt_num]) || (t2[i] != _c[i + reg_elt_num * 2])) {
      return TEST_FAIL;
    }
  }
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld3q_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  const int reg_elt_num = 2 * 2;
  int32_t in[reg_elt_num * 4];
  merge_arrays(_a, _b, in, reg_elt_num);
  int32_t _c[reg_elt_num * 3];

  int32x4x3_t c = vld3q_s32(_a);
  for (int i = 0; i < reg_elt_num; i++) {
    _c[i] = _a[3 * i];
    _c[i + reg_elt_num] = _a[3 * i + 1];
    _c[i + reg_elt_num * 2] = _a[3 * i + 2];
  }
#if defined(__riscv) || defined(__riscv__)
  vint32m1_t a0 = __riscv_vget_v_i32m1x3_i32m1(c, 0);
  vint32m1_t a1 = __riscv_vget_v_i32m1x3_i32m1(c, 1);
  vint32m1_t a2 = __riscv_vget_v_i32m1x3_i32m1(c, 2);
  const int32_t *t0 = (const int32_t *)&a0;
  const int32_t *t1 = (const int32_t *)&a1;
  const int32_t *t2 = (const int32_t *)&a2;
#elif defined(__aarch64__) || defined(_M_ARM64)
  const int32_t *t0 = (const int32_t *)&c.val[0];
  const int32_t *t1 = (const int32_t *)&c.val[1];
  const int32_t *t2 = (const int32_t *)&c.val[2];
#endif

  for (int i = 0; i < reg_elt_num; i++) {
    if ((t0[i] != _c[i]) || (t1[i] != _c[i + reg_elt_num]) || (t2[i] != _c[i + reg_elt_num * 2])) {
      return TEST_FAIL;
    }
  }
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld3q_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (float *)impl.test_cases_int_pointer1;
  const float *_b = (float *)impl.test_cases_int_pointer2;
  const int reg_elt_num = 2 * 2;
  float in[reg_elt_num * 4];
  merge_arrays(_a, _b, in, reg_elt_num);
  float _c[reg_elt_num * 3];

  float32x4x3_t c = vld3q_f32(_a);
  for (int i = 0; i < reg_elt_num; i++) {
    _c[i] = _a[3 * i];
    _c[i + reg_elt_num] = _a[3 * i + 1];
    _c[i + reg_elt_num * 2] = _a[3 * i + 2];
  }
#if defined(__riscv) || defined(__riscv__)
  vfloat32m1_t a0 = __riscv_vget_v_f32m1x3_f32m1(c, 0);
  vfloat32m1_t a1 = __riscv_vget_v_f32m1x3_f32m1(c, 1);
  vfloat32m1_t a2 = __riscv_vget_v_f32m1x3_f32m1(c, 2);
  const float *t0 = (const float *)&a0;
  const float *t1 = (const float *)&a1;
  const float *t2 = (const float *)&a2;
#elif defined(__aarch64__) || defined(_M_ARM64)
  const float *t0 = (const float *)&c.val[0];
  const float *t1 = (const float *)&c.val[1];
  const float *t2 = (const float *)&c.val[2];
#endif

  for (int i = 0; i < reg_elt_num; i++) {
    if (validate_float_pair(t0[i], _c[i]) == TEST_FAIL ||
        validate_float_pair(t1[i], _c[i + reg_elt_num]) == TEST_FAIL ||
        validate_float_pair(t2[i], _c[i + reg_elt_num * 2]) == TEST_FAIL) {
      return TEST_FAIL;
    }
  }
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld3_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld3q_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld3_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld3q_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld3q_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (uint8_t *)impl.test_cases_int_pointer2;
  const int reg_elt_num = 8 * 2;
  uint8_t in[reg_elt_num * 4];
  merge_arrays(_a, _b, in, reg_elt_num);
  uint8_t _c[reg_elt_num * 3];

  uint8x16x3_t c = vld3q_u8(_a);
  for (int i = 0; i < reg_elt_num; i++) {
    _c[i] = _a[3 * i];
    _c[i + reg_elt_num] = _a[3 * i + 1];
    _c[i + reg_elt_num * 2] = _a[3 * i + 2];
  }
#if defined(__riscv) || defined(__riscv__)
  vuint8m1_t a0 = __riscv_vget_v_u8m1x3_u8m1(c, 0);
  vuint8m1_t a1 = __riscv_vget_v_u8m1x3_u8m1(c, 1);
  vuint8m1_t a2 = __riscv_vget_v_u8m1x3_u8m1(c, 2);
  const uint8_t *t0 = (const uint8_t *)&a0;
  const uint8_t *t1 = (const uint8_t *)&a1;
  const uint8_t *t2 = (const uint8_t *)&a2;
#elif defined(__aarch64__) || defined(_M_ARM64)
  const uint8_t *t0 = (const uint8_t *)&c.val[0];
  const uint8_t *t1 = (const uint8_t *)&c.val[1];
  const uint8_t *t2 = (const uint8_t *)&c.val[2];
#endif

  for (int i = 0; i < reg_elt_num; i++) {
    if ((t0[i] != _c[i]) || (t1[i] != _c[i + reg_elt_num]) || (t2[i] != _c[i + reg_elt_num * 2])) {
      return TEST_FAIL;
    }
  }
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld3q_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (uint16_t *)impl.test_cases_int_pointer2;
  const int reg_elt_num = 4 * 2;
  uint16_t in[reg_elt_num * 4];
  merge_arrays(_a, _b, in, reg_elt_num);
  uint16_t _c[reg_elt_num * 3];

  uint16x8x3_t c = vld3q_u16(_a);
  for (int i = 0; i < reg_elt_num; i++) {
    _c[i] = _a[3 * i];
    _c[i + reg_elt_num] = _a[3 * i + 1];
    _c[i + reg_elt_num * 2] = _a[3 * i + 2];
  }
#if defined(__riscv) || defined(__riscv__)
  vuint16m1_t a0 = __riscv_vget_v_u16m1x3_u16m1(c, 0);
  vuint16m1_t a1 = __riscv_vget_v_u16m1x3_u16m1(c, 1);
  vuint16m1_t a2 = __riscv_vget_v_u16m1x3_u16m1(c, 2);
  const uint16_t *t0 = (const uint16_t *)&a0;
  const uint16_t *t1 = (const uint16_t *)&a1;
  const uint16_t *t2 = (const uint16_t *)&a2;
#elif defined(__aarch64__) || defined(_M_ARM64)
  const uint16_t *t0 = (const uint16_t *)&c.val[0];
  const uint16_t *t1 = (const uint16_t *)&c.val[1];
  const uint16_t *t2 = (const uint16_t *)&c.val[2];
#endif

  for (int i = 0; i < reg_elt_num; i++) {
    if ((t0[i] != _c[i]) || (t1[i] != _c[i + reg_elt_num]) || (t2[i] != _c[i + reg_elt_num * 2])) {
      return TEST_FAIL;
    }
  }
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld3q_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (uint32_t *)impl.test_cases_int_pointer2;
  const int reg_elt_num = 2 * 2;
  uint32_t in[reg_elt_num * 4];
  merge_arrays(_a, _b, in, reg_elt_num);
  uint32_t _c[reg_elt_num * 3];

  uint32x4x3_t c = vld3q_u32(_a);
  for (int i = 0; i < reg_elt_num; i++) {
    _c[i] = _a[3 * i];
    _c[i + reg_elt_num] = _a[3 * i + 1];
    _c[i + reg_elt_num * 2] = _a[3 * i + 2];
  }
#if defined(__riscv) || defined(__riscv__)
  vuint32m1_t a0 = __riscv_vget_v_u32m1x3_u32m1(c, 0);
  vuint32m1_t a1 = __riscv_vget_v_u32m1x3_u32m1(c, 1);
  vuint32m1_t a2 = __riscv_vget_v_u32m1x3_u32m1(c, 2);
  const uint32_t *t0 = (const uint32_t *)&a0;
  const uint32_t *t1 = (const uint32_t *)&a1;
  const uint32_t *t2 = (const uint32_t *)&a2;
#elif defined(__aarch64__) || defined(_M_ARM64)
  const uint32_t *t0 = (const uint32_t *)&c.val[0];
  const uint32_t *t1 = (const uint32_t *)&c.val[1];
  const uint32_t *t2 = (const uint32_t *)&c.val[2];
#endif

  for (int i = 0; i < reg_elt_num; i++) {
    if ((t0[i] != _c[i]) || (t1[i] != _c[i + reg_elt_num]) || (t2[i] != _c[i + reg_elt_num * 2])) {
      return TEST_FAIL;
    }
  }
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld3_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld3q_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld3_lane_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (int8_t *)impl.test_cases_int_pointer2;
  const int reg_elt_num = 8;
  int8_t _c[reg_elt_num * 3];
  int8x8x3_t c;
  int8x8x3_t b = vld3_s8(_b);
  int8x8_t c0, c1, c2;

#define TEST_IMPL(IDX)                                                                          \
  for (int i = 0; i < reg_elt_num; i++) {                                                       \
    if (i != IDX) {                                                                             \
      _c[i] = _b[3 * i];                                                                        \
      _c[i + reg_elt_num] = _b[3 * i + 1];                                                      \
      _c[i + reg_elt_num * 2] = _b[3 * i + 2];                                                  \
    } else {                                                                                    \
      _c[i] = _a[0];                                                                            \
      _c[i + reg_elt_num] = _a[1];                                                              \
      _c[i + reg_elt_num * 2] = _a[2];                                                          \
    }                                                                                           \
  }                                                                                             \
  c = vld3_lane_s8(_a, b, IDX);                                                                 \
  int8x3_get_int8(c, &c0, &c1, &c2);                                                            \
  CHECK_RESULT(validate_int8(c0, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]))       \
  CHECK_RESULT(validate_int8(c1, _c[8], _c[9], _c[10], _c[11], _c[12], _c[13], _c[14], _c[15])) \
  CHECK_RESULT(validate_int8(c2, _c[16], _c[17], _c[18], _c[19], _c[20], _c[21], _c[22], _c[23]))

  IMM_8_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld3_lane_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  const int reg_elt_num = 4;
  int16_t _c[reg_elt_num * 3];
  int16x4x3_t c;
  int16x4x3_t b = vld3_s16(_b);
  int16x4_t c0, c1, c2;

#define TEST_IMPL(IDX)                                         \
  for (int i = 0; i < reg_elt_num; i++) {                      \
    if (i != IDX) {                                            \
      _c[i] = _b[3 * i];                                       \
      _c[i + reg_elt_num] = _b[3 * i + 1];                     \
      _c[i + reg_elt_num * 2] = _b[3 * i + 2];                 \
    } else {                                                   \
      _c[i] = _a[0];                                           \
      _c[i + reg_elt_num] = _a[1];                             \
      _c[i + reg_elt_num * 2] = _a[2];                         \
    }                                                          \
  }                                                            \
  c = vld3_lane_s16(_a, b, IDX);                               \
  int16x3_get_int16(c, &c0, &c1, &c2);                         \
  CHECK_RESULT(validate_int16(c0, _c[0], _c[1], _c[2], _c[3])) \
  CHECK_RESULT(validate_int16(c1, _c[4], _c[5], _c[6], _c[7])) \
  CHECK_RESULT(validate_int16(c2, _c[8], _c[9], _c[10], _c[11]))

  IMM_4_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld3_lane_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  const int reg_elt_num = 2;
  int32_t _c[reg_elt_num * 3];
  int32x2x3_t c;
  int32x2x3_t b = vld3_s32(_b);
  int32x2_t c0, c1, c2;

#define TEST_IMPL(IDX)                           \
  for (int i = 0; i < reg_elt_num; i++) {        \
    if (i != IDX) {                              \
      _c[i] = _b[3 * i];                         \
      _c[i + reg_elt_num] = _b[3 * i + 1];       \
      _c[i + reg_elt_num * 2] = _b[3 * i + 2];   \
    } else {                                     \
      _c[i] = _a[0];                             \
      _c[i + reg_elt_num] = _a[1];               \
      _c[i + reg_elt_num * 2] = _a[2];           \
    }                                            \
  }                                              \
  c = vld3_lane_s32(_a, b, IDX);                 \
  int32x3_get_int32(c, &c0, &c1, &c2);           \
  CHECK_RESULT(validate_int32(c0, _c[0], _c[1])) \
  CHECK_RESULT(validate_int32(c1, _c[2], _c[3])) \
  CHECK_RESULT(validate_int32(c2, _c[4], _c[5]))

  IMM_2_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld3_lane_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (float *)impl.test_cases_float_pointer1;
  const float *_b = (float *)impl.test_cases_float_pointer2;
  const int reg_elt_num = 2;
  float _c[reg_elt_num * 3];
  float32x2x3_t c;
  float32x2x3_t b = vld3_f32(_b);
  float32x2_t c0, c1, c2;

#define TEST_IMPL(IDX)                           \
  for (int i = 0; i < reg_elt_num; i++) {        \
    if (i != IDX) {                              \
      _c[i] = _b[3 * i];                         \
      _c[i + reg_elt_num] = _b[3 * i + 1];       \
      _c[i + reg_elt_num * 2] = _b[3 * i + 2];   \
    } else {                                     \
      _c[i] = _a[0];                             \
      _c[i + reg_elt_num] = _a[1];               \
      _c[i + reg_elt_num * 2] = _a[2];           \
    }                                            \
  }                                              \
  c = vld3_lane_f32(_a, b, IDX);                 \
  float32x3_get_float32(c, &c0, &c1, &c2);       \
  CHECK_RESULT(validate_float(c0, _c[0], _c[1])) \
  CHECK_RESULT(validate_float(c1, _c[2], _c[3])) \
  CHECK_RESULT(validate_float(c2, _c[4], _c[5]))

  IMM_2_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld3_lane_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (uint8_t *)impl.test_cases_int_pointer2;
  const int reg_elt_num = 8;
  uint8_t _c[reg_elt_num * 3];
  uint8x8x3_t c;
  uint8x8x3_t b = vld3_u8(_b);
  uint8x8_t c0, c1, c2;

#define TEST_IMPL(IDX)                                                                           \
  for (int i = 0; i < reg_elt_num; i++) {                                                        \
    if (i != IDX) {                                                                              \
      _c[i] = _b[3 * i];                                                                         \
      _c[i + reg_elt_num] = _b[3 * i + 1];                                                       \
      _c[i + reg_elt_num * 2] = _b[3 * i + 2];                                                   \
    } else {                                                                                     \
      _c[i] = _a[0];                                                                             \
      _c[i + reg_elt_num] = _a[1];                                                               \
      _c[i + reg_elt_num * 2] = _a[2];                                                           \
    }                                                                                            \
  }                                                                                              \
  c = vld3_lane_u8(_a, b, IDX);                                                                  \
  uint8x3_get_uint8(c, &c0, &c1, &c2);                                                           \
  CHECK_RESULT(validate_uint8(c0, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]))       \
  CHECK_RESULT(validate_uint8(c1, _c[8], _c[9], _c[10], _c[11], _c[12], _c[13], _c[14], _c[15])) \
  CHECK_RESULT(validate_uint8(c2, _c[16], _c[17], _c[18], _c[19], _c[20], _c[21], _c[22], _c[23]))

  IMM_8_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld3_lane_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld3q_lane_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld3q_lane_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld3q_lane_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld3_lane_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld3q_lane_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld3_lane_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld3q_lane_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld3_lane_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld3q_lane_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld3_lane_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld3q_lane_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld3_lane_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (uint16_t *)impl.test_cases_int_pointer2;
  const int reg_elt_num = 4;
  uint16_t _c[reg_elt_num * 3];
  uint16x4x3_t c;
  uint16x4x3_t b = vld3_u16(_b);
  uint16x4_t c0, c1, c2;

#define TEST_IMPL(IDX)                                          \
  for (int i = 0; i < reg_elt_num; i++) {                       \
    if (i != IDX) {                                             \
      _c[i] = _b[3 * i];                                        \
      _c[i + reg_elt_num] = _b[3 * i + 1];                      \
      _c[i + reg_elt_num * 2] = _b[3 * i + 2];                  \
    } else {                                                    \
      _c[i] = _a[0];                                            \
      _c[i + reg_elt_num] = _a[1];                              \
      _c[i + reg_elt_num * 2] = _a[2];                          \
    }                                                           \
  }                                                             \
  c = vld3_lane_u16(_a, b, IDX);                                \
  uint16x3_get_uint16(c, &c0, &c1, &c2);                        \
  CHECK_RESULT(validate_uint16(c0, _c[0], _c[1], _c[2], _c[3])) \
  CHECK_RESULT(validate_uint16(c1, _c[4], _c[5], _c[6], _c[7])) \
  CHECK_RESULT(validate_uint16(c2, _c[8], _c[9], _c[10], _c[11]))

  IMM_4_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld3_lane_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (uint32_t *)impl.test_cases_int_pointer2;
  const int reg_elt_num = 2;
  uint32_t _c[reg_elt_num * 3];
  uint32x2x3_t c;
  uint32x2x3_t b = vld3_u32(_b);
  uint32x2_t c0, c1, c2;

#define TEST_IMPL(IDX)                            \
  for (int i = 0; i < reg_elt_num; i++) {         \
    if (i != IDX) {                               \
      _c[i] = _b[3 * i];                          \
      _c[i + reg_elt_num] = _b[3 * i + 1];        \
      _c[i + reg_elt_num * 2] = _b[3 * i + 2];    \
    } else {                                      \
      _c[i] = _a[0];                              \
      _c[i + reg_elt_num] = _a[1];                \
      _c[i + reg_elt_num * 2] = _a[2];            \
    }                                             \
  }                                               \
  c = vld3_lane_u32(_a, b, IDX);                  \
  uint32x3_get_uint32(c, &c0, &c1, &c2);          \
  CHECK_RESULT(validate_uint32(c0, _c[0], _c[1])) \
  CHECK_RESULT(validate_uint32(c1, _c[2], _c[3])) \
  CHECK_RESULT(validate_uint32(c2, _c[4], _c[5]))

  IMM_2_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld3q_lane_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  const int reg_elt_num = 8;
  int16_t _c[reg_elt_num * 3];
  int16x8x3_t c;
  int16x8x3_t b = vld3q_s16(_b);
  int16x8_t c0, c1, c2;

#define TEST_IMPL(IDX)                                                                           \
  for (int i = 0; i < reg_elt_num; i++) {                                                        \
    if (i != IDX) {                                                                              \
      _c[i] = _b[3 * i];                                                                         \
      _c[i + reg_elt_num] = _b[3 * i + 1];                                                       \
      _c[i + reg_elt_num * 2] = _b[3 * i + 2];                                                   \
    } else {                                                                                     \
      _c[i] = _a[0];                                                                             \
      _c[i + reg_elt_num] = _a[1];                                                               \
      _c[i + reg_elt_num * 2] = _a[2];                                                           \
    }                                                                                            \
  }                                                                                              \
  c = vld3q_lane_s16(_a, b, IDX);                                                                \
  int16x3_get_int16(c, &c0, &c1, &c2);                                                           \
  CHECK_RESULT(validate_int16(c0, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]))       \
  CHECK_RESULT(validate_int16(c1, _c[8], _c[9], _c[10], _c[11], _c[12], _c[13], _c[14], _c[15])) \
  CHECK_RESULT(validate_int16(c2, _c[16], _c[17], _c[18], _c[19], _c[20], _c[21], _c[22], _c[23]))

  IMM_8_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld3q_lane_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  const int reg_elt_num = 4;
  int32_t _c[reg_elt_num * 3];
  int32x4x3_t c;
  int32x4x3_t b = vld3q_s32(_b);
  int32x4_t c0, c1, c2;

#define TEST_IMPL(IDX)                                         \
  for (int i = 0; i < reg_elt_num; i++) {                      \
    if (i != IDX) {                                            \
      _c[i] = _b[3 * i];                                       \
      _c[i + reg_elt_num] = _b[3 * i + 1];                     \
      _c[i + reg_elt_num * 2] = _b[3 * i + 2];                 \
    } else {                                                   \
      _c[i] = _a[0];                                           \
      _c[i + reg_elt_num] = _a[1];                             \
      _c[i + reg_elt_num * 2] = _a[2];                         \
    }                                                          \
  }                                                            \
  c = vld3q_lane_s32(_a, b, IDX);                              \
  int32x3_get_int32(c, &c0, &c1, &c2);                         \
  CHECK_RESULT(validate_int32(c0, _c[0], _c[1], _c[2], _c[3])) \
  CHECK_RESULT(validate_int32(c1, _c[4], _c[5], _c[6], _c[7])) \
  CHECK_RESULT(validate_int32(c2, _c[8], _c[9], _c[10], _c[11]))

  IMM_4_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld3q_lane_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (float *)impl.test_cases_float_pointer1;
  const float *_b = (float *)impl.test_cases_float_pointer2;
  const int reg_elt_num = 4;
  float _c[reg_elt_num * 3];
  float32x4x3_t c;
  float32x4x3_t b = vld3q_f32(_b);
  float32x4_t c0, c1, c2;

#define TEST_IMPL(IDX)                                         \
  for (int i = 0; i < reg_elt_num; i++) {                      \
    if (i != IDX) {                                            \
      _c[i] = _b[3 * i];                                       \
      _c[i + reg_elt_num] = _b[3 * i + 1];                     \
      _c[i + reg_elt_num * 2] = _b[3 * i + 2];                 \
    } else {                                                   \
      _c[i] = _a[0];                                           \
      _c[i + reg_elt_num] = _a[1];                             \
      _c[i + reg_elt_num * 2] = _a[2];                         \
    }                                                          \
  }                                                            \
  c = vld3q_lane_f32(_a, b, IDX);                              \
  float32x3_get_float32(c, &c0, &c1, &c2);                     \
  CHECK_RESULT(validate_float(c0, _c[0], _c[1], _c[2], _c[3])) \
  CHECK_RESULT(validate_float(c1, _c[4], _c[5], _c[6], _c[7])) \
  CHECK_RESULT(validate_float(c2, _c[8], _c[9], _c[10], _c[11]))

  IMM_4_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld3_lane_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld3q_lane_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld3q_lane_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (uint16_t *)impl.test_cases_int_pointer2;
  const int reg_elt_num = 8;
  uint16_t _c[reg_elt_num * 3];
  uint16x8x3_t c;
  uint16x8x3_t b = vld3q_u16(_b);
  uint16x8_t c0, c1, c2;

#define TEST_IMPL(IDX)                                                                            \
  for (int i = 0; i < reg_elt_num; i++) {                                                         \
    if (i != IDX) {                                                                               \
      _c[i] = _b[3 * i];                                                                          \
      _c[i + reg_elt_num] = _b[3 * i + 1];                                                        \
      _c[i + reg_elt_num * 2] = _b[3 * i + 2];                                                    \
    } else {                                                                                      \
      _c[i] = _a[0];                                                                              \
      _c[i + reg_elt_num] = _a[1];                                                                \
      _c[i + reg_elt_num * 2] = _a[2];                                                            \
    }                                                                                             \
  }                                                                                               \
  c = vld3q_lane_u16(_a, b, IDX);                                                                 \
  uint16x3_get_uint16(c, &c0, &c1, &c2);                                                          \
  CHECK_RESULT(validate_uint16(c0, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]))       \
  CHECK_RESULT(validate_uint16(c1, _c[8], _c[9], _c[10], _c[11], _c[12], _c[13], _c[14], _c[15])) \
  CHECK_RESULT(validate_uint16(c2, _c[16], _c[17], _c[18], _c[19], _c[20], _c[21], _c[22], _c[23]))

  IMM_8_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld3q_lane_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (uint32_t *)impl.test_cases_int_pointer2;
  const int reg_elt_num = 4;
  uint32_t _c[reg_elt_num * 3];
  uint32x4x3_t c;
  uint32x4x3_t b = vld3q_u32(_b);
  uint32x4_t c0, c1, c2;

#define TEST_IMPL(IDX)                                          \
  for (int i = 0; i < reg_elt_num; i++) {                       \
    if (i != IDX) {                                             \
      _c[i] = _b[3 * i];                                        \
      _c[i + reg_elt_num] = _b[3 * i + 1];                      \
      _c[i + reg_elt_num * 2] = _b[3 * i + 2];                  \
    } else {                                                    \
      _c[i] = _a[0];                                            \
      _c[i + reg_elt_num] = _a[1];                              \
      _c[i + reg_elt_num * 2] = _a[2];                          \
    }                                                           \
  }                                                             \
  c = vld3q_lane_u32(_a, b, IDX);                               \
  uint32x3_get_uint32(c, &c0, &c1, &c2);                        \
  CHECK_RESULT(validate_uint32(c0, _c[0], _c[1], _c[2], _c[3])) \
  CHECK_RESULT(validate_uint32(c1, _c[4], _c[5], _c[6], _c[7])) \
  CHECK_RESULT(validate_uint32(c2, _c[8], _c[9], _c[10], _c[11]))

  IMM_4_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld3_lane_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld3q_lane_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld3_dup_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (const int8_t *)impl.test_cases_int_pointer1;
  int8x8_t c0, c1, c2;
  int8x8x3_t c = vld3_dup_s8(_a);
  int8x3_get_int8(c, &c0, &c1, &c2);
  CHECK_RESULT(validate_int8(c0, _a[0], _a[0], _a[0], _a[0], _a[0], _a[0], _a[0], _a[0]))
  CHECK_RESULT(validate_int8(c1, _a[1], _a[1], _a[1], _a[1], _a[1], _a[1], _a[1], _a[1]))
  CHECK_RESULT(validate_int8(c2, _a[2], _a[2], _a[2], _a[2], _a[2], _a[2], _a[2], _a[2]))
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld3q_dup_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld3_dup_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (const int16_t *)impl.test_cases_int_pointer1;
  int16x4_t c0, c1, c2;
  int16x4x3_t c = vld3_dup_s16(_a);
  int16x3_get_int16(c, &c0, &c1, &c2);
  CHECK_RESULT(validate_int16(c0, _a[0], _a[0], _a[0], _a[0]))
  CHECK_RESULT(validate_int16(c1, _a[1], _a[1], _a[1], _a[1]))
  CHECK_RESULT(validate_int16(c2, _a[2], _a[2], _a[2], _a[2]))
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld3q_dup_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld3_dup_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (const int32_t *)impl.test_cases_int_pointer1;
  int32x2_t c0, c1, c2;
  int32x2x3_t c = vld3_dup_s32(_a);
  int32x3_get_int32(c, &c0, &c1, &c2);
  CHECK_RESULT(validate_int32(c0, _a[0], _a[0]))
  CHECK_RESULT(validate_int32(c1, _a[1], _a[1]))
  CHECK_RESULT(validate_int32(c2, _a[2], _a[2]))
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld3q_dup_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld3_dup_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (const float *)impl.test_cases_float_pointer1;
  float32x2_t c0, c1, c2;
  float32x2x3_t c = vld3_dup_f32(_a);
  float32x3_get_float32(c, &c0, &c1, &c2);
  CHECK_RESULT(validate_float(c0, _a[0], _a[0]))
  CHECK_RESULT(validate_float(c1, _a[1], _a[1]))
  CHECK_RESULT(validate_float(c2, _a[2], _a[2]))
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld3q_dup_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld3_dup_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld3q_dup_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld3_dup_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld3q_dup_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld3_dup_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (const uint8_t *)impl.test_cases_int_pointer1;
  uint8x8_t c0, c1, c2;
  uint8x8x3_t c = vld3_dup_u8(_a);
  uint8x3_get_uint8(c, &c0, &c1, &c2);
  CHECK_RESULT(validate_uint8(c0, _a[0], _a[0], _a[0], _a[0], _a[0], _a[0], _a[0], _a[0]))
  CHECK_RESULT(validate_uint8(c1, _a[1], _a[1], _a[1], _a[1], _a[1], _a[1], _a[1], _a[1]))
  CHECK_RESULT(validate_uint8(c2, _a[2], _a[2], _a[2], _a[2], _a[2], _a[2], _a[2], _a[2]))
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld3q_dup_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld3_dup_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (const uint16_t *)impl.test_cases_int_pointer1;
  uint16x4_t c0, c1, c2;
  uint16x4x3_t c = vld3_dup_u16(_a);
  uint16x3_get_uint16(c, &c0, &c1, &c2);
  CHECK_RESULT(validate_uint16(c0, _a[0], _a[0], _a[0], _a[0]))
  CHECK_RESULT(validate_uint16(c1, _a[1], _a[1], _a[1], _a[1]))
  CHECK_RESULT(validate_uint16(c2, _a[2], _a[2], _a[2], _a[2]))
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld3q_dup_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld3_dup_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (const uint32_t *)impl.test_cases_int_pointer1;
  uint32x2_t c0, c1, c2;
  uint32x2x3_t c = vld3_dup_u32(_a);
  uint32x3_get_uint32(c, &c0, &c1, &c2);
  CHECK_RESULT(validate_uint32(c0, _a[0], _a[0]))
  CHECK_RESULT(validate_uint32(c1, _a[1], _a[1]))
  CHECK_RESULT(validate_uint32(c2, _a[2], _a[2]))
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld3q_dup_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld3_dup_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld3q_dup_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld3_dup_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (const int64_t *)impl.test_cases_int_pointer1;
  int64x1_t c0, c1, c2;
  int64x1x3_t c = vld3_dup_s64(_a);
  int64x3_get_int64(c, &c0, &c1, &c2);
  CHECK_RESULT(validate_int64(c0, _a[0]))
  CHECK_RESULT(validate_int64(c1, _a[1]))
  CHECK_RESULT(validate_int64(c2, _a[2]))
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld3_dup_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (const uint64_t *)impl.test_cases_int_pointer1;
  uint64x1_t c0, c1, c2;
  uint64x1x3_t c = vld3_dup_u64(_a);
  uint64x3_get_uint64(c, &c0, &c1, &c2);
  CHECK_RESULT(validate_uint64(c0, _a[0]))
  CHECK_RESULT(validate_uint64(c1, _a[1]))
  CHECK_RESULT(validate_uint64(c2, _a[2]))
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld3_dup_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld3q_dup_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld3q_dup_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld3q_dup_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld3_dup_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld3q_dup_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst3_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (int8_t *)impl.test_cases_int_pointer1;
  const int reg_elt_num = 8;
  int8_t _in[reg_elt_num * 4];
  merge_arrays(_a, _b, _in, reg_elt_num);
  int8_t _c[reg_elt_num * 3];
  int8x8x3_t in = vld3_s8(_in);
  vst3_s8(_c, in);
  for (int i = 0; i < reg_elt_num * 3; i++) {
    if (_in[i] != _c[i]) {
      return TEST_FAIL;
    }
  }
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst3_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer1;
  const int reg_elt_num = 4;
  int16_t _in[reg_elt_num * 4];
  merge_arrays(_a, _b, _in, reg_elt_num);
  int16_t _c[reg_elt_num * 3];
  int16x4x3_t in = vld3_s16(_in);
  vst3_s16(_c, in);
  for (int i = 0; i < reg_elt_num * 3; i++) {
    if (_in[i] != _c[i]) {
      return TEST_FAIL;
    }
  }
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst3_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer1;
  const int reg_elt_num = 2;
  int32_t _in[reg_elt_num * 4];
  merge_arrays(_a, _b, _in, reg_elt_num);
  int32_t _c[reg_elt_num * 3];
  int32x2x3_t in = vld3_s32(_in);
  vst3_s32(_c, in);
  for (int i = 0; i < reg_elt_num * 3; i++) {
    if (_in[i] != _c[i]) {
      return TEST_FAIL;
    }
  }
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst3_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (float *)impl.test_cases_float_pointer1;
  const float *_b = (float *)impl.test_cases_float_pointer1;
  const int reg_elt_num = 2;
  float _in[reg_elt_num * 4];
  merge_arrays(_a, _b, _in, reg_elt_num);
  float _c[reg_elt_num * 3];
  float32x2x3_t in = vld3_f32(_in);
  vst3_f32(_c, in);
  for (int i = 0; i < reg_elt_num * 3; i++) {
    if (_in[i] != _c[i]) {
      return TEST_FAIL;
    }
  }
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst3_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (uint8_t *)impl.test_cases_int_pointer1;
  const int reg_elt_num = 8;
  uint8_t _in[reg_elt_num * 4];
  merge_arrays(_a, _b, _in, reg_elt_num);
  uint8_t _c[reg_elt_num * 3];
  uint8x8x3_t in = vld3_u8(_in);
  vst3_u8(_c, in);
  for (int i = 0; i < reg_elt_num * 3; i++) {
    if (_in[i] != _c[i]) {
      return TEST_FAIL;
    }
  }
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst3_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (uint16_t *)impl.test_cases_int_pointer1;
  const int reg_elt_num = 4;
  uint16_t _in[reg_elt_num * 4];
  merge_arrays(_a, _b, _in, reg_elt_num);
  uint16_t _c[reg_elt_num * 3];
  uint16x4x3_t in = vld3_u16(_in);
  vst3_u16(_c, in);
  for (int i = 0; i < reg_elt_num * 3; i++) {
    if (_in[i] != _c[i]) {
      return TEST_FAIL;
    }
  }
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst3_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (uint32_t *)impl.test_cases_int_pointer1;
  const int reg_elt_num = 2;
  uint32_t _in[reg_elt_num * 4];
  merge_arrays(_a, _b, _in, reg_elt_num);
  uint32_t _c[reg_elt_num * 3];
  uint32x2x3_t in = vld3_u32(_in);
  vst3_u32(_c, in);
  for (int i = 0; i < reg_elt_num * 3; i++) {
    if (_in[i] != _c[i]) {
      return TEST_FAIL;
    }
  }
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst3_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (int64_t *)impl.test_cases_int_pointer1;
  const int64_t *_b = (int64_t *)impl.test_cases_int_pointer1;
  const int reg_elt_num = 1;
  int64_t _in[reg_elt_num * 4];
  merge_arrays(_a, _b, _in, reg_elt_num);
  int64_t _c[reg_elt_num * 3];
  int64x1x3_t in = vld3_s64(_in);
  vst3_s64(_c, in);
  for (int i = 0; i < reg_elt_num * 3; i++) {
    if (_in[i] != _c[i]) {
      return TEST_FAIL;
    }
  }
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst3_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (uint64_t *)impl.test_cases_int_pointer1;
  const uint64_t *_b = (uint64_t *)impl.test_cases_int_pointer1;
  const int reg_elt_num = 1;
  uint64_t _in[reg_elt_num * 4];
  merge_arrays(_a, _b, _in, reg_elt_num);
  uint64_t _c[reg_elt_num * 3];
  uint64x1x3_t in = vld3_u64(_in);
  vst3_u64(_c, in);
  for (int i = 0; i < reg_elt_num * 3; i++) {
    if (_in[i] != _c[i]) {
      return TEST_FAIL;
    }
  }
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst3_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst3q_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst3q_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst3q_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst3_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst3q_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst3q_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (int8_t *)impl.test_cases_int_pointer1;
  const int reg_elt_num = 16;
  int8_t _in[reg_elt_num * 4];
  merge_arrays(_a, _b, _in, reg_elt_num);
  int8_t _c[reg_elt_num * 3];
  int8x16x3_t in = vld3q_s8(_in);
  vst3q_s8(_c, in);
  for (int i = 0; i < reg_elt_num * 3; i++) {
    if (_in[i] != _c[i]) {
      return TEST_FAIL;
    }
  }
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst3q_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer1;
  const int reg_elt_num = 8;
  int16_t _in[reg_elt_num * 4];
  merge_arrays(_a, _b, _in, reg_elt_num);
  int16_t _c[reg_elt_num * 3];
  int16x8x3_t in = vld3q_s16(_in);
  vst3q_s16(_c, in);
  for (int i = 0; i < reg_elt_num * 3; i++) {
    if (_in[i] != _c[i]) {
      return TEST_FAIL;
    }
  }
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst3q_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer1;
  const int reg_elt_num = 4;
  int32_t _in[reg_elt_num * 4];
  merge_arrays(_a, _b, _in, reg_elt_num);
  int32_t _c[reg_elt_num * 3];
  int32x4x3_t in = vld3q_s32(_in);
  vst3q_s32(_c, in);
  for (int i = 0; i < reg_elt_num * 3; i++) {
    if (_in[i] != _c[i]) {
      return TEST_FAIL;
    }
  }
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst3q_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (float *)impl.test_cases_float_pointer1;
  const float *_b = (float *)impl.test_cases_float_pointer1;
  const int reg_elt_num = 4;
  float _in[reg_elt_num * 4];
  merge_arrays(_a, _b, _in, reg_elt_num);
  float _c[reg_elt_num * 3];
  float32x4x3_t in = vld3q_f32(_in);
  vst3q_f32(_c, in);
  for (int i = 0; i < reg_elt_num * 3; i++) {
    if (validate_float_pair(_in[i], _c[i] != TEST_SUCCESS)) {
      return TEST_FAIL;
    }
  }
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst3_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst3q_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst3_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst3q_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst3q_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (uint8_t *)impl.test_cases_int_pointer1;
  const int reg_elt_num = 16;
  uint8_t _in[reg_elt_num * 4];
  merge_arrays(_a, _b, _in, reg_elt_num);
  uint8_t _c[reg_elt_num * 3];
  uint8x16x3_t in = vld3q_u8(_in);
  vst3q_u8(_c, in);
  for (int i = 0; i < reg_elt_num * 3; i++) {
    if (_in[i] != _c[i]) {
      return TEST_FAIL;
    }
  }
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst3q_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (uint16_t *)impl.test_cases_int_pointer1;
  const int reg_elt_num = 8;
  uint16_t _in[reg_elt_num * 4];
  merge_arrays(_a, _b, _in, reg_elt_num);
  uint16_t _c[reg_elt_num * 3];
  uint16x8x3_t in = vld3q_u16(_in);
  vst3q_u16(_c, in);
  for (int i = 0; i < reg_elt_num * 3; i++) {
    if (_in[i] != _c[i]) {
      return TEST_FAIL;
    }
  }
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst3q_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (uint32_t *)impl.test_cases_int_pointer1;
  const int reg_elt_num = 4;
  uint32_t _in[reg_elt_num * 4];
  merge_arrays(_a, _b, _in, reg_elt_num);
  uint32_t _c[reg_elt_num * 3];
  uint32x4x3_t in = vld3q_u32(_in);
  vst3q_u32(_c, in);
  for (int i = 0; i < reg_elt_num * 3; i++) {
    if (_in[i] != _c[i]) {
      return TEST_FAIL;
    }
  }
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst3_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst3q_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst3_lane_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int reg_elt_num = 8;
  int8_t _a[reg_elt_num * 3];
  const int8_t *_in1 = (int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_in2 = (int8_t *)impl.test_cases_int_pointer2;
  const int8_t *_in3 = (int8_t *)impl.test_cases_int_pointer3;
  int8_t _b[reg_elt_num * 3];
  int8_t in[reg_elt_num * 4];
  merge_arrays(_in1, _in2, _in3, in, reg_elt_num);
  int8x8x3_t b;

  for (int i = 0; i < reg_elt_num; i++) {
    _b[i] = in[3 * i];
    _b[i + reg_elt_num] = in[3 * i + 1];
    _b[i + reg_elt_num * 2] = in[3 * i + 2];
  }

#define TEST_IMPL(IDX)                                                                                  \
  b = vld3_s8(in);                                                                                      \
  vst3_lane_s8(_a, b, IDX);                                                                             \
  if ((_a[0] != _b[IDX]) || (_a[1] != _b[IDX + reg_elt_num]) || (_a[2] != _b[IDX + reg_elt_num * 2])) { \
    return TEST_FAIL;                                                                                   \
  }

  IMM_8_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst3_lane_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int reg_elt_num = 4;
  int16_t _a[reg_elt_num * 3];
  const int16_t *_in1 = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_in2 = (int16_t *)impl.test_cases_int_pointer2;
  const int16_t *_in3 = (int16_t *)impl.test_cases_int_pointer3;
  int16_t _b[reg_elt_num * 3];
  int16_t in[reg_elt_num * 4];
  merge_arrays(_in1, _in2, _in3, in, reg_elt_num);
  int16x4x3_t b;

  for (int i = 0; i < reg_elt_num; i++) {
    _b[i] = in[3 * i];
    _b[i + reg_elt_num] = in[3 * i + 1];
    _b[i + reg_elt_num * 2] = in[3 * i + 2];
  }

#define TEST_IMPL(IDX)                                                                                  \
  b = vld3_s16(in);                                                                                     \
  vst3_lane_s16(_a, b, IDX);                                                                            \
  if ((_a[0] != _b[IDX]) || (_a[1] != _b[IDX + reg_elt_num]) || (_a[2] != _b[IDX + reg_elt_num * 2])) { \
    return TEST_FAIL;                                                                                   \
  }

  IMM_4_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst3_lane_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int reg_elt_num = 2;
  int32_t _a[reg_elt_num * 3];
  const int32_t *_in1 = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_in2 = (int32_t *)impl.test_cases_int_pointer2;
  const int32_t *_in3 = (int32_t *)impl.test_cases_int_pointer3;
  int32_t _b[reg_elt_num * 3];
  int32_t in[reg_elt_num * 4];
  merge_arrays(_in1, _in2, _in3, in, reg_elt_num);
  int32x2x3_t b;

  for (int i = 0; i < reg_elt_num; i++) {
    _b[i] = in[3 * i];
    _b[i + reg_elt_num] = in[3 * i + 1];
    _b[i + reg_elt_num * 2] = in[3 * i + 2];
  }

#define TEST_IMPL(IDX)                                                                                  \
  b = vld3_s32(in);                                                                                     \
  vst3_lane_s32(_a, b, IDX);                                                                            \
  if ((_a[0] != _b[IDX]) || (_a[1] != _b[IDX + reg_elt_num]) || (_a[2] != _b[IDX + reg_elt_num * 2])) { \
    return TEST_FAIL;                                                                                   \
  }

  IMM_2_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst3_lane_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int reg_elt_num = 2;
  float _a[reg_elt_num * 3];
  const float *_in1 = (float *)impl.test_cases_float_pointer1;
  const float *_in2 = (float *)impl.test_cases_float_pointer2;
  const float *_in3 = (float *)impl.test_cases_float_pointer3;
  float _b[reg_elt_num * 3];
  float in[reg_elt_num * 4];
  merge_arrays(_in1, _in2, _in3, in, reg_elt_num);
  float32x2x3_t b;

  for (int i = 0; i < reg_elt_num; i++) {
    _b[i] = in[3 * i];
    _b[i + reg_elt_num] = in[3 * i + 1];
    _b[i + reg_elt_num * 2] = in[3 * i + 2];
  }

#define TEST_IMPL(IDX)                                                                                  \
  b = vld3_f32(in);                                                                                     \
  vst3_lane_f32(_a, b, IDX);                                                                            \
  if ((_a[0] != _b[IDX]) || (_a[1] != _b[IDX + reg_elt_num]) || (_a[2] != _b[IDX + reg_elt_num * 2])) { \
    return TEST_FAIL;                                                                                   \
  }

  IMM_2_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst3_lane_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int reg_elt_num = 8;
  uint8_t _a[reg_elt_num * 3];
  const uint8_t *_in1 = (uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_in2 = (uint8_t *)impl.test_cases_int_pointer2;
  const uint8_t *_in3 = (uint8_t *)impl.test_cases_int_pointer3;
  uint8_t _b[reg_elt_num * 3];
  uint8_t in[reg_elt_num * 4];
  merge_arrays(_in1, _in2, _in3, in, reg_elt_num);
  uint8x8x3_t b;

  for (int i = 0; i < reg_elt_num; i++) {
    _b[i] = in[3 * i];
    _b[i + reg_elt_num] = in[3 * i + 1];
    _b[i + reg_elt_num * 2] = in[3 * i + 2];
  }

#define TEST_IMPL(IDX)                                                                                  \
  b = vld3_u8(in);                                                                                      \
  vst3_lane_u8(_a, b, IDX);                                                                             \
  if ((_a[0] != _b[IDX]) || (_a[1] != _b[IDX + reg_elt_num]) || (_a[2] != _b[IDX + reg_elt_num * 2])) { \
    return TEST_FAIL;                                                                                   \
  }

  IMM_8_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst3_lane_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst3_lane_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int reg_elt_num = 4;
  uint16_t _a[reg_elt_num * 3];
  const uint16_t *_in1 = (uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_in2 = (uint16_t *)impl.test_cases_int_pointer2;
  const uint16_t *_in3 = (uint16_t *)impl.test_cases_int_pointer3;
  uint16_t _b[reg_elt_num * 3];
  uint16_t in[reg_elt_num * 4];
  merge_arrays(_in1, _in2, _in3, in, reg_elt_num);
  uint16x4x3_t b;

  for (int i = 0; i < reg_elt_num; i++) {
    _b[i] = in[3 * i];
    _b[i + reg_elt_num] = in[3 * i + 1];
    _b[i + reg_elt_num * 2] = in[3 * i + 2];
  }

#define TEST_IMPL(IDX)                                                                                  \
  b = vld3_u16(in);                                                                                     \
  vst3_lane_u16(_a, b, IDX);                                                                            \
  if ((_a[0] != _b[IDX]) || (_a[1] != _b[IDX + reg_elt_num]) || (_a[2] != _b[IDX + reg_elt_num * 2])) { \
    return TEST_FAIL;                                                                                   \
  }

  IMM_4_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst3_lane_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int reg_elt_num = 2;
  uint32_t _a[reg_elt_num * 3];
  const uint32_t *_in1 = (uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_in2 = (uint32_t *)impl.test_cases_int_pointer2;
  const uint32_t *_in3 = (uint32_t *)impl.test_cases_int_pointer3;
  uint32_t _b[reg_elt_num * 3];
  uint32_t in[reg_elt_num * 4];
  merge_arrays(_in1, _in2, _in3, in, reg_elt_num);
  uint32x2x3_t b;

  for (int i = 0; i < reg_elt_num; i++) {
    _b[i] = in[3 * i];
    _b[i + reg_elt_num] = in[3 * i + 1];
    _b[i + reg_elt_num * 2] = in[3 * i + 2];
  }

#define TEST_IMPL(IDX)                                                                                  \
  b = vld3_u32(in);                                                                                     \
  vst3_lane_u32(_a, b, IDX);                                                                            \
  if ((_a[0] != _b[IDX]) || (_a[1] != _b[IDX + reg_elt_num]) || (_a[2] != _b[IDX + reg_elt_num * 2])) { \
    return TEST_FAIL;                                                                                   \
  }

  IMM_2_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst3q_lane_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int reg_elt_num = 8;
  int16_t _a[reg_elt_num * 3];
  const int16_t *_in1 = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_in2 = (int16_t *)impl.test_cases_int_pointer2;
  const int16_t *_in3 = (int16_t *)impl.test_cases_int_pointer3;
  int16_t _b[reg_elt_num * 3];
  int16_t in[reg_elt_num * 4];
  merge_arrays(_in1, _in2, _in3, in, reg_elt_num);
  int16x8x3_t b;

  for (int i = 0; i < reg_elt_num; i++) {
    _b[i] = in[3 * i];
    _b[i + reg_elt_num] = in[3 * i + 1];
    _b[i + reg_elt_num * 2] = in[3 * i + 2];
  }

#define TEST_IMPL(IDX)                                                                                  \
  b = vld3q_s16(in);                                                                                    \
  vst3q_lane_s16(_a, b, IDX);                                                                           \
  if ((_a[0] != _b[IDX]) || (_a[1] != _b[IDX + reg_elt_num]) || (_a[2] != _b[IDX + reg_elt_num * 2])) { \
    return TEST_FAIL;                                                                                   \
  }

  IMM_4_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst3q_lane_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int reg_elt_num = 4;
  int32_t _a[reg_elt_num * 3];
  const int32_t *_in1 = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_in2 = (int32_t *)impl.test_cases_int_pointer2;
  const int32_t *_in3 = (int32_t *)impl.test_cases_int_pointer3;
  int32_t _b[reg_elt_num * 3];
  int32_t in[reg_elt_num * 4];
  merge_arrays(_in1, _in2, _in3, in, reg_elt_num);
  int32x4x3_t b;

  for (int i = 0; i < reg_elt_num; i++) {
    _b[i] = in[3 * i];
    _b[i + reg_elt_num] = in[3 * i + 1];
    _b[i + reg_elt_num * 2] = in[3 * i + 2];
  }

#define TEST_IMPL(IDX)                                                                                  \
  b = vld3q_s32(in);                                                                                    \
  vst3q_lane_s32(_a, b, IDX);                                                                           \
  if ((_a[0] != _b[IDX]) || (_a[1] != _b[IDX + reg_elt_num]) || (_a[2] != _b[IDX + reg_elt_num * 2])) { \
    return TEST_FAIL;                                                                                   \
  }

  IMM_4_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst3q_lane_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int reg_elt_num = 4;
  float _a[reg_elt_num * 3];
  const float *_in1 = (float *)impl.test_cases_float_pointer1;
  const float *_in2 = (float *)impl.test_cases_float_pointer2;
  const float *_in3 = (float *)impl.test_cases_float_pointer3;
  float _b[reg_elt_num * 3];
  float in[reg_elt_num * 4];
  merge_arrays(_in1, _in2, _in3, in, reg_elt_num);
  float32x4x3_t b;

  for (int i = 0; i < reg_elt_num; i++) {
    _b[i] = in[3 * i];
    _b[i + reg_elt_num] = in[3 * i + 1];
    _b[i + reg_elt_num * 2] = in[3 * i + 2];
  }

#define TEST_IMPL(IDX)                                                                                  \
  b = vld3q_f32(in);                                                                                    \
  vst3q_lane_f32(_a, b, IDX);                                                                           \
  if ((_a[0] != _b[IDX]) || (_a[1] != _b[IDX + reg_elt_num]) || (_a[2] != _b[IDX + reg_elt_num * 2])) { \
    return TEST_FAIL;                                                                                   \
  }

  IMM_4_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst3_lane_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst3q_lane_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst3q_lane_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst3q_lane_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst3q_lane_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst3_lane_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst3q_lane_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst3_lane_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst3q_lane_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst3_lane_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst3q_lane_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst3_lane_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst3q_lane_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst3q_lane_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int reg_elt_num = 8;
  uint16_t _a[reg_elt_num * 3];
  const uint16_t *_in1 = (uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_in2 = (uint16_t *)impl.test_cases_int_pointer2;
  const uint16_t *_in3 = (uint16_t *)impl.test_cases_int_pointer3;
  uint16_t _b[reg_elt_num * 3];
  uint16_t in[reg_elt_num * 4];
  merge_arrays(_in1, _in2, _in3, in, reg_elt_num);
  uint16x8x3_t b;

  for (int i = 0; i < reg_elt_num; i++) {
    _b[i] = in[3 * i];
    _b[i + reg_elt_num] = in[3 * i + 1];
    _b[i + reg_elt_num * 2] = in[3 * i + 2];
  }

#define TEST_IMPL(IDX)                                                                                  \
  b = vld3q_u16(in);                                                                                    \
  vst3q_lane_u16(_a, b, IDX);                                                                           \
  if ((_a[0] != _b[IDX]) || (_a[1] != _b[IDX + reg_elt_num]) || (_a[2] != _b[IDX + reg_elt_num * 2])) { \
    return TEST_FAIL;                                                                                   \
  }

  IMM_8_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst3q_lane_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int reg_elt_num = 4;
  uint32_t _a[reg_elt_num * 3];
  const uint32_t *_in1 = (uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_in2 = (uint32_t *)impl.test_cases_int_pointer2;
  const uint32_t *_in3 = (uint32_t *)impl.test_cases_int_pointer3;
  uint32_t _b[reg_elt_num * 3];
  uint32_t in[reg_elt_num * 4];
  merge_arrays(_in1, _in2, _in3, in, reg_elt_num);
  uint32x4x3_t b;

  for (int i = 0; i < reg_elt_num; i++) {
    _b[i] = in[3 * i];
    _b[i + reg_elt_num] = in[3 * i + 1];
    _b[i + reg_elt_num * 2] = in[3 * i + 2];
  }

#define TEST_IMPL(IDX)                                                                                  \
  b = vld3q_u32(in);                                                                                    \
  vst3q_lane_u32(_a, b, IDX);                                                                           \
  if ((_a[0] != _b[IDX]) || (_a[1] != _b[IDX + reg_elt_num]) || (_a[2] != _b[IDX + reg_elt_num * 2])) { \
    return TEST_FAIL;                                                                                   \
  }

  IMM_4_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst3_lane_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst3q_lane_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld4_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (int8_t *)impl.test_cases_int_pointer1;
  const int reg_elt_num = 8;
  int8_t in[reg_elt_num * 4];
  merge_arrays(_a, _b, in, reg_elt_num);
  int8_t _c[reg_elt_num * 4];

  int8x8x4_t c = vld4_s8(_a);
  for (int i = 0; i < reg_elt_num; i++) {
    _c[i] = _a[4 * i];
    _c[i + reg_elt_num] = _a[4 * i + 1];
    _c[i + reg_elt_num * 2] = _a[4 * i + 2];
    _c[i + reg_elt_num * 3] = _a[4 * i + 3];
  }
#if defined(__riscv) || defined(__riscv__)
  vint8m1_t a0 = __riscv_vget_v_i8m1x4_i8m1(c, 0);
  vint8m1_t a1 = __riscv_vget_v_i8m1x4_i8m1(c, 1);
  vint8m1_t a2 = __riscv_vget_v_i8m1x4_i8m1(c, 2);
  vint8m1_t a3 = __riscv_vget_v_i8m1x4_i8m1(c, 3);
  const int8_t *t0 = (const int8_t *)&a0;
  const int8_t *t1 = (const int8_t *)&a1;
  const int8_t *t2 = (const int8_t *)&a2;
  const int8_t *t3 = (const int8_t *)&a3;
#elif defined(__aarch64__) || defined(_M_ARM64)
  const int8_t *t0 = (const int8_t *)&c.val[0];
  const int8_t *t1 = (const int8_t *)&c.val[1];
  const int8_t *t2 = (const int8_t *)&c.val[2];
  const int8_t *t3 = (const int8_t *)&c.val[3];
#endif

  for (int i = 0; i < reg_elt_num; i++) {
    if ((t0[i] != _c[i]) || (t1[i] != _c[i + reg_elt_num]) || (t2[i] != _c[i + reg_elt_num * 2]) ||
        (t3[i] != _c[i + reg_elt_num * 3])) {
      return TEST_FAIL;
    }
  }
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld4_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer1;
  const int reg_elt_num = 4;
  int16_t in[reg_elt_num * 4];
  merge_arrays(_a, _b, in, reg_elt_num);
  int16_t _c[reg_elt_num * 4];

  int16x4x4_t c = vld4_s16(_a);
  for (int i = 0; i < reg_elt_num; i++) {
    _c[i] = _a[4 * i];
    _c[i + reg_elt_num] = _a[4 * i + 1];
    _c[i + reg_elt_num * 2] = _a[4 * i + 2];
    _c[i + reg_elt_num * 3] = _a[4 * i + 3];
  }
#if defined(__riscv) || defined(__riscv__)
  vint16m1_t a0 = __riscv_vget_v_i16m1x4_i16m1(c, 0);
  vint16m1_t a1 = __riscv_vget_v_i16m1x4_i16m1(c, 1);
  vint16m1_t a2 = __riscv_vget_v_i16m1x4_i16m1(c, 2);
  vint16m1_t a3 = __riscv_vget_v_i16m1x4_i16m1(c, 3);
  const int16_t *t0 = (const int16_t *)&a0;
  const int16_t *t1 = (const int16_t *)&a1;
  const int16_t *t2 = (const int16_t *)&a2;
  const int16_t *t3 = (const int16_t *)&a3;
#elif defined(__aarch64__) || defined(_M_ARM64)
  const int16_t *t0 = (const int16_t *)&c.val[0];
  const int16_t *t1 = (const int16_t *)&c.val[1];
  const int16_t *t2 = (const int16_t *)&c.val[2];
  const int16_t *t3 = (const int16_t *)&c.val[3];
#endif

  for (int i = 0; i < reg_elt_num; i++) {
    if ((t0[i] != _c[i]) || (t1[i] != _c[i + reg_elt_num]) || (t2[i] != _c[i + reg_elt_num * 2]) ||
        (t3[i] != _c[i + reg_elt_num * 3])) {
      return TEST_FAIL;
    }
  }
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld4_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer1;
  const int reg_elt_num = 2;
  int32_t in[reg_elt_num * 4];
  merge_arrays(_a, _b, in, reg_elt_num);
  int32_t _c[reg_elt_num * 4];

  int32x2x4_t c = vld4_s32(_a);
  for (int i = 0; i < reg_elt_num; i++) {
    _c[i] = _a[4 * i];
    _c[i + reg_elt_num] = _a[4 * i + 1];
    _c[i + reg_elt_num * 2] = _a[4 * i + 2];
    _c[i + reg_elt_num * 3] = _a[4 * i + 3];
  }
#if defined(__riscv) || defined(__riscv__)
  vint32m1_t a0 = __riscv_vget_v_i32m1x4_i32m1(c, 0);
  vint32m1_t a1 = __riscv_vget_v_i32m1x4_i32m1(c, 1);
  vint32m1_t a2 = __riscv_vget_v_i32m1x4_i32m1(c, 2);
  vint32m1_t a3 = __riscv_vget_v_i32m1x4_i32m1(c, 3);
  const int32_t *t0 = (const int32_t *)&a0;
  const int32_t *t1 = (const int32_t *)&a1;
  const int32_t *t2 = (const int32_t *)&a2;
  const int32_t *t3 = (const int32_t *)&a3;
#elif defined(__aarch64__) || defined(_M_ARM64)
  const int32_t *t0 = (const int32_t *)&c.val[0];
  const int32_t *t1 = (const int32_t *)&c.val[1];
  const int32_t *t2 = (const int32_t *)&c.val[2];
  const int32_t *t3 = (const int32_t *)&c.val[3];
#endif

  for (int i = 0; i < reg_elt_num; i++) {
    if ((t0[i] != _c[i]) || (t1[i] != _c[i + reg_elt_num]) || (t2[i] != _c[i + reg_elt_num * 2]) ||
        (t3[i] != _c[i + reg_elt_num * 3])) {
      return TEST_FAIL;
    }
  }
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld4_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (float *)impl.test_cases_int_pointer1;
  const float *_b = (float *)impl.test_cases_int_pointer1;
  const int reg_elt_num = 2;
  float in[reg_elt_num * 4];
  merge_arrays(_a, _b, in, reg_elt_num);
  float _c[reg_elt_num * 4];

  float32x2x4_t c = vld4_f32(_a);
  for (int i = 0; i < reg_elt_num; i++) {
    _c[i] = _a[4 * i];
    _c[i + reg_elt_num] = _a[4 * i + 1];
    _c[i + reg_elt_num * 2] = _a[4 * i + 2];
    _c[i + reg_elt_num * 3] = _a[4 * i + 3];
  }
#if defined(__riscv) || defined(__riscv__)
  vfloat32m1_t a0 = __riscv_vget_v_f32m1x4_f32m1(c, 0);
  vfloat32m1_t a1 = __riscv_vget_v_f32m1x4_f32m1(c, 1);
  vfloat32m1_t a2 = __riscv_vget_v_f32m1x4_f32m1(c, 2);
  vfloat32m1_t a3 = __riscv_vget_v_f32m1x4_f32m1(c, 3);
  const float *t0 = (const float *)&a0;
  const float *t1 = (const float *)&a1;
  const float *t2 = (const float *)&a2;
  const float *t3 = (const float *)&a3;
#elif defined(__aarch64__) || defined(_M_ARM64)
  const float *t0 = (const float *)&c.val[0];
  const float *t1 = (const float *)&c.val[1];
  const float *t2 = (const float *)&c.val[2];
  const float *t3 = (const float *)&c.val[3];
#endif

  for (int i = 0; i < reg_elt_num; i++) {
    if (validate_float_pair(t0[i], _c[i]) == TEST_FAIL ||
        validate_float_pair(t1[i], _c[i + reg_elt_num]) == TEST_FAIL ||
        validate_float_pair(t2[i], _c[i + reg_elt_num * 2]) == TEST_FAIL ||
        validate_float_pair(t3[i], _c[i + reg_elt_num * 3]) == TEST_FAIL) {
      return TEST_FAIL;
    }
  }
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld4_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (uint8_t *)impl.test_cases_int_pointer1;
  const int reg_elt_num = 8;
  uint8_t in[reg_elt_num * 4];
  merge_arrays(_a, _b, in, reg_elt_num);
  uint8_t _c[reg_elt_num * 4];

  uint8x8x4_t c = vld4_u8(_a);
  for (int i = 0; i < reg_elt_num; i++) {
    _c[i] = _a[4 * i];
    _c[i + reg_elt_num] = _a[4 * i + 1];
    _c[i + reg_elt_num * 2] = _a[4 * i + 2];
    _c[i + reg_elt_num * 3] = _a[4 * i + 3];
  }
#if defined(__riscv) || defined(__riscv__)
  vuint8m1_t a0 = __riscv_vget_v_u8m1x4_u8m1(c, 0);
  vuint8m1_t a1 = __riscv_vget_v_u8m1x4_u8m1(c, 1);
  vuint8m1_t a2 = __riscv_vget_v_u8m1x4_u8m1(c, 2);
  vuint8m1_t a3 = __riscv_vget_v_u8m1x4_u8m1(c, 3);
  const uint8_t *t0 = (const uint8_t *)&a0;
  const uint8_t *t1 = (const uint8_t *)&a1;
  const uint8_t *t2 = (const uint8_t *)&a2;
  const uint8_t *t3 = (const uint8_t *)&a3;
#elif defined(__aarch64__) || defined(_M_ARM64)
  const uint8_t *t0 = (const uint8_t *)&c.val[0];
  const uint8_t *t1 = (const uint8_t *)&c.val[1];
  const uint8_t *t2 = (const uint8_t *)&c.val[2];
  const uint8_t *t3 = (const uint8_t *)&c.val[3];
#endif

  for (int i = 0; i < reg_elt_num; i++) {
    if ((t0[i] != _c[i]) || (t1[i] != _c[i + reg_elt_num]) || (t2[i] != _c[i + reg_elt_num * 2]) ||
        (t3[i] != _c[i + reg_elt_num * 3])) {
      return TEST_FAIL;
    }
  }
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld4_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (uint16_t *)impl.test_cases_int_pointer1;
  const int reg_elt_num = 4;
  uint16_t in[reg_elt_num * 4];
  merge_arrays(_a, _b, in, reg_elt_num);
  uint16_t _c[reg_elt_num * 4];

  uint16x4x4_t c = vld4_u16(_a);
  for (int i = 0; i < reg_elt_num; i++) {
    _c[i] = _a[4 * i];
    _c[i + reg_elt_num] = _a[4 * i + 1];
    _c[i + reg_elt_num * 2] = _a[4 * i + 2];
    _c[i + reg_elt_num * 3] = _a[4 * i + 3];
  }
#if defined(__riscv) || defined(__riscv__)
  vuint16m1_t a0 = __riscv_vget_v_u16m1x4_u16m1(c, 0);
  vuint16m1_t a1 = __riscv_vget_v_u16m1x4_u16m1(c, 1);
  vuint16m1_t a2 = __riscv_vget_v_u16m1x4_u16m1(c, 2);
  vuint16m1_t a3 = __riscv_vget_v_u16m1x4_u16m1(c, 3);
  const uint16_t *t0 = (const uint16_t *)&a0;
  const uint16_t *t1 = (const uint16_t *)&a1;
  const uint16_t *t2 = (const uint16_t *)&a2;
  const uint16_t *t3 = (const uint16_t *)&a3;
#elif defined(__aarch64__) || defined(_M_ARM64)
  const uint16_t *t0 = (const uint16_t *)&c.val[0];
  const uint16_t *t1 = (const uint16_t *)&c.val[1];
  const uint16_t *t2 = (const uint16_t *)&c.val[2];
  const uint16_t *t3 = (const uint16_t *)&c.val[3];
#endif

  for (int i = 0; i < reg_elt_num; i++) {
    if ((t0[i] != _c[i]) || (t1[i] != _c[i + reg_elt_num]) || (t2[i] != _c[i + reg_elt_num * 2]) ||
        (t3[i] != _c[i + reg_elt_num * 3])) {
      return TEST_FAIL;
    }
  }
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld4_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (uint32_t *)impl.test_cases_int_pointer1;
  const int reg_elt_num = 2;
  uint32_t in[reg_elt_num * 4];
  merge_arrays(_a, _b, in, reg_elt_num);
  uint32_t _c[reg_elt_num * 4];

  uint32x2x4_t c = vld4_u32(_a);
  for (int i = 0; i < reg_elt_num; i++) {
    _c[i] = _a[4 * i];
    _c[i + reg_elt_num] = _a[4 * i + 1];
    _c[i + reg_elt_num * 2] = _a[4 * i + 2];
    _c[i + reg_elt_num * 3] = _a[4 * i + 3];
  }
#if defined(__riscv) || defined(__riscv__)
  vuint32m1_t a0 = __riscv_vget_v_u32m1x4_u32m1(c, 0);
  vuint32m1_t a1 = __riscv_vget_v_u32m1x4_u32m1(c, 1);
  vuint32m1_t a2 = __riscv_vget_v_u32m1x4_u32m1(c, 2);
  vuint32m1_t a3 = __riscv_vget_v_u32m1x4_u32m1(c, 3);
  const uint32_t *t0 = (const uint32_t *)&a0;
  const uint32_t *t1 = (const uint32_t *)&a1;
  const uint32_t *t2 = (const uint32_t *)&a2;
  const uint32_t *t3 = (const uint32_t *)&a3;
#elif defined(__aarch64__) || defined(_M_ARM64)
  const uint32_t *t0 = (const uint32_t *)&c.val[0];
  const uint32_t *t1 = (const uint32_t *)&c.val[1];
  const uint32_t *t2 = (const uint32_t *)&c.val[2];
  const uint32_t *t3 = (const uint32_t *)&c.val[3];
#endif

  for (int i = 0; i < reg_elt_num; i++) {
    if ((t0[i] != _c[i]) || (t1[i] != _c[i + reg_elt_num]) || (t2[i] != _c[i + reg_elt_num * 2]) ||
        (t3[i] != _c[i + reg_elt_num * 3])) {
      return TEST_FAIL;
    }
  }
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld4_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (int64_t *)impl.test_cases_int_pointer1;
  const int64_t *_b = (int64_t *)impl.test_cases_int_pointer1;
  const int reg_elt_num = 1;
  int64_t in[reg_elt_num * 4];
  merge_arrays(_a, _b, in, reg_elt_num);
  int64_t _c[reg_elt_num * 4];

  int64x1x4_t c = vld4_s64(_a);
  for (int i = 0; i < reg_elt_num; i++) {
    _c[i] = _a[4 * i];
    _c[i + reg_elt_num] = _a[4 * i + 1];
    _c[i + reg_elt_num * 2] = _a[4 * i + 2];
    _c[i + reg_elt_num * 3] = _a[4 * i + 3];
  }
#if defined(__riscv) || defined(__riscv__)
  vint64m1_t a0 = __riscv_vget_v_i64m1x4_i64m1(c, 0);
  vint64m1_t a1 = __riscv_vget_v_i64m1x4_i64m1(c, 1);
  vint64m1_t a2 = __riscv_vget_v_i64m1x4_i64m1(c, 2);
  vint64m1_t a3 = __riscv_vget_v_i64m1x4_i64m1(c, 3);
  const int64_t *t0 = (const int64_t *)&a0;
  const int64_t *t1 = (const int64_t *)&a1;
  const int64_t *t2 = (const int64_t *)&a2;
  const int64_t *t3 = (const int64_t *)&a3;
#elif defined(__aarch64__) || defined(_M_ARM64)
  const int64_t *t0 = (const int64_t *)&c.val[0];
  const int64_t *t1 = (const int64_t *)&c.val[1];
  const int64_t *t2 = (const int64_t *)&c.val[2];
  const int64_t *t3 = (const int64_t *)&c.val[3];
#endif

  for (int i = 0; i < reg_elt_num; i++) {
    if ((t0[i] != _c[i]) || (t1[i] != _c[i + reg_elt_num]) || (t2[i] != _c[i + reg_elt_num * 2]) ||
        (t3[i] != _c[i + reg_elt_num * 3])) {
      return TEST_FAIL;
    }
  }
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld4_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (uint64_t *)impl.test_cases_int_pointer1;
  const uint64_t *_b = (uint64_t *)impl.test_cases_int_pointer1;
  const int reg_elt_num = 1;
  uint64_t in[reg_elt_num * 4];
  merge_arrays(_a, _b, in, reg_elt_num);
  uint64_t _c[reg_elt_num * 4];

  uint64x1x4_t c = vld4_u64(_a);
  for (int i = 0; i < reg_elt_num; i++) {
    _c[i] = _a[4 * i];
    _c[i + reg_elt_num] = _a[4 * i + 1];
    _c[i + reg_elt_num * 2] = _a[4 * i + 2];
    _c[i + reg_elt_num * 3] = _a[4 * i + 3];
  }
#if defined(__riscv) || defined(__riscv__)
  vuint64m1_t a0 = __riscv_vget_v_u64m1x4_u64m1(c, 0);
  vuint64m1_t a1 = __riscv_vget_v_u64m1x4_u64m1(c, 1);
  vuint64m1_t a2 = __riscv_vget_v_u64m1x4_u64m1(c, 2);
  vuint64m1_t a3 = __riscv_vget_v_u64m1x4_u64m1(c, 3);
  const uint64_t *t0 = (const uint64_t *)&a0;
  const uint64_t *t1 = (const uint64_t *)&a1;
  const uint64_t *t2 = (const uint64_t *)&a2;
  const uint64_t *t3 = (const uint64_t *)&a3;
#elif defined(__aarch64__) || defined(_M_ARM64)
  const uint64_t *t0 = (const uint64_t *)&c.val[0];
  const uint64_t *t1 = (const uint64_t *)&c.val[1];
  const uint64_t *t2 = (const uint64_t *)&c.val[2];
  const uint64_t *t3 = (const uint64_t *)&c.val[3];
#endif

  for (int i = 0; i < reg_elt_num; i++) {
    if ((t0[i] != _c[i]) || (t1[i] != _c[i + reg_elt_num]) || (t2[i] != _c[i + reg_elt_num * 2]) ||
        (t3[i] != _c[i + reg_elt_num * 3])) {
      return TEST_FAIL;
    }
  }
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld4_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld4q_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld4q_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld4q_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld4_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld4q_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld4q_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (int8_t *)impl.test_cases_int_pointer1;
  const int reg_elt_num = 8 * 2;
  int8_t in[reg_elt_num * 4];
  merge_arrays(_a, _b, in, reg_elt_num);
  int8_t _c[reg_elt_num * 4];

  int8x16x4_t c = vld4q_s8(_a);
  for (int i = 0; i < reg_elt_num; i++) {
    _c[i] = _a[4 * i];
    _c[i + reg_elt_num] = _a[4 * i + 1];
    _c[i + reg_elt_num * 2] = _a[4 * i + 2];
    _c[i + reg_elt_num * 3] = _a[4 * i + 3];
  }
#if defined(__riscv) || defined(__riscv__)
  vint8m1_t a0 = __riscv_vget_v_i8m1x4_i8m1(c, 0);
  vint8m1_t a1 = __riscv_vget_v_i8m1x4_i8m1(c, 1);
  vint8m1_t a2 = __riscv_vget_v_i8m1x4_i8m1(c, 2);
  vint8m1_t a3 = __riscv_vget_v_i8m1x4_i8m1(c, 3);
  const int8_t *t0 = (const int8_t *)&a0;
  const int8_t *t1 = (const int8_t *)&a1;
  const int8_t *t2 = (const int8_t *)&a2;
  const int8_t *t3 = (const int8_t *)&a3;
#elif defined(__aarch64__) || defined(_M_ARM64)
  const int8_t *t0 = (const int8_t *)&c.val[0];
  const int8_t *t1 = (const int8_t *)&c.val[1];
  const int8_t *t2 = (const int8_t *)&c.val[2];
  const int8_t *t3 = (const int8_t *)&c.val[3];
#endif

  for (int i = 0; i < reg_elt_num; i++) {
    if ((t0[i] != _c[i]) || (t1[i] != _c[i + reg_elt_num]) || (t2[i] != _c[i + reg_elt_num * 2]) ||
        (t3[i] != _c[i + reg_elt_num * 3])) {
      return TEST_FAIL;
    }
  }
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld4q_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer1;
  const int reg_elt_num = 4 * 2;
  int16_t in[reg_elt_num * 4];
  merge_arrays(_a, _b, in, reg_elt_num);
  int16_t _c[reg_elt_num * 4];

  int16x8x4_t c = vld4q_s16(_a);
  for (int i = 0; i < reg_elt_num; i++) {
    _c[i] = _a[4 * i];
    _c[i + reg_elt_num] = _a[4 * i + 1];
    _c[i + reg_elt_num * 2] = _a[4 * i + 2];
    _c[i + reg_elt_num * 3] = _a[4 * i + 3];
  }
#if defined(__riscv) || defined(__riscv__)
  vint16m1_t a0 = __riscv_vget_v_i16m1x4_i16m1(c, 0);
  vint16m1_t a1 = __riscv_vget_v_i16m1x4_i16m1(c, 1);
  vint16m1_t a2 = __riscv_vget_v_i16m1x4_i16m1(c, 2);
  vint16m1_t a3 = __riscv_vget_v_i16m1x4_i16m1(c, 3);
  const int16_t *t0 = (const int16_t *)&a0;
  const int16_t *t1 = (const int16_t *)&a1;
  const int16_t *t2 = (const int16_t *)&a2;
  const int16_t *t3 = (const int16_t *)&a3;
#elif defined(__aarch64__) || defined(_M_ARM64)
  const int16_t *t0 = (const int16_t *)&c.val[0];
  const int16_t *t1 = (const int16_t *)&c.val[1];
  const int16_t *t2 = (const int16_t *)&c.val[2];
  const int16_t *t3 = (const int16_t *)&c.val[3];
#endif

  for (int i = 0; i < reg_elt_num; i++) {
    if ((t0[i] != _c[i]) || (t1[i] != _c[i + reg_elt_num]) || (t2[i] != _c[i + reg_elt_num * 2]) ||
        (t3[i] != _c[i + reg_elt_num * 3])) {
      return TEST_FAIL;
    }
  }
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld4q_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer1;
  const int reg_elt_num = 2 * 2;
  int32_t in[reg_elt_num * 4];
  merge_arrays(_a, _b, in, reg_elt_num);
  int32_t _c[reg_elt_num * 4];

  int32x4x4_t c = vld4q_s32(_a);
  for (int i = 0; i < reg_elt_num; i++) {
    _c[i] = _a[4 * i];
    _c[i + reg_elt_num] = _a[4 * i + 1];
    _c[i + reg_elt_num * 2] = _a[4 * i + 2];
    _c[i + reg_elt_num * 3] = _a[4 * i + 3];
  }
#if defined(__riscv) || defined(__riscv__)
  vint32m1_t a0 = __riscv_vget_v_i32m1x4_i32m1(c, 0);
  vint32m1_t a1 = __riscv_vget_v_i32m1x4_i32m1(c, 1);
  vint32m1_t a2 = __riscv_vget_v_i32m1x4_i32m1(c, 2);
  vint32m1_t a3 = __riscv_vget_v_i32m1x4_i32m1(c, 3);
  const int32_t *t0 = (const int32_t *)&a0;
  const int32_t *t1 = (const int32_t *)&a1;
  const int32_t *t2 = (const int32_t *)&a2;
  const int32_t *t3 = (const int32_t *)&a3;
#elif defined(__aarch64__) || defined(_M_ARM64)
  const int32_t *t0 = (const int32_t *)&c.val[0];
  const int32_t *t1 = (const int32_t *)&c.val[1];
  const int32_t *t2 = (const int32_t *)&c.val[2];
  const int32_t *t3 = (const int32_t *)&c.val[3];
#endif

  for (int i = 0; i < reg_elt_num; i++) {
    if ((t0[i] != _c[i]) || (t1[i] != _c[i + reg_elt_num]) || (t2[i] != _c[i + reg_elt_num * 2]) ||
        (t3[i] != _c[i + reg_elt_num * 3])) {
      return TEST_FAIL;
    }
  }
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld4q_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (float *)impl.test_cases_int_pointer1;
  const float *_b = (float *)impl.test_cases_int_pointer1;
  const int reg_elt_num = 2 * 2;
  float in[reg_elt_num * 4];
  merge_arrays(_a, _b, in, reg_elt_num);
  float _c[reg_elt_num * 4];

  float32x4x4_t c = vld4q_f32(_a);
  for (int i = 0; i < reg_elt_num; i++) {
    _c[i] = _a[4 * i];
    _c[i + reg_elt_num] = _a[4 * i + 1];
    _c[i + reg_elt_num * 2] = _a[4 * i + 2];
    _c[i + reg_elt_num * 3] = _a[4 * i + 3];
  }
#if defined(__riscv) || defined(__riscv__)
  vfloat32m1_t a0 = __riscv_vget_v_f32m1x4_f32m1(c, 0);
  vfloat32m1_t a1 = __riscv_vget_v_f32m1x4_f32m1(c, 1);
  vfloat32m1_t a2 = __riscv_vget_v_f32m1x4_f32m1(c, 2);
  vfloat32m1_t a3 = __riscv_vget_v_f32m1x4_f32m1(c, 3);
  const float *t0 = (const float *)&a0;
  const float *t1 = (const float *)&a1;
  const float *t2 = (const float *)&a2;
  const float *t3 = (const float *)&a3;
#elif defined(__aarch64__) || defined(_M_ARM64)
  const float *t0 = (const float *)&c.val[0];
  const float *t1 = (const float *)&c.val[1];
  const float *t2 = (const float *)&c.val[2];
  const float *t3 = (const float *)&c.val[3];
#endif

  for (int i = 0; i < reg_elt_num; i++) {
    if (validate_float_pair(t0[i], _c[i]) == TEST_FAIL ||
        validate_float_pair(t1[i], _c[i + reg_elt_num]) == TEST_FAIL ||
        validate_float_pair(t2[i], _c[i + reg_elt_num * 2]) == TEST_FAIL ||
        validate_float_pair(t3[i], _c[i + reg_elt_num * 3]) == TEST_FAIL) {
      return TEST_FAIL;
    }
  }
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld4_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld4q_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld4_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld4q_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld4q_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (uint8_t *)impl.test_cases_int_pointer1;
  const int reg_elt_num = 8 * 2;
  uint8_t in[reg_elt_num * 4];
  merge_arrays(_a, _b, in, reg_elt_num);
  uint8_t _c[reg_elt_num * 4];

  uint8x16x4_t c = vld4q_u8(_a);
  for (int i = 0; i < reg_elt_num; i++) {
    _c[i] = _a[4 * i];
    _c[i + reg_elt_num] = _a[4 * i + 1];
    _c[i + reg_elt_num * 2] = _a[4 * i + 2];
    _c[i + reg_elt_num * 3] = _a[4 * i + 3];
  }
#if defined(__riscv) || defined(__riscv__)
  vuint8m1_t a0 = __riscv_vget_v_u8m1x4_u8m1(c, 0);
  vuint8m1_t a1 = __riscv_vget_v_u8m1x4_u8m1(c, 1);
  vuint8m1_t a2 = __riscv_vget_v_u8m1x4_u8m1(c, 2);
  vuint8m1_t a3 = __riscv_vget_v_u8m1x4_u8m1(c, 3);
  const uint8_t *t0 = (const uint8_t *)&a0;
  const uint8_t *t1 = (const uint8_t *)&a1;
  const uint8_t *t2 = (const uint8_t *)&a2;
  const uint8_t *t3 = (const uint8_t *)&a3;
#elif defined(__aarch64__) || defined(_M_ARM64)
  const uint8_t *t0 = (const uint8_t *)&c.val[0];
  const uint8_t *t1 = (const uint8_t *)&c.val[1];
  const uint8_t *t2 = (const uint8_t *)&c.val[2];
  const uint8_t *t3 = (const uint8_t *)&c.val[3];
#endif

  for (int i = 0; i < reg_elt_num; i++) {
    if ((t0[i] != _c[i]) || (t1[i] != _c[i + reg_elt_num]) || (t2[i] != _c[i + reg_elt_num * 2]) ||
        (t3[i] != _c[i + reg_elt_num * 3])) {
      return TEST_FAIL;
    }
  }
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld4q_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (uint16_t *)impl.test_cases_int_pointer1;
  const int reg_elt_num = 4 * 2;
  uint16_t in[reg_elt_num * 4];
  merge_arrays(_a, _b, in, reg_elt_num);
  uint16_t _c[reg_elt_num * 4];

  uint16x8x4_t c = vld4q_u16(_a);
  for (int i = 0; i < reg_elt_num; i++) {
    _c[i] = _a[4 * i];
    _c[i + reg_elt_num] = _a[4 * i + 1];
    _c[i + reg_elt_num * 2] = _a[4 * i + 2];
    _c[i + reg_elt_num * 3] = _a[4 * i + 3];
  }
#if defined(__riscv) || defined(__riscv__)
  vuint16m1_t a0 = __riscv_vget_v_u16m1x4_u16m1(c, 0);
  vuint16m1_t a1 = __riscv_vget_v_u16m1x4_u16m1(c, 1);
  vuint16m1_t a2 = __riscv_vget_v_u16m1x4_u16m1(c, 2);
  vuint16m1_t a3 = __riscv_vget_v_u16m1x4_u16m1(c, 3);
  const uint16_t *t0 = (const uint16_t *)&a0;
  const uint16_t *t1 = (const uint16_t *)&a1;
  const uint16_t *t2 = (const uint16_t *)&a2;
  const uint16_t *t3 = (const uint16_t *)&a3;
#elif defined(__aarch64__) || defined(_M_ARM64)
  const uint16_t *t0 = (const uint16_t *)&c.val[0];
  const uint16_t *t1 = (const uint16_t *)&c.val[1];
  const uint16_t *t2 = (const uint16_t *)&c.val[2];
  const uint16_t *t3 = (const uint16_t *)&c.val[3];
#endif

  for (int i = 0; i < reg_elt_num; i++) {
    if ((t0[i] != _c[i]) || (t1[i] != _c[i + reg_elt_num]) || (t2[i] != _c[i + reg_elt_num * 2]) ||
        (t3[i] != _c[i + reg_elt_num * 3])) {
      return TEST_FAIL;
    }
  }
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld4q_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (uint32_t *)impl.test_cases_int_pointer1;
  const int reg_elt_num = 2 * 2;
  uint32_t in[reg_elt_num * 4];
  merge_arrays(_a, _b, in, reg_elt_num);
  uint32_t _c[reg_elt_num * 4];

  uint32x4x4_t c = vld4q_u32(_a);
  for (int i = 0; i < reg_elt_num; i++) {
    _c[i] = _a[4 * i];
    _c[i + reg_elt_num] = _a[4 * i + 1];
    _c[i + reg_elt_num * 2] = _a[4 * i + 2];
    _c[i + reg_elt_num * 3] = _a[4 * i + 3];
  }
#if defined(__riscv) || defined(__riscv__)
  vuint32m1_t a0 = __riscv_vget_v_u32m1x4_u32m1(c, 0);
  vuint32m1_t a1 = __riscv_vget_v_u32m1x4_u32m1(c, 1);
  vuint32m1_t a2 = __riscv_vget_v_u32m1x4_u32m1(c, 2);
  vuint32m1_t a3 = __riscv_vget_v_u32m1x4_u32m1(c, 3);
  const uint32_t *t0 = (const uint32_t *)&a0;
  const uint32_t *t1 = (const uint32_t *)&a1;
  const uint32_t *t2 = (const uint32_t *)&a2;
  const uint32_t *t3 = (const uint32_t *)&a3;
#elif defined(__aarch64__) || defined(_M_ARM64)
  const uint32_t *t0 = (const uint32_t *)&c.val[0];
  const uint32_t *t1 = (const uint32_t *)&c.val[1];
  const uint32_t *t2 = (const uint32_t *)&c.val[2];
  const uint32_t *t3 = (const uint32_t *)&c.val[3];
#endif

  for (int i = 0; i < reg_elt_num; i++) {
    if ((t0[i] != _c[i]) || (t1[i] != _c[i + reg_elt_num]) || (t2[i] != _c[i + reg_elt_num * 2]) ||
        (t3[i] != _c[i + reg_elt_num * 3])) {
      return TEST_FAIL;
    }
  }
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld4_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld4q_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld4_lane_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (int8_t *)impl.test_cases_int_pointer2;
  const int reg_elt_num = 8;
  int8_t _c[reg_elt_num * 4];
  int8x8x4_t c;
  int8x8x4_t b = vld4_s8(_b);
  int8x8_t c0, c1, c2, c3;

#define TEST_IMPL(IDX)                                                                            \
  for (int i = 0; i < reg_elt_num; i++) {                                                         \
    if (i != IDX) {                                                                               \
      _c[i] = _b[4 * i];                                                                          \
      _c[i + reg_elt_num] = _b[4 * i + 1];                                                        \
      _c[i + reg_elt_num * 2] = _b[4 * i + 2];                                                    \
      _c[i + reg_elt_num * 3] = _b[4 * i + 3];                                                    \
    } else {                                                                                      \
      _c[i] = _a[0];                                                                              \
      _c[i + reg_elt_num] = _a[1];                                                                \
      _c[i + reg_elt_num * 2] = _a[2];                                                            \
      _c[i + reg_elt_num * 3] = _a[3];                                                            \
    }                                                                                             \
  }                                                                                               \
  c = vld4_lane_s8(_a, b, IDX);                                                                   \
  int8x4_get_int8(c, &c0, &c1, &c2, &c3);                                                         \
  CHECK_RESULT(validate_int8(c0, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]))         \
  CHECK_RESULT(validate_int8(c1, _c[8], _c[9], _c[10], _c[11], _c[12], _c[13], _c[14], _c[15]))   \
  CHECK_RESULT(validate_int8(c2, _c[16], _c[17], _c[18], _c[19], _c[20], _c[21], _c[22], _c[23])) \
  CHECK_RESULT(validate_int8(c3, _c[24], _c[25], _c[26], _c[27], _c[28], _c[29], _c[30], _c[31]))

  IMM_8_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld4_lane_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  const int reg_elt_num = 4;
  int16_t _c[reg_elt_num * 4];
  int16x4x4_t c;
  int16x4x4_t b = vld4_s16(_b);
  int16x4_t c0, c1, c2, c3;

#define TEST_IMPL(IDX)                                           \
  for (int i = 0; i < reg_elt_num; i++) {                        \
    if (i != IDX) {                                              \
      _c[i] = _b[4 * i];                                         \
      _c[i + reg_elt_num] = _b[4 * i + 1];                       \
      _c[i + reg_elt_num * 2] = _b[4 * i + 2];                   \
      _c[i + reg_elt_num * 3] = _b[4 * i + 3];                   \
    } else {                                                     \
      _c[i] = _a[0];                                             \
      _c[i + reg_elt_num] = _a[1];                               \
      _c[i + reg_elt_num * 2] = _a[2];                           \
      _c[i + reg_elt_num * 3] = _a[3];                           \
    }                                                            \
  }                                                              \
  c = vld4_lane_s16(_a, b, IDX);                                 \
  int16x4_get_int16(c, &c0, &c1, &c2, &c3);                      \
  CHECK_RESULT(validate_int16(c0, _c[0], _c[1], _c[2], _c[3]))   \
  CHECK_RESULT(validate_int16(c1, _c[4], _c[5], _c[6], _c[7]))   \
  CHECK_RESULT(validate_int16(c2, _c[8], _c[9], _c[10], _c[11])) \
  CHECK_RESULT(validate_int16(c3, _c[12], _c[13], _c[14], _c[15]))

  IMM_4_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld4_lane_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  const int reg_elt_num = 2;
  int32_t _c[reg_elt_num * 4];
  int32x2x4_t c;
  int32x2x4_t b = vld4_s32(_b);
  int32x2_t c0, c1, c2, c3;

#define TEST_IMPL(IDX)                           \
  for (int i = 0; i < reg_elt_num; i++) {        \
    if (i != IDX) {                              \
      _c[i] = _b[4 * i];                         \
      _c[i + reg_elt_num] = _b[4 * i + 1];       \
      _c[i + reg_elt_num * 2] = _b[4 * i + 2];   \
      _c[i + reg_elt_num * 3] = _b[4 * i + 3];   \
    } else {                                     \
      _c[i] = _a[0];                             \
      _c[i + reg_elt_num] = _a[1];               \
      _c[i + reg_elt_num * 2] = _a[2];           \
      _c[i + reg_elt_num * 3] = _a[3];           \
    }                                            \
  }                                              \
  c = vld4_lane_s32(_a, b, IDX);                 \
  int32x4_get_int32(c, &c0, &c1, &c2, &c3);      \
  CHECK_RESULT(validate_int32(c0, _c[0], _c[1])) \
  CHECK_RESULT(validate_int32(c1, _c[2], _c[3])) \
  CHECK_RESULT(validate_int32(c2, _c[4], _c[5])) \
  CHECK_RESULT(validate_int32(c3, _c[6], _c[7]))

  IMM_2_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld4_lane_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (float *)impl.test_cases_float_pointer1;
  const float *_b = (float *)impl.test_cases_float_pointer2;
  const int reg_elt_num = 2;
  float _c[reg_elt_num * 4];
  float32x2x4_t c;
  float32x2x4_t b = vld4_f32(_b);
  float32x2_t c0, c1, c2, c3;

#define TEST_IMPL(IDX)                           \
  for (int i = 0; i < reg_elt_num; i++) {        \
    if (i != IDX) {                              \
      _c[i] = _b[4 * i];                         \
      _c[i + reg_elt_num] = _b[4 * i + 1];       \
      _c[i + reg_elt_num * 2] = _b[4 * i + 2];   \
      _c[i + reg_elt_num * 3] = _b[4 * i + 3];   \
    } else {                                     \
      _c[i] = _a[0];                             \
      _c[i + reg_elt_num] = _a[1];               \
      _c[i + reg_elt_num * 2] = _a[2];           \
      _c[i + reg_elt_num * 3] = _a[3];           \
    }                                            \
  }                                              \
  c = vld4_lane_f32(_a, b, IDX);                 \
  float32x4_get_float32(c, &c0, &c1, &c2, &c3);  \
  CHECK_RESULT(validate_float(c0, _c[0], _c[1])) \
  CHECK_RESULT(validate_float(c1, _c[2], _c[3])) \
  CHECK_RESULT(validate_float(c2, _c[4], _c[5])) \
  CHECK_RESULT(validate_float(c3, _c[6], _c[7]))

  IMM_2_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld4_lane_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (uint8_t *)impl.test_cases_int_pointer2;
  const int reg_elt_num = 8;
  uint8_t _c[reg_elt_num * 4];
  uint8x8x4_t c;
  uint8x8x4_t b = vld4_u8(_b);
  uint8x8_t c0, c1, c2, c3;

#define TEST_IMPL(IDX)                                                                             \
  for (int i = 0; i < reg_elt_num; i++) {                                                          \
    if (i != IDX) {                                                                                \
      _c[i] = _b[4 * i];                                                                           \
      _c[i + reg_elt_num] = _b[4 * i + 1];                                                         \
      _c[i + reg_elt_num * 2] = _b[4 * i + 2];                                                     \
      _c[i + reg_elt_num * 3] = _b[4 * i + 3];                                                     \
    } else {                                                                                       \
      _c[i] = _a[0];                                                                               \
      _c[i + reg_elt_num] = _a[1];                                                                 \
      _c[i + reg_elt_num * 2] = _a[2];                                                             \
      _c[i + reg_elt_num * 3] = _a[3];                                                             \
    }                                                                                              \
  }                                                                                                \
  c = vld4_lane_u8(_a, b, IDX);                                                                    \
  uint8x4_get_uint8(c, &c0, &c1, &c2, &c3);                                                        \
  CHECK_RESULT(validate_uint8(c0, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]))         \
  CHECK_RESULT(validate_uint8(c1, _c[8], _c[9], _c[10], _c[11], _c[12], _c[13], _c[14], _c[15]))   \
  CHECK_RESULT(validate_uint8(c2, _c[16], _c[17], _c[18], _c[19], _c[20], _c[21], _c[22], _c[23])) \
  CHECK_RESULT(validate_uint8(c3, _c[24], _c[25], _c[26], _c[27], _c[28], _c[29], _c[30], _c[31]))

  IMM_8_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld4_lane_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld4q_lane_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld4q_lane_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld4q_lane_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld4_lane_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld4q_lane_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld4_lane_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld4q_lane_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld4_lane_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld4q_lane_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld4_lane_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld4q_lane_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld4_lane_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (uint16_t *)impl.test_cases_int_pointer2;
  const int reg_elt_num = 4;
  uint16_t _c[reg_elt_num * 4];
  uint16x4x4_t c;
  uint16x4x4_t b = vld4_u16(_b);
  uint16x4_t c0, c1, c2, c3;

#define TEST_IMPL(IDX)                                            \
  for (int i = 0; i < reg_elt_num; i++) {                         \
    if (i != IDX) {                                               \
      _c[i] = _b[4 * i];                                          \
      _c[i + reg_elt_num] = _b[4 * i + 1];                        \
      _c[i + reg_elt_num * 2] = _b[4 * i + 2];                    \
      _c[i + reg_elt_num * 3] = _b[4 * i + 3];                    \
    } else {                                                      \
      _c[i] = _a[0];                                              \
      _c[i + reg_elt_num] = _a[1];                                \
      _c[i + reg_elt_num * 2] = _a[2];                            \
      _c[i + reg_elt_num * 3] = _a[3];                            \
    }                                                             \
  }                                                               \
  c = vld4_lane_u16(_a, b, IDX);                                  \
  uint16x4_get_uint16(c, &c0, &c1, &c2, &c3);                     \
  CHECK_RESULT(validate_uint16(c0, _c[0], _c[1], _c[2], _c[3]))   \
  CHECK_RESULT(validate_uint16(c1, _c[4], _c[5], _c[6], _c[7]))   \
  CHECK_RESULT(validate_uint16(c2, _c[8], _c[9], _c[10], _c[11])) \
  CHECK_RESULT(validate_uint16(c3, _c[12], _c[13], _c[14], _c[15]))

  IMM_4_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld4_lane_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (uint32_t *)impl.test_cases_int_pointer2;
  const int reg_elt_num = 2;
  uint32_t _c[reg_elt_num * 4];
  uint32x2x4_t c;
  uint32x2x4_t b = vld4_u32(_b);
  uint32x2_t c0, c1, c2, c3;

#define TEST_IMPL(IDX)                            \
  for (int i = 0; i < reg_elt_num; i++) {         \
    if (i != IDX) {                               \
      _c[i] = _b[4 * i];                          \
      _c[i + reg_elt_num] = _b[4 * i + 1];        \
      _c[i + reg_elt_num * 2] = _b[4 * i + 2];    \
      _c[i + reg_elt_num * 3] = _b[4 * i + 3];    \
    } else {                                      \
      _c[i] = _a[0];                              \
      _c[i + reg_elt_num] = _a[1];                \
      _c[i + reg_elt_num * 2] = _a[2];            \
      _c[i + reg_elt_num * 3] = _a[3];            \
    }                                             \
  }                                               \
  c = vld4_lane_u32(_a, b, IDX);                  \
  uint32x4_get_uint32(c, &c0, &c1, &c2, &c3);     \
  CHECK_RESULT(validate_uint32(c0, _c[0], _c[1])) \
  CHECK_RESULT(validate_uint32(c1, _c[2], _c[3])) \
  CHECK_RESULT(validate_uint32(c2, _c[4], _c[5])) \
  CHECK_RESULT(validate_uint32(c3, _c[6], _c[7]))

  IMM_2_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld4q_lane_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  const int reg_elt_num = 8;
  int16_t _c[reg_elt_num * 4];
  int16x8x4_t c;
  int16x8x4_t b = vld4q_s16(_b);
  int16x8_t c0, c1, c2, c3;

#define TEST_IMPL(IDX)                                                                             \
  for (int i = 0; i < reg_elt_num; i++) {                                                          \
    if (i != IDX) {                                                                                \
      _c[i] = _b[4 * i];                                                                           \
      _c[i + reg_elt_num] = _b[4 * i + 1];                                                         \
      _c[i + reg_elt_num * 2] = _b[4 * i + 2];                                                     \
      _c[i + reg_elt_num * 3] = _b[4 * i + 3];                                                     \
    } else {                                                                                       \
      _c[i] = _a[0];                                                                               \
      _c[i + reg_elt_num] = _a[1];                                                                 \
      _c[i + reg_elt_num * 2] = _a[2];                                                             \
      _c[i + reg_elt_num * 3] = _a[3];                                                             \
    }                                                                                              \
  }                                                                                                \
  c = vld4q_lane_s16(_a, b, IDX);                                                                  \
  int16x4_get_int16(c, &c0, &c1, &c2, &c3);                                                        \
  CHECK_RESULT(validate_int16(c0, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]))         \
  CHECK_RESULT(validate_int16(c1, _c[8], _c[9], _c[10], _c[11], _c[12], _c[13], _c[14], _c[15]))   \
  CHECK_RESULT(validate_int16(c2, _c[16], _c[17], _c[18], _c[19], _c[20], _c[21], _c[22], _c[23])) \
  CHECK_RESULT(validate_int16(c3, _c[24], _c[25], _c[26], _c[27], _c[28], _c[29], _c[30], _c[31]))

  IMM_8_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld4q_lane_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  const int reg_elt_num = 4;
  int32_t _c[reg_elt_num * 4];
  int32x4x4_t c;
  int32x4x4_t b = vld4q_s32(_b);
  int32x4_t c0, c1, c2, c3;

#define TEST_IMPL(IDX)                                           \
  for (int i = 0; i < reg_elt_num; i++) {                        \
    if (i != IDX) {                                              \
      _c[i] = _b[4 * i];                                         \
      _c[i + reg_elt_num] = _b[4 * i + 1];                       \
      _c[i + reg_elt_num * 2] = _b[4 * i + 2];                   \
      _c[i + reg_elt_num * 3] = _b[4 * i + 3];                   \
    } else {                                                     \
      _c[i] = _a[0];                                             \
      _c[i + reg_elt_num] = _a[1];                               \
      _c[i + reg_elt_num * 2] = _a[2];                           \
      _c[i + reg_elt_num * 3] = _a[3];                           \
    }                                                            \
  }                                                              \
  c = vld4q_lane_s32(_a, b, IDX);                                \
  int32x4_get_int32(c, &c0, &c1, &c2, &c3);                      \
  CHECK_RESULT(validate_int32(c0, _c[0], _c[1], _c[2], _c[3]))   \
  CHECK_RESULT(validate_int32(c1, _c[4], _c[5], _c[6], _c[7]))   \
  CHECK_RESULT(validate_int32(c2, _c[8], _c[9], _c[10], _c[11])) \
  CHECK_RESULT(validate_int32(c3, _c[12], _c[13], _c[14], _c[15]))

  IMM_4_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld4q_lane_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (float *)impl.test_cases_float_pointer1;
  const float *_b = (float *)impl.test_cases_float_pointer2;
  const int reg_elt_num = 4;
  float _c[reg_elt_num * 4];
  float32x4x4_t c;
  float32x4x4_t b = vld4q_f32(_b);
  float32x4_t c0, c1, c2, c3;

#define TEST_IMPL(IDX)                                           \
  for (int i = 0; i < reg_elt_num; i++) {                        \
    if (i != IDX) {                                              \
      _c[i] = _b[4 * i];                                         \
      _c[i + reg_elt_num] = _b[4 * i + 1];                       \
      _c[i + reg_elt_num * 2] = _b[4 * i + 2];                   \
      _c[i + reg_elt_num * 3] = _b[4 * i + 3];                   \
    } else {                                                     \
      _c[i] = _a[0];                                             \
      _c[i + reg_elt_num] = _a[1];                               \
      _c[i + reg_elt_num * 2] = _a[2];                           \
      _c[i + reg_elt_num * 3] = _a[3];                           \
    }                                                            \
  }                                                              \
  c = vld4q_lane_f32(_a, b, IDX);                                \
  float32x4_get_float32(c, &c0, &c1, &c2, &c3);                  \
  CHECK_RESULT(validate_float(c0, _c[0], _c[1], _c[2], _c[3]))   \
  CHECK_RESULT(validate_float(c1, _c[4], _c[5], _c[6], _c[7]))   \
  CHECK_RESULT(validate_float(c2, _c[8], _c[9], _c[10], _c[11])) \
  CHECK_RESULT(validate_float(c3, _c[12], _c[13], _c[14], _c[15]))

  IMM_2_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld4_lane_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld4q_lane_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld4q_lane_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (uint16_t *)impl.test_cases_int_pointer2;
  const int reg_elt_num = 8;
  uint16_t _c[reg_elt_num * 4];
  uint16x8x4_t c;
  uint16x8x4_t b = vld4q_u16(_b);
  uint16x8_t c0, c1, c2, c3;

#define TEST_IMPL(IDX)                                                                              \
  for (int i = 0; i < reg_elt_num; i++) {                                                           \
    if (i != IDX) {                                                                                 \
      _c[i] = _b[4 * i];                                                                            \
      _c[i + reg_elt_num] = _b[4 * i + 1];                                                          \
      _c[i + reg_elt_num * 2] = _b[4 * i + 2];                                                      \
      _c[i + reg_elt_num * 3] = _b[4 * i + 3];                                                      \
    } else {                                                                                        \
      _c[i] = _a[0];                                                                                \
      _c[i + reg_elt_num] = _a[1];                                                                  \
      _c[i + reg_elt_num * 2] = _a[2];                                                              \
      _c[i + reg_elt_num * 3] = _a[3];                                                              \
    }                                                                                               \
  }                                                                                                 \
  c = vld4q_lane_u16(_a, b, IDX);                                                                   \
  uint16x4_get_uint16(c, &c0, &c1, &c2, &c3);                                                       \
  CHECK_RESULT(validate_uint16(c0, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]))         \
  CHECK_RESULT(validate_uint16(c1, _c[8], _c[9], _c[10], _c[11], _c[12], _c[13], _c[14], _c[15]))   \
  CHECK_RESULT(validate_uint16(c2, _c[16], _c[17], _c[18], _c[19], _c[20], _c[21], _c[22], _c[23])) \
  CHECK_RESULT(validate_uint16(c3, _c[24], _c[25], _c[26], _c[27], _c[28], _c[29], _c[30], _c[31]))

  IMM_8_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld4q_lane_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (uint32_t *)impl.test_cases_int_pointer2;
  const int reg_elt_num = 4;
  uint32_t _c[reg_elt_num * 4];
  uint32x4x4_t c;
  uint32x4x4_t b = vld4q_u32(_b);
  uint32x4_t c0, c1, c2, c3;

#define TEST_IMPL(IDX)                                            \
  for (int i = 0; i < reg_elt_num; i++) {                         \
    if (i != IDX) {                                               \
      _c[i] = _b[4 * i];                                          \
      _c[i + reg_elt_num] = _b[4 * i + 1];                        \
      _c[i + reg_elt_num * 2] = _b[4 * i + 2];                    \
      _c[i + reg_elt_num * 3] = _b[4 * i + 3];                    \
    } else {                                                      \
      _c[i] = _a[0];                                              \
      _c[i + reg_elt_num] = _a[1];                                \
      _c[i + reg_elt_num * 2] = _a[2];                            \
      _c[i + reg_elt_num * 3] = _a[3];                            \
    }                                                             \
  }                                                               \
  c = vld4q_lane_u32(_a, b, IDX);                                 \
  uint32x4_get_uint32(c, &c0, &c1, &c2, &c3);                     \
  CHECK_RESULT(validate_uint32(c0, _c[0], _c[1], _c[2], _c[3]))   \
  CHECK_RESULT(validate_uint32(c1, _c[4], _c[5], _c[6], _c[7]))   \
  CHECK_RESULT(validate_uint32(c2, _c[8], _c[9], _c[10], _c[11])) \
  CHECK_RESULT(validate_uint32(c3, _c[12], _c[13], _c[14], _c[15]))

  IMM_4_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld4_lane_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld4q_lane_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld4_dup_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (const int8_t *)impl.test_cases_int_pointer1;
  int8x8_t c0, c1, c2, c3;
  int8x8x4_t c = vld4_dup_s8(_a);
  int8x4_get_int8(c, &c0, &c1, &c2, &c3);
  CHECK_RESULT(validate_int8(c0, _a[0], _a[0], _a[0], _a[0], _a[0], _a[0], _a[0], _a[0]))
  CHECK_RESULT(validate_int8(c1, _a[1], _a[1], _a[1], _a[1], _a[1], _a[1], _a[1], _a[1]))
  CHECK_RESULT(validate_int8(c2, _a[2], _a[2], _a[2], _a[2], _a[2], _a[2], _a[2], _a[2]))
  CHECK_RESULT(validate_int8(c3, _a[3], _a[3], _a[3], _a[3], _a[3], _a[3], _a[3], _a[3]))
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld4q_dup_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld4_dup_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (const int16_t *)impl.test_cases_int_pointer1;
  int16x4_t c0, c1, c2, c3;
  int16x4x4_t c = vld4_dup_s16(_a);
  int16x4_get_int16(c, &c0, &c1, &c2, &c3);
  CHECK_RESULT(validate_int16(c0, _a[0], _a[0], _a[0], _a[0]))
  CHECK_RESULT(validate_int16(c1, _a[1], _a[1], _a[1], _a[1]))
  CHECK_RESULT(validate_int16(c2, _a[2], _a[2], _a[2], _a[2]))
  CHECK_RESULT(validate_int16(c3, _a[3], _a[3], _a[3], _a[3]))
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld4q_dup_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld4_dup_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (const int32_t *)impl.test_cases_int_pointer1;
  int32x2_t c0, c1, c2, c3;
  int32x2x4_t c = vld4_dup_s32(_a);
  int32x4_get_int32(c, &c0, &c1, &c2, &c3);
  CHECK_RESULT(validate_int32(c0, _a[0], _a[0]))
  CHECK_RESULT(validate_int32(c1, _a[1], _a[1]))
  CHECK_RESULT(validate_int32(c2, _a[2], _a[2]))
  CHECK_RESULT(validate_int32(c3, _a[3], _a[3]))
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld4q_dup_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld4_dup_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (const float *)impl.test_cases_float_pointer1;
  float32x2_t c0, c1, c2, c3;
  float32x2x4_t c = vld4_dup_f32(_a);
  float32x4_get_float32(c, &c0, &c1, &c2, &c3);
  CHECK_RESULT(validate_float(c0, _a[0], _a[0]))
  CHECK_RESULT(validate_float(c1, _a[1], _a[1]))
  CHECK_RESULT(validate_float(c2, _a[2], _a[2]))
  CHECK_RESULT(validate_float(c3, _a[3], _a[3]))
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld4q_dup_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld4_dup_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld4q_dup_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld4_dup_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld4q_dup_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld4_dup_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (const uint8_t *)impl.test_cases_int_pointer1;
  uint8x8_t c0, c1, c2, c3;
  uint8x8x4_t c = vld4_dup_u8(_a);
  uint8x4_get_uint8(c, &c0, &c1, &c2, &c3);
  CHECK_RESULT(validate_uint8(c0, _a[0], _a[0], _a[0], _a[0], _a[0], _a[0], _a[0], _a[0]))
  CHECK_RESULT(validate_uint8(c1, _a[1], _a[1], _a[1], _a[1], _a[1], _a[1], _a[1], _a[1]))
  CHECK_RESULT(validate_uint8(c2, _a[2], _a[2], _a[2], _a[2], _a[2], _a[2], _a[2], _a[2]))
  CHECK_RESULT(validate_uint8(c3, _a[3], _a[3], _a[3], _a[3], _a[3], _a[3], _a[3], _a[3]))
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld4q_dup_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld4_dup_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (const uint16_t *)impl.test_cases_int_pointer1;
  uint16x4_t c0, c1, c2, c3;
  uint16x4x4_t c = vld4_dup_u16(_a);
  uint16x4_get_uint16(c, &c0, &c1, &c2, &c3);
  CHECK_RESULT(validate_uint16(c0, _a[0], _a[0], _a[0], _a[0]))
  CHECK_RESULT(validate_uint16(c1, _a[1], _a[1], _a[1], _a[1]))
  CHECK_RESULT(validate_uint16(c2, _a[2], _a[2], _a[2], _a[2]))
  CHECK_RESULT(validate_uint16(c3, _a[3], _a[3], _a[3], _a[3]))
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld4q_dup_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld4_dup_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (const uint32_t *)impl.test_cases_int_pointer1;
  uint32x2_t c0, c1, c2, c3;
  uint32x2x4_t c = vld4_dup_u32(_a);
  uint32x4_get_uint32(c, &c0, &c1, &c2, &c3);
  CHECK_RESULT(validate_uint32(c0, _a[0], _a[0]))
  CHECK_RESULT(validate_uint32(c1, _a[1], _a[1]))
  CHECK_RESULT(validate_uint32(c2, _a[2], _a[2]))
  CHECK_RESULT(validate_uint32(c3, _a[3], _a[3]))
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld4q_dup_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld4_dup_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld4q_dup_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld4_dup_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (const int64_t *)impl.test_cases_int_pointer1;
  int64x1_t c0, c1, c2, c3;
  int64x1x4_t c = vld4_dup_s64(_a);
  int64x4_get_int64(c, &c0, &c1, &c2, &c3);
  CHECK_RESULT(validate_int64(c0, _a[0]))
  CHECK_RESULT(validate_int64(c1, _a[1]))
  CHECK_RESULT(validate_int64(c2, _a[2]))
  CHECK_RESULT(validate_int64(c3, _a[3]))
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld4_dup_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (const uint64_t *)impl.test_cases_int_pointer1;
  uint64x1_t c0, c1, c2, c3;
  uint64x1x4_t c = vld4_dup_u64(_a);
  uint64x4_get_uint64(c, &c0, &c1, &c2, &c3);
  CHECK_RESULT(validate_uint64(c0, _a[0]))
  CHECK_RESULT(validate_uint64(c1, _a[1]))
  CHECK_RESULT(validate_uint64(c2, _a[2]))
  CHECK_RESULT(validate_uint64(c3, _a[3]))
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vld4_dup_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld4q_dup_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld4q_dup_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld4q_dup_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld4_dup_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld4q_dup_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst4_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (int8_t *)impl.test_cases_int_pointer1;
  const int reg_elt_num = 8;
  int8_t _in[reg_elt_num * 4];
  merge_arrays(_a, _b, _in, reg_elt_num);
  int8_t _c[reg_elt_num * 4];
  int8x8x4_t in = vld4_s8(_in);
  vst4_s8(_c, in);
  for (int i = 0; i < reg_elt_num * 4; i++) {
    if (_in[i] != _c[i]) {
      return TEST_FAIL;
    }
  }
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst4_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer1;
  const int reg_elt_num = 4;
  int16_t _in[reg_elt_num * 4];
  merge_arrays(_a, _b, _in, reg_elt_num);
  int16_t _c[reg_elt_num * 4];
  int16x4x4_t in = vld4_s16(_in);
  vst4_s16(_c, in);
  for (int i = 0; i < reg_elt_num * 4; i++) {
    if (_in[i] != _c[i]) {
      return TEST_FAIL;
    }
  }
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst4_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer1;
  const int reg_elt_num = 2;
  int32_t _in[reg_elt_num * 4];
  merge_arrays(_a, _b, _in, reg_elt_num);
  int32_t _c[reg_elt_num * 4];
  int32x2x4_t in = vld4_s32(_in);
  vst4_s32(_c, in);
  for (int i = 0; i < reg_elt_num * 4; i++) {
    if (_in[i] != _c[i]) {
      return TEST_FAIL;
    }
  }
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst4_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_in1 = (float *)impl.test_cases_float_pointer1;
  const float *_in2 = (float *)impl.test_cases_float_pointer2;
  const float *_in3 = (float *)impl.test_cases_float_pointer3;
  const float *_in4 = (float *)impl.test_cases_float_pointer4;
  const int reg_elt_num = 2;
  float _in[reg_elt_num * 4];
  merge_arrays(_in1, _in2, _in3, _in4, _in, reg_elt_num);
  float _c[reg_elt_num * 4];
  float32x2x4_t in = vld4_f32(_in);
  vst4_f32(_c, in);
  for (int i = 0; i < reg_elt_num * 4; i++) {
    if (_in[i] != _c[i]) {
      return TEST_FAIL;
    }
  }
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst4_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (uint8_t *)impl.test_cases_int_pointer1;
  const int reg_elt_num = 8;
  uint8_t _in[reg_elt_num * 4];
  merge_arrays(_a, _b, _in, reg_elt_num);
  uint8_t _c[reg_elt_num * 4];
  uint8x8x4_t in = vld4_u8(_in);
  vst4_u8(_c, in);
  for (int i = 0; i < reg_elt_num * 4; i++) {
    if (_in[i] != _c[i]) {
      return TEST_FAIL;
    }
  }
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst4_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (uint16_t *)impl.test_cases_int_pointer1;
  const int reg_elt_num = 4;
  uint16_t _in[reg_elt_num * 4];
  merge_arrays(_a, _b, _in, reg_elt_num);
  uint16_t _c[reg_elt_num * 4];
  uint16x4x4_t in = vld4_u16(_in);
  vst4_u16(_c, in);
  for (int i = 0; i < reg_elt_num * 4; i++) {
    if (_in[i] != _c[i]) {
      return TEST_FAIL;
    }
  }
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst4_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (uint32_t *)impl.test_cases_int_pointer1;
  const int reg_elt_num = 2;
  uint32_t _in[reg_elt_num * 4];
  merge_arrays(_a, _b, _in, reg_elt_num);
  uint32_t _c[reg_elt_num * 4];
  uint32x2x4_t in = vld4_u32(_in);
  vst4_u32(_c, in);
  for (int i = 0; i < reg_elt_num * 4; i++) {
    if (_in[i] != _c[i]) {
      return TEST_FAIL;
    }
  }
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst4_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (int64_t *)impl.test_cases_int_pointer1;
  const int64_t *_b = (int64_t *)impl.test_cases_int_pointer1;
  const int reg_elt_num = 1;
  int64_t _in[reg_elt_num * 4];
  merge_arrays(_a, _b, _in, reg_elt_num);
  int64_t _c[reg_elt_num * 4];
  int64x1x4_t in = vld4_s64(_in);
  vst4_s64(_c, in);
  for (int i = 0; i < reg_elt_num * 4; i++) {
    if (_in[i] != _c[i]) {
      return TEST_FAIL;
    }
  }
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst4_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (uint64_t *)impl.test_cases_int_pointer1;
  const uint64_t *_b = (uint64_t *)impl.test_cases_int_pointer1;
  const int reg_elt_num = 1;
  uint64_t _in[reg_elt_num * 4];
  merge_arrays(_a, _b, _in, reg_elt_num);
  uint64_t _c[reg_elt_num * 4];
  uint64x1x4_t in = vld4_u64(_in);
  vst4_u64(_c, in);
  for (int i = 0; i < reg_elt_num * 4; i++) {
    if (_in[i] != _c[i]) {
      return TEST_FAIL;
    }
  }
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst4_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst4q_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst4q_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst4q_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst4_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst4q_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst4q_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (int8_t *)impl.test_cases_int_pointer1;
  const int reg_elt_num = 16;
  int8_t _in[reg_elt_num * 4];
  merge_arrays(_a, _b, _in, reg_elt_num);
  int8_t _c[reg_elt_num * 4];
  int8x16x4_t in = vld4q_s8(_in);
  vst4q_s8(_c, in);
  for (int i = 0; i < reg_elt_num * 4; i++) {
    if (_in[i] != _c[i]) {
      return TEST_FAIL;
    }
  }
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst4q_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer1;
  const int reg_elt_num = 8;
  int16_t _in[reg_elt_num * 4];
  merge_arrays(_a, _b, _in, reg_elt_num);
  int16_t _c[reg_elt_num * 4];
  int16x8x4_t in = vld4q_s16(_in);
  vst4q_s16(_c, in);
  for (int i = 0; i < reg_elt_num * 4; i++) {
    if (_in[i] != _c[i]) {
      return TEST_FAIL;
    }
  }
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst4q_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer1;
  const int reg_elt_num = 4;
  int32_t _in[reg_elt_num * 4];
  merge_arrays(_a, _b, _in, reg_elt_num);
  int32_t _c[reg_elt_num * 4];
  int32x4x4_t in = vld4q_s32(_in);
  vst4q_s32(_c, in);
  for (int i = 0; i < reg_elt_num * 4; i++) {
    if (_in[i] != _c[i]) {
      return TEST_FAIL;
    }
  }
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst4q_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const float *_a = (float *)impl.test_cases_float_pointer1;
  const float *_b = (float *)impl.test_cases_float_pointer1;
  const int reg_elt_num = 4;
  float _in[reg_elt_num * 4];
  merge_arrays(_a, _b, _in, reg_elt_num);
  float _c[reg_elt_num * 4];
  float32x4x4_t in = vld4q_f32(_in);
  vst4q_f32(_c, in);
  for (int i = 0; i < reg_elt_num * 4; i++) {
    if (validate_float_pair(_in[i], _c[i] != TEST_SUCCESS)) {
      return TEST_FAIL;
    }
  }
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst4_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst4q_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst4_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst4q_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst4q_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (uint8_t *)impl.test_cases_int_pointer1;
  const int reg_elt_num = 16;
  uint8_t _in[reg_elt_num * 4];
  merge_arrays(_a, _b, _in, reg_elt_num);
  uint8_t _c[reg_elt_num * 4];
  uint8x16x4_t in = vld4q_u8(_in);
  vst4q_u8(_c, in);
  for (int i = 0; i < reg_elt_num * 4; i++) {
    if (_in[i] != _c[i]) {
      return TEST_FAIL;
    }
  }
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst4q_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (uint16_t *)impl.test_cases_int_pointer1;
  const int reg_elt_num = 8;
  uint16_t _in[reg_elt_num * 4];
  merge_arrays(_a, _b, _in, reg_elt_num);
  uint16_t _c[reg_elt_num * 4];
  uint16x8x4_t in = vld4q_u16(_in);
  vst4q_u16(_c, in);
  for (int i = 0; i < reg_elt_num * 4; i++) {
    if (_in[i] != _c[i]) {
      return TEST_FAIL;
    }
  }
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst4q_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (uint32_t *)impl.test_cases_int_pointer1;
  const int reg_elt_num = 4;
  uint32_t _in[reg_elt_num * 4];
  merge_arrays(_a, _b, _in, reg_elt_num);
  uint32_t _c[reg_elt_num * 4];
  uint32x4x4_t in = vld4q_u32(_in);
  vst4q_u32(_c, in);
  for (int i = 0; i < reg_elt_num * 4; i++) {
    if (_in[i] != _c[i]) {
      return TEST_FAIL;
    }
  }
  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst4_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst4q_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst4_lane_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int reg_elt_num = 8;
  int8_t _a[reg_elt_num * 4];
  const int8_t *_in1 = (int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_in2 = (int8_t *)impl.test_cases_int_pointer2;
  const int8_t *_in3 = (int8_t *)impl.test_cases_int_pointer3;
  const int8_t *_in4 = (int8_t *)impl.test_cases_int_pointer4;
  int8_t _b[reg_elt_num * 4];
  int8_t in[reg_elt_num * 4];
  merge_arrays(_in1, _in2, _in3, _in4, in, reg_elt_num);
  int8x8x4_t b;

  for (int i = 0; i < reg_elt_num; i++) {
    _b[i] = in[4 * i];
    _b[i + reg_elt_num] = in[4 * i + 1];
    _b[i + reg_elt_num * 2] = in[4 * i + 2];
    _b[i + reg_elt_num * 3] = in[4 * i + 3];
  }

#define TEST_IMPL(IDX)                                                                                  \
  b = vld4_s8(in);                                                                                      \
  vst4_lane_s8(_a, b, IDX);                                                                             \
  if ((_a[0] != _b[IDX]) || (_a[1] != _b[IDX + reg_elt_num]) || (_a[2] != _b[IDX + reg_elt_num * 2]) || \
      (_a[3] != _b[IDX + reg_elt_num * 3])) {                                                           \
    return TEST_FAIL;                                                                                   \
  }

  IMM_8_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst4_lane_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int reg_elt_num = 4;
  int16_t _a[reg_elt_num * 4];
  const int16_t *_in1 = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_in2 = (int16_t *)impl.test_cases_int_pointer2;
  const int16_t *_in3 = (int16_t *)impl.test_cases_int_pointer3;
  const int16_t *_in4 = (int16_t *)impl.test_cases_int_pointer4;
  int16_t _b[reg_elt_num * 4];
  int16_t in[reg_elt_num * 4];
  merge_arrays(_in1, _in2, _in3, _in4, in, reg_elt_num);
  int16x4x4_t b;

  for (int i = 0; i < reg_elt_num; i++) {
    _b[i] = in[4 * i];
    _b[i + reg_elt_num] = in[4 * i + 1];
    _b[i + reg_elt_num * 2] = in[4 * i + 2];
    _b[i + reg_elt_num * 3] = in[4 * i + 3];
  }

#define TEST_IMPL(IDX)                                                                                  \
  b = vld4_s16(in);                                                                                     \
  vst4_lane_s16(_a, b, IDX);                                                                            \
  if ((_a[0] != _b[IDX]) || (_a[1] != _b[IDX + reg_elt_num]) || (_a[2] != _b[IDX + reg_elt_num * 2]) || \
      (_a[3] != _b[IDX + reg_elt_num * 3])) {                                                           \
    return TEST_FAIL;                                                                                   \
  }

  IMM_4_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst4_lane_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int reg_elt_num = 2;
  int32_t _a[reg_elt_num * 4];
  const int32_t *_in1 = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_in2 = (int32_t *)impl.test_cases_int_pointer2;
  const int32_t *_in3 = (int32_t *)impl.test_cases_int_pointer3;
  const int32_t *_in4 = (int32_t *)impl.test_cases_int_pointer4;
  int32_t _b[reg_elt_num * 4];
  int32_t in[reg_elt_num * 4];
  merge_arrays(_in1, _in2, _in3, _in4, in, reg_elt_num);
  int32x2x4_t b;

  for (int i = 0; i < reg_elt_num; i++) {
    _b[i] = in[4 * i];
    _b[i + reg_elt_num] = in[4 * i + 1];
    _b[i + reg_elt_num * 2] = in[4 * i + 2];
    _b[i + reg_elt_num * 3] = in[4 * i + 3];
  }

#define TEST_IMPL(IDX)                                                                                  \
  b = vld4_s32(in);                                                                                     \
  vst4_lane_s32(_a, b, IDX);                                                                            \
  if ((_a[0] != _b[IDX]) || (_a[1] != _b[IDX + reg_elt_num]) || (_a[2] != _b[IDX + reg_elt_num * 2]) || \
      (_a[3] != _b[IDX + reg_elt_num * 3])) {                                                           \
    return TEST_FAIL;                                                                                   \
  }

  IMM_2_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst4_lane_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int reg_elt_num = 2;
  float _a[reg_elt_num * 4];
  const float *_in1 = (float *)impl.test_cases_float_pointer1;
  const float *_in2 = (float *)impl.test_cases_float_pointer2;
  const float *_in3 = (float *)impl.test_cases_float_pointer3;
  const float *_in4 = (float *)impl.test_cases_float_pointer4;
  float _b[reg_elt_num * 4];
  float in[reg_elt_num * 4];
  merge_arrays(_in1, _in2, _in3, _in4, in, reg_elt_num);
  float32x2x4_t b;

  for (int i = 0; i < reg_elt_num; i++) {
    _b[i] = in[4 * i];
    _b[i + reg_elt_num] = in[4 * i + 1];
    _b[i + reg_elt_num * 2] = in[4 * i + 2];
    _b[i + reg_elt_num * 3] = in[4 * i + 3];
  }

#define TEST_IMPL(IDX)                                                                                  \
  b = vld4_f32(in);                                                                                     \
  vst4_lane_f32(_a, b, IDX);                                                                            \
  if ((_a[0] != _b[IDX]) || (_a[1] != _b[IDX + reg_elt_num]) || (_a[2] != _b[IDX + reg_elt_num * 2]) || \
      (_a[3] != _b[IDX + reg_elt_num * 3])) {                                                           \
    return TEST_FAIL;                                                                                   \
  }

  IMM_2_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst4_lane_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int reg_elt_num = 8;
  uint8_t _a[reg_elt_num * 4];
  const uint8_t *_in1 = (uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_in2 = (uint8_t *)impl.test_cases_int_pointer2;
  const uint8_t *_in3 = (uint8_t *)impl.test_cases_int_pointer3;
  const uint8_t *_in4 = (uint8_t *)impl.test_cases_int_pointer4;
  uint8_t _b[reg_elt_num * 4];
  uint8_t in[reg_elt_num * 4];
  merge_arrays(_in1, _in2, _in3, _in4, in, reg_elt_num);
  uint8x8x4_t b;

  for (int i = 0; i < reg_elt_num; i++) {
    _b[i] = in[4 * i];
    _b[i + reg_elt_num] = in[4 * i + 1];
    _b[i + reg_elt_num * 2] = in[4 * i + 2];
    _b[i + reg_elt_num * 3] = in[4 * i + 3];
  }

#define TEST_IMPL(IDX)                                                                                  \
  b = vld4_u8(in);                                                                                      \
  vst4_lane_u8(_a, b, IDX);                                                                             \
  if ((_a[0] != _b[IDX]) || (_a[1] != _b[IDX + reg_elt_num]) || (_a[2] != _b[IDX + reg_elt_num * 2]) || \
      (_a[3] != _b[IDX + reg_elt_num * 3])) {                                                           \
    return TEST_FAIL;                                                                                   \
  }

  IMM_8_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst4_lane_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst4_lane_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int reg_elt_num = 4;
  uint16_t _a[reg_elt_num * 4];
  const uint16_t *_in1 = (uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_in2 = (uint16_t *)impl.test_cases_int_pointer2;
  const uint16_t *_in3 = (uint16_t *)impl.test_cases_int_pointer3;
  const uint16_t *_in4 = (uint16_t *)impl.test_cases_int_pointer4;
  uint16_t _b[reg_elt_num * 4];
  uint16_t in[reg_elt_num * 4];
  merge_arrays(_in1, _in2, _in3, _in4, in, reg_elt_num);
  uint16x4x4_t b;

  for (int i = 0; i < reg_elt_num; i++) {
    _b[i] = in[4 * i];
    _b[i + reg_elt_num] = in[4 * i + 1];
    _b[i + reg_elt_num * 2] = in[4 * i + 2];
    _b[i + reg_elt_num * 3] = in[4 * i + 3];
  }

#define TEST_IMPL(IDX)                                                                                  \
  b = vld4_u16(in);                                                                                     \
  vst4_lane_u16(_a, b, IDX);                                                                            \
  if ((_a[0] != _b[IDX]) || (_a[1] != _b[IDX + reg_elt_num]) || (_a[2] != _b[IDX + reg_elt_num * 2]) || \
      (_a[3] != _b[IDX + reg_elt_num * 3])) {                                                           \
    return TEST_FAIL;                                                                                   \
  }

  IMM_4_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst4_lane_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int reg_elt_num = 2;
  uint32_t _a[reg_elt_num * 4];
  const uint32_t *_in1 = (uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_in2 = (uint32_t *)impl.test_cases_int_pointer2;
  const uint32_t *_in3 = (uint32_t *)impl.test_cases_int_pointer3;
  const uint32_t *_in4 = (uint32_t *)impl.test_cases_int_pointer4;
  uint32_t _b[reg_elt_num * 4];
  uint32_t in[reg_elt_num * 4];
  merge_arrays(_in1, _in2, _in3, _in4, in, reg_elt_num);
  uint32x2x4_t b;

  for (int i = 0; i < reg_elt_num; i++) {
    _b[i] = in[4 * i];
    _b[i + reg_elt_num] = in[4 * i + 1];
    _b[i + reg_elt_num * 2] = in[4 * i + 2];
    _b[i + reg_elt_num * 3] = in[4 * i + 3];
  }

#define TEST_IMPL(IDX)                                                                                  \
  b = vld4_u32(in);                                                                                     \
  vst4_lane_u32(_a, b, IDX);                                                                            \
  if ((_a[0] != _b[IDX]) || (_a[1] != _b[IDX + reg_elt_num]) || (_a[2] != _b[IDX + reg_elt_num * 2]) || \
      (_a[3] != _b[IDX + reg_elt_num * 3])) {                                                           \
    return TEST_FAIL;                                                                                   \
  }

  IMM_2_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst4q_lane_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int reg_elt_num = 8;
  int16_t _a[reg_elt_num * 4];
  const int16_t *_in1 = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_in2 = (int16_t *)impl.test_cases_int_pointer2;
  const int16_t *_in3 = (int16_t *)impl.test_cases_int_pointer3;
  const int16_t *_in4 = (int16_t *)impl.test_cases_int_pointer4;
  int16_t _b[reg_elt_num * 4];
  int16_t in[reg_elt_num * 4];
  merge_arrays(_in1, _in2, _in3, _in4, in, reg_elt_num);
  int16x8x4_t b;

  for (int i = 0; i < reg_elt_num; i++) {
    _b[i] = in[4 * i];
    _b[i + reg_elt_num] = in[4 * i + 1];
    _b[i + reg_elt_num * 2] = in[4 * i + 2];
    _b[i + reg_elt_num * 3] = in[4 * i + 3];
  }

#define TEST_IMPL(IDX)                                                                                  \
  b = vld4q_s16(in);                                                                                    \
  vst4q_lane_s16(_a, b, IDX);                                                                           \
  if ((_a[0] != _b[IDX]) || (_a[1] != _b[IDX + reg_elt_num]) || (_a[2] != _b[IDX + reg_elt_num * 2]) || \
      (_a[3] != _b[IDX + reg_elt_num * 3])) {                                                           \
    return TEST_FAIL;                                                                                   \
  }

  IMM_8_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst4q_lane_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int reg_elt_num = 4;
  int32_t _a[reg_elt_num * 4];
  const int32_t *_in1 = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_in2 = (int32_t *)impl.test_cases_int_pointer2;
  const int32_t *_in3 = (int32_t *)impl.test_cases_int_pointer3;
  const int32_t *_in4 = (int32_t *)impl.test_cases_int_pointer4;
  int32_t _b[reg_elt_num * 4];
  int32_t in[reg_elt_num * 4];
  merge_arrays(_in1, _in2, _in3, _in4, in, reg_elt_num);
  int32x4x4_t b;

  for (int i = 0; i < reg_elt_num; i++) {
    _b[i] = in[4 * i];
    _b[i + reg_elt_num] = in[4 * i + 1];
    _b[i + reg_elt_num * 2] = in[4 * i + 2];
    _b[i + reg_elt_num * 3] = in[4 * i + 3];
  }

#define TEST_IMPL(IDX)                                                                                  \
  b = vld4q_s32(in);                                                                                    \
  vst4q_lane_s32(_a, b, IDX);                                                                           \
  if ((_a[0] != _b[IDX]) || (_a[1] != _b[IDX + reg_elt_num]) || (_a[2] != _b[IDX + reg_elt_num * 2]) || \
      (_a[3] != _b[IDX + reg_elt_num * 3])) {                                                           \
    return TEST_FAIL;                                                                                   \
  }

  IMM_4_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst4q_lane_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int reg_elt_num = 4;
  float _a[reg_elt_num * 4];
  const float *_in1 = (float *)impl.test_cases_float_pointer1;
  const float *_in2 = (float *)impl.test_cases_float_pointer2;
  const float *_in3 = (float *)impl.test_cases_float_pointer3;
  const float *_in4 = (float *)impl.test_cases_float_pointer4;
  float _b[reg_elt_num * 4];
  float in[reg_elt_num * 4];
  merge_arrays(_in1, _in2, _in3, _in4, in, reg_elt_num);
  float32x4x4_t b;

  for (int i = 0; i < reg_elt_num; i++) {
    _b[i] = in[4 * i];
    _b[i + reg_elt_num] = in[4 * i + 1];
    _b[i + reg_elt_num * 2] = in[4 * i + 2];
    _b[i + reg_elt_num * 3] = in[4 * i + 3];
  }

#define TEST_IMPL(IDX)                                                                                  \
  b = vld4q_f32(in);                                                                                    \
  vst4q_lane_f32(_a, b, IDX);                                                                           \
  if ((_a[0] != _b[IDX]) || (_a[1] != _b[IDX + reg_elt_num]) || (_a[2] != _b[IDX + reg_elt_num * 2]) || \
      (_a[3] != _b[IDX + reg_elt_num * 3])) {                                                           \
    return TEST_FAIL;                                                                                   \
  }

  IMM_4_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst4_lane_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst4q_lane_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst4q_lane_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst4q_lane_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst4q_lane_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst4_lane_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst4q_lane_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst4_lane_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst4q_lane_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst4_lane_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst4q_lane_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst4_lane_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst4q_lane_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1_s8_x2(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1q_s8_x2(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1_s16_x2(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1q_s16_x2(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1_s32_x2(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1q_s32_x2(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1_u8_x2(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1q_u8_x2(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1_u16_x2(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1q_u16_x2(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1_u32_x2(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1q_u32_x2(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1_f16_x2(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1q_f16_x2(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1_f32_x2(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1q_f32_x2(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1_p8_x2(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1q_p8_x2(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1_p16_x2(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1q_p16_x2(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1_s64_x2(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1_u64_x2(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1_p64_x2(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1q_s64_x2(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1q_u64_x2(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1q_p64_x2(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1_f64_x2(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1q_f64_x2(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1_s8_x3(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1q_s8_x3(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1_s16_x3(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1q_s16_x3(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1_s32_x3(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1q_s32_x3(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1_u8_x3(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1q_u8_x3(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1_u16_x3(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1q_u16_x3(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1_u32_x3(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1q_u32_x3(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1_f16_x3(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1q_f16_x3(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1_f32_x3(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1q_f32_x3(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1_p8_x3(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1q_p8_x3(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1_p16_x3(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1q_p16_x3(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1_s64_x3(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1_u64_x3(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1_p64_x3(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1q_s64_x3(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1q_u64_x3(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1q_p64_x3(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1_f64_x3(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1q_f64_x3(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1_s8_x4(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1q_s8_x4(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1_s16_x4(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1q_s16_x4(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1_s32_x4(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1q_s32_x4(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1_u8_x4(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1q_u8_x4(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1_u16_x4(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1q_u16_x4(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1_u32_x4(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1q_u32_x4(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1_f16_x4(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1q_f16_x4(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1_f32_x4(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1q_f32_x4(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1_p8_x4(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1q_p8_x4(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1_p16_x4(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1q_p16_x4(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1_s64_x4(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1_u64_x4(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1_p64_x4(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1q_s64_x4(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1q_u64_x4(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1q_p64_x4(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1_f64_x4(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst1q_f64_x4(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1_s8_x2(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1q_s8_x2(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1_s16_x2(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1q_s16_x2(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1_s32_x2(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1q_s32_x2(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1_u8_x2(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1q_u8_x2(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1_u16_x2(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1q_u16_x2(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1_u32_x2(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1q_u32_x2(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1_f16_x2(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1q_f16_x2(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1_f32_x2(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1q_f32_x2(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1_p8_x2(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1q_p8_x2(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1_p16_x2(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1q_p16_x2(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1_s64_x2(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1_u64_x2(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1_p64_x2(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1q_s64_x2(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1q_u64_x2(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1q_p64_x2(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1_f64_x2(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1q_f64_x2(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1_s8_x3(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1q_s8_x3(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1_s16_x3(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1q_s16_x3(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1_s32_x3(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1q_s32_x3(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1_u8_x3(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1q_u8_x3(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1_u16_x3(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1q_u16_x3(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1_u32_x3(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1q_u32_x3(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1_f16_x3(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1q_f16_x3(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1_f32_x3(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1q_f32_x3(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1_p8_x3(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1q_p8_x3(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1_p16_x3(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1q_p16_x3(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1_s64_x3(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1_u64_x3(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1_p64_x3(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1q_s64_x3(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1q_u64_x3(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1q_p64_x3(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1_f64_x3(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1q_f64_x3(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1_s8_x4(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1q_s8_x4(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1_s16_x4(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1q_s16_x4(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1_s32_x4(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1q_s32_x4(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1_u8_x4(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1q_u8_x4(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1_u16_x4(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1q_u16_x4(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1_u32_x4(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1q_u32_x4(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1_f16_x4(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1q_f16_x4(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1_f32_x4(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1q_f32_x4(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1_p8_x4(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1q_p8_x4(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1_p16_x4(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1q_p16_x4(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1_s64_x4(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1_u64_x4(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1_p64_x4(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1q_s64_x4(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1q_u64_x4(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1q_p64_x4(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1_f64_x4(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vld1q_f64_x4(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst4q_lane_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int reg_elt_num = 8;
  uint16_t _a[reg_elt_num * 4];
  const uint16_t *_in1 = (uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_in2 = (uint16_t *)impl.test_cases_int_pointer2;
  const uint16_t *_in3 = (uint16_t *)impl.test_cases_int_pointer3;
  const uint16_t *_in4 = (uint16_t *)impl.test_cases_int_pointer4;
  uint16_t _b[reg_elt_num * 4];
  uint16_t in[reg_elt_num * 4];
  merge_arrays(_in1, _in2, _in3, _in4, in, reg_elt_num);
  uint16x8x4_t b;

  for (int i = 0; i < reg_elt_num; i++) {
    _b[i] = in[4 * i];
    _b[i + reg_elt_num] = in[4 * i + 1];
    _b[i + reg_elt_num * 2] = in[4 * i + 2];
    _b[i + reg_elt_num * 3] = in[4 * i + 3];
  }

#define TEST_IMPL(IDX)                                                                                  \
  b = vld4q_u16(in);                                                                                    \
  vst4q_lane_u16(_a, b, IDX);                                                                           \
  if ((_a[0] != _b[IDX]) || (_a[1] != _b[IDX + reg_elt_num]) || (_a[2] != _b[IDX + reg_elt_num * 2]) || \
      (_a[3] != _b[IDX + reg_elt_num * 3])) {                                                           \
    return TEST_FAIL;                                                                                   \
  }

  IMM_8_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst4q_lane_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int reg_elt_num = 4;
  uint32_t _a[reg_elt_num * 4];
  const uint32_t *_in1 = (uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_in2 = (uint32_t *)impl.test_cases_int_pointer2;
  const uint32_t *_in3 = (uint32_t *)impl.test_cases_int_pointer3;
  const uint32_t *_in4 = (uint32_t *)impl.test_cases_int_pointer4;
  uint32_t _b[reg_elt_num * 4];
  uint32_t in[reg_elt_num * 4];
  merge_arrays(_in1, _in2, _in3, _in4, in, reg_elt_num);
  uint32x4x4_t b;

  for (int i = 0; i < reg_elt_num; i++) {
    _b[i] = in[4 * i];
    _b[i + reg_elt_num] = in[4 * i + 1];
    _b[i + reg_elt_num * 2] = in[4 * i + 2];
    _b[i + reg_elt_num * 3] = in[4 * i + 3];
  }

#define TEST_IMPL(IDX)                                                                                  \
  b = vld4q_u32(in);                                                                                    \
  vst4q_lane_u32(_a, b, IDX);                                                                           \
  if ((_a[0] != _b[IDX]) || (_a[1] != _b[IDX + reg_elt_num]) || (_a[2] != _b[IDX + reg_elt_num * 2]) || \
      (_a[3] != _b[IDX + reg_elt_num * 3])) {                                                           \
    return TEST_FAIL;                                                                                   \
  }

  IMM_4_ITER
#undef TEST_IMPL

  return TEST_SUCCESS;
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vst4_lane_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vst4q_lane_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vand_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (int8_t *)impl.test_cases_int_pointer2;
  int8_t _d[8];
  for (int i = 0; i < 8; i++) {
    _d[i] = _a[i] & _b[i];
  }

  int8x8_t a = vld1_s8(_a);
  int8x8_t b = vld1_s8(_b);
  int8x8_t c = vand_s8(a, b);
  return validate_int8(c, _d[0], _d[1], _d[2], _d[3], _d[4], _d[5], _d[6], _d[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vand_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  int16_t _d[4];
  for (int i = 0; i < 4; i++) {
    _d[i] = _a[i] & _b[i];
  }

  int16x4_t a = vld1_s16(_a);
  int16x4_t b = vld1_s16(_b);
  int16x4_t c = vand_s16(a, b);
  return validate_int16(c, _d[0], _d[1], _d[2], _d[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vand_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  int32_t _d[2];
  for (int i = 0; i < 2; i++) {
    _d[i] = _a[i] & _b[i];
  }

  int32x2_t a = vld1_s32(_a);
  int32x2_t b = vld1_s32(_b);
  int32x2_t c = vand_s32(a, b);
  return validate_int32(c, _d[0], _d[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vand_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (uint8_t *)impl.test_cases_int_pointer2;
  uint8_t _d[8];
  for (int i = 0; i < 8; i++) {
    _d[i] = _a[i] & _b[i];
  }

  uint8x8_t a = vld1_u8(_a);
  uint8x8_t b = vld1_u8(_b);
  uint8x8_t c = vand_u8(a, b);
  return validate_uint8(c, _d[0], _d[1], _d[2], _d[3], _d[4], _d[5], _d[6], _d[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vand_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (uint16_t *)impl.test_cases_int_pointer2;
  uint16_t _d[4];
  for (int i = 0; i < 4; i++) {
    _d[i] = _a[i] & _b[i];
  }

  uint16x4_t a = vld1_u16(_a);
  uint16x4_t b = vld1_u16(_b);
  uint16x4_t c = vand_u16(a, b);
  return validate_uint16(c, _d[0], _d[1], _d[2], _d[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vand_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (uint32_t *)impl.test_cases_int_pointer2;
  uint32_t _d[2];
  for (int i = 0; i < 2; i++) {
    _d[i] = _a[i] & _b[i];
  }

  uint32x2_t a = vld1_u32(_a);
  uint32x2_t b = vld1_u32(_b);
  uint32x2_t c = vand_u32(a, b);
  return validate_uint32(c, _d[0], _d[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vand_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (int64_t *)impl.test_cases_int_pointer1;
  const int64_t *_b = (int64_t *)impl.test_cases_int_pointer2;
  int64_t _d[1];
  for (int i = 0; i < 1; i++) {
    _d[i] = _a[i] & _b[i];
  }

  int64x1_t a = vld1_s64(_a);
  int64x1_t b = vld1_s64(_b);
  int64x1_t c = vand_s64(a, b);
  return validate_int64(c, _d[0]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vand_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (uint64_t *)impl.test_cases_int_pointer1;
  const uint64_t *_b = (uint64_t *)impl.test_cases_int_pointer2;
  uint64_t _d[1];
  for (int i = 0; i < 1; i++) {
    _d[i] = _a[i] & _b[i];
  }

  uint64x1_t a = vld1_u64(_a);
  uint64x1_t b = vld1_u64(_b);
  uint64x1_t c = vand_u64(a, b);
  return validate_uint64(c, _d[0]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vandq_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (int8_t *)impl.test_cases_int_pointer2;
  int8_t _d[16];
  for (int i = 0; i < 16; i++) {
    _d[i] = _a[i] & _b[i];
  }

  int8x16_t a = vld1q_s8(_a);
  int8x16_t b = vld1q_s8(_b);
  int8x16_t c = vandq_s8(a, b);
  return validate_int8(c, _d[0], _d[1], _d[2], _d[3], _d[4], _d[5], _d[6], _d[7], _d[8], _d[9], _d[10], _d[11], _d[12],
                       _d[13], _d[14], _d[15]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vandq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  int16_t _d[8];
  for (int i = 0; i < 8; i++) {
    _d[i] = _a[i] & _b[i];
  }

  int16x8_t a = vld1q_s16(_a);
  int16x8_t b = vld1q_s16(_b);
  int16x8_t c = vandq_s16(a, b);
  return validate_int16(c, _d[0], _d[1], _d[2], _d[3], _d[4], _d[5], _d[6], _d[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vandq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  int32_t _d[4];
  for (int i = 0; i < 4; i++) {
    _d[i] = _a[i] & _b[i];
  }

  int32x4_t a = vld1q_s32(_a);
  int32x4_t b = vld1q_s32(_b);
  int32x4_t c = vandq_s32(a, b);
  return validate_int32(c, _d[0], _d[1], _d[2], _d[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vandq_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (int64_t *)impl.test_cases_int_pointer1;
  const int64_t *_b = (int64_t *)impl.test_cases_int_pointer2;
  int64_t _d[2];
  for (int i = 0; i < 2; i++) {
    _d[i] = _a[i] & _b[i];
  }

  int64x2_t a = vld1q_s64(_a);
  int64x2_t b = vld1q_s64(_b);
  int64x2_t c = vandq_s64(a, b);
  return validate_int64(c, _d[0], _d[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vandq_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (uint8_t *)impl.test_cases_int_pointer2;
  uint8_t _d[16];
  for (int i = 0; i < 16; i++) {
    _d[i] = _a[i] & _b[i];
  }

  uint8x16_t a = vld1q_u8(_a);
  uint8x16_t b = vld1q_u8(_b);
  uint8x16_t c = vandq_u8(a, b);
  return validate_uint8(c, _d[0], _d[1], _d[2], _d[3], _d[4], _d[5], _d[6], _d[7], _d[8], _d[9], _d[10], _d[11], _d[12],
                        _d[13], _d[14], _d[15]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vandq_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (uint16_t *)impl.test_cases_int_pointer2;
  uint16_t _d[8];
  for (int i = 0; i < 8; i++) {
    _d[i] = _a[i] & _b[i];
  }

  uint16x8_t a = vld1q_u16(_a);
  uint16x8_t b = vld1q_u16(_b);
  uint16x8_t c = vandq_u16(a, b);
  return validate_uint16(c, _d[0], _d[1], _d[2], _d[3], _d[4], _d[5], _d[6], _d[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vandq_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (uint32_t *)impl.test_cases_int_pointer2;
  uint32_t _d[4];
  for (int i = 0; i < 4; i++) {
    _d[i] = _a[i] & _b[i];
  }

  uint32x4_t a = vld1q_u32(_a);
  uint32x4_t b = vld1q_u32(_b);
  uint32x4_t c = vandq_u32(a, b);
  return validate_uint32(c, _d[0], _d[1], _d[2], _d[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vandq_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (uint64_t *)impl.test_cases_int_pointer1;
  const uint64_t *_b = (uint64_t *)impl.test_cases_int_pointer2;
  uint64_t _d[2];
  for (int i = 0; i < 2; i++) {
    _d[i] = _a[i] & _b[i];
  }

  uint64x2_t a = vld1q_u64(_a);
  uint64x2_t b = vld1q_u64(_b);
  uint64x2_t c = vandq_u64(a, b);
  return validate_uint64(c, _d[0], _d[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vorr_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (int8_t *)impl.test_cases_int_pointer2;
  int8_t _d[8];
  for (int i = 0; i < 8; i++) {
    _d[i] = _a[i] | _b[i];
  }

  int8x8_t a = vld1_s8(_a);
  int8x8_t b = vld1_s8(_b);
  int8x8_t c = vorr_s8(a, b);
  return validate_int8(c, _d[0], _d[1], _d[2], _d[3], _d[4], _d[5], _d[6], _d[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vorr_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  int16_t _d[4];
  for (int i = 0; i < 4; i++) {
    _d[i] = _a[i] | _b[i];
  }

  int16x4_t a = vld1_s16(_a);
  int16x4_t b = vld1_s16(_b);
  int16x4_t c = vorr_s16(a, b);
  return validate_int16(c, _d[0], _d[1], _d[2], _d[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vorr_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  int32_t _d[2];
  for (int i = 0; i < 2; i++) {
    _d[i] = _a[i] | _b[i];
  }

  int32x2_t a = vld1_s32(_a);
  int32x2_t b = vld1_s32(_b);
  int32x2_t c = vorr_s32(a, b);
  return validate_int32(c, _d[0], _d[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vorr_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (uint8_t *)impl.test_cases_int_pointer2;
  uint8_t _d[8];
  for (int i = 0; i < 8; i++) {
    _d[i] = _a[i] | _b[i];
  }

  uint8x8_t a = vld1_u8(_a);
  uint8x8_t b = vld1_u8(_b);
  uint8x8_t c = vorr_u8(a, b);
  return validate_uint8(c, _d[0], _d[1], _d[2], _d[3], _d[4], _d[5], _d[6], _d[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vorr_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (uint16_t *)impl.test_cases_int_pointer2;
  uint16_t _d[4];
  for (int i = 0; i < 4; i++) {
    _d[i] = _a[i] | _b[i];
  }

  uint16x4_t a = vld1_u16(_a);
  uint16x4_t b = vld1_u16(_b);
  uint16x4_t c = vorr_u16(a, b);
  return validate_uint16(c, _d[0], _d[1], _d[2], _d[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vorr_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (uint32_t *)impl.test_cases_int_pointer2;
  uint32_t _d[2];
  for (int i = 0; i < 2; i++) {
    _d[i] = _a[i] | _b[i];
  }

  uint32x2_t a = vld1_u32(_a);
  uint32x2_t b = vld1_u32(_b);
  uint32x2_t c = vorr_u32(a, b);
  return validate_uint32(c, _d[0], _d[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vorr_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (int64_t *)impl.test_cases_int_pointer1;
  const int64_t *_b = (int64_t *)impl.test_cases_int_pointer2;
  int64_t _d[1];
  for (int i = 0; i < 1; i++) {
    _d[i] = _a[i] | _b[i];
  }

  int64x1_t a = vld1_s64(_a);
  int64x1_t b = vld1_s64(_b);
  int64x1_t c = vorr_s64(a, b);
  return validate_int64(c, _d[0]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vorr_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (uint64_t *)impl.test_cases_int_pointer1;
  const uint64_t *_b = (uint64_t *)impl.test_cases_int_pointer2;
  uint64_t _d[1];
  for (int i = 0; i < 1; i++) {
    _d[i] = _a[i] | _b[i];
  }

  uint64x1_t a = vld1_u64(_a);
  uint64x1_t b = vld1_u64(_b);
  uint64x1_t c = vorr_u64(a, b);
  return validate_uint64(c, _d[0]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vorrq_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (int8_t *)impl.test_cases_int_pointer2;
  int8_t _d[16];
  for (int i = 0; i < 16; i++) {
    _d[i] = _a[i] | _b[i];
  }

  int8x16_t a = vld1q_s8(_a);
  int8x16_t b = vld1q_s8(_b);
  int8x16_t c = vorrq_s8(a, b);
  return validate_int8(c, _d[0], _d[1], _d[2], _d[3], _d[4], _d[5], _d[6], _d[7], _d[8], _d[9], _d[10], _d[11], _d[12],
                       _d[13], _d[14], _d[15]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vorrq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  int16_t _d[8];
  for (int i = 0; i < 8; i++) {
    _d[i] = _a[i] | _b[i];
  }

  int16x8_t a = vld1q_s16(_a);
  int16x8_t b = vld1q_s16(_b);
  int16x8_t c = vorrq_s16(a, b);
  return validate_int16(c, _d[0], _d[1], _d[2], _d[3], _d[4], _d[5], _d[6], _d[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vorrq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  int32_t _d[4];
  for (int i = 0; i < 4; i++) {
    _d[i] = _a[i] | _b[i];
  }

  int32x4_t a = vld1q_s32(_a);
  int32x4_t b = vld1q_s32(_b);
  int32x4_t c = vorrq_s32(a, b);
  return validate_int32(c, _d[0], _d[1], _d[2], _d[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vorrq_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (int64_t *)impl.test_cases_int_pointer1;
  const int64_t *_b = (int64_t *)impl.test_cases_int_pointer2;
  int64_t _d[2];
  for (int i = 0; i < 2; i++) {
    _d[i] = _a[i] | _b[i];
  }

  int64x2_t a = vld1q_s64(_a);
  int64x2_t b = vld1q_s64(_b);
  int64x2_t c = vorrq_s64(a, b);
  return validate_int64(c, _d[0], _d[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vorrq_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (uint8_t *)impl.test_cases_int_pointer2;
  uint8_t _d[16];
  for (int i = 0; i < 16; i++) {
    _d[i] = _a[i] | _b[i];
  }

  uint8x16_t a = vld1q_u8(_a);
  uint8x16_t b = vld1q_u8(_b);
  uint8x16_t c = vorrq_u8(a, b);
  return validate_uint8(c, _d[0], _d[1], _d[2], _d[3], _d[4], _d[5], _d[6], _d[7], _d[8], _d[9], _d[10], _d[11], _d[12],
                        _d[13], _d[14], _d[15]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vorrq_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (uint16_t *)impl.test_cases_int_pointer2;
  uint16_t _d[8];
  for (int i = 0; i < 8; i++) {
    _d[i] = _a[i] | _b[i];
  }

  uint16x8_t a = vld1q_u16(_a);
  uint16x8_t b = vld1q_u16(_b);
  uint16x8_t c = vorrq_u16(a, b);
  return validate_uint16(c, _d[0], _d[1], _d[2], _d[3], _d[4], _d[5], _d[6], _d[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vorrq_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (uint32_t *)impl.test_cases_int_pointer2;
  uint32_t _d[4];
  for (int i = 0; i < 4; i++) {
    _d[i] = _a[i] | _b[i];
  }

  uint32x4_t a = vld1q_u32(_a);
  uint32x4_t b = vld1q_u32(_b);
  uint32x4_t c = vorrq_u32(a, b);
  return validate_uint32(c, _d[0], _d[1], _d[2], _d[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vorrq_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (uint64_t *)impl.test_cases_int_pointer1;
  const uint64_t *_b = (uint64_t *)impl.test_cases_int_pointer2;
  uint64_t _d[2];
  for (int i = 0; i < 2; i++) {
    _d[i] = _a[i] | _b[i];
  }

  uint64x2_t a = vld1q_u64(_a);
  uint64x2_t b = vld1q_u64(_b);
  uint64x2_t c = vorrq_u64(a, b);
  return validate_uint64(c, _d[0], _d[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_veor_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (int8_t *)impl.test_cases_int_pointer2;
  int8_t _d[8];
  for (int i = 0; i < 8; i++) {
    _d[i] = _a[i] ^ _b[i];
  }

  int8x8_t a = vld1_s8(_a);
  int8x8_t b = vld1_s8(_b);
  int8x8_t c = veor_s8(a, b);
  return validate_int8(c, _d[0], _d[1], _d[2], _d[3], _d[4], _d[5], _d[6], _d[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_veor_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  int16_t _d[4];
  for (int i = 0; i < 4; i++) {
    _d[i] = _a[i] ^ _b[i];
  }

  int16x4_t a = vld1_s16(_a);
  int16x4_t b = vld1_s16(_b);
  int16x4_t c = veor_s16(a, b);
  return validate_int16(c, _d[0], _d[1], _d[2], _d[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_veor_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  int32_t _d[2];
  for (int i = 0; i < 2; i++) {
    _d[i] = _a[i] ^ _b[i];
  }

  int32x2_t a = vld1_s32(_a);
  int32x2_t b = vld1_s32(_b);
  int32x2_t c = veor_s32(a, b);
  return validate_int32(c, _d[0], _d[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_veor_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (uint8_t *)impl.test_cases_int_pointer2;
  uint8_t _d[8];
  for (int i = 0; i < 8; i++) {
    _d[i] = _a[i] ^ _b[i];
  }

  uint8x8_t a = vld1_u8(_a);
  uint8x8_t b = vld1_u8(_b);
  uint8x8_t c = veor_u8(a, b);
  return validate_uint8(c, _d[0], _d[1], _d[2], _d[3], _d[4], _d[5], _d[6], _d[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_veor_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (uint16_t *)impl.test_cases_int_pointer2;
  uint16_t _d[4];
  for (int i = 0; i < 4; i++) {
    _d[i] = _a[i] ^ _b[i];
  }

  uint16x4_t a = vld1_u16(_a);
  uint16x4_t b = vld1_u16(_b);
  uint16x4_t c = veor_u16(a, b);
  return validate_uint16(c, _d[0], _d[1], _d[2], _d[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_veor_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (uint32_t *)impl.test_cases_int_pointer2;
  uint32_t _d[2];
  for (int i = 0; i < 2; i++) {
    _d[i] = _a[i] ^ _b[i];
  }

  uint32x2_t a = vld1_u32(_a);
  uint32x2_t b = vld1_u32(_b);
  uint32x2_t c = veor_u32(a, b);
  return validate_uint32(c, _d[0], _d[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_veor_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (int64_t *)impl.test_cases_int_pointer1;
  const int64_t *_b = (int64_t *)impl.test_cases_int_pointer2;
  int64_t _d[1];
  for (int i = 0; i < 1; i++) {
    _d[i] = _a[i] ^ _b[i];
  }

  int64x1_t a = vld1_s64(_a);
  int64x1_t b = vld1_s64(_b);
  int64x1_t c = veor_s64(a, b);
  return validate_int64(c, _d[0]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_veor_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (uint64_t *)impl.test_cases_int_pointer1;
  const uint64_t *_b = (uint64_t *)impl.test_cases_int_pointer2;
  uint64_t _d[1];
  for (int i = 0; i < 1; i++) {
    _d[i] = _a[i] ^ _b[i];
  }

  uint64x1_t a = vld1_u64(_a);
  uint64x1_t b = vld1_u64(_b);
  uint64x1_t c = veor_u64(a, b);
  return validate_uint64(c, _d[0]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_veorq_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (int8_t *)impl.test_cases_int_pointer2;
  int8_t _d[16];
  for (int i = 0; i < 16; i++) {
    _d[i] = _a[i] ^ _b[i];
  }

  int8x16_t a = vld1q_s8(_a);
  int8x16_t b = vld1q_s8(_b);
  int8x16_t c = veorq_s8(a, b);
  return validate_int8(c, _d[0], _d[1], _d[2], _d[3], _d[4], _d[5], _d[6], _d[7], _d[8], _d[9], _d[10], _d[11], _d[12],
                       _d[13], _d[14], _d[15]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_veorq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  int16_t _d[8];
  for (int i = 0; i < 8; i++) {
    _d[i] = _a[i] ^ _b[i];
  }

  int16x8_t a = vld1q_s16(_a);
  int16x8_t b = vld1q_s16(_b);
  int16x8_t c = veorq_s16(a, b);
  return validate_int16(c, _d[0], _d[1], _d[2], _d[3], _d[4], _d[5], _d[6], _d[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_veorq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  int32_t _d[4];
  for (int i = 0; i < 4; i++) {
    _d[i] = _a[i] ^ _b[i];
  }

  int32x4_t a = vld1q_s32(_a);
  int32x4_t b = vld1q_s32(_b);
  int32x4_t c = veorq_s32(a, b);
  return validate_int32(c, _d[0], _d[1], _d[2], _d[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_veorq_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (int64_t *)impl.test_cases_int_pointer1;
  const int64_t *_b = (int64_t *)impl.test_cases_int_pointer2;
  int64_t _d[2];
  for (int i = 0; i < 2; i++) {
    _d[i] = _a[i] ^ _b[i];
  }

  int64x2_t a = vld1q_s64(_a);
  int64x2_t b = vld1q_s64(_b);
  int64x2_t c = veorq_s64(a, b);
  return validate_int64(c, _d[0], _d[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_veorq_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (uint8_t *)impl.test_cases_int_pointer2;
  uint8_t _d[16];
  for (int i = 0; i < 16; i++) {
    _d[i] = _a[i] ^ _b[i];
  }

  uint8x16_t a = vld1q_u8(_a);
  uint8x16_t b = vld1q_u8(_b);
  uint8x16_t c = veorq_u8(a, b);
  return validate_uint8(c, _d[0], _d[1], _d[2], _d[3], _d[4], _d[5], _d[6], _d[7], _d[8], _d[9], _d[10], _d[11], _d[12],
                        _d[13], _d[14], _d[15]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_veorq_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (uint16_t *)impl.test_cases_int_pointer2;
  uint16_t _d[8];
  for (int i = 0; i < 8; i++) {
    _d[i] = _a[i] ^ _b[i];
  }

  uint16x8_t a = vld1q_u16(_a);
  uint16x8_t b = vld1q_u16(_b);
  uint16x8_t c = veorq_u16(a, b);
  return validate_uint16(c, _d[0], _d[1], _d[2], _d[3], _d[4], _d[5], _d[6], _d[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_veorq_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (uint32_t *)impl.test_cases_int_pointer2;
  uint32_t _d[4];
  for (int i = 0; i < 4; i++) {
    _d[i] = _a[i] ^ _b[i];
  }

  uint32x4_t a = vld1q_u32(_a);
  uint32x4_t b = vld1q_u32(_b);
  uint32x4_t c = veorq_u32(a, b);
  return validate_uint32(c, _d[0], _d[1], _d[2], _d[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_veorq_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (uint64_t *)impl.test_cases_int_pointer1;
  const uint64_t *_b = (uint64_t *)impl.test_cases_int_pointer2;
  uint64_t _d[2];
  for (int i = 0; i < 2; i++) {
    _d[i] = _a[i] ^ _b[i];
  }

  uint64x2_t a = vld1q_u64(_a);
  uint64x2_t b = vld1q_u64(_b);
  uint64x2_t c = veorq_u64(a, b);
  return validate_uint64(c, _d[0], _d[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vbic_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (int8_t *)impl.test_cases_int_pointer2;
  int8_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = _a[i] & ~_b[i];
  }

  int8x8_t a = vld1_s8(_a);
  int8x8_t b = vld1_s8(_b);
  int8x8_t c = vbic_s8(a, b);
  return validate_int8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vbic_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  int16_t _d[4];
  for (int i = 0; i < 4; i++) {
    _d[i] = _a[i] & ~_b[i];
  }

  int16x4_t a = vld1_s16(_a);
  int16x4_t b = vld1_s16(_b);
  int16x4_t c = vbic_s16(a, b);
  return validate_int16(c, _d[0], _d[1], _d[2], _d[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vbic_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  int32_t _d[2];
  for (int i = 0; i < 2; i++) {
    _d[i] = _a[i] & ~_b[i];
  }

  int32x2_t a = vld1_s32(_a);
  int32x2_t b = vld1_s32(_b);
  int32x2_t c = vbic_s32(a, b);
  return validate_int32(c, _d[0], _d[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vbic_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (uint8_t *)impl.test_cases_int_pointer2;
  uint8_t _d[8];
  for (int i = 0; i < 8; i++) {
    _d[i] = _a[i] & ~_b[i];
  }

  uint8x8_t a = vld1_u8(_a);
  uint8x8_t b = vld1_u8(_b);
  uint8x8_t c = vbic_u8(a, b);
  return validate_uint8(c, _d[0], _d[1], _d[2], _d[3], _d[4], _d[5], _d[6], _d[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vbic_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (uint16_t *)impl.test_cases_int_pointer2;
  uint16_t _d[4];
  for (int i = 0; i < 4; i++) {
    _d[i] = _a[i] & ~_b[i];
  }

  uint16x4_t a = vld1_u16(_a);
  uint16x4_t b = vld1_u16(_b);
  uint16x4_t c = vbic_u16(a, b);
  return validate_uint16(c, _d[0], _d[1], _d[2], _d[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vbic_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (uint32_t *)impl.test_cases_int_pointer2;
  uint32_t _d[2];
  for (int i = 0; i < 2; i++) {
    _d[i] = _a[i] & ~_b[i];
  }

  uint32x2_t a = vld1_u32(_a);
  uint32x2_t b = vld1_u32(_b);
  uint32x2_t c = vbic_u32(a, b);
  return validate_uint32(c, _d[0], _d[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vbic_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (int64_t *)impl.test_cases_int_pointer1;
  const int64_t *_b = (int64_t *)impl.test_cases_int_pointer2;
  int64_t _d[1];
  for (int i = 0; i < 1; i++) {
    _d[i] = _a[i] & ~_b[i];
  }

  int64x1_t a = vld1_s64(_a);
  int64x1_t b = vld1_s64(_b);
  int64x1_t c = vbic_s64(a, b);
  return validate_int64(c, _d[0]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vbic_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (uint64_t *)impl.test_cases_int_pointer1;
  const uint64_t *_b = (uint64_t *)impl.test_cases_int_pointer2;
  uint64_t _d[1];
  for (int i = 0; i < 1; i++) {
    _d[i] = _a[i] & ~_b[i];
  }

  uint64x1_t a = vld1_u64(_a);
  uint64x1_t b = vld1_u64(_b);
  uint64x1_t c = vbic_u64(a, b);
  return validate_uint64(c, _d[0]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vbicq_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (int8_t *)impl.test_cases_int_pointer2;
  int8_t _d[16];
  for (int i = 0; i < 16; i++) {
    _d[i] = _a[i] & ~_b[i];
  }

  int8x16_t a = vld1q_s8(_a);
  int8x16_t b = vld1q_s8(_b);
  int8x16_t c = vbicq_s8(a, b);
  return validate_int8(c, _d[0], _d[1], _d[2], _d[3], _d[4], _d[5], _d[6], _d[7], _d[8], _d[9], _d[10], _d[11], _d[12],
                       _d[13], _d[14], _d[15]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vbicq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  int16_t _d[8];
  for (int i = 0; i < 8; i++) {
    _d[i] = _a[i] & ~_b[i];
  }

  int16x8_t a = vld1q_s16(_a);
  int16x8_t b = vld1q_s16(_b);
  int16x8_t c = vbicq_s16(a, b);
  return validate_int16(c, _d[0], _d[1], _d[2], _d[3], _d[4], _d[5], _d[6], _d[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vbicq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  int32_t _d[4];
  for (int i = 0; i < 4; i++) {
    _d[i] = _a[i] & ~_b[i];
  }

  int32x4_t a = vld1q_s32(_a);
  int32x4_t b = vld1q_s32(_b);
  int32x4_t c = vbicq_s32(a, b);
  return validate_int32(c, _d[0], _d[1], _d[2], _d[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vbicq_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (int64_t *)impl.test_cases_int_pointer1;
  const int64_t *_b = (int64_t *)impl.test_cases_int_pointer2;
  int64_t _d[2];
  for (int i = 0; i < 2; i++) {
    _d[i] = _a[i] & ~_b[i];
  }

  int64x2_t a = vld1q_s64(_a);
  int64x2_t b = vld1q_s64(_b);
  int64x2_t c = vbicq_s64(a, b);
  return validate_int64(c, _d[0], _d[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vbicq_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (uint8_t *)impl.test_cases_int_pointer2;
  uint8_t _d[16];
  for (int i = 0; i < 16; i++) {
    _d[i] = _a[i] & ~_b[i];
  }

  uint8x16_t a = vld1q_u8(_a);
  uint8x16_t b = vld1q_u8(_b);
  uint8x16_t c = vbicq_u8(a, b);
  return validate_uint8(c, _d[0], _d[1], _d[2], _d[3], _d[4], _d[5], _d[6], _d[7], _d[8], _d[9], _d[10], _d[11], _d[12],
                        _d[13], _d[14], _d[15]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vbicq_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (uint16_t *)impl.test_cases_int_pointer2;
  uint16_t _d[8];
  for (int i = 0; i < 8; i++) {
    _d[i] = _a[i] & ~_b[i];
  }

  uint16x8_t a = vld1q_u16(_a);
  uint16x8_t b = vld1q_u16(_b);
  uint16x8_t c = vbicq_u16(a, b);
  return validate_uint16(c, _d[0], _d[1], _d[2], _d[3], _d[4], _d[5], _d[6], _d[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vbicq_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (uint32_t *)impl.test_cases_int_pointer2;
  uint32_t _d[4];
  for (int i = 0; i < 4; i++) {
    _d[i] = _a[i] & ~_b[i];
  }

  uint32x4_t a = vld1q_u32(_a);
  uint32x4_t b = vld1q_u32(_b);
  uint32x4_t c = vbicq_u32(a, b);
  return validate_uint32(c, _d[0], _d[1], _d[2], _d[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vbicq_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (uint64_t *)impl.test_cases_int_pointer1;
  const uint64_t *_b = (uint64_t *)impl.test_cases_int_pointer2;
  uint64_t _d[2];
  for (int i = 0; i < 2; i++) {
    _d[i] = _a[i] & ~_b[i];
  }

  uint64x2_t a = vld1q_u64(_a);
  uint64x2_t b = vld1q_u64(_b);
  uint64x2_t c = vbicq_u64(a, b);
  return validate_uint64(c, _d[0], _d[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vorn_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (int8_t *)impl.test_cases_int_pointer2;
  int8_t _c[8];
  for (int i = 0; i < 8; i++) {
    _c[i] = _a[i] | ~_b[i];
  }

  int8x8_t a = vld1_s8(_a);
  int8x8_t b = vld1_s8(_b);
  int8x8_t c = vorn_s8(a, b);
  return validate_int8(c, _c[0], _c[1], _c[2], _c[3], _c[4], _c[5], _c[6], _c[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vorn_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  int16_t _d[4];
  for (int i = 0; i < 4; i++) {
    _d[i] = _a[i] | ~_b[i];
  }

  int16x4_t a = vld1_s16(_a);
  int16x4_t b = vld1_s16(_b);
  int16x4_t c = vorn_s16(a, b);
  return validate_int16(c, _d[0], _d[1], _d[2], _d[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vorn_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  int32_t _d[2];
  for (int i = 0; i < 2; i++) {
    _d[i] = _a[i] | ~_b[i];
  }

  int32x2_t a = vld1_s32(_a);
  int32x2_t b = vld1_s32(_b);
  int32x2_t c = vorn_s32(a, b);
  return validate_int32(c, _d[0], _d[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vorn_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (uint8_t *)impl.test_cases_int_pointer2;
  uint8_t _d[8];
  for (int i = 0; i < 8; i++) {
    _d[i] = _a[i] | ~_b[i];
  }

  uint8x8_t a = vld1_u8(_a);
  uint8x8_t b = vld1_u8(_b);
  uint8x8_t c = vorn_u8(a, b);
  return validate_uint8(c, _d[0], _d[1], _d[2], _d[3], _d[4], _d[5], _d[6], _d[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vorn_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (uint16_t *)impl.test_cases_int_pointer2;
  uint16_t _d[4];
  for (int i = 0; i < 4; i++) {
    _d[i] = _a[i] | ~_b[i];
  }

  uint16x4_t a = vld1_u16(_a);
  uint16x4_t b = vld1_u16(_b);
  uint16x4_t c = vorn_u16(a, b);
  return validate_uint16(c, _d[0], _d[1], _d[2], _d[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vorn_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (uint32_t *)impl.test_cases_int_pointer2;
  uint32_t _d[2];
  for (int i = 0; i < 2; i++) {
    _d[i] = _a[i] | ~_b[i];
  }

  uint32x2_t a = vld1_u32(_a);
  uint32x2_t b = vld1_u32(_b);
  uint32x2_t c = vorn_u32(a, b);
  return validate_uint32(c, _d[0], _d[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vorn_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (int64_t *)impl.test_cases_int_pointer1;
  const int64_t *_b = (int64_t *)impl.test_cases_int_pointer2;
  int64_t _d[1];
  for (int i = 0; i < 1; i++) {
    _d[i] = _a[i] | ~_b[i];
  }

  int64x1_t a = vld1_s64(_a);
  int64x1_t b = vld1_s64(_b);
  int64x1_t c = vorn_s64(a, b);
  return validate_int64(c, _d[0]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vorn_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (uint64_t *)impl.test_cases_int_pointer1;
  const uint64_t *_b = (uint64_t *)impl.test_cases_int_pointer2;
  uint64_t _d[1];
  for (int i = 0; i < 1; i++) {
    _d[i] = _a[i] | ~_b[i];
  }

  uint64x1_t a = vld1_u64(_a);
  uint64x1_t b = vld1_u64(_b);
  uint64x1_t c = vorn_u64(a, b);
  return validate_uint64(c, _d[0]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vornq_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  const int8_t *_b = (int8_t *)impl.test_cases_int_pointer2;
  int8_t _d[16];
  for (int i = 0; i < 16; i++) {
    _d[i] = _a[i] | ~_b[i];
  }

  int8x16_t a = vld1q_s8(_a);
  int8x16_t b = vld1q_s8(_b);
  int8x16_t c = vornq_s8(a, b);
  return validate_int8(c, _d[0], _d[1], _d[2], _d[3], _d[4], _d[5], _d[6], _d[7], _d[8], _d[9], _d[10], _d[11], _d[12],
                       _d[13], _d[14], _d[15]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vornq_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int16_t *_a = (int16_t *)impl.test_cases_int_pointer1;
  const int16_t *_b = (int16_t *)impl.test_cases_int_pointer2;
  int16_t _d[8];
  for (int i = 0; i < 8; i++) {
    _d[i] = _a[i] | ~_b[i];
  }

  int16x8_t a = vld1q_s16(_a);
  int16x8_t b = vld1q_s16(_b);
  int16x8_t c = vornq_s16(a, b);
  return validate_int16(c, _d[0], _d[1], _d[2], _d[3], _d[4], _d[5], _d[6], _d[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vornq_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  const int32_t *_b = (int32_t *)impl.test_cases_int_pointer2;
  int32_t _d[4];
  for (int i = 0; i < 4; i++) {
    _d[i] = _a[i] | ~_b[i];
  }

  int32x4_t a = vld1q_s32(_a);
  int32x4_t b = vld1q_s32(_b);
  int32x4_t c = vornq_s32(a, b);
  return validate_int32(c, _d[0], _d[1], _d[2], _d[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vornq_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (int64_t *)impl.test_cases_int_pointer1;
  const int64_t *_b = (int64_t *)impl.test_cases_int_pointer2;
  int64_t _d[2];
  for (int i = 0; i < 2; i++) {
    _d[i] = _a[i] | ~_b[i];
  }

  int64x2_t a = vld1q_s64(_a);
  int64x2_t b = vld1q_s64(_b);
  int64x2_t c = vornq_s64(a, b);
  return validate_int64(c, _d[0], _d[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vornq_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint8_t *_a = (uint8_t *)impl.test_cases_int_pointer1;
  const uint8_t *_b = (uint8_t *)impl.test_cases_int_pointer2;
  uint8_t _d[16];
  for (int i = 0; i < 16; i++) {
    _d[i] = _a[i] | ~_b[i];
  }

  uint8x16_t a = vld1q_u8(_a);
  uint8x16_t b = vld1q_u8(_b);
  uint8x16_t c = vornq_u8(a, b);
  return validate_uint8(c, _d[0], _d[1], _d[2], _d[3], _d[4], _d[5], _d[6], _d[7], _d[8], _d[9], _d[10], _d[11], _d[12],
                        _d[13], _d[14], _d[15]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vornq_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint16_t *_a = (uint16_t *)impl.test_cases_int_pointer1;
  const uint16_t *_b = (uint16_t *)impl.test_cases_int_pointer2;
  uint16_t _d[8];
  for (int i = 0; i < 8; i++) {
    _d[i] = _a[i] | ~_b[i];
  }

  uint16x8_t a = vld1q_u16(_a);
  uint16x8_t b = vld1q_u16(_b);
  uint16x8_t c = vornq_u16(a, b);
  return validate_uint16(c, _d[0], _d[1], _d[2], _d[3], _d[4], _d[5], _d[6], _d[7]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vornq_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint32_t *_a = (uint32_t *)impl.test_cases_int_pointer1;
  const uint32_t *_b = (uint32_t *)impl.test_cases_int_pointer2;
  uint32_t _d[4];
  for (int i = 0; i < 4; i++) {
    _d[i] = _a[i] | ~_b[i];
  }

  uint32x4_t a = vld1q_u32(_a);
  uint32x4_t b = vld1q_u32(_b);
  uint32x4_t c = vornq_u32(a, b);
  return validate_uint32(c, _d[0], _d[1], _d[2], _d[3]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vornq_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const uint64_t *_a = (uint64_t *)impl.test_cases_int_pointer1;
  const uint64_t *_b = (uint64_t *)impl.test_cases_int_pointer2;
  uint64_t _d[2];
  for (int i = 0; i < 2; i++) {
    _d[i] = _a[i] | ~_b[i];
  }

  uint64x2_t a = vld1q_u64(_a);
  uint64x2_t b = vld1q_u64(_b);
  uint64x2_t c = vornq_u64(a, b);
  return validate_uint64(c, _d[0], _d[1]);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vreinterpret_f32_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int64_t *_a = (int64_t *)impl.test_cases_int_pointer1;
  int64x1_t a = vld1_s64(_a);
  float32x2_t c = vreinterpret_f32_s64(a);

  return validate_64_bits(c, a);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vreinterpret_f32_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_f32_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_f32_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_f32_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_f32_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_f32_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_f32_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_s64_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_f64_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_p64_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_p64_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_f16_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_s64_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_f64_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_p64_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_f16_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_s64_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int8_t *_a = (int8_t *)impl.test_cases_int_pointer1;
  int8x8_t a = vld1_s8(_a);
  int64x1_t c = vreinterpret_s64_s8(a);

  return validate_64_bits(c, a);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vreinterpret_f64_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_p64_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_f16_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_s64_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_f64_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_p64_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_f16_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_s64_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_f64_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_p64_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_f16_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_s64_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_f64_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_p64_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_f16_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_s64_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_f64_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_p64_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_f16_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_s64_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_f64_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_p64_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_f16_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_s8_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_s16_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_s32_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_f32_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_u8_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_u16_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_u32_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_p16_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_u64_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_s64_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_f64_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_p64_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_f16_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_s8_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_s16_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_s32_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_f32_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_u8_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_u16_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_u32_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_p8_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_u64_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_s64_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_f64_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_p64_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_f16_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_u64_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_u64_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_f64_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_u64_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_f16_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_s8_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_s16_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_s32_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_f32_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_u8_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_u16_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_u32_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_p8_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_p16_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_u64_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_s64_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_f64_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_p64_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_u64_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_u64_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_u64_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_u64_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_u64_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_u64_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_s8_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_s8_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_s8_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_s8_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_s8_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) {
#ifdef ENABLE_TEST_ALL
  const int32_t *_a = (int32_t *)impl.test_cases_int_pointer1;
  int32x2_t a = vld1_s32(_a);
  int8x8_t c = vreinterpret_s8_s32(a);

  return validate_64_bits(c, a);
#else
  return TEST_UNIMPL;
#endif  // ENABLE_TEST_ALL
}

result_t test_vreinterpret_s8_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_s8_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_s8_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_s16_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_s16_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_s16_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_s16_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_s16_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_s16_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_s16_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_s16_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_s32_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_s32_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_s32_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_s32_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_s32_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_s32_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_s32_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_s32_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_u8_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_u8_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_u8_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_u8_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_u8_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_u8_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_u8_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_u8_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_u16_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_u16_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_u16_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_u16_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_u16_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_u16_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_u16_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_u16_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_p8_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_p16_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_u32_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_p8_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_p16_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_u32_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_p8_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_p16_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_u32_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_p8_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_p16_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_u32_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_p8_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_p16_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_u32_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_p8_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_p16_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_u32_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_p8_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_p16_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_u32_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_p8_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_p16_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_u32_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_p8_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_p16_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_f32_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_f32_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_f32_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_f32_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_f32_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_f32_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_f32_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_f32_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_s64_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_f64_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_p64_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_p128_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_p64_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_p128_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_f16_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_s64_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_f64_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_f64_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_p64_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_p128_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_p64_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_p128_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_f16_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_s64_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_f64_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_p64_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_p128_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_f16_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_s64_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_f64_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_p64_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_p128_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_f16_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_s64_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_f64_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_p64_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_p128_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_f16_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_s64_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_f64_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_p64_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_p128_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_f16_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_s64_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_f64_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_p64_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_p128_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_f16_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_s64_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_f64_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_p64_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_p128_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_f16_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_s8_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_s16_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_s32_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_f32_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_u8_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_u16_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_u32_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_p16_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_u64_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_s64_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_f64_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_p64_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_p128_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_f16_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_s8_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_s16_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_s32_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_f32_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_u8_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_u16_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_u32_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_p8_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_u64_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_s64_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_f64_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_p64_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_p128_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_f16_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_u64_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_u64_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_u64_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_f16_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_s8_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_s16_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_s32_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_f32_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_u8_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_u16_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_u32_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_p8_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_p16_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_u64_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_s64_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_f64_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_p64_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_p128_f16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_s8_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_s16_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_s32_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_u8_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_u16_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_u32_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_p8_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_p16_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_u64_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_s64_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_f16_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_f32_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_s8_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_s16_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_s32_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_u8_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_u16_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_u32_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_p8_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_p16_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_u64_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_s64_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_f16_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_f32_f64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_s8_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_s16_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_s32_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_u8_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_u16_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_u32_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_p8_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_p16_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_s64_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_f64_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpret_f16_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_s8_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_s16_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_s32_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_u8_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_u16_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_u32_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_p8_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_p16_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_s64_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_f64_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_f16_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_s8_p128(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_s16_p128(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_s32_p128(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_u8_p128(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_u16_p128(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_u32_p128(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_p8_p128(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_p16_p128(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_u64_p128(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_s64_p128(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_f64_p128(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_f16_p128(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vldrq_p128(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vstrq_p128(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_u64_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_u64_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_u64_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_u64_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_u64_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_u64_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_s8_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_s8_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_s8_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_s8_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_s8_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_s8_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_s8_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_s8_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_s16_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_s16_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_s16_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_s16_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_s16_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_s16_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_s16_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_s16_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_s32_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_s32_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_s32_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_s32_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_s32_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_s32_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_s32_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_s32_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_u8_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_u8_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_u8_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_u8_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_u8_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_u8_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_u8_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_u8_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_u16_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_u16_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_u16_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_u16_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_u16_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_u16_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_u16_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_u16_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_p8_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_p16_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_u32_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_p8_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_p16_f32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_u32_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_p8_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_p16_s64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_u32_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_p8_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_p16_u64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_u32_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_p8_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_p16_s8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_u32_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_p8_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_p16_s16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_u32_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_p8_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_p16_s32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_u32_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_p8_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_p16_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_u32_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_p8_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vreinterpretq_p16_u16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vaeseq_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vaesdq_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vaesmcq_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vaesimcq_u8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vsha1h_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vsha1cq_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vsha1pq_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vsha1mq_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vsha1su0q_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vsha1su1q_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vsha256hq_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vsha256h2q_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vsha256su0q_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vsha256su1q_u32(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

// Dummy function to match the case label in run_single_test.
result_t test_vmull_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vmull_high_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vadd_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vadd_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vadd_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vaddq_p8(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vaddq_p16(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vaddq_p64(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_vaddq_p128(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test___crc32b(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test___crc32h(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test___crc32w(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test___crc32d(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test___crc32cb(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test___crc32ch(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test___crc32cw(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test___crc32cd(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_UNIMPL; }

result_t test_last(const NEON2RVV_TEST_IMPL &impl, uint32_t iter) { return TEST_SUCCESS; }

result_t NEON2RVV_TEST_IMPL::run_single_test(INSTRUCTION_TEST test, uint32_t iter) {
  result_t ret = TEST_SUCCESS;

  switch (test) {
#define _(x)                     \
  case it_##x:                   \
    ret = test_##x(*this, iter); \
    break;
    INTRIN_LIST
#undef _
  }

  return ret;
}

}  // namespace NEON2RVV
